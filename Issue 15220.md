# Issue 15220: sage-cleaner does not quit

Issue created by migration from https://trac.sagemath.org/ticket/15457

Original creator: vbraun

Original creation time: 2013-11-26 22:52:06

If there are files in `DOT_SAGE/temp/HOSTNAME` then the sage cleaner process never stops. Note that Sage temp files must(!) be under `DOT_SAGE/temp/HOSTNAME/<pid>`.




---

Comment by vbraun created at 2013-11-27 00:15:14

Also, clean up the cleaner sources a bit. And move the pid file to `SAGE_TMP_ROOT/cleaner.pid`. And log the output to `SAGE_TMP_ROOT/cleaner.log`.


---

Comment by vbraun created at 2013-11-27 01:29:55

New commits:


---

Comment by vbraun created at 2013-11-27 01:29:55

Changing status from new to needs_review.


---

Comment by jdemeyer created at 2013-12-10 08:52:58

Who or what is writing to `DOT_SAGE/temp/HOSTNAME`? I haven't seen this problem appear before.


---

Comment by vbraun created at 2013-12-10 11:05:28

The files were fairly old afair. Of course it is hard to say where they came from, could even have been a ticket that was not merged that way. I guess you just haven't noticed since you didn't try to delete DOT_SAGE (which will fail on NFS if files are still open). In any case, the sage cleaner shoudn't break just because there is a temp file in the wrong location. By outright deleting the illegal file we hopefully hurt whoever put it there so they notice the error in their ways.

For the record, I configured the new buildbot so that full builds start with a fresh DOT_SAGE and incremental builds keep using the previous one.


---

Comment by jdemeyer created at 2013-12-10 11:09:45

Replying to [comment:6 vbraun]:
> The files were fairly old afair. Of course it is hard to say where they came from, could even have been a ticket that was not merged that way.
Thanks, that's a good explanation.


---

Comment by vbraun created at 2013-12-23 13:01:30

Can you review this ticket?


---

Comment by jdemeyer created at 2014-01-01 14:32:46

What's the motivation for always re-opening the file in `LogFile`?


---

Comment by jdemeyer created at 2014-01-01 14:36:23

There is also this: [http://docs.python.org/2/library/logging.html](http://docs.python.org/2/library/logging.html), see also [http://docs.python.org/2/howto/logging.html](http://docs.python.org/2/howto/logging.html)


---

Comment by jdemeyer created at 2014-01-01 14:39:47

And why not replace

```
    if not os.path.isdir(SAGE_TMP_ROOT):
        mkdir_p(SAGE_TMP_ROOT)
```

by

```
    mkdir_p(SAGE_TMP_ROOT)
```

(or at least, move the `isdir` check inside `mkdir_p`)


---

Comment by jdemeyer created at 2014-01-01 14:51:35

Working on review patch, hang on...


---

Comment by jdemeyer created at 2014-01-01 16:09:48

And what was wrong with

```
open(pidfile,'w').write(str(os.getpid()))
```

???


---

Comment by jdemeyer created at 2014-01-01 17:32:21

Additional commit needs review.
----
New commits:


---

Comment by vbraun created at 2014-01-02 04:24:48

IMHO it is bad to keep log files open for extended amounts of time. This is just going to cause problems (depending on the file system) if multiple processes try do do that. And before you say that there is only one cleaner process, the whole point of the logging is to have a log to prove that if things go south again. The Python logging module does not support multiple processes logging to the same file, for the record. But at least it flushes the output.

The `open(pidfile,'w').write(str(os.getpid()))` construct works but is IMHO bad style. For starters, it does an implicit close (explicit is better than implicit). The point in the program flow where the close occurs is also not specified (CPython implementation detail closes it immediately, I think, but the specs don't specify). And until the close there is (probably, again implementation/fs detail) nothing written to disk.


---

Comment by jdemeyer created at 2014-01-02 08:11:30

Replying to [comment:17 vbraun]:
> IMHO it is bad to keep log files open for extended amounts of time. This is just going to cause problems (depending on the file system) if multiple processes try do do that. And before you say that there is only one cleaner process, the whole point of the logging is to have a log to prove that if things go south again. The Python logging module does not support multiple processes logging to the same file, for the record. But at least it flushes the output.

Having multiple processes append to the same file is indeed subject to race conditions on NFS (but almost everything with NFS has race conditions). However, this is independent of how many processes have the file open, I see no evidence that simply having a file open makes things worse.


---

Comment by git created at 2014-01-02 08:11:39

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by vbraun created at 2014-01-03 06:43:50

NFS isn't even close to being the worst case here. For example on the PanFS network file system opening a file also locks it, so all other processes get EACCESS. Its not about a race, its that other processes can't even log that something is wrong.


---

Comment by jdemeyer created at 2014-01-09 17:02:26

Should we really jump through hoops to support broken file systems?


---

Comment by vbraun created at 2014-01-12 03:14:08

Afaik there is nothing in the spec that disallows automatic mandatory file locking. Its not done in the usual local filesystems, but that doesn't mean that Panasas is broken. But even if it goes agains POSIX then its still a widely-used filesystem in the HPC world, so we would only hurt ourselves if we were to intentionally break Sage on it.


---

Comment by vbraun created at 2014-02-14 19:44:59

Resolution: fixed
