# Issue 29078: Make LLL reduction for integer matrix kernel optional

archive/issues_029078.json:
```json
{
    "body": "Keywords: integer matrices, kernel, speed\n\nIn the `_right_kernel_matrix` method of `matrix_integer_dense` there is a choice of 3 algorithms. With choice `algorithm='pari'` it calls the `matkerint` routine of PARI. According to the documentation this \"gives an LLL-reduced \u2124-basis\".\nThe `matker(x, flag = 1)` routine omits the LLL-reduction, and for large matrices is much faster. It seems that the `padic` and `flint` algorithms also compute this LLL-reduced form.\n\nIn some applications this LLL reduction is not necessary. \n\nI recommend documenting this fact and making LLL-reduction optional (but perhaps default).\n\nIn my particular application all three algorithms about equally fast, but directly calling\n    `M.__pari__().matker(flag=1).mattranspose().sage()`\ngives a speedup of several orders of magnitude for large matrices. (In my case sparse matrices of shape around 2000x1000.)\n\n\nIssue created by migration from https://trac.sagemath.org/ticket/29315\n\n",
    "created_at": "2020-03-11T15:35:28Z",
    "labels": [
        "linear algebra",
        "major",
        "enhancement"
    ],
    "milestone": "https://github.com/sagemath/sagetest/milestones/sage-9.8",
    "title": "Make LLL reduction for integer matrix kernel optional",
    "type": "issue",
    "url": "https://github.com/sagemath/sagetest/issues/29078",
    "user": "@RikVoorhaar"
}
```
Keywords: integer matrices, kernel, speed

In the `_right_kernel_matrix` method of `matrix_integer_dense` there is a choice of 3 algorithms. With choice `algorithm='pari'` it calls the `matkerint` routine of PARI. According to the documentation this "gives an LLL-reduced â„¤-basis".
The `matker(x, flag = 1)` routine omits the LLL-reduction, and for large matrices is much faster. It seems that the `padic` and `flint` algorithms also compute this LLL-reduced form.

In some applications this LLL reduction is not necessary. 

I recommend documenting this fact and making LLL-reduction optional (but perhaps default).

In my particular application all three algorithms about equally fast, but directly calling
    `M.__pari__().matker(flag=1).mattranspose().sage()`
gives a speedup of several orders of magnitude for large matrices. (In my case sparse matrices of shape around 2000x1000.)


Issue created by migration from https://trac.sagemath.org/ticket/29315





---

archive/issue_comments_411602.json:
```json
{
    "body": "Batch modifying tickets that will likely not be ready for 9.1, based on a review of the ticket title, branch/review status, and last modification date.",
    "created_at": "2020-04-14T19:41:51Z",
    "issue": "https://github.com/sagemath/sagetest/issues/29078",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/29078#issuecomment-411602",
    "user": "mkoeppe"
}
```

Batch modifying tickets that will likely not be ready for 9.1, based on a review of the ticket title, branch/review status, and last modification date.



---

archive/issue_comments_411603.json:
```json
{
    "body": "Setting new milestone based on a cursory review of ticket status, priority, and last modification date.",
    "created_at": "2021-02-13T20:51:01Z",
    "issue": "https://github.com/sagemath/sagetest/issues/29078",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/29078#issuecomment-411603",
    "user": "mkoeppe"
}
```

Setting new milestone based on a cursory review of ticket status, priority, and last modification date.
