# Issue 17429: False positive for memory leak check on OSX

Issue created by migration from Trac.

Original creator: vbraun

Original creation time: 2015-01-24 19:05:35




---

Comment by vbraun created at 2015-01-24 19:07:56

Changing type from PLEASE CHANGE to defect.


---

Comment by vbraun created at 2015-01-24 19:07:56

Changing component from PLEASE CHANGE to algebra.


---

Comment by vbraun created at 2015-01-24 19:21:30

Changing status from new to needs_review.


---

Comment by vbraun created at 2015-01-24 19:21:30

New commits:


---

Comment by jdemeyer created at 2015-01-24 22:07:03

Changing status from needs_review to needs_info.


---

Comment by jdemeyer created at 2015-01-24 22:07:03

How do we know it's a _false_ positive?


---

Comment by jhpalmieri created at 2015-01-24 23:13:11

For what it's worth, I've run tests about 100 times on an OS X machine and haven't gotten any failures.


---

Comment by vbraun created at 2015-01-24 23:55:41

An actual memory leak leaks memory every time...


---

Comment by jdemeyer created at 2015-01-25 09:04:30

Replying to [comment:6 vbraun]:
> An actual memory leak leaks memory every time...
Depending on the implementation, that doesn't need to be the case. `malloc` usually pre-allocates more memory than strictly needed. Your test would pass even if there was an actual memory leak.

I think a better test would be that the amount of memory needed to execute `leak(10000)` n times is bounded by a constant which does not depend on n.
Something like (pseudocode):

```
L = []
for i in range(10):
    leak(10000)
    L.append(memory_usage())
m = max(L)  # taking the max because the memory usage might increase and decrease
for i in range(10):
    leak(10000)
    assert memory_usage() <= m
```



---

Comment by vbraun created at 2015-01-25 13:12:07

And you need to run at least as many iterations such that a leak would have to fill up the current process space. Which is IMHO way too slow for a doctest. A good enough heuristic is to hope that at least one of the tested OSes has a malloc pool granularity that is small enough (less than 16 * 10000)


---

Comment by vbraun created at 2015-01-29 08:44:08

Changing status from needs_info to needs_review.


---

Comment by jdemeyer created at 2015-01-29 13:26:23

`@`vbraun: what is the result of

```
for i in range(100):
    print leak(10000)
```



---

Comment by jdemeyer created at 2015-01-29 13:26:23

Changing status from needs_review to needs_info.


---

Comment by vbraun created at 2015-01-29 13:41:51

The result is that it takes way longer than what a long doctest ought to use:

```
sage: %time [leak(10000) for i in range(100)]
CPU times: user 1min 16s, sys: 327 ms, total: 1min 17s
Wall time: 1min 15s
```

Output on OSX is:

```
[155189248, 0, 0, 0, 83886080, 0, 0, 0, 79691776, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
```



---

Comment by vbraun created at 2015-01-29 13:41:51

Changing status from needs_info to needs_review.


---

Comment by jdemeyer created at 2015-01-29 15:09:48

That output suggests that the test could better be written as

```
sage: for i in range(10):
....:    leak(10000)
sage: leak(10000)
0
```



---

Comment by vbraun created at 2015-01-29 15:11:24

Tried that, didn't work reliably.


---

Comment by jdemeyer created at 2015-01-29 15:24:02

How about checking for 5 _consequtive_ zero values? What I want to avoid is that the doctest would accept `[1000000, 0, 1000000, 0, 1000000, 0, 1000000,...]` which would probably still be a memory leak.


---

Comment by vbraun created at 2015-01-29 15:28:21

Isn't that just a variant of increasing the count by an order of magnitude? Too slow.


---

Comment by jdemeyer created at 2015-01-29 15:43:50

Replying to [comment:15 vbraun]:
> Isn't that just a variant of increasing the count by an order of magnitude? Too slow.
Doing 10 tests (your commit) is fine, but doing _14 tests_ (5 consequtive zeros in your example `[155189248, 0, 0, 0, 83886080, 0, 0, 0, 79691776, 0, 0, 0, 0, 0]` is an order of magnitude slower?


---

Comment by jdemeyer created at 2015-02-04 10:58:22

Changing status from needs_review to needs_info.


---

Comment by jdemeyer created at 2015-02-04 10:58:59

Please explain why 14 is an order of magnitude more than 10...


---

Comment by vbraun created at 2015-02-04 14:06:56

If you want to change the patch then be my guest, but I had enough of it.


---

Comment by vbraun created at 2015-02-04 14:10:05

Changing priority from major to blocker.


---

Comment by jdemeyer created at 2015-02-05 10:05:31

Changing status from needs_info to needs_review.


---

Comment by jdemeyer created at 2015-02-05 10:05:31

New commits:


---

Comment by jdemeyer created at 2015-02-05 10:05:39

Does this work for you?


---

Comment by vbraun created at 2015-02-05 14:44:44

I'm travelling right now so I can't test it on OSX, but it should fail as it ought to at least once print "Leaked N bytes" with N>0.

Also, the first couple of iterations will always succeed (even if there is a leak) as singular has pre-allocated buckets, and as long as you don't exhaust these no new memory will be allocated. At least in the original leak I did need the `leak(50000)` to fill these up.


---

Comment by git created at 2015-02-05 14:58:04

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by vbraun created at 2015-02-05 15:00:27

Changing status from needs_review to positive_review.


---

Comment by vbraun created at 2015-02-08 15:26:28

Resolution: fixed
