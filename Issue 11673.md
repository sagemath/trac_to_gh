# Issue 11673: Pickle python functions

Issue created by migration from https://trac.sagemath.org/ticket/11845

Original creator: nbruin

Original creation time: 2011-09-25 02:29:43

Assignee: was

Simon King pointed out that, although python function objects are normally not guaranteed to be picklable, the marshal module is happy to serialize code objects (although portability of the result is not guaranteed across versions), see

[sage-devel thread](http://groups.google.com/group/sage-devel/browse_thread/thread/f1a213d1cac0719c)

Since sage pickles are supposed to be highly portable, we should probably not enable the feature by default, but the feature can be extremely useful when, for instance, distributing jobs across multiple worker nodes.

Some work is needed to work properly with closures, so having a debugged and well-maintained interface for pickling python functions is desirable. I have no idea whether it would be appropriate to stuff somewhere in the sage library, so for now this ticket can serve as a repository.

------


---

Comment by nbruin created at 2011-09-25 02:30:40

implementation of a PickleableFunction class (not a patch!)


---

Attachment

Note that there is already some code in the library for this in `sage.misc.fpickle`. It is used at least in ``@`parallel` and pickling of symbolic functions with user defined evaluation, derivation, etc. methods. Now that I read the thread on sage-devel, I realize that we might have problems unpickling these symbolic functions if this pickle format is not compatible between Python versions.


---

Comment by nbruin created at 2011-09-26 01:07:45

Replying to [comment:1 burcin]:
> Note that there is already some code in the library for this in `sage.misc.fpickle`. It is used at least in ``@`parallel` and pickling of symbolic functions with user defined evaluation, derivation, etc. methods.

Are those pickles doctested? In that case, sage's picklejar would already be tainted. Incidentally, if `@`parallel uses this to distribute code & data over workers, then supporting closures is probably a very welcome improvement. Creating a closure for each job is a virtually ideal way of wrapping code&data together for distribution.
