# Issue 17683: Reimplement IntegerLists using MILP

Issue created by migration from Trac.

Original creator: jdemeyer

Original creation time: 2015-03-09 17:52:44

CC:  ncohen aschilling tscrim nthiery




---

Comment by jdemeyer created at 2015-03-09 20:56:34

The Sage MILP solvers cannot enumerate all solutions => closing as invalid.


---

Comment by jdemeyer created at 2015-03-09 20:56:34

Resolution: invalid


---

Comment by jdemeyer created at 2015-03-10 15:41:56

Changing status from closed to new.


---

Comment by jdemeyer created at 2015-03-10 15:41:56

Resolution changed from invalid to 


---

Comment by ncohen created at 2015-03-12 07:16:35

I do not understand what this is... Did you copy/paste the original file? It seems that you copy/pasted the original files and made some modifications to it `O_o`

Nathann
----
New commits:


---

Comment by jdemeyer created at 2015-03-12 10:02:39

Yes, that's what I did. Anyway, this is still very much work in progress...


---

Comment by ncohen created at 2015-03-12 10:03:35

> Yes, that's what I did. Anyway, this is still very much work in progress...

Oh, okay!

Nathann


---

Comment by git created at 2015-03-12 16:41:59

Branch pushed to git repo; I updated commit sha1. This was a forced push. New commits:


---

Comment by git created at 2015-03-13 10:38:04

Branch pushed to git repo; I updated commit sha1. This was a forced push. New commits:


---

Comment by git created at 2015-03-14 14:11:46

Branch pushed to git repo; I updated commit sha1. This was a forced push. New commits:


---

Comment by jdemeyer created at 2015-03-14 14:17:41

This now seems to work reasonably well. Not yet ready, but good enough for example to compare with the existing implementation. That's how I found all the bugs at #17548.

Due to the polyhedra overhead, it is generally (a lot) slower than the existing code.


---

Comment by ncohen created at 2015-03-14 16:40:08

Replying to [comment:12 jdemeyer]:
> This now seems to work reasonably well. Not yet ready, but good enough for example to compare with the existing implementation. That's how I found all the bugs at #17548.
> 
> Due to the polyhedra overhead, it is generally (a lot) slower than the existing code.

Is it worth changing this branch so that it changes the existing code instead of adding a new file ? As you said: let's be correct first, *then* fast.

Nathann


---

Comment by jdemeyer created at 2015-03-14 16:43:59

My code does not yet support all (undocumented!) features of the old `IntegerListsLex`, so we cannot yet replace `IntegerListsLex`.


---

Comment by git created at 2015-03-14 18:24:59

Branch pushed to git repo; I updated commit sha1. This was a forced push. New commits:


---

Comment by git created at 2015-03-14 22:03:17

Branch pushed to git repo; I updated commit sha1. This was a forced push. New commits:


---

Comment by jdemeyer created at 2015-03-14 22:05:21

This now implements `Compositions` using my new `IntegerListsLex` (is the lex ordering really important? I guess not, it's for sure nowhere documented). However, doing the same for `Partitions` leads to all kinds of breakage and I don't understand why.


---

Comment by git created at 2015-03-14 22:11:32

Branch pushed to git repo; I updated commit sha1. This was a forced push. New commits:


---

Comment by git created at 2015-03-14 22:23:21

Branch pushed to git repo; I updated commit sha1. This was a forced push. New commits:


---

Comment by git created at 2015-03-15 11:06:18

Branch pushed to git repo; I updated commit sha1. This was a forced push. New commits:


---

Comment by git created at 2015-03-15 11:19:28

Branch pushed to git repo; I updated commit sha1. This was a forced push. New commits:


---

Comment by jdemeyer created at 2015-03-15 11:22:05

Note that this changes 3 tests (just reordering the output) in `src/sage/tests/book_schilling_zabrocki_kschur_primer.py`


---

Comment by jdemeyer created at 2015-03-15 11:23:30

The code on this ticket is essentially complete, I just need to add more doctests to comply with the "coverage" policy.


---

Comment by git created at 2015-03-15 12:38:47

Branch pushed to git repo; I updated commit sha1. This was a forced push. New commits:


---

Comment by git created at 2015-03-15 15:03:25

Branch pushed to git repo; I updated commit sha1. This was a forced push. New commits:


---

Comment by jdemeyer created at 2015-03-15 15:08:29

Changing status from new to needs_review.


---

Comment by tscrim created at 2015-03-15 15:25:29

Do you have some timings?

Also, both of these are wrong:

```
sage: Compositions(3, max_length=2, inner=[1,1,1]).list()
[]
sage: Compositions(10, outer=[4], inner=[1,1]).list()
[]
```

The first should be `[[2, 1], [1, 2]]` since the `inner` (or `outer`) are not related to the min or max lengths. For the second, the inner composition is extendedby the minimum part, so there are many such compositions, such as `[4,6]`, `[2,8]`, etc.


---

Comment by vdelecroix created at 2015-03-15 15:28:48

Replying to [comment:27 tscrim]:
> Do you have some timings?

Slow is better than wrong, isn't it? ;-)


---

Comment by jdemeyer created at 2015-03-15 15:29:49

Replying to [comment:27 tscrim]:
> Do you have some timings?
My code is much slower.

> Also, both of these are wrong:
> {{{
> sage: Compositions(3, max_length=2, inner=[1,1,1]).list()
> []
> sage: Compositions(10, outer=[4], inner=[1,1]).list()
> []
> }}}
> The first should be `[[2, 1], [1, 2]]`
I don't think so. The `Compositions` code explicitly adds the length of the `inner` argument as minimal length. I didn't change this.


---

Comment by jdemeyer created at 2015-03-15 15:31:09

Changing priority from major to blocker.


---

Comment by jdemeyer created at 2015-03-15 15:31:09

Setting to blocker status since either #17920 or #17956 should be fixed.


---

Comment by jdemeyer created at 2015-03-15 15:35:24

Replying to [comment:27 tscrim]:
> The first should be `[[2, 1], [1, 2]]` since the `inner` (or `outer`) are not related to the min or max lengths.

To clarify: you might be confusing with the `floor` and `ceiling` arguments of `IntegerListsLex`. Those do not have any effect on the length, but `inner`/`outer` _do_ add lower/upper bounds to the length. With both the existing code as well as with my code, we have for example

```
sage: Compositions(3, inner=[1,1,1]).list()
[This is the Trac macro *1, 1, 1* that was inherited from the migration](https://trac.sagemath.org/wiki/WikiMacros#1, 1, 1-macro)
```



---

Comment by tscrim created at 2015-03-15 15:35:42

On the ordering, from the title of the class, the output should be in lexicographical order. Moreover, since these are `EnumeratedSets`, the change in the ordering could lead to subtle changes that breaks people's code.

`Compositions` also does a similar thing with the max length and `outer`, so I agree that those should be empty. However IMO these tests should be in `Compositions`.

`@`vdelecroix It's mostly correct and there is a lot of code which depends on this being fast. Minimal slowdowns are okay (IMO), but significant slowdowns are unacceptable.


---

Comment by ncohen created at 2015-03-15 15:42:06

> On the ordering, from the title of the class, the output should be in lexicographical order. Moreover, since these are `EnumeratedSets`, the change in the ordering could lead to subtle changes that breaks people's code.

We can sort it before returning it I guess.

> `@`vdelecroix It's mostly correct

Jeroen compiled many related bugs in the description of #17548.

> Minimal slowdowns are okay (IMO), but significant slowdowns are unacceptable.

Significant slowdown can be a problem, that's for sure. If they turn out to be our only way to have a code which does not return wrong results, however, we will learn to live with them.

Nathann


---

Comment by aschilling created at 2015-03-15 15:45:22

I think it is great that Jeroen implemented this to get the correct results! Of course we do want fast code at the end.

As I mentioned on sage-devel, the order of lists of tableaux does not matter very much.

As Travis mentioned, there might be some subtle places where the order matters. One example that comes to mind is that the representations of S_n and characters are returned as matrices with rows and columns indexed by integers instead of partitions. So if the order of partitions changes, the interpretation of the results might change!


---

Comment by jdemeyer created at 2015-03-15 15:47:08

Replying to [comment:33 tscrim]:
> On the ordering, from the title of the class, the output should be in lexicographical order.
The name is now `IntegerLists` and I do provide `IntegerListsLex` for "backwards compatibility" which does sort.

Since the documentation of neither `Partitions` nor `Compositions` says anything about the order, I think it's allowed to change the order.


---

Comment by jdemeyer created at 2015-03-15 15:54:46

About the speed: if you manage to fix all existing bugs in the `IntegerListsLex` code, you can again use that implementation for `Compositions` and `Partitions`. It's probably good to have two indepdendent implementations anyway.

Even better would of course be that somebody speeds up `Polyhedron().integral_points()` which would benefit everybody using polyhedra.


---

Comment by nthiery created at 2015-03-16 05:10:18

Dear Jeroen,

Thanks a lot for taking action! It's definitely a good thing to have a
good connection between ``IntegerListLex`` and ``Polyhedron``, as
there is some non trivial overlap. The main differences is that
``IntegerListLex`` was specifically designed for allowing for
(essentially) Constant Amortized Time lexicographic Iteration in
almost constant memory, which is an important feature.

So I can see a work path along the following lines:

- Get this ticket in to have a robust implementation of list

- Completely rewrite the current ``IntegerListLex`` iterator to be
  robust (it's definitely possible); keep the Polyhedron
  implementation for testing purposes as well as for counting, ...

- Optimize the iterator (Cythonization, using ClonableIntArray, ...).

Please do not change the enumeration order, at least as default: quite
some code depends on it (I agree, this should be made explicit in the
documentation). The proposed generalizations (n in a range, negative
entries) are fine since the iterator could be made to handle them.

Cheers,
                       Nicolas


---

Comment by jdemeyer created at 2015-03-16 07:30:57

Replying to [comment:39 nthiery]:
> Please do not change the enumeration order, at least as default
I disagree with this: the default should be "do not sort, return stuff in the fastest possible way". Sorting an iterator is very expensive and should only be done if really needed.

> quite some code depends on it
Is that really true? The only doctest failures that I saw where "obvious" failures where some list order changed, I didn't see anything subtle.


---

Comment by jdemeyer created at 2015-03-16 08:55:49

Replying to [comment:39 nthiery]:
> keep the Polyhedron implementation for testing purposes as well as for counting, ...

I'm not sure about the counting... I guess a well-written Cython implementation of `IntegerListsLex` will usually be faster than the current polyhedra code. Profiling shows that a lot of time is spent in just _constructing_ the polyhedra (if there are not so many points, enumerating them takes a lot less time than constructing the polyhedron in the first place).


---

Comment by ncohen created at 2015-03-16 09:15:59

Hello,

> I'm not sure about the counting... I guess a well-written Cython implementation of `IntegerListsLex` will usually be faster than the current polyhedra code.

True. This being said, your polyhedron code may very well be 'all we can do' to implement this feature while handling all possible combinations of parameters.

> Profiling shows that a lot of time is spent in just _constructing_ the polyhedra

True. Do you have any idea where that comes from ? I had similar troubles with the Poset constructor (related to memory usage).

Nathann


---

Comment by jdemeyer created at 2015-03-16 09:22:04

Replying to [comment:42 ncohen]:
> > Profiling shows that a lot of time is spent in just _constructing_ the polyhedra
> 
> True. Do you have any idea where that comes from ?
It's just PPL.

Interestingly, arithmetic with infinity also shows up quite high in the profiling reports (up to 10% of the time), so optimizing `src/sage/rings/infinity.py` will also give some speedup.


---

Comment by ncohen created at 2015-03-16 09:25:25

> Interestingly, arithmetic with infinity also shows up quite high in the profiling reports (up to 10% of the time), so optimizing `src/sage/rings/infinity.py` will also give some speedup.

Aahahah. Yaeh, Vincent has been fighting a lot with some abstractions we have, which makes code run *much* slower. For `+oo` he advises to solve the problem by using float("inf") instead of Infinity. It is *MUCH* faster.

At some point he got some crazy somewhere by adding 'from math import sqrt' in a module to overwrite Sage's sqrt function.

Nathann


---

Comment by jdemeyer created at 2015-03-16 09:29:21

Replying to [comment:44 ncohen]:
> > Interestingly, arithmetic with infinity also shows up quite high in the profiling reports (up to 10% of the time), so optimizing `src/sage/rings/infinity.py` will also give some speedup.
> 
> Aahahah. Yaeh, Vincent has been fighting a lot with some abstractions we have, which makes code run *much* slower. For `+oo` he advises to solve the problem by using float("inf") instead of Infinity.

In general, I don't like the "X is slow, therefore let's not use X" mentality. My idea is: "let's use X and then optimize X".


---

Comment by mmezzarobba created at 2015-03-16 10:08:16

Replying to [comment:45 jdemeyer]:
> > > Interestingly, arithmetic with infinity also shows up quite high in the profiling reports (up to 10% of the time), so optimizing `src/sage/rings/infinity.py` will also give some speedup.
> > 
> > Aahahah. Yaeh, Vincent has been fighting a lot with some abstractions we have, which makes code run *much* slower. For `+oo` he advises to solve the problem by using float("inf") instead of Infinity.
> 
> In general, I don't like the "X is slow, therefore let's not use X" mentality. My idea is: "let's use X and then optimize X".

On a tangential note: if someone makes major changes to the infinity rings, please consider adding a `NaN` element to them.


---

Comment by ncohen created at 2015-03-16 10:40:52

> In general, I don't like the "X is slow, therefore let's not use X" mentality. My idea is: "let's use X and then optimize X".

Well, for the sqrt problem we were only computing on floats, and sqrt(5) in Sage is not a float. Having this symbolic value in the code we compared it with floats and this had a cost we had no reason to pay, so `from math import sqrt` made total sense, and there was nothing in Sage's sqrt that we could have wanted to change.

As per Sage's Infinity... Well, it also seems to have been designed with a different aim in mind. I usually want speed, and I do not want to pay for pointless abstraction. In infinity.py you will find parents, elements, rings and generators, while the feature I need is already provided by the constant LONG_MAX.

This Sage object is called 'infinity', but it turns out that one definition of "infinity" cannot cover all uses that we have for infinity on a computer. And I don't think that we could beat a single CPU instruction while dealing with parents and elements in a .py file.

Nathann


---

Comment by jdemeyer created at 2015-03-16 11:50:36

Replying to [comment:47 ncohen]:
> while the feature I need is already provided by the constant LONG_MAX.
In this case, we shouldn't aritificially restrict to `long`s:

```
sage: IntegerLists(10^100, max_length=1).list()
[This is the Trac macro *10000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000* that was inherited from the migration](https://trac.sagemath.org/wiki/WikiMacros#10000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000-macro)
```


> This Sage object is called 'infinity', but it turns out that one definition of "infinity" cannot cover all uses that we have for infinity on a computer.
I think we can have one definition which covers all uses _within Sage_. There is nothing fundamentally wrong with `Infinity`, it's just slow.


---

Comment by jdemeyer created at 2015-03-16 11:54:21

Note the difference of a factor 20 between the following:

```
sage: b = ZZ(1); a = Infinity; timeit('a < b', repeat=20, number=10^4)
10000 loops, best of 20: 11.7 µs per loop
sage: b = ZZ(1); a = QQ(2); timeit('a < b', repeat=20, number=10^4)
10000 loops, best of 20: 681 ns per loop
```

A proper Cython implementation of `Infinity` should match the speed for `QQ`.


---

Comment by git created at 2015-03-16 13:53:16

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by jdemeyer created at 2015-03-16 13:54:04

Replying to [comment:33 tscrim]:
> However IMO these tests should be in `Compositions`.
Done


---

Comment by nthiery created at 2015-03-16 14:30:08

Replying to [comment:40 jdemeyer]:
> Replying to [comment:39 nthiery]:
> > Please do not change the enumeration order, at least as default
> I disagree with this: the default should be "do not sort, return stuff in the fastest possible way". Sorting an iterator is very expensive and should only be done if really needed.

For IntegerList itself, any default is fine, and sorting is certainly
very bad. But for Partitions, Compositions, ... users are really
expecting lexicographic order. Besides, this is only a temporary
solution, and we will switch back to lexicographic once we have a
proper implementation of IntegerListLex.

> Is that really true? The only doctest failures that I saw where
> "obvious" failures where some list order changed, I didn't see
> anything subtle.

That's a point indeed; my feeling is that we have been lucky, although
it could be that some changes w.r.t. MuPAD-Combinat makes the code
less dependent on that feature.  I am worried by user's personal code
out there. Well, if you are willing to help those guys ...

Cheers,
                                    Nicolas


---

Comment by nthiery created at 2015-03-16 14:36:42

Replying to [comment:41 jdemeyer]:
> I'm not sure about the counting... I guess a well-written Cython
> implementation of `IntegerListsLex` will usually be faster than the
> current polyhedra code. Profiling shows that a lot of time is spent in
> just _constructing_ the polyhedra (if there are not so many points,
> enumerating them takes a lot less time than constructing the
> polyhedron in the first place).

Agreed, especially if we further go parallel: counting through
polyhedral methods only becomes relevant for relatively large
polyhedron. But this would be a very useful feature. So count
would eventually have some threshold to choose between the
two methods. 

By the way: we don't yet use Barvinok-like algorithms for counting
(e.g. through LattE), or do we? This could make a difference too.

Cheers,
                               Nicolas


---

Comment by jdemeyer created at 2015-03-16 14:47:38

Replying to [comment:54 nthiery]:
> By the way: we don't yet use Barvinok-like algorithms for counting
> (e.g. through LattE), or do we? This could make a difference too.

I just read the first paragraph of the LattE manual and it does *exactly* what we need for counting:


```
1.1    What is LattE?

The name “LattE” is an abbreviation for “Lattice point Enumeration.” LattE
was developed in 2001 to count lattice points contained in convex polyhedra
defined by linear equations and inequalities with integer coefficients. The poly-
hedra can be of any (reasonably small) dimension.
```



---

Comment by jdemeyer created at 2015-03-16 14:55:34

Replying to [comment:53 nthiery]:
> But for Partitions, Compositions, ... users are really expecting lexicographic order.
Well, certainly for `Compositions`, the current order is not defined:

```
sage: Compositions(2).list()
[[1, 1], [2]]
sage: Compositions(2, max_slope=0).list()
[[2], [1, 1]]
```



---

Comment by ncohen created at 2015-03-16 14:56:44

http://trac.sagemath.org/ticket/17529#comment:11 (we already have a LattE package)


---

Comment by nthiery created at 2015-03-16 14:58:22

Replying to [comment:55 jdemeyer]:
> I just read the first paragraph of the LattE manual and it does *exactly* what we need for counting:

Yes indeed! See also #15180.

Btw: in case this could be useful, the developers are in Davis where I
currently am for the upcoming Sage Days 64.

Cheers,
                             Nicolas


---

Comment by git created at 2015-03-16 14:58:45

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by tscrim created at 2015-03-16 15:09:21

FYI - `float('inf')` works quite well as a good and fast substitute for `Infinity` (which is why it is used in the current `IntegerListsLex`).


---

Comment by jdemeyer created at 2015-03-16 15:13:34

Replying to [comment:53 nthiery]:
> But for Partitions users are really expecting lexicographic order.
For which applications does this really matter?

I know that's how partitions are traditionally written down and how things are done in Sage historically. But I don't think that's enough reason to not change it, especially given the fact that the documentation doesn't say anything about the order. Any order of the list of partitions is a good answer mathematically.


---

Comment by tscrim created at 2015-03-16 15:17:12

I'm worried this could lead to errors being raised when trying to convert between different bases of the symmetric functions (which are indexed by partitions). IIRC the code relies on some of the (graded) transition matrices being upper triangular, which requires the order be compatible with dominance ordering.


---

Comment by jdemeyer created at 2015-03-16 15:26:41

Replying to [comment:62 tscrim]:
> I'm worried this could lead to errors being raised when trying to convert between different bases of the symmetric functions (which are indexed by partitions). IIRC the code relies on some of the (graded) transition matrices being upper triangular, which requires the order be compatible with dominance ordering.

To be honest, I don't know what you mean mathematically. But, like I said, the fact that there are no strange doctest failures shows that the issue cannot be so serious.

And in the cases where the order really matters, I think those places should simply explicitly sort or use `IntegerListsLex`. Slowing down all of `Paritions()` just because one or two applications require it seems stupid.


---

Comment by aschilling created at 2015-03-16 19:01:58

> But, like I said, the fact that there are no strange doctest failures shows that the issue cannot be so serious.

This might be an issue though

```
sage: S=SymmetricGroup(3)
sage: S.character_table()
[ 1 -1  1]
[ 2  0 -1]
[ 1  1  1]
sage: type(S.character_table())
<type 'sage.matrix.matrix_cyclo_dense.Matrix_cyclo_dense'>
```

The character table should really be indexed by partitions (or conjugacy classes of S_n).
So the meaning of the matrix changes if the order of the list of partitions changes.


---

Comment by jdemeyer created at 2015-03-16 19:31:46

Replying to [comment:64 aschilling]:
> This might be an issue though
> {{{
> sage: S=SymmetricGroup(3)
> sage: S.character_table()
> [ 1 -1  1]
> [ 2  0 -1]
> [ 1  1  1]
> sage: type(S.character_table())
> <type 'sage.matrix.matrix_cyclo_dense.Matrix_cyclo_dense'>
> }}}
> The character table should really be indexed by partitions (or conjugacy classes of S_n).
> So the meaning of the matrix changes if the order of the list of partitions changes.

Okay, so the meaning of the matrix changes. There is nothing wrong with output _changing_ as long as things stay mathematically correct and internally consistent.


---

Comment by dimpase created at 2015-03-18 10:13:48

Replying to [comment:55 jdemeyer]:
> Replying to [comment:54 nthiery]:
> > By the way: we don't yet use Barvinok-like algorithms for counting
> > (e.g. through LattE), or do we? This could make a difference too.
> 
> I just read the first paragraph of the LattE manual and it does *exactly* what we need for counting:

Moreover, counting the points is faster than enumerating the points; there could be exponentially many points to count, but still the number of them is only polynomial in the input size, for fixed dimension, and LattE provides a truly polynomial-time procedure for this counting.


---

Comment by chapoton created at 2015-03-25 20:01:10

Changing status from needs_review to needs_work.


---

Comment by chapoton created at 2015-03-25 20:01:10

a badly formated doc in composition.py

```
     TESTS::
 
+    Check that :trac:`17548` is fixed::
```



---

Comment by git created at 2015-03-25 22:34:14

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2015-03-25 22:36:40

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by jdemeyer created at 2015-03-25 22:37:13

Changing status from needs_work to needs_review.


---

Comment by git created at 2015-04-05 07:01:25

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by vbraun created at 2015-04-12 11:24:26

Whats your plan with the code here? It might be useful to check. Thoughts?


---

Comment by vbraun created at 2015-04-12 11:24:26

Changing priority from blocker to major.


---

Comment by vbraun created at 2015-04-12 11:24:26

Changing status from needs_review to needs_info.


---

Comment by tscrim created at 2015-04-12 11:47:09

This code is useful as it works in more general context than the new `IntegerListsLex` as it allows entries in `ZZ` (instead of just `NN`) and when lex ordering doesn't hit every element in finite time. Plus I like alternative algorithms for testing, and this is faster in certain cases currently as well. I just need to find some time to review this.


---

Comment by tscrim created at 2015-04-12 11:47:09

Changing status from needs_info to needs_review.


---

Comment by nthiery created at 2015-04-12 14:54:29

Indeed, we want this code in Sage! I promised Jeroen I would rebase his code, and work on the review. This could be a good sprint for Sage Days 67. But yes this certainly is not a blocker anymore for 6.6.


---

Comment by jdemeyer created at 2015-04-13 07:09:46

Needs to be rebased in any case. I might also try to make it work in _all_ cases of infinite iterator (currently, I still require that there are only finitely many lists of every given length).


---

Comment by jdemeyer created at 2015-04-13 07:09:46

Changing status from needs_review to needs_work.


---

Comment by jdemeyer created at 2015-04-13 07:47:19

I would actually like to redesign `IntegerListsLex` and `IntegerLists_polyhedron` such that they share code: they could be the same class but with a different implementation for `__iter__` and `__contains__`.


---

Comment by vdelecroix created at 2015-04-13 08:00:02

Replying to [comment:77 jdemeyer]:
> I would actually like to redesign `IntegerListsLex` and `IntegerLists_polyhedron` such that they share code: they could be the same class but with a different implementation for `__iter__` and `__contains__`.

+1

why not several iterators on the same class? (with a reasonable one by default in `__iter__`).


---

Comment by jdemeyer created at 2015-04-13 08:22:33

Replying to [comment:78 vdelecroix]:
> Replying to [comment:77 jdemeyer]:
> > I would actually like to redesign `IntegerListsLex` and `IntegerLists_polyhedron` such that they share code: they could be the same class but with a different implementation for `__iter__` and `__contains__`.
> 
> +1
> 
> why not several iterators on the same class? (with a reasonable one by default in `__iter__`).
Well, it will be something along those lines. But I haven't thought too much about the actual design.


---

Comment by jdemeyer created at 2015-04-13 08:46:54

Replying to [comment:75 nthiery]:
> I promised Jeroen I would rebase his code
Thanks for the offer, but that will not be needed (in any case, it's just merging with `-X theirs` essentially)


---

Comment by nthiery created at 2015-04-13 11:38:40

Replying to [comment:79 jdemeyer]:
> Replying to [comment:78 vdelecroix]:
> > Replying to [comment:77 jdemeyer]:
> > > I would actually like to redesign `IntegerListsLex` and `IntegerLists_polyhedron` such that they share code: they could be the same class but with a different implementation for `__iter__` and `__contains__`.
> > 
> > +1
> > 
> > why not several iterators on the same class? (with a reasonable one by default in `__iter__`).
> Well, it will be something along those lines. But I haven't thought too much about the actual design.

+1 to sharing code between the classes; in fact I had put a mental
note on doing this when I offered to do the merge :-)

Having a class that can handle any set of constraints, even if it does
only containment check, would be useful. We would need this in
particular to properly refactor integer vectors.

I am not sure whether we want a single class, or two classes:


```
class IntegerLists:
    __iter__ -> __iter__ on the polyhedron

class IntegerListsLex(IntegerLists):
```


With the second one having the additional specification that the
enumeration shall be lexicographic.

Thoughts?

Cheers,
                              Nicolas
