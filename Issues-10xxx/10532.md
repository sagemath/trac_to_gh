# Issue 10532: Faster multiplication for multivariate power series

archive/issues_010479.json:
```json
{
    "assignees": [],
    "body": "Multivariate power series are implemented in #1956.  Ticket #10480 has a couple of different algorithms for improving `PowerSeries_poly` multiplication.  `MPowerSeries._mul_` should be modified to take advantage of the optimal algorithm.\n\n**Assignee:** @malb\n\n**CC:**  mario pernici @lftabera @nathanncohen\n\n**Keywords:** multivariate power series multiplication Karatsuba\n\n**Author:** pernici\n\n**Reviewer:** Niles Johnson\n\nIssue created by migration from https://trac.sagemath.org/ticket/10532\n\n",
    "created_at": "2010-12-29T15:47:22Z",
    "labels": [
        "https://github.com/sagemath/sage/labels/component%3A%20commutative%20algebra",
        "https://github.com/sagemath/sage/labels/enhancement",
        "https://github.com/sagemath/sage/labels/needs%20info"
    ],
    "reactions": [],
    "repository": "https://github.com/sagemath/sage",
    "title": "Faster multiplication for multivariate power series",
    "type": "issue",
    "updated_at": "2011-02-15T17:10:40Z",
    "url": "https://github.com/sagemath/sage/issues/10532",
    "user": "https://github.com/nilesjohnson"
}
```
Multivariate power series are implemented in #1956.  Ticket #10480 has a couple of different algorithms for improving `PowerSeries_poly` multiplication.  `MPowerSeries._mul_` should be modified to take advantage of the optimal algorithm.

**Assignee:** @malb

**CC:**  mario pernici @lftabera @nathanncohen

**Keywords:** multivariate power series multiplication Karatsuba

**Author:** pernici

**Reviewer:** Niles Johnson

Issue created by migration from https://trac.sagemath.org/ticket/10532





---

archive/issue_events_116412.json:
```json
{
    "actor": "https://github.com/nilesjohnson",
    "created_at": "2010-12-29T15:47:22Z",
    "event": "labeled",
    "issue": "https://github.com/sagemath/sage/issues/10532",
    "label": "https://github.com/sagemath/sage/labels/component%3A%20commutative%20algebra",
    "label_color": "08517b",
    "label_name": "component: commutative algebra",
    "label_text_color": "ffffff",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sage/issues/10532#event-116412"
}
```



---

archive/issue_events_116413.json:
```json
{
    "actor": "https://github.com/nilesjohnson",
    "created_at": "2010-12-29T15:47:22Z",
    "event": "labeled",
    "issue": "https://github.com/sagemath/sage/issues/10532",
    "label": "https://github.com/sagemath/sage/labels/enhancement",
    "label_color": "008080",
    "label_name": "enhancement",
    "label_text_color": "ffffff",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sage/issues/10532#event-116413"
}
```



---

archive/issue_comments_102158.json:
```json
{
    "body": "depends on #1956 and `trac_10480_fast_PowerSeries_poly_multiplication2.patch`",
    "created_at": "2010-12-29T15:51:42Z",
    "formatter": "markdown",
    "issue": "https://github.com/sagemath/sage/issues/10532",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/10532#issuecomment-102158",
    "user": "https://github.com/nilesjohnson"
}
```

depends on #1956 and `trac_10480_fast_PowerSeries_poly_multiplication2.patch`



---

archive/issue_comments_102159.json:
```json
{
    "body": "**Author:** pernici",
    "created_at": "2010-12-29T15:58:06Z",
    "formatter": "markdown",
    "issue": "https://github.com/sagemath/sage/issues/10532",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/10532#issuecomment-102159",
    "user": "https://github.com/nilesjohnson"
}
```

**Author:** pernici



---

archive/issue_comments_102160.json:
```json
{
    "body": "<a id='comment:1'>**Comment 1:**</a>\n**Attachment:** [trac_10532_faster_MPowerSeries_mul.patch.gz](https://github.com/sagemath/sage/files/ticket10532/trac_10532_faster_MPowerSeries_mul.patch.gz)\n\nA patch posted by pernici at #1956:  First apply #1956, then `trac_10480_fast_PowerSeries_poly_multiplication2.patch` from #10480, then [attachment:trac_10532_faster_MPowerSeries_mul.patch](https://github.com/sagemath/sage/files/ticket10532/trac_10532_faster_MPowerSeries_mul.patch).  Timings before and after the patch are listed in [#1956, comment 59](https://github.com/sagemath/sage/issues/1956#comment:59), showing much improvement with this patch.\n\nComparisons with the Karatsuba algorithm of #10480 still need to be done.",
    "created_at": "2010-12-29T15:58:06Z",
    "formatter": "markdown",
    "issue": "https://github.com/sagemath/sage/issues/10532",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/10532#issuecomment-102160",
    "user": "https://github.com/nilesjohnson"
}
```

<a id='comment:1'>**Comment 1:**</a>
**Attachment:** [trac_10532_faster_MPowerSeries_mul.patch.gz](https://github.com/sagemath/sage/files/ticket10532/trac_10532_faster_MPowerSeries_mul.patch.gz)

A patch posted by pernici at #1956:  First apply #1956, then `trac_10480_fast_PowerSeries_poly_multiplication2.patch` from #10480, then [attachment:trac_10532_faster_MPowerSeries_mul.patch](https://github.com/sagemath/sage/files/ticket10532/trac_10532_faster_MPowerSeries_mul.patch).  Timings before and after the patch are listed in [#1956, comment 59](https://github.com/sagemath/sage/issues/1956#comment:59), showing much improvement with this patch.

Comparisons with the Karatsuba algorithm of #10480 still need to be done.



---

archive/issue_comments_102161.json:
```json
{
    "body": "**Reviewer:** Niles Johnson",
    "created_at": "2010-12-29T15:58:06Z",
    "formatter": "markdown",
    "issue": "https://github.com/sagemath/sage/issues/10532",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/10532#issuecomment-102161",
    "user": "https://github.com/nilesjohnson"
}
```

**Reviewer:** Niles Johnson



---

archive/issue_events_116414.json:
```json
{
    "actor": "https://github.com/nilesjohnson",
    "created_at": "2010-12-29T15:58:06Z",
    "event": "labeled",
    "issue": "https://github.com/sagemath/sage/issues/10532",
    "label": "https://github.com/sagemath/sage/labels/needs%20info",
    "label_color": "008080",
    "label_name": "needs info",
    "label_text_color": "ffffff",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sage/issues/10532#event-116414"
}
```



---

archive/issue_comments_102162.json:
```json
{
    "body": "<a id='comment:2'>**Comment 2:**</a>\n(cc me)",
    "created_at": "2010-12-29T18:42:16Z",
    "formatter": "markdown",
    "issue": "https://github.com/sagemath/sage/issues/10532",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/10532#issuecomment-102162",
    "user": "https://github.com/nathanncohen"
}
```

<a id='comment:2'>**Comment 2:**</a>
(cc me)



---

archive/issue_comments_102163.json:
```json
{
    "body": "benchmark",
    "created_at": "2011-01-09T12:09:07Z",
    "formatter": "markdown",
    "issue": "https://github.com/sagemath/sage/issues/10532",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/10532#issuecomment-102163",
    "user": "https://github.com/sagetrac-pernici"
}
```

benchmark



---

archive/issue_comments_102164.json:
```json
{
    "body": "**Attachment:** [mu2.sage.gz](https://github.com/sagemath/sage/files/ticket10532/mu2.sage.gz)\n\nbenchmark",
    "created_at": "2011-01-09T12:09:32Z",
    "formatter": "markdown",
    "issue": "https://github.com/sagemath/sage/issues/10532",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/10532#issuecomment-102164",
    "user": "https://github.com/sagetrac-pernici"
}
```

**Attachment:** [mu2.sage.gz](https://github.com/sagemath/sage/files/ticket10532/mu2.sage.gz)

benchmark



---

archive/issue_comments_102165.json:
```json
{
    "body": "<a id='comment:3'>**Comment 3:**</a>\n**Attachment:** [bench1.sage.gz](https://github.com/sagemath/sage/files/ticket10532/bench1.sage.gz)\n\nAttachments: bench1.sage, mu2.sage\n\nHere are some benchmarks comparing:\n\n(1)  with do_mul_trunc_generic\nfrom trac_10480_fast_PowerSeries_poly_multiplication2.patch,\ntrac_1956_faster_MPowerSeries_mul.patch\n\n(2,K)  with do_trunc_karatsuba, where K is K_threshold\nfrom trac_karatsuba_improvements.patch,\ntrac_10480_fast_PowerSeries_poly_multiplication-alternative.patch\n\n(1) or (2) are applied after applying\ntrac_1956_multi_power_series_new_4.patch,\ntrac_1956_uni_multi_ps_2.patch,\ntrac_1956_multi_ps_cleanup.patch.\n\nThese tests are run with QQ and GF(7) as examples of fields\nimplemented in libsingular, RR as field not implemented there.\n\nVarious values of K are tried; (1) corresponds to the K=infinity case\nfor QQ and GF(7) (slightly slower because do_mul_trunc_generic has a\nslightly slower implementation than the corresponding do_trunc_classical\nby lftabera), but not for RR (and I guess for other fields not used in\nlibsingular), where (1) is slower.\n\nThe conclusion is that I think that (2) with K=infinity (or a large\ninteger to avoid using infinity) is the best choice.\n\nbench1.sage are the benchmarks posted by Niles to compare with Magma,\nwith precision multiplied by N.\n\ntimes are in seconds;\nprocessor:4-core: Intel Core i7 CPU 860 @ 2.80GHz\non x86_64 GNU/Linux\n\n```\nprec = prec1*N\nbench1.sage with GF(7)\ntest no. 1     2     3     4     5     6     7     8\nprec1    16    15    50    30    51    30    30    30\nN=3\n(1)      0.45  0.03                    0.49  0.49  0.45\n(2,8)    2.16  0.06                    1.21  1.25  1.10\n(2,64)   0.45  0.03                    0.55  0.56  0.54\n(2,128)  0.43  0.03                    0.44  0.45  0.44\nN=4\n(1)      1.80  0.06                    1.44  1.34  1.22\n(2,8)    3.95  0.12                    3.89  3.79  3.25\n(2,64)   1.88  0.06                    1.69  1.60  1.50\n(2,128)  1.78  0.06                    1.45  1.34  1.22\nN=5\n(1)      8.96  0.21                    5.01  4.65  4.27\n(2,8)    23.2  0.52                    14.8  14.3  12.3\n(2,64)   11.2  0.23                    6.55  6.01  5.53\n(2,128)  8.74  0.19                    5.50  5.11  4.69\nN=6\n(1)      27.0  0.67                    9.99  9.35  9.17\n(2,8)    87.2  1.56                    30.4  31.2  26.4\n(2,64)   34.5  0.74                    13.6  12.8  12.4\n(2,128)  26.1  0.67                    10.9  10.1  9.79\nN=7\n(1)      40.8  1.46                    18.6  17.3  16.1\n(2,8)    132   3.67                    57.6  60.4  51.4\n(2,64)   51.1  1.55                    25.0  23.3  21.1\n(2,128)  39.3  1.51                    20.4  19.2  17.6\n(2,256)  38.3  1.32                    18.3  16.9  15.9\n\n\nbench1.sage with RR\ntest no. 1     2     3     4     5     6     7     8\nprec1    16    15    50    30    51    30    30    30\nN=1\n(1)      1.18  0.06  0.88  0.70  0.23  0.67  0.69  0.70\n(2,8)    0.34  0.04  0.61  4.92  0.18  0.47  0.57  0.89\n(2,64)   0.18  0.04  0.74  0.27  0.20  0.24  0.26  0.26\nN=2\n(1)      57    0.96  1.6   8.4   0.67  8.2   8.5   8.4\n(2,8)    19.5  0.29  1.4   >540  0.44  9.9   32    183\n(2,64)   6.06  0.16  1.2   2.65  0.43  2.55  2.63  2.68\n(2,128)  6.07  0.16  1.3   2.64  0.48  2.57  2.63  2.63\nN=3\n(2,64)   58.1  0.93  1.39  79.4  0.72  18.5  28.8  48.8\n(2,128)  58.9  0.94  1.59  11.8  0.78  11.6  12.0  11.7\n```\n\nmu2.sage is a modification of the benchmark mu.sage posted in ticket #1956\nin which the random polynomials are evaluated in t_i + 1;\nthe various series are stored in dat/ to compare times with\nthe same series and different algorithms; this is a workabout for\nthe lack of something like random.seed for random_element.\nTimings are only indicative.\n\n```\nmu2.sage  with QQ\n        N=1   2     3     4     5     6     7     8\nn=2\nprec=20 bound=20\n(1)     0.007 0.01  0.02  0.04  0.09  0.21  0.58  1.79\n(2,8)   0.015 0.03  0.06  0.10  0.22  0.58  1.88  5.92\n(2,32)  0.007 0.01  0.02  0.04  0.09  0.20  0.57  1.74\nprec=20 bound=100\n(1)     0.007 0.01  0.03  0.05  0.11  0.28  0.79  2.4\n(2,8)   0.019 0.04  0.07  0.13  0.30  0.85  2.64  8.2\n(2,32)  0.007 0.01  0.03  0.05  0.11  0.27  0.78  2.4\nprec=100 bound=100\n(1)     2.96  4.46  7.14  13.4  31.8\n(2,8)   18.0  32.6  67.1  162   494\n(2,32)  6.82  10.7  18.8  38.7  104\n(2,128) 2.91  4.40  7.23  13.5  32.1\n\nmu2.sage  with GF(7)\nn=2\nprec=100 bound=100\n(1)     0.08  0.08  0.08  0.08  0.09  0.09  0.09  0.09\n(2,8)   0.41  0.45  0.45  0.44  0.45  0.45  0.46  0.44\n(2,128) 0.07  0.08  0.08  0.08  0.08  0.08  0.08  0.08\n\nprec=200 bound=200\n(1)     1.05  1.21  1.22  1.23  1.22\n(2,8)   11.0  12.5  12.4  12.4  12.5\n(2,128) 1.41  1.59  1.58  1.59  1.58\n(2,256) 1.00  1.14  1.12  1.14  1.15\n\nmu2.sage with RR\nn=2\nprec=20 bound=20\n(1)     0.03  0.06  0.06  0.06  0.06  0.06  0.06  0.06\n(2,8)   0.03  0.04  0.15  0.41  1.15  3.66  12.8  45.7\n(2,128) 0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01\n\nprec=20 bound=100\n(1)     0.05  0.05  0.06  0.06  0.06  0.06  0.06  0.06\n(2,8)   0.03  0.07  0.23  0.42  1.08  2.71  5.94  10.2\n(2,128) 0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01\n\nprec=100 bound=100\n(1)     1.87  1.87  1.91  1.87  1.88\n(2,8)   1.06  8.95  69.0  332   2050\n(2,128) 0.31  0.31  0.31  0.31  0.31\n\nn=4\nprec=20 bound=20\n(1)     4.05  68.8  69.5  71.1  76.1\n(2,8)   3.91  66.0  615   >2000\n(2,128) 1.16  2.00  2.02  2.05  2.03\n```",
    "created_at": "2011-01-09T12:10:57Z",
    "formatter": "markdown",
    "issue": "https://github.com/sagemath/sage/issues/10532",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/10532#issuecomment-102165",
    "user": "https://github.com/sagetrac-pernici"
}
```

<a id='comment:3'>**Comment 3:**</a>
**Attachment:** [bench1.sage.gz](https://github.com/sagemath/sage/files/ticket10532/bench1.sage.gz)

Attachments: bench1.sage, mu2.sage

Here are some benchmarks comparing:

(1)  with do_mul_trunc_generic
from trac_10480_fast_PowerSeries_poly_multiplication2.patch,
trac_1956_faster_MPowerSeries_mul.patch

(2,K)  with do_trunc_karatsuba, where K is K_threshold
from trac_karatsuba_improvements.patch,
trac_10480_fast_PowerSeries_poly_multiplication-alternative.patch

(1) or (2) are applied after applying
trac_1956_multi_power_series_new_4.patch,
trac_1956_uni_multi_ps_2.patch,
trac_1956_multi_ps_cleanup.patch.

These tests are run with QQ and GF(7) as examples of fields
implemented in libsingular, RR as field not implemented there.

Various values of K are tried; (1) corresponds to the K=infinity case
for QQ and GF(7) (slightly slower because do_mul_trunc_generic has a
slightly slower implementation than the corresponding do_trunc_classical
by lftabera), but not for RR (and I guess for other fields not used in
libsingular), where (1) is slower.

The conclusion is that I think that (2) with K=infinity (or a large
integer to avoid using infinity) is the best choice.

bench1.sage are the benchmarks posted by Niles to compare with Magma,
with precision multiplied by N.

times are in seconds;
processor:4-core: Intel Core i7 CPU 860 @ 2.80GHz
on x86_64 GNU/Linux

```
prec = prec1*N
bench1.sage with GF(7)
test no. 1     2     3     4     5     6     7     8
prec1    16    15    50    30    51    30    30    30
N=3
(1)      0.45  0.03                    0.49  0.49  0.45
(2,8)    2.16  0.06                    1.21  1.25  1.10
(2,64)   0.45  0.03                    0.55  0.56  0.54
(2,128)  0.43  0.03                    0.44  0.45  0.44
N=4
(1)      1.80  0.06                    1.44  1.34  1.22
(2,8)    3.95  0.12                    3.89  3.79  3.25
(2,64)   1.88  0.06                    1.69  1.60  1.50
(2,128)  1.78  0.06                    1.45  1.34  1.22
N=5
(1)      8.96  0.21                    5.01  4.65  4.27
(2,8)    23.2  0.52                    14.8  14.3  12.3
(2,64)   11.2  0.23                    6.55  6.01  5.53
(2,128)  8.74  0.19                    5.50  5.11  4.69
N=6
(1)      27.0  0.67                    9.99  9.35  9.17
(2,8)    87.2  1.56                    30.4  31.2  26.4
(2,64)   34.5  0.74                    13.6  12.8  12.4
(2,128)  26.1  0.67                    10.9  10.1  9.79
N=7
(1)      40.8  1.46                    18.6  17.3  16.1
(2,8)    132   3.67                    57.6  60.4  51.4
(2,64)   51.1  1.55                    25.0  23.3  21.1
(2,128)  39.3  1.51                    20.4  19.2  17.6
(2,256)  38.3  1.32                    18.3  16.9  15.9


bench1.sage with RR
test no. 1     2     3     4     5     6     7     8
prec1    16    15    50    30    51    30    30    30
N=1
(1)      1.18  0.06  0.88  0.70  0.23  0.67  0.69  0.70
(2,8)    0.34  0.04  0.61  4.92  0.18  0.47  0.57  0.89
(2,64)   0.18  0.04  0.74  0.27  0.20  0.24  0.26  0.26
N=2
(1)      57    0.96  1.6   8.4   0.67  8.2   8.5   8.4
(2,8)    19.5  0.29  1.4   >540  0.44  9.9   32    183
(2,64)   6.06  0.16  1.2   2.65  0.43  2.55  2.63  2.68
(2,128)  6.07  0.16  1.3   2.64  0.48  2.57  2.63  2.63
N=3
(2,64)   58.1  0.93  1.39  79.4  0.72  18.5  28.8  48.8
(2,128)  58.9  0.94  1.59  11.8  0.78  11.6  12.0  11.7
```

mu2.sage is a modification of the benchmark mu.sage posted in ticket #1956
in which the random polynomials are evaluated in t_i + 1;
the various series are stored in dat/ to compare times with
the same series and different algorithms; this is a workabout for
the lack of something like random.seed for random_element.
Timings are only indicative.

```
mu2.sage  with QQ
        N=1   2     3     4     5     6     7     8
n=2
prec=20 bound=20
(1)     0.007 0.01  0.02  0.04  0.09  0.21  0.58  1.79
(2,8)   0.015 0.03  0.06  0.10  0.22  0.58  1.88  5.92
(2,32)  0.007 0.01  0.02  0.04  0.09  0.20  0.57  1.74
prec=20 bound=100
(1)     0.007 0.01  0.03  0.05  0.11  0.28  0.79  2.4
(2,8)   0.019 0.04  0.07  0.13  0.30  0.85  2.64  8.2
(2,32)  0.007 0.01  0.03  0.05  0.11  0.27  0.78  2.4
prec=100 bound=100
(1)     2.96  4.46  7.14  13.4  31.8
(2,8)   18.0  32.6  67.1  162   494
(2,32)  6.82  10.7  18.8  38.7  104
(2,128) 2.91  4.40  7.23  13.5  32.1

mu2.sage  with GF(7)
n=2
prec=100 bound=100
(1)     0.08  0.08  0.08  0.08  0.09  0.09  0.09  0.09
(2,8)   0.41  0.45  0.45  0.44  0.45  0.45  0.46  0.44
(2,128) 0.07  0.08  0.08  0.08  0.08  0.08  0.08  0.08

prec=200 bound=200
(1)     1.05  1.21  1.22  1.23  1.22
(2,8)   11.0  12.5  12.4  12.4  12.5
(2,128) 1.41  1.59  1.58  1.59  1.58
(2,256) 1.00  1.14  1.12  1.14  1.15

mu2.sage with RR
n=2
prec=20 bound=20
(1)     0.03  0.06  0.06  0.06  0.06  0.06  0.06  0.06
(2,8)   0.03  0.04  0.15  0.41  1.15  3.66  12.8  45.7
(2,128) 0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01

prec=20 bound=100
(1)     0.05  0.05  0.06  0.06  0.06  0.06  0.06  0.06
(2,8)   0.03  0.07  0.23  0.42  1.08  2.71  5.94  10.2
(2,128) 0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01

prec=100 bound=100
(1)     1.87  1.87  1.91  1.87  1.88
(2,8)   1.06  8.95  69.0  332   2050
(2,128) 0.31  0.31  0.31  0.31  0.31

n=4
prec=20 bound=20
(1)     4.05  68.8  69.5  71.1  76.1
(2,8)   3.91  66.0  615   >2000
(2,128) 1.16  2.00  2.02  2.05  2.03
```



---

archive/issue_comments_102166.json:
```json
{
    "body": "<a id='comment:4'>**Comment 4:**</a>\nIf K=infinity is needed to obtain good performance then either we are doing something wrong or truncated karatsuba should be eliminated in favor of the classical truncated algorithm. I will try to look at this, but probably not this week.",
    "created_at": "2011-01-09T20:02:44Z",
    "formatter": "markdown",
    "issue": "https://github.com/sagemath/sage/issues/10532",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/10532#issuecomment-102166",
    "user": "https://github.com/lftabera"
}
```

<a id='comment:4'>**Comment 4:**</a>
If K=infinity is needed to obtain good performance then either we are doing something wrong or truncated karatsuba should be eliminated in favor of the classical truncated algorithm. I will try to look at this, but probably not this week.



---

archive/issue_comments_102167.json:
```json
{
    "body": "<a id='comment:5'>**Comment 5:**</a>\nIn the message above I claimed that patch (1) uses do_mul_trunc_generic;\nthis is not true for RR, in which case it falls back to _mul_generic,\nthe classical multiplication;\nthis is the reason for which (1) is much slower than the K=infinity\ncase for RR, calling do_trunc_classical. \nSince the truncated classical multiplication\ndo_trunc_classical computes\nthe same terms as the classical multiplication, apart from those\nwhich are then truncated away, it is fine for non-exact fields.\n\nThe conclusion of the previous message stands:\nI think that (2) with K=infinity (or a large integer to avoid \nusing infinity) is the best choice.\n\nlftabera wrote:\n>If K=infinity is needed to obtain good performance then either we are doing something wrong or truncated karatsuba should be eliminated in favor of the classical truncated algorithm.\n\nRight, it can call directly the classical truncated algorithm, but the K=infinity case \ncalls the classical truncated algorithm almost immediately, so\nI think that the overhead of calling it is negligible anyway.",
    "created_at": "2011-01-10T00:03:19Z",
    "formatter": "markdown",
    "issue": "https://github.com/sagemath/sage/issues/10532",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/10532#issuecomment-102167",
    "user": "https://github.com/sagetrac-pernici"
}
```

<a id='comment:5'>**Comment 5:**</a>
In the message above I claimed that patch (1) uses do_mul_trunc_generic;
this is not true for RR, in which case it falls back to _mul_generic,
the classical multiplication;
this is the reason for which (1) is much slower than the K=infinity
case for RR, calling do_trunc_classical. 
Since the truncated classical multiplication
do_trunc_classical computes
the same terms as the classical multiplication, apart from those
which are then truncated away, it is fine for non-exact fields.

The conclusion of the previous message stands:
I think that (2) with K=infinity (or a large integer to avoid 
using infinity) is the best choice.

lftabera wrote:
>If K=infinity is needed to obtain good performance then either we are doing something wrong or truncated karatsuba should be eliminated in favor of the classical truncated algorithm.

Right, it can call directly the classical truncated algorithm, but the K=infinity case 
calls the classical truncated algorithm almost immediately, so
I think that the overhead of calling it is negligible anyway.



---

archive/issue_comments_102168.json:
```json
{
    "body": "**Attachment:** [trac_1956_faster_MPowerSeries_mul2.patch.gz](https://github.com/sagemath/sage/files/ticket10532/trac_1956_faster_MPowerSeries_mul2.patch.gz)",
    "created_at": "2011-01-19T17:12:32Z",
    "formatter": "markdown",
    "issue": "https://github.com/sagemath/sage/issues/10532",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/10532#issuecomment-102168",
    "user": "https://github.com/sagetrac-pernici"
}
```

**Attachment:** [trac_1956_faster_MPowerSeries_mul2.patch.gz](https://github.com/sagemath/sage/files/ticket10532/trac_1956_faster_MPowerSeries_mul2.patch.gz)



---

archive/issue_comments_102169.json:
```json
{
    "body": "<a id='comment:6'>**Comment 6:**</a>\nThe attached patch trac_1956_faster_MPowerSeries_mul2.patch\nis applied after\ntrac_1956_multi_power_series_new_4.patch,\ntrac_1956_uni_multi_ps_2.patch,\ntrac_1956_multi_ps_cleanup.patch\n\nFor multivariate series Karatsuba multiplication is slower than generic\nmultiplication also in the case of `prec=infinity`\n\n```\nsage: R.<x,y,z,w> = QQ[[]]\nsage: p = 1 + x/2 + y/3 + z/4\nsage: %timeit p^20\n\ntimes in ms; K=K_threshold\n                  p^5     p^10    p^20       p^40\ngeneric           0.31    1.62    28.5       1070\nKaratsuba K=8     0.56    5.7     172        1900\nKaratsuba K=64    0.56    5.7     167        1080\n```\n\nThe attached patch uses generic multiplication for any precision;\nit has been made independent from ticket #10480, which deals mainly\nwith the truncated Karatsuba multiplication, which is fast only\nfor univariate series.\n\n`_mul_trunc_generic`, coming from do_trunc_classical by lftabera,\nhas a lot of code in common with `_mul_generic` and maybe it should be merged\nwith it; also, it would be nice to do the `_square_generic` optimization\nfor finite `prec`.",
    "created_at": "2011-01-19T17:13:07Z",
    "formatter": "markdown",
    "issue": "https://github.com/sagemath/sage/issues/10532",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/10532#issuecomment-102169",
    "user": "https://github.com/sagetrac-pernici"
}
```

<a id='comment:6'>**Comment 6:**</a>
The attached patch trac_1956_faster_MPowerSeries_mul2.patch
is applied after
trac_1956_multi_power_series_new_4.patch,
trac_1956_uni_multi_ps_2.patch,
trac_1956_multi_ps_cleanup.patch

For multivariate series Karatsuba multiplication is slower than generic
multiplication also in the case of `prec=infinity`

```
sage: R.<x,y,z,w> = QQ[[]]
sage: p = 1 + x/2 + y/3 + z/4
sage: %timeit p^20

times in ms; K=K_threshold
                  p^5     p^10    p^20       p^40
generic           0.31    1.62    28.5       1070
Karatsuba K=8     0.56    5.7     172        1900
Karatsuba K=64    0.56    5.7     167        1080
```

The attached patch uses generic multiplication for any precision;
it has been made independent from ticket #10480, which deals mainly
with the truncated Karatsuba multiplication, which is fast only
for univariate series.

`_mul_trunc_generic`, coming from do_trunc_classical by lftabera,
has a lot of code in common with `_mul_generic` and maybe it should be merged
with it; also, it would be nice to do the `_square_generic` optimization
for finite `prec`.



---

archive/issue_comments_102170.json:
```json
{
    "body": "**Attachment:** [trac_10532_invert.patch.gz](https://github.com/sagemath/sage/files/ticket10532/trac_10532_invert.patch.gz)",
    "created_at": "2011-02-08T18:26:43Z",
    "formatter": "markdown",
    "issue": "https://github.com/sagemath/sage/issues/10532",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/10532#issuecomment-102170",
    "user": "https://github.com/sagetrac-pernici"
}
```

**Attachment:** [trac_10532_invert.patch.gz](https://github.com/sagemath/sage/files/ticket10532/trac_10532_invert.patch.gz)



---

archive/issue_comments_102171.json:
```json
{
    "body": "<a id='comment:7'>**Comment 7:**</a>\nThe attached trac_10532_invert.patch is applied after #1956 patches and\ntrac_1956_faster_MPowerSeries_mul2.patch\n\n\nIn this patch `__invert__` is implemented using `_mul_trunc_generic`;\ninversion of a generic multivariate series becomes much faster.\n\nIn the benchmarks (0) is without this patch, (1) with it\n\n```\nsage: N = 4\nsage: R = PowerSeriesRing(QQ,N,'x')\nsage: x = R.gens()\nsage: sx = sum(x)\nsage: prec = 15\nsage: p = (1 + sx + R.O(prec))^-1 + (1 + 2*sx + R.O(prec))^-1\nsage: %time p1 = p^-1\nWall time: 0.40 s\n\nN  prec     (0)    (1)\n2  30       1.18   0.08\n2  50       30.3   0.87\n4  15       42.0   0.40\n4  20       662    3.2\n```\n\n```\nsage: N = 4\nsage: R = PowerSeriesRing(QQ,N,'x')\nsage: x = R.gens()\nsage: prec = 30\nsage: p = sum([(i+1)*x[i]^(i+1) for i in range(N)]) + R.O(prec)\nsage: p = 1 + sum([p^i/i for i in range(1,prec)])\nsage: %time p1 = p^-1\nWall time: 0.28 s\n\nN  prec     (0)    (1)\n2  30       0.37   0.03\n2  50       5.7    0.28\n4  30       32.6   0.28\n8  30       1566   1.0\n```\n\n\nA special kind of series inversion are series of degree much lower than prec, like\n\n```\np = 1 + 2*x[0] + 3*x[1] + 4*x[2] + 5*x[3]  + R.O(30)\n```\ninversion is much faster because in the iteration in the Newton method\nthe expensive multiplication at order next_prec becomes trivial.\nIt remains a square of a polynomial of degree roughly next_prec/2 .\nIn this case this patch does not change speed; in this ticket there is a lot\nof benchmarks for this case, see bench1.sage\n\n\nFinally I point out that in ticket #10720 I wrote a similar but slower\nversion of `__invert__` for series on rings of polynomials; I will improve\nthat version, but notice that the speedup of `__invert__` in a generic\nseries on rings of polynomials is much smaller than here.",
    "created_at": "2011-02-08T18:27:25Z",
    "formatter": "markdown",
    "issue": "https://github.com/sagemath/sage/issues/10532",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/10532#issuecomment-102171",
    "user": "https://github.com/sagetrac-pernici"
}
```

<a id='comment:7'>**Comment 7:**</a>
The attached trac_10532_invert.patch is applied after #1956 patches and
trac_1956_faster_MPowerSeries_mul2.patch


In this patch `__invert__` is implemented using `_mul_trunc_generic`;
inversion of a generic multivariate series becomes much faster.

In the benchmarks (0) is without this patch, (1) with it

```
sage: N = 4
sage: R = PowerSeriesRing(QQ,N,'x')
sage: x = R.gens()
sage: sx = sum(x)
sage: prec = 15
sage: p = (1 + sx + R.O(prec))^-1 + (1 + 2*sx + R.O(prec))^-1
sage: %time p1 = p^-1
Wall time: 0.40 s

N  prec     (0)    (1)
2  30       1.18   0.08
2  50       30.3   0.87
4  15       42.0   0.40
4  20       662    3.2
```

```
sage: N = 4
sage: R = PowerSeriesRing(QQ,N,'x')
sage: x = R.gens()
sage: prec = 30
sage: p = sum([(i+1)*x[i]^(i+1) for i in range(N)]) + R.O(prec)
sage: p = 1 + sum([p^i/i for i in range(1,prec)])
sage: %time p1 = p^-1
Wall time: 0.28 s

N  prec     (0)    (1)
2  30       0.37   0.03
2  50       5.7    0.28
4  30       32.6   0.28
8  30       1566   1.0
```


A special kind of series inversion are series of degree much lower than prec, like

```
p = 1 + 2*x[0] + 3*x[1] + 4*x[2] + 5*x[3]  + R.O(30)
```
inversion is much faster because in the iteration in the Newton method
the expensive multiplication at order next_prec becomes trivial.
It remains a square of a polynomial of degree roughly next_prec/2 .
In this case this patch does not change speed; in this ticket there is a lot
of benchmarks for this case, see bench1.sage


Finally I point out that in ticket #10720 I wrote a similar but slower
version of `__invert__` for series on rings of polynomials; I will improve
that version, but notice that the speedup of `__invert__` in a generic
series on rings of polynomials is much smaller than here.



---

archive/issue_comments_102172.json:
```json
{
    "body": "**Attachment:** [trac_10532_square_trunc.patch.gz](https://github.com/sagemath/sage/files/ticket10532/trac_10532_square_trunc.patch.gz)",
    "created_at": "2011-02-09T15:28:27Z",
    "formatter": "markdown",
    "issue": "https://github.com/sagemath/sage/issues/10532",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/10532#issuecomment-102172",
    "user": "https://github.com/sagetrac-pernici"
}
```

**Attachment:** [trac_10532_square_trunc.patch.gz](https://github.com/sagemath/sage/files/ticket10532/trac_10532_square_trunc.patch.gz)



---

archive/issue_comments_102173.json:
```json
{
    "body": "<a id='comment:8'>**Comment 8:**</a>\nThe attached trac_10532_square_trunc.patch is applied after #1956 patches,\ntrac_1956_faster_MPowerSeries_mul2.patch and trac_10532_invert.patch\n\n\nWith this patch truncated multiplication is optimized for squares.\n\nBenchmark comparison with PARI/GP:\n\n```\nsage: N = 4\nsage: R = PowerSeriesRing(QQ,N,'x')\nsage: x = R.gens()\nsage: sx = sum(x)\nsage: prec = 20\nsage: n = 1\nsage: %time p = ((1 + sx + R.O(prec))^-1 + (1 + 2*sx + R.O(prec))^-1)^-n\nWall time: 4.06 s\n```\n\nto do the computation with `gp` allocate more memory than the one assigned\nby default; here the computation\nis done directly with the background field\n\n```\nsage: try:\n....:     gp.allocatemem()\n....: except:\n....:     pass\n....:\nsage: N = 4\nsage: prec = 20\nsage: n = 1\nsage: sx = '+'.join(['x%d' % i for i in range(N)])\nsage: fmt = '((1 + t*(%s) + O(t^%s))^-1 + (1 + 2*t*(%s) + O(t^%s))^-1)^-%s'\nsage: %time p1 = gp(fmt %(sx,prec,sx,prec,n))\nWall time: 1.56 s\n\n(0) version of ticket #1956\n(1) with trac_10532_invert.patch\n(2) with trac_10532_square_trunc.patch\n(3) with gp (PARI/GP)\nN  prec  n   (0)    (1)    (2)    (3)\n2  30    1   1.2    0.10   0.10   0.06\n2  30    20  8.6    0.22   0.18   0.12\n2  50    1   21     1.2    1.2    0.55\n2  50    20  213    2.1    1.8    1.2\n4  15    1   42     0.46   0.46   0.22\n4  15    20  323    1.2    0.96   0.43\n4  20    1   673    4.1    4.1    1.6\n4  20    20  >7000  10     8.1    3.2\n```",
    "created_at": "2011-02-09T15:28:50Z",
    "formatter": "markdown",
    "issue": "https://github.com/sagemath/sage/issues/10532",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/10532#issuecomment-102173",
    "user": "https://github.com/sagetrac-pernici"
}
```

<a id='comment:8'>**Comment 8:**</a>
The attached trac_10532_square_trunc.patch is applied after #1956 patches,
trac_1956_faster_MPowerSeries_mul2.patch and trac_10532_invert.patch


With this patch truncated multiplication is optimized for squares.

Benchmark comparison with PARI/GP:

```
sage: N = 4
sage: R = PowerSeriesRing(QQ,N,'x')
sage: x = R.gens()
sage: sx = sum(x)
sage: prec = 20
sage: n = 1
sage: %time p = ((1 + sx + R.O(prec))^-1 + (1 + 2*sx + R.O(prec))^-1)^-n
Wall time: 4.06 s
```

to do the computation with `gp` allocate more memory than the one assigned
by default; here the computation
is done directly with the background field

```
sage: try:
....:     gp.allocatemem()
....: except:
....:     pass
....:
sage: N = 4
sage: prec = 20
sage: n = 1
sage: sx = '+'.join(['x%d' % i for i in range(N)])
sage: fmt = '((1 + t*(%s) + O(t^%s))^-1 + (1 + 2*t*(%s) + O(t^%s))^-1)^-%s'
sage: %time p1 = gp(fmt %(sx,prec,sx,prec,n))
Wall time: 1.56 s

(0) version of ticket #1956
(1) with trac_10532_invert.patch
(2) with trac_10532_square_trunc.patch
(3) with gp (PARI/GP)
N  prec  n   (0)    (1)    (2)    (3)
2  30    1   1.2    0.10   0.10   0.06
2  30    20  8.6    0.22   0.18   0.12
2  50    1   21     1.2    1.2    0.55
2  50    20  213    2.1    1.8    1.2
4  15    1   42     0.46   0.46   0.22
4  15    20  323    1.2    0.96   0.43
4  20    1   673    4.1    4.1    1.6
4  20    20  >7000  10     8.1    3.2
```



---

archive/issue_comments_102174.json:
```json
{
    "body": "<a id='comment:9'>**Comment 9:**</a>\nReplying to [pernici](#comment%3A8):\n> \n\n```\n(0) version of ticket #1956\n(1) with trac_10532_invert.patch\n(2) with trac_10532_square_trunc.patch\n(3) with gp (PARI/GP)\n```\n\nThis looks *really good* -- but I'm a little confused by the comparison with `gp` . . . If that's always faster, should we just always do the multiplication there?  There must be more subtleties involved, but I don't know *anything* about them :(",
    "created_at": "2011-02-09T16:11:37Z",
    "formatter": "markdown",
    "issue": "https://github.com/sagemath/sage/issues/10532",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/10532#issuecomment-102174",
    "user": "https://github.com/nilesjohnson"
}
```

<a id='comment:9'>**Comment 9:**</a>
Replying to [pernici](#comment%3A8):
> 

```
(0) version of ticket #1956
(1) with trac_10532_invert.patch
(2) with trac_10532_square_trunc.patch
(3) with gp (PARI/GP)
```

This looks *really good* -- but I'm a little confused by the comparison with `gp` . . . If that's always faster, should we just always do the multiplication there?  There must be more subtleties involved, but I don't know *anything* about them :(



---

archive/issue_comments_102175.json:
```json
{
    "body": "<a id='comment:10'>**Comment 10:**</a>\nniles wrote:\n>This looks *really good* -- but I'm a little confused by the comparison\n\n with `gp` . . . If that's always faster, should we just always do the\n multiplication there?  There must be more subtleties involved, but I don't\n know *anything* about them :(\n\n\nWell, I don't know either, I just looked at it today.\nI think that if one would like to use PARI, one should avoid `gp`\nas much as possible and call directly the PARI C library functions;\nin fact `gp` has a big overhead\n\n```\nsage: g = gp('1 + (x+y)*t + O(t^6)')\nsage: %timeit g^2\n25 loops, best of 3: 16 ms per loop\nsage: R.<x,y> = QQ[[]]\nsage: p = 1 + x + y + R.O(6)\nsage: %timeit p^2\n625 loops, best of 3: 56.5 \u00b5s per loop\n```\nso that it starts to be convenient to use it when the computation is long\nenough.\n\nFor this reason\nin the benchmark in the previous mail `gp` is slower for small precision\n\n```\nN  prec  n   (0)    (2)    (3)\n2  10    1   0.02   0.01   0.02\n2  20    1   0.23   0.03   0.03\n```\n\n\nIn the above benchmarks `gp` is at most 2.5x faster; \nin those cases the overhead is negligible, so I guess that using directly\nthe PARI library the speedup would be the same.",
    "created_at": "2011-02-09T18:24:51Z",
    "formatter": "markdown",
    "issue": "https://github.com/sagemath/sage/issues/10532",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/10532#issuecomment-102175",
    "user": "https://github.com/sagetrac-pernici"
}
```

<a id='comment:10'>**Comment 10:**</a>
niles wrote:
>This looks *really good* -- but I'm a little confused by the comparison

 with `gp` . . . If that's always faster, should we just always do the
 multiplication there?  There must be more subtleties involved, but I don't
 know *anything* about them :(


Well, I don't know either, I just looked at it today.
I think that if one would like to use PARI, one should avoid `gp`
as much as possible and call directly the PARI C library functions;
in fact `gp` has a big overhead

```
sage: g = gp('1 + (x+y)*t + O(t^6)')
sage: %timeit g^2
25 loops, best of 3: 16 ms per loop
sage: R.<x,y> = QQ[[]]
sage: p = 1 + x + y + R.O(6)
sage: %timeit p^2
625 loops, best of 3: 56.5 µs per loop
```
so that it starts to be convenient to use it when the computation is long
enough.

For this reason
in the benchmark in the previous mail `gp` is slower for small precision

```
N  prec  n   (0)    (2)    (3)
2  10    1   0.02   0.01   0.02
2  20    1   0.23   0.03   0.03
```


In the above benchmarks `gp` is at most 2.5x faster; 
in those cases the overhead is negligible, so I guess that using directly
the PARI library the speedup would be the same.



---

archive/issue_comments_102176.json:
```json
{
    "body": "<a id='comment:11'>**Comment 11:**</a>\nReplying to [pernici](#comment%3A10):\n> In the above benchmarks `gp` is at most 2.5x faster; \n> in those cases the overhead is negligible, so I guess that using directly\n> the PARI library the speedup would be the same.\n\nI see -- maybe -- can this patch be written to use PARI directly by default then?  In the cases where it isn't as fast, the computation time should be small anyway, right?",
    "created_at": "2011-02-09T18:53:01Z",
    "formatter": "markdown",
    "issue": "https://github.com/sagemath/sage/issues/10532",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/10532#issuecomment-102176",
    "user": "https://github.com/nilesjohnson"
}
```

<a id='comment:11'>**Comment 11:**</a>
Replying to [pernici](#comment%3A10):
> In the above benchmarks `gp` is at most 2.5x faster; 
> in those cases the overhead is negligible, so I guess that using directly
> the PARI library the speedup would be the same.

I see -- maybe -- can this patch be written to use PARI directly by default then?  In the cases where it isn't as fast, the computation time should be small anyway, right?



---

archive/issue_comments_102177.json:
```json
{
    "body": "<a id='comment:12'>**Comment 12:**</a>\nReplying to [@nilesjohnson](#comment%3A11):\n> Replying to [pernici](#comment%3A10):\n> > In the above benchmarks `gp` is at most 2.5x faster; \n> > in those cases the overhead is negligible, so I guess that using directly\n> > the PARI library the speedup would be the same.\n\n> \n> I see -- maybe -- can this patch be written to use PARI directly by default then?  In the cases where it isn't as fast, the computation time should be small anyway, right?\n\nIt depends on the use cases; a user may need to do usually a lot of computations with low precision series; then it is important that they are done fast; in the rare case in which he needs a high precision computation, maybe he does not care that it takes 3x longer. Another user may care only for long computations.\n\nAnother observation: I suspect that total degree multivariate power series implemented with PARI would require changes in the implementation in ticket #1956, not only in this patch; the background power series ring would not be `PowerSeriesRing(self.__poly_ring, T)`, but a PARI power series. For certain rings probably one cannot use PARI (e.g. symbolic rings?), then the current implementation should be used instead.\n\nMaybe it would be better to make a specialized multivariate power series class using PARI; this would be the argument of another ticket, if someone is interested in working on it; ticket #1956 and this patch would deal with the generic implementation.",
    "created_at": "2011-02-10T00:24:41Z",
    "formatter": "markdown",
    "issue": "https://github.com/sagemath/sage/issues/10532",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/10532#issuecomment-102177",
    "user": "https://github.com/sagetrac-pernici"
}
```

<a id='comment:12'>**Comment 12:**</a>
Replying to [@nilesjohnson](#comment%3A11):
> Replying to [pernici](#comment%3A10):
> > In the above benchmarks `gp` is at most 2.5x faster; 
> > in those cases the overhead is negligible, so I guess that using directly
> > the PARI library the speedup would be the same.

> 
> I see -- maybe -- can this patch be written to use PARI directly by default then?  In the cases where it isn't as fast, the computation time should be small anyway, right?

It depends on the use cases; a user may need to do usually a lot of computations with low precision series; then it is important that they are done fast; in the rare case in which he needs a high precision computation, maybe he does not care that it takes 3x longer. Another user may care only for long computations.

Another observation: I suspect that total degree multivariate power series implemented with PARI would require changes in the implementation in ticket #1956, not only in this patch; the background power series ring would not be `PowerSeriesRing(self.__poly_ring, T)`, but a PARI power series. For certain rings probably one cannot use PARI (e.g. symbolic rings?), then the current implementation should be used instead.

Maybe it would be better to make a specialized multivariate power series class using PARI; this would be the argument of another ticket, if someone is interested in working on it; ticket #1956 and this patch would deal with the generic implementation.



---

archive/issue_comments_102178.json:
```json
{
    "body": "<a id='comment:13'>**Comment 13:**</a>\nReplying to [pernici](#comment%3A12):\n\n> Another observation: I suspect that total degree multivariate power series implemented with PARI would require changes in the implementation in ticket #1956, not only in this patch; the background power series ring would not be `PowerSeriesRing(self.__poly_ring, T)`, but a PARI power series. For certain rings probably one cannot use PARI (e.g. symbolic rings?), then the current implementation should be used instead.\n\n>\n\n> \n> Maybe it would be better to make a specialized multivariate power series class using PARI; this would be the argument of another ticket, if someone is interested in working on it; ticket #1956 and this patch would deal with the generic implementation.\n\nThis sounds like a good idea -- thanks for clarifying.  The improvements you've made are certainly worth finishing and including in sage.",
    "created_at": "2011-02-10T11:55:57Z",
    "formatter": "markdown",
    "issue": "https://github.com/sagemath/sage/issues/10532",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/10532#issuecomment-102178",
    "user": "https://github.com/nilesjohnson"
}
```

<a id='comment:13'>**Comment 13:**</a>
Replying to [pernici](#comment%3A12):

> Another observation: I suspect that total degree multivariate power series implemented with PARI would require changes in the implementation in ticket #1956, not only in this patch; the background power series ring would not be `PowerSeriesRing(self.__poly_ring, T)`, but a PARI power series. For certain rings probably one cannot use PARI (e.g. symbolic rings?), then the current implementation should be used instead.

>

> 
> Maybe it would be better to make a specialized multivariate power series class using PARI; this would be the argument of another ticket, if someone is interested in working on it; ticket #1956 and this patch would deal with the generic implementation.

This sounds like a good idea -- thanks for clarifying.  The improvements you've made are certainly worth finishing and including in sage.



---

archive/issue_comments_102179.json:
```json
{
    "body": "**Attachment:** [trac_10532_send_to_bg.patch.gz](https://github.com/sagemath/sage/files/ticket10532/trac_10532_send_to_bg.patch.gz)",
    "created_at": "2011-02-15T17:09:09Z",
    "formatter": "markdown",
    "issue": "https://github.com/sagemath/sage/issues/10532",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/10532#issuecomment-102179",
    "user": "https://github.com/sagetrac-pernici"
}
```

**Attachment:** [trac_10532_send_to_bg.patch.gz](https://github.com/sagemath/sage/files/ticket10532/trac_10532_send_to_bg.patch.gz)



---

archive/issue_comments_102180.json:
```json
{
    "body": "<a id='comment:14'>**Comment 14:**</a>\nThe attached trac_10532_send_to_bg.patch fixes _send_to_bg in the case \nof multivariate series in one variable, see comments 64-70 in ticket #1956\n\n```\nsage: R = PowerSeriesRing(QQ,1,'x')                                                \nsage: f = R._poly_ring().gens()[0]\nsage: R._send_to_bg(f + f^2)\nx*T + x^2*T^2\nsage: R.random_element(4)\n-3/25*x^3 - 3*x^2 + x + O(x)^4\n```",
    "created_at": "2011-02-15T17:10:40Z",
    "formatter": "markdown",
    "issue": "https://github.com/sagemath/sage/issues/10532",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/10532#issuecomment-102180",
    "user": "https://github.com/sagetrac-pernici"
}
```

<a id='comment:14'>**Comment 14:**</a>
The attached trac_10532_send_to_bg.patch fixes _send_to_bg in the case 
of multivariate series in one variable, see comments 64-70 in ticket #1956

```
sage: R = PowerSeriesRing(QQ,1,'x')                                                
sage: f = R._poly_ring().gens()[0]
sage: R._send_to_bg(f + f^2)
x*T + x^2*T^2
sage: R.random_element(4)
-3/25*x^3 - 3*x^2 + x + O(x)^4
```
