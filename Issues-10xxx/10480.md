# Issue 10480: fast PowerSeries_poly multiplication

archive/issues_010427.json:
```json
{
    "body": "In this patch truncated multiplication of dense polynomials is\nused in `PowerSeries_poly` multiplication.\n\nin Sage-4.6 on my computer with Intel Core i7 2.8GHz\n\n```\nsage: R.<a,b> = QQ[]\nsage: K.<t> = PowerSeriesRing(R)\nsage: time p1 = (1 + a*t + b*t^2 + O(t^50))^-40\nWall time: 7.62s\n```\n\nwith this patch it takes 0.12s\nThe speed-up increases with the number of variables and with the precision.\n\nApply: trac_10480_fast_PowerSeries_poly_multiplication-alternative.patch\n\n\nAssignee: @malb\n\nCC:  @nilesjohnson @zimmermann6\n\nKeywords: power series\n\nAuthor: Mario Pernici, Luis Felipe Tabera Alonso\n\nBranch: public/ticket/10480\n\nStatus: needs_work\n\nDependencies: #10255\n\nCommit: e2cdc54972a0011715f6aae07cedc10e2d19abdc\n\nIssue created by migration from https://trac.sagemath.org/ticket/10480\n\n",
    "created_at": "2010-12-16T10:02:56Z",
    "labels": [
        "component: commutative algebra"
    ],
    "milestone": "https://github.com/sagemath/sagetest/milestones/sage-6.6",
    "title": "fast PowerSeries_poly multiplication",
    "type": "issue",
    "url": "https://github.com/sagemath/sagetest/issues/10480",
    "user": "https://trac.sagemath.org/admin/accounts/users/pernici"
}
```
In this patch truncated multiplication of dense polynomials is
used in `PowerSeries_poly` multiplication.

in Sage-4.6 on my computer with Intel Core i7 2.8GHz

```
sage: R.<a,b> = QQ[]
sage: K.<t> = PowerSeriesRing(R)
sage: time p1 = (1 + a*t + b*t^2 + O(t^50))^-40
Wall time: 7.62s
```

with this patch it takes 0.12s
The speed-up increases with the number of variables and with the precision.

Apply: trac_10480_fast_PowerSeries_poly_multiplication-alternative.patch


Assignee: @malb

CC:  @nilesjohnson @zimmermann6

Keywords: power series

Author: Mario Pernici, Luis Felipe Tabera Alonso

Branch: public/ticket/10480

Status: needs_work

Dependencies: #10255

Commit: e2cdc54972a0011715f6aae07cedc10e2d19abdc

Issue created by migration from https://trac.sagemath.org/ticket/10480





---

archive/issue_comments_112422.json:
```json
{
    "body": "Attachment [trac_10480_fast_PowerSeries_poly_multiplication.patch](tarball://root/attachments/some-uuid/ticket10480/trac_10480_fast_PowerSeries_poly_multiplication.patch) by pernici created at 2010-12-16 10:18:31",
    "created_at": "2010-12-16T10:18:31Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112422",
    "user": "https://trac.sagemath.org/admin/accounts/users/pernici"
}
```

Attachment [trac_10480_fast_PowerSeries_poly_multiplication.patch](tarball://root/attachments/some-uuid/ticket10480/trac_10480_fast_PowerSeries_poly_multiplication.patch) by pernici created at 2010-12-16 10:18:31



---

archive/issue_comments_112423.json:
```json
{
    "body": "Changing status from new to needs_work.",
    "created_at": "2010-12-16T10:53:17Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112423",
    "user": "https://github.com/lftabera"
}
```

Changing status from new to needs_work.



---

archive/issue_events_026832.json:
```json
{
    "actor": "https://github.com/lftabera",
    "created_at": "2010-12-16T10:53:17Z",
    "event": "milestoned",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "milestone": "sage-4.6.2",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sagetest/issues/10480#event-26832"
}
```



---

archive/issue_comments_112424.json:
```json
{
    "body": "<a id='comment:1'></a>Could you please check if the changes of #10255 in karatsuba multiplication provide further improvement?\n\nPowerSeries are constructed over commutative rings, but polynomial_elements do not. Hence mul_trunc needs to work also over noncommutative rings. It does not right now (al least lines 5342 and 5345 do not differenciate between left and right multiplication).\n\nI see several improvements:\n\nI think that \n\ncdef int i, j, a1len, a2len, n1, n2, ih\n\nin line 5334 should be Py_ssize_t, but maybe a cython expert should look at this.\n\nc = [0]*h in line 5346 of the patch is inefficient in several cases. One of the most contributions in 10480 is to avoid python 0 'int' in the code, that can be (relatively) expensive to coerce. I guess that this code will be slow if the base ring is a number field (that has slow coercion).\n\nThe last loop is classical multiplication up to the precision required. I wonder if part of that multiplication could use do_karatsuba or a truncated_do_karatsuba.",
    "created_at": "2010-12-16T10:53:17Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112424",
    "user": "https://github.com/lftabera"
}
```

<a id='comment:1'></a>Could you please check if the changes of #10255 in karatsuba multiplication provide further improvement?

PowerSeries are constructed over commutative rings, but polynomial_elements do not. Hence mul_trunc needs to work also over noncommutative rings. It does not right now (al least lines 5342 and 5345 do not differenciate between left and right multiplication).

I see several improvements:

I think that 

cdef int i, j, a1len, a2len, n1, n2, ih

in line 5334 should be Py_ssize_t, but maybe a cython expert should look at this.

c = [0]*h in line 5346 of the patch is inefficient in several cases. One of the most contributions in 10480 is to avoid python 0 'int' in the code, that can be (relatively) expensive to coerce. I guess that this code will be slow if the base ring is a number field (that has slow coercion).

The last loop is classical multiplication up to the precision required. I wonder if part of that multiplication could use do_karatsuba or a truncated_do_karatsuba.



---

archive/issue_comments_112425.json:
```json
{
    "body": "<a id='comment:2'></a>Some more numbers with your patch showing what I said on my previous post.\nPatch aginst a clean sage 4.6\n\nwith patch:\n\n```\nsage: K.<t>=QQ['a'][]\nsage: p1 = K.random_element(800) + O(t^990)\nsage: p2 = K.random_element(800) + O(t^990)\nsage: %time _=p1*p2\nCPU times: user 6.09 s, sys: 0.08 s, total: 6.17 s\nWall time: 6.49 s\n```\n\nwithout patch\n\n```\nsage: sage: K.<t>=QQ['a'][]\nsage: sage: p1 = K.random_element(800) + O(t^990)\nsage: sage: p2 = K.random_element(800) + O(t^990)\nsage: sage: %time _=p1*p2\nCPU times: user 3.24 s, sys: 0.03 s, total: 3.27 s\nWall time: 3.39 s\n```\n\nI think that we can define an algorithm that works like karatsuba but that has a prec parameter. If a portion will have order greater than the prec. That part is discarded.\nThe prec is updated on recursive calls.",
    "created_at": "2010-12-17T20:35:48Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112425",
    "user": "https://github.com/lftabera"
}
```

<a id='comment:2'></a>Some more numbers with your patch showing what I said on my previous post.
Patch aginst a clean sage 4.6

with patch:

```
sage: K.<t>=QQ['a'][]
sage: p1 = K.random_element(800) + O(t^990)
sage: p2 = K.random_element(800) + O(t^990)
sage: %time _=p1*p2
CPU times: user 6.09 s, sys: 0.08 s, total: 6.17 s
Wall time: 6.49 s
```

without patch

```
sage: sage: K.<t>=QQ['a'][]
sage: sage: p1 = K.random_element(800) + O(t^990)
sage: sage: p2 = K.random_element(800) + O(t^990)
sage: sage: %time _=p1*p2
CPU times: user 3.24 s, sys: 0.03 s, total: 3.27 s
Wall time: 3.39 s
```

I think that we can define an algorithm that works like karatsuba but that has a prec parameter. If a portion will have order greater than the prec. That part is discarded.
The prec is updated on recursive calls.



---

archive/issue_comments_112426.json:
```json
{
    "body": "<a id='comment:4'></a>I will try to implement the algorithm at \"A long note on Mulders\u2019 short product\" of Hanrot and Zimmermann that looks not harder than Karatsuba. The authors claim that heuristically the gain time is on the average 0.7 x Karatsuba time.\n\nAlso, the following cases have to be correctly covered:\n\n```\nsage: O(x)*O(x)\n0\nsage: O(x^2)*O(x^3)\n0\n```",
    "created_at": "2010-12-21T22:51:05Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112426",
    "user": "https://github.com/lftabera"
}
```

<a id='comment:4'></a>I will try to implement the algorithm at "A long note on Muldersâ€™ short product" of Hanrot and Zimmermann that looks not harder than Karatsuba. The authors claim that heuristically the gain time is on the average 0.7 x Karatsuba time.

Also, the following cases have to be correctly covered:

```
sage: O(x)*O(x)
0
sage: O(x^2)*O(x^3)
0
```



---

archive/issue_comments_112427.json:
```json
{
    "body": "Attachment [trac_10480_fast_PowerSeries_poly_multiplication2.patch](tarball://root/attachments/some-uuid/ticket10480/trac_10480_fast_PowerSeries_poly_multiplication2.patch) by pernici created at 2010-12-22 22:17:09\n\nbenchmark file",
    "created_at": "2010-12-22T22:17:09Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112427",
    "user": "https://trac.sagemath.org/admin/accounts/users/pernici"
}
```

Attachment [trac_10480_fast_PowerSeries_poly_multiplication2.patch](tarball://root/attachments/some-uuid/ticket10480/trac_10480_fast_PowerSeries_poly_multiplication2.patch) by pernici created at 2010-12-22 22:17:09

benchmark file



---

archive/issue_comments_112428.json:
```json
{
    "body": "<a id='comment:5'></a>Attachment [un.sage](tarball://root/attachments/some-uuid/ticket10480/un.sage) by pernici created at 2010-12-22 22:18:20\n\nHello,\n\nlftabera wrote:\n>I think that we can define an algorithm that works like karatsuba but that has a prec parameter. If a portion will have order greater than the prec. That part is discarded. The prec is updated on recursive calls.\n\n\nI followed your suggestion to perform truncated multiplication recursively,\nkeeping track of the precision, calling Karatsuba multiplication\nwhen there are no truncations.\n\n>Also, the following cases have to be correctly covered:\n\n\n```\nsage: O(x)*O(x)\n0\nsage: O(x^2)*O(x^3)\n0\n```\n\nThe new patch trac_10480_fast_PowerSeries_poly_multiplication2.patch passes all tests, included these.\nIt performs generally better than the unpached Sage4.6,\nexcept the case in which the series has degree lower than the precision,\nlike your example\n\n```\np1 = K.random_element(800) + O(t^990)\n```\n\non which it is typically up to 50% slower, while with the previous\npatch it was 2x slower.\n\nThe first patch was also slow in other cases, see below.\n\nThe performance of truncated multiplication vs Karatsuba multiplication\ndepends on the distribution of the terms in the univariate series;\ntruncated multiplication is fast when the high powers in the univariate\nvariable t have many more terms than the low powers, like in this example\n\nusing this patch:\n\n```\nsage: from sage.rings.power_series_poly import PowerSeries_poly\nsage: R.<a,b> = QQ[]\nsage: K.<t> = R[]\nsage: p = (1 + a*t + b*t^2 + O(t^50))^-1\nsage: v = [len(x.coefficients()) for x in p.coefficients()]\nsage: v[:6], v[-6:]\n([1, 1, 2, 2, 3, 3], [23, 23, 24, 24, 25, 25])\nsage: %timeit p*p\n25 loops, best of 3: 26 ms per loop\nsage: %timeit PowerSeries_poly(p.parent(),p.polynomial().mul_trunc(p.polynomial(),50,1),50)\n125 loops, best of 3: 4.89 ms per loop\nsage: p*p - PowerSeries_poly(p.parent(),p.polynomial().mul_trunc(p.polynomial(),50,1),50)\nO(t^50)\n```\n\nunpached Sage (main): \n\n```\nsage: %timeit p*p\n5 loops, best of 3: 833 ms per loop\n```\n\n`mul_trunc(self, right, h, generic=1)`  calls `do_mul_trunc_generic`, which\nis the algorithm used in the first patch; in this case it is faster,\nbut in other cases it is slower, so I think it is better to use `do_mul_trunc`.\nHowever in multivariate series `do_mul_trunc_generic` seems to perform always\nbetter; I will post a patch about this in ticket #1956\n\n```\np = K.random_element(50) + O(t^50) \n```\n\nhas uniform distribution; for `p*p` the patched version performs as the main version.\n\n\nIn un.sage one takes N subsequent `p=p*(p+1)` starting with a\nrandom univariate series on a polynomial ring with n variables;\nthe ratio of the number of terms in the upper half of the univariate series\nand the lower half is given.\nThe ratio is close to 1 in a random polynomial, and increases with n and N.\nThere is a correlation between the speedup\nusing truncated multiplication and this ratio.\nThe old patch (patch1) in some cases performs badly; the worst case is given.\n\n```\nn variables in polynomial ring on QQ; h precision;\nN = number of times p = p*(p+1) is taken\nn=1\nh=20  N=1     2    3     4    5    6   7\nratio  0.86  0.98  1     1    1    1   1\nmain   0.005 0.008 0.022 0.09 0.41 3.5 53.5\npatch  0.004 0.006 0.016 0.06 0.31 2.5 41.5\nh=100\nratio  0.93  1     1     1    1\nmain   0.049 0.14  0.47  1.6  7.9\npatch  0.043 0.10  0.31  1.1  5.5\nh=500\nratio  0.96  1.0\nmain   1.5   20.9\npatch1 2.0   49.1\npatch  1.3   17.0\n\nn=2\nh=20\nratio  0.81  1.06  1.10  1.19 1.34\nmain   0.009 0.04  0.30  4.3  134\npatch  0.007 0.03  0.22  2.6  61\nh=100\nratio  1.05  1.01  1.0   1.0\nmain   0.11  0.80  7.8   171\npatch  0.09  0.59  5.5   103\n\nn=4\nh=20\nratio  1.08  1.53  1.64\nmain   0.015 0.35  21.0\npatch  0.010 0.19  10.9\n\nn=8\nh=10\nratio  1.28  2.67  5.43\nmain   0.008 0.38  127\npatch  0.006 0.046 4.4\n\nn=16\nh=10\nratio  1.00  2.77  8.90\nmain   0.013 1.95  > 19m(6GB)\npatch  0.009 0.14  29.0(0.5GB)\n```\n\nIn the last example I stopped the computation with main because too much\nmemory was used.\n\n> I will try to implement the algorithm at \"A long note on Mulders\u2019 short product\" of Hanrot and Zimmermann that looks not harder than Karatsuba. The authors claim that heuristically the gain time is on the average 0.7 x Karatsuba time.\n\n\nIf I understand correctly, that paper deals with univariate series\non numeric rings. Maybe in the case of univariate series over polynomial\nrings one could use the list of the number of elements to guide the\nalgorithm.",
    "created_at": "2010-12-22T22:18:20Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112428",
    "user": "https://trac.sagemath.org/admin/accounts/users/pernici"
}
```

<a id='comment:5'></a>Attachment [un.sage](tarball://root/attachments/some-uuid/ticket10480/un.sage) by pernici created at 2010-12-22 22:18:20

Hello,

lftabera wrote:
>I think that we can define an algorithm that works like karatsuba but that has a prec parameter. If a portion will have order greater than the prec. That part is discarded. The prec is updated on recursive calls.


I followed your suggestion to perform truncated multiplication recursively,
keeping track of the precision, calling Karatsuba multiplication
when there are no truncations.

>Also, the following cases have to be correctly covered:


```
sage: O(x)*O(x)
0
sage: O(x^2)*O(x^3)
0
```

The new patch trac_10480_fast_PowerSeries_poly_multiplication2.patch passes all tests, included these.
It performs generally better than the unpached Sage4.6,
except the case in which the series has degree lower than the precision,
like your example

```
p1 = K.random_element(800) + O(t^990)
```

on which it is typically up to 50% slower, while with the previous
patch it was 2x slower.

The first patch was also slow in other cases, see below.

The performance of truncated multiplication vs Karatsuba multiplication
depends on the distribution of the terms in the univariate series;
truncated multiplication is fast when the high powers in the univariate
variable t have many more terms than the low powers, like in this example

using this patch:

```
sage: from sage.rings.power_series_poly import PowerSeries_poly
sage: R.<a,b> = QQ[]
sage: K.<t> = R[]
sage: p = (1 + a*t + b*t^2 + O(t^50))^-1
sage: v = [len(x.coefficients()) for x in p.coefficients()]
sage: v[:6], v[-6:]
([1, 1, 2, 2, 3, 3], [23, 23, 24, 24, 25, 25])
sage: %timeit p*p
25 loops, best of 3: 26 ms per loop
sage: %timeit PowerSeries_poly(p.parent(),p.polynomial().mul_trunc(p.polynomial(),50,1),50)
125 loops, best of 3: 4.89 ms per loop
sage: p*p - PowerSeries_poly(p.parent(),p.polynomial().mul_trunc(p.polynomial(),50,1),50)
O(t^50)
```

unpached Sage (main): 

```
sage: %timeit p*p
5 loops, best of 3: 833 ms per loop
```

`mul_trunc(self, right, h, generic=1)`  calls `do_mul_trunc_generic`, which
is the algorithm used in the first patch; in this case it is faster,
but in other cases it is slower, so I think it is better to use `do_mul_trunc`.
However in multivariate series `do_mul_trunc_generic` seems to perform always
better; I will post a patch about this in ticket #1956

```
p = K.random_element(50) + O(t^50) 
```

has uniform distribution; for `p*p` the patched version performs as the main version.


In un.sage one takes N subsequent `p=p*(p+1)` starting with a
random univariate series on a polynomial ring with n variables;
the ratio of the number of terms in the upper half of the univariate series
and the lower half is given.
The ratio is close to 1 in a random polynomial, and increases with n and N.
There is a correlation between the speedup
using truncated multiplication and this ratio.
The old patch (patch1) in some cases performs badly; the worst case is given.

```
n variables in polynomial ring on QQ; h precision;
N = number of times p = p*(p+1) is taken
n=1
h=20  N=1     2    3     4    5    6   7
ratio  0.86  0.98  1     1    1    1   1
main   0.005 0.008 0.022 0.09 0.41 3.5 53.5
patch  0.004 0.006 0.016 0.06 0.31 2.5 41.5
h=100
ratio  0.93  1     1     1    1
main   0.049 0.14  0.47  1.6  7.9
patch  0.043 0.10  0.31  1.1  5.5
h=500
ratio  0.96  1.0
main   1.5   20.9
patch1 2.0   49.1
patch  1.3   17.0

n=2
h=20
ratio  0.81  1.06  1.10  1.19 1.34
main   0.009 0.04  0.30  4.3  134
patch  0.007 0.03  0.22  2.6  61
h=100
ratio  1.05  1.01  1.0   1.0
main   0.11  0.80  7.8   171
patch  0.09  0.59  5.5   103

n=4
h=20
ratio  1.08  1.53  1.64
main   0.015 0.35  21.0
patch  0.010 0.19  10.9

n=8
h=10
ratio  1.28  2.67  5.43
main   0.008 0.38  127
patch  0.006 0.046 4.4

n=16
h=10
ratio  1.00  2.77  8.90
main   0.013 1.95  > 19m(6GB)
patch  0.009 0.14  29.0(0.5GB)
```

In the last example I stopped the computation with main because too much
memory was used.

> I will try to implement the algorithm at "A long note on Muldersâ€™ short product" of Hanrot and Zimmermann that looks not harder than Karatsuba. The authors claim that heuristically the gain time is on the average 0.7 x Karatsuba time.


If I understand correctly, that paper deals with univariate series
on numeric rings. Maybe in the case of univariate series over polynomial
rings one could use the list of the number of elements to guide the
algorithm.



---

archive/issue_comments_112429.json:
```json
{
    "body": "<a id='comment:6'></a>Oops, we have been duplicating work,\n\nI have written a proof of concept of a truncated Karatsuba to check that it derives a correct algorithm. It is much much slower than plain sage. It needs to eliminate unnecesary slicing and calls of type K(f).list()\n\nI will take a look at your patch.\n\nMy patch depends on #10255",
    "created_at": "2010-12-23T15:41:32Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112429",
    "user": "https://github.com/lftabera"
}
```

<a id='comment:6'></a>Oops, we have been duplicating work,

I have written a proof of concept of a truncated Karatsuba to check that it derives a correct algorithm. It is much much slower than plain sage. It needs to eliminate unnecesary slicing and calls of type K(f).list()

I will take a look at your patch.

My patch depends on #10255



---

archive/issue_comments_112430.json:
```json
{
    "body": "<a id='comment:7'></a>Mario,\n\nThis part on your patch\n\n```\nzeros = [0] * e \nt0 = do_mul_trunc(b,d,h) \nt1a = do_mul_trunc(a,d,h-e) \nt1b = do_mul_trunc(b,c,h-e) \nt1 = zeros + _karatsuba_sum(t1a,t1b) \nt2 = zeros + zeros + do_mul_trunc(a,c,h-2*e) \nreturn _karatsuba_sum(t0,_karatsuba_sum(t1,t2)) \n```\n\nIs inefficient, 2/3 of the operations in this part is adding a ring element with python zero. This was included in original do_karatsuba and was the reason to rewrite it in #10255.\n\nI get the following numbers with the patches:\n\n```\nsage: R.<a,b> = QQ[]\nsage: K.<t> = PowerSeriesRing(R)\nsage: time p1 = (1 + a*t + b*t^2 + O(t^50))^-40\n```\n\nNo patch: 8.92\n\nmultiplication2: 0.66\n\nalternative: 0.45\n\n```\nsage: K.<x>=PowerSeriesRing(QQ[I])\nsage: p1 = K.random_element(800)\nsage: p2 = K.random_element(800)\n```\n\nNo patch: 1.59\n\n#10255: 0.24 \n\nmultiplication2: 1.57 \n\nalternative2: 0.19\n\n```\nsage: R.<a,b> = QQ[]\nsage: K.<t> = PowerSeriesRing(R)\nsage: p1 = QQ[a,b][t].random_element(800) + O(t^800)\nsage: p2 = QQ[a,b][t].random_element(800) + O(t^800)\n```\n\nNo patch: 5.75 \n \n#10255: 5.25 \n\nmultiplication2: 4.62 \n\nalternative2: 2.41",
    "created_at": "2010-12-28T09:53:31Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112430",
    "user": "https://github.com/lftabera"
}
```

<a id='comment:7'></a>Mario,

This part on your patch

```
zeros = [0] * e 
t0 = do_mul_trunc(b,d,h) 
t1a = do_mul_trunc(a,d,h-e) 
t1b = do_mul_trunc(b,c,h-e) 
t1 = zeros + _karatsuba_sum(t1a,t1b) 
t2 = zeros + zeros + do_mul_trunc(a,c,h-2*e) 
return _karatsuba_sum(t0,_karatsuba_sum(t1,t2)) 
```

Is inefficient, 2/3 of the operations in this part is adding a ring element with python zero. This was included in original do_karatsuba and was the reason to rewrite it in #10255.

I get the following numbers with the patches:

```
sage: R.<a,b> = QQ[]
sage: K.<t> = PowerSeriesRing(R)
sage: time p1 = (1 + a*t + b*t^2 + O(t^50))^-40
```

No patch: 8.92

multiplication2: 0.66

alternative: 0.45

```
sage: K.<x>=PowerSeriesRing(QQ[I])
sage: p1 = K.random_element(800)
sage: p2 = K.random_element(800)
```

No patch: 1.59

#10255: 0.24 

multiplication2: 1.57 

alternative2: 0.19

```
sage: R.<a,b> = QQ[]
sage: K.<t> = PowerSeriesRing(R)
sage: p1 = QQ[a,b][t].random_element(800) + O(t^800)
sage: p2 = QQ[a,b][t].random_element(800) + O(t^800)
```

No patch: 5.75 
 
#10255: 5.25 

multiplication2: 4.62 

alternative2: 2.41



---

archive/issue_comments_112431.json:
```json
{
    "body": "<a id='comment:8'></a>You are right, your patch is faster on generic univariate series; I will look at it.\n\nIn the related ticket #1956 on multivariate series do_mul_trunc_generic is faster than Karatsuba even using your improved version, in the benchmarks I posted there.",
    "created_at": "2010-12-28T12:34:17Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112431",
    "user": "https://trac.sagemath.org/admin/accounts/users/pernici"
}
```

<a id='comment:8'></a>You are right, your patch is faster on generic univariate series; I will look at it.

In the related ticket #1956 on multivariate series do_mul_trunc_generic is faster than Karatsuba even using your improved version, in the benchmarks I posted there.



---

archive/issue_comments_112432.json:
```json
{
    "body": "<a id='comment:9'></a>In that case, one can play with set_karatsuba_threshold in the underlying univariate polynomial ring to try to find a better balance between karatsuba and classical multiplication.",
    "created_at": "2010-12-28T17:37:23Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112432",
    "user": "https://github.com/lftabera"
}
```

<a id='comment:9'></a>In that case, one can play with set_karatsuba_threshold in the underlying univariate polynomial ring to try to find a better balance between karatsuba and classical multiplication.



---

archive/issue_comments_112433.json:
```json
{
    "body": "<a id='comment:10'></a>Replying to [comment:9 lftabera]:\n> In that case, one can play with set_karatsuba_threshold in the underlying univariate polynomial ring to try to find a better balance between karatsuba and classical multiplication.\n\n\nOptimizing multivariate power series for the algorithms here is now #10532.  Since I've never heard of the Karatsuba algorithm before, could someone here point me to a reference which would explain it well enough for me to know what the better balance is? (or just tell me :)\n\nthanks,\nNiles\n\np.s.  thanks to those of you involved with this -- I think it's awesome to have these tailored algorithms in Sage!",
    "created_at": "2010-12-29T16:04:57Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112433",
    "user": "https://github.com/nilesjohnson"
}
```

<a id='comment:10'></a>Replying to [comment:9 lftabera]:
> In that case, one can play with set_karatsuba_threshold in the underlying univariate polynomial ring to try to find a better balance between karatsuba and classical multiplication.


Optimizing multivariate power series for the algorithms here is now #10532.  Since I've never heard of the Karatsuba algorithm before, could someone here point me to a reference which would explain it well enough for me to know what the better balance is? (or just tell me :)

thanks,
Niles

p.s.  thanks to those of you involved with this -- I think it's awesome to have these tailored algorithms in Sage!



---

archive/issue_comments_112434.json:
```json
{
    "body": "<a id='comment:11'></a>Well, Karatsuba is just the first algorithm you can find on faster polynomial multiplication. There is no good balance that will work for every ring. For a fixed ring it even depends on the specific input as has been shown in Mario's examples.\n\nvirtually any book on computer algebra will mention Karatsuba method of multiplication. You could take a look, for example, to Joachim von zur Gathen, J\u00fcrgen Gerhard, \"Modern Computer Algebra\" were Karatsuba and Sch\u00f6nhage\u2013Strassen methods are discussed.",
    "created_at": "2011-01-03T09:56:51Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112434",
    "user": "https://github.com/lftabera"
}
```

<a id='comment:11'></a>Well, Karatsuba is just the first algorithm you can find on faster polynomial multiplication. There is no good balance that will work for every ring. For a fixed ring it even depends on the specific input as has been shown in Mario's examples.

virtually any book on computer algebra will mention Karatsuba method of multiplication. You could take a look, for example, to Joachim von zur Gathen, JÃ¼rgen Gerhard, "Modern Computer Algebra" were Karatsuba and SchÃ¶nhageâ€“Strassen methods are discussed.



---

archive/issue_comments_112435.json:
```json
{
    "body": "<a id='comment:12'></a>lftabera wrote:\n>In that case, one can play with set_karatsuba_threshold in the underlying univariate polynomial ring to try to find a better balance between karatsuba and classical multiplication.\n\n\nRight, one can always use your Karatsuba code; in the case of multivariate\nseries it seems to me that the best value for K_threshold is infinity.\nI have posted some benchmarks in #10532; I have no idea why,\nbut the case K_threshold =infinity and classical multiplication\nperform the same for QQ and GF(7), while the former performs much better\nthan the latter in the case of RR; I guess that this might generalize to\nthe statement that the former performs much better than the latter in the\ncase of (a class of) fields not covered by libsingular.\n\nI do not think that optimizing the code to avoid summing to Python 0\nwould change much the performance of do_mul_trunc,\nsince that part of the code takes little time.\nI think that do_trunc_karatsuba is faster than do_mul_trunc\nbecause in the former there is a clever split\n\n```\nleft_even  = left[::2]; left_odd   = left[1::2] \n```\ncorresponding to\nseparating the polynomial `p(t)` in `p_even(t^2)` and `t*p_odd(t^2)`\nso that the precision `prec` in `t` is reduced to the precision `n1=(prec+1)//2` in `t^2`\n\n```\nl = do_trunc_karatsuba(left_even, right_even, n1, K_threshold)\n```\nwhile in the latter b and d are the polynomials reduced to `O(t^e)`,\nwith `e` close to `prec//2`, so that the product is done at full precision\n\n```\nt0 = do_mul_trunc(b,d,h), with h = prec.\n```\n\nThe middle products in the two cases are comparable.\n\nMaybe you could add a comment about the splitting in do_trunc_karatsuba?\nAlso there is in the docstring of do_generic_product the misprint `bellow` .",
    "created_at": "2011-01-09T17:32:45Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112435",
    "user": "https://trac.sagemath.org/admin/accounts/users/pernici"
}
```

<a id='comment:12'></a>lftabera wrote:
>In that case, one can play with set_karatsuba_threshold in the underlying univariate polynomial ring to try to find a better balance between karatsuba and classical multiplication.


Right, one can always use your Karatsuba code; in the case of multivariate
series it seems to me that the best value for K_threshold is infinity.
I have posted some benchmarks in #10532; I have no idea why,
but the case K_threshold =infinity and classical multiplication
perform the same for QQ and GF(7), while the former performs much better
than the latter in the case of RR; I guess that this might generalize to
the statement that the former performs much better than the latter in the
case of (a class of) fields not covered by libsingular.

I do not think that optimizing the code to avoid summing to Python 0
would change much the performance of do_mul_trunc,
since that part of the code takes little time.
I think that do_trunc_karatsuba is faster than do_mul_trunc
because in the former there is a clever split

```
left_even  = left[::2]; left_odd   = left[1::2] 
```
corresponding to
separating the polynomial `p(t)` in `p_even(t^2)` and `t*p_odd(t^2)`
so that the precision `prec` in `t` is reduced to the precision `n1=(prec+1)//2` in `t^2`

```
l = do_trunc_karatsuba(left_even, right_even, n1, K_threshold)
```
while in the latter b and d are the polynomials reduced to `O(t^e)`,
with `e` close to `prec//2`, so that the product is done at full precision

```
t0 = do_mul_trunc(b,d,h), with h = prec.
```

The middle products in the two cases are comparable.

Maybe you could add a comment about the splitting in do_trunc_karatsuba?
Also there is in the docstring of do_generic_product the misprint `bellow` .



---

archive/issue_comments_112436.json:
```json
{
    "body": "<a id='comment:13'></a>I will take a look and include your suggestions.",
    "created_at": "2011-01-09T19:59:41Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112436",
    "user": "https://github.com/lftabera"
}
```

<a id='comment:13'></a>I will take a look and include your suggestions.



---

archive/issue_comments_112437.json:
```json
{
    "body": "<a id='comment:14'></a>In ticket #10720 I used truncated multiplication from this ticket to speedup \nnth_root and inversion for series on polynomial rings. The speedup increases with\nthe number of variables.",
    "created_at": "2011-02-05T16:54:02Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112437",
    "user": "https://trac.sagemath.org/admin/accounts/users/pernici"
}
```

<a id='comment:14'></a>In ticket #10720 I used truncated multiplication from this ticket to speedup 
nth_root and inversion for series on polynomial rings. The speedup increases with
the number of variables.



---

archive/issue_comments_112438.json:
```json
{
    "body": "<a id='comment:15'></a>Previous implementation was not better than full multiplication. I  have added a patch with original Mulder's short multiplication. If the cost of operations is similar for all coefficients of the power series, then the short multiplication compatible with karatsuba will be faster than the naive one.\n\nSaid this, for multivariate power series, typically higher terms are big polynomials with significant multiplication cost. That is why the generic multiplication is better in those cases.\n\nApply: trac_10480_fast_Powerseries_Mulder.patch",
    "created_at": "2013-03-05T14:01:20Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112438",
    "user": "https://github.com/lftabera"
}
```

<a id='comment:15'></a>Previous implementation was not better than full multiplication. I  have added a patch with original Mulder's short multiplication. If the cost of operations is similar for all coefficients of the power series, then the short multiplication compatible with karatsuba will be faster than the naive one.

Said this, for multivariate power series, typically higher terms are big polynomials with significant multiplication cost. That is why the generic multiplication is better in those cases.

Apply: trac_10480_fast_Powerseries_Mulder.patch



---

archive/issue_comments_112439.json:
```json
{
    "body": "Changing status from needs_work to needs_review.",
    "created_at": "2013-03-05T14:01:20Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112439",
    "user": "https://github.com/lftabera"
}
```

Changing status from needs_work to needs_review.



---

archive/issue_comments_112440.json:
```json
{
    "body": "Mulder algorithm",
    "created_at": "2013-03-05T14:09:47Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112440",
    "user": "https://github.com/lftabera"
}
```

Mulder algorithm



---

archive/issue_comments_112441.json:
```json
{
    "body": "<a id='comment:16'></a>Attachment [trac_10480_fast_Powerseries_Mulder.patch](tarball://root/attachments/some-uuid/ticket10480/trac_10480_fast_Powerseries_Mulder.patch) by @lftabera created at 2013-03-05 14:10:33\n\nApply: trac_10480_fast_Powerseries_Mulder.patch",
    "created_at": "2013-03-05T14:10:33Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112441",
    "user": "https://github.com/lftabera"
}
```

<a id='comment:16'></a>Attachment [trac_10480_fast_Powerseries_Mulder.patch](tarball://root/attachments/some-uuid/ticket10480/trac_10480_fast_Powerseries_Mulder.patch) by @lftabera created at 2013-03-05 14:10:33

Apply: trac_10480_fast_Powerseries_Mulder.patch



---

archive/issue_comments_112442.json:
```json
{
    "body": "<a id='comment:17'></a>Use only Mulders method patch\n\nApply: trac_10480_fast_Powerseries_Mulder.patch",
    "created_at": "2013-03-06T12:13:48Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112442",
    "user": "https://github.com/lftabera"
}
```

<a id='comment:17'></a>Use only Mulders method patch

Apply: trac_10480_fast_Powerseries_Mulder.patch



---

archive/issue_comments_112443.json:
```json
{
    "body": "<a id='comment:18'></a>Replying to [comment:17 lftabera]:\n\nGlad to see some progress here!  I don't fully understand some of your remarks though; could you post some timings  with and without the various patches here, demonstrating the relative advantages?",
    "created_at": "2013-03-08T18:15:33Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112443",
    "user": "https://github.com/nilesjohnson"
}
```

<a id='comment:18'></a>Replying to [comment:17 lftabera]:

Glad to see some progress here!  I don't fully understand some of your remarks though; could you post some timings  with and without the various patches here, demonstrating the relative advantages?



---

archive/issue_comments_112444.json:
```json
{
    "body": "Changing status from needs_review to needs_work.",
    "created_at": "2013-03-10T21:52:13Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112444",
    "user": "https://github.com/lftabera"
}
```

Changing status from needs_review to needs_work.



---

archive/issue_comments_112445.json:
```json
{
    "body": "<a id='comment:19'></a>mmm, it seems that my two-year old patch is faster in more instances than the new one.",
    "created_at": "2013-03-10T21:52:13Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112445",
    "user": "https://github.com/lftabera"
}
```

<a id='comment:19'></a>mmm, it seems that my two-year old patch is faster in more instances than the new one.



---

archive/issue_comments_112446.json:
```json
{
    "body": "rebase against 5.10.beta2",
    "created_at": "2013-05-15T08:50:41Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112446",
    "user": "https://github.com/lftabera"
}
```

rebase against 5.10.beta2



---

archive/issue_comments_112447.json:
```json
{
    "body": "Description changed:\n``````diff\n--- \n+++ \n@@ -13,6 +13,9 @@\n with this patch it takes 0.12s\n The speed-up increases with the number of variables and with the precision.\n \n+Apply: trac_10480_fast_PowerSeries_poly_multiplication-alternative.patch\n+\n+\n Author: mario pernici\n \n Issue created by migration from https://trac.sagemath.org/ticket/10480\n``````\n",
    "created_at": "2013-05-15T08:52:04Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112447",
    "user": "https://github.com/lftabera"
}
```

Description changed:
``````diff
--- 
+++ 
@@ -13,6 +13,9 @@
 with this patch it takes 0.12s
 The speed-up increases with the number of variables and with the precision.
 
+Apply: trac_10480_fast_PowerSeries_poly_multiplication-alternative.patch
+
+
 Author: mario pernici
 
 Issue created by migration from https://trac.sagemath.org/ticket/10480
``````




---

archive/issue_comments_112448.json:
```json
{
    "body": "Changing status from needs_work to needs_review.",
    "created_at": "2013-05-15T08:52:04Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112448",
    "user": "https://github.com/lftabera"
}
```

Changing status from needs_work to needs_review.



---

archive/issue_comments_112449.json:
```json
{
    "body": "<a id='comment:20'></a>Attachment [trac_10480_fast_PowerSeries_poly_multiplication-alternative.patch](tarball://root/attachments/some-uuid/ticket10480/trac_10480_fast_PowerSeries_poly_multiplication-alternative.patch) by @lftabera created at 2013-05-15 08:52:04\n\nI made some experiments and Mulder's algorithm is generally worse and when it is better, the gain is residual so I go back to my first proposal.\n\nNote that the underlying series in #10532 are rather special, so this method as is is not the best for that case.\n\nApply: trac_10480_fast_PowerSeries_poly_multiplication-alternative.patch",
    "created_at": "2013-05-15T08:52:04Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112449",
    "user": "https://github.com/lftabera"
}
```

<a id='comment:20'></a>Attachment [trac_10480_fast_PowerSeries_poly_multiplication-alternative.patch](tarball://root/attachments/some-uuid/ticket10480/trac_10480_fast_PowerSeries_poly_multiplication-alternative.patch) by @lftabera created at 2013-05-15 08:52:04

I made some experiments and Mulder's algorithm is generally worse and when it is better, the gain is residual so I go back to my first proposal.

Note that the underlying series in #10532 are rather special, so this method as is is not the best for that case.

Apply: trac_10480_fast_PowerSeries_poly_multiplication-alternative.patch



---

archive/issue_events_026833.json:
```json
{
    "actor": "https://github.com/jdemeyer",
    "created_at": "2013-08-13T15:35:53Z",
    "event": "demilestoned",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "milestone": "sage-4.6.2",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sagetest/issues/10480#event-26833"
}
```



---

archive/issue_events_026834.json:
```json
{
    "actor": "https://github.com/jdemeyer",
    "created_at": "2013-08-13T15:35:53Z",
    "event": "milestoned",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "milestone": "sage-5.12",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sagetest/issues/10480#event-26834"
}
```



---

archive/issue_events_026835.json:
```json
{
    "actor": "https://trac.sagemath.org/admin/accounts/users/vbraun_spam",
    "created_at": "2014-01-30T21:20:52Z",
    "event": "demilestoned",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "milestone": "sage-5.12",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sagetest/issues/10480#event-26835"
}
```



---

archive/issue_events_026836.json:
```json
{
    "actor": "https://trac.sagemath.org/admin/accounts/users/vbraun_spam",
    "created_at": "2014-01-30T21:20:52Z",
    "event": "milestoned",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "milestone": "sage-6.2",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sagetest/issues/10480#event-26836"
}
```



---

archive/issue_comments_112450.json:
```json
{
    "body": "<a id='comment:23'></a>Have you looked at the implementation of Karatsuba and Sch\u00f6nhage-Strassen in GMP-ECM? Quote:\n\nGMP-ECM features Sch\u00f6nhage-Strassen multiplication for polynomials in \nstage 2 when factoring Fermat numbers (not in the new, fast stage 2 for\nP+1 and P-1. This is to be implemented.) This greatly reduces the number of \nmodular multiplications required, thus improving speed. It does, however, \nrestrict the length of the polynomials to powers of two, so that for a given \nnumber of blocks (-k parameter), the B2 value can only increase by factors of \napproximately 4.\nFor the number of blocks, choices of 2, 3 or 4 usually give best performance.\nHowever, if the polynomial degree becomes too large, relatively expensive\nKaratsuba or Toom-Coom methods are required to split the polynomial before\nSch\u00f6nhage-Strassen's method can handle them. That can make a larger number \nof blocks worthwhile. ...",
    "created_at": "2014-04-22T09:53:42Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112450",
    "user": "https://github.com/rwst"
}
```

<a id='comment:23'></a>Have you looked at the implementation of Karatsuba and SchÃ¶nhage-Strassen in GMP-ECM? Quote:

GMP-ECM features SchÃ¶nhage-Strassen multiplication for polynomials in 
stage 2 when factoring Fermat numbers (not in the new, fast stage 2 for
P+1 and P-1. This is to be implemented.) This greatly reduces the number of 
modular multiplications required, thus improving speed. It does, however, 
restrict the length of the polynomials to powers of two, so that for a given 
number of blocks (-k parameter), the B2 value can only increase by factors of 
approximately 4.
For the number of blocks, choices of 2, 3 or 4 usually give best performance.
However, if the polynomial degree becomes too large, relatively expensive
Karatsuba or Toom-Coom methods are required to split the polynomial before
SchÃ¶nhage-Strassen's method can handle them. That can make a larger number 
of blocks worthwhile. ...



---

archive/issue_comments_112451.json:
```json
{
    "body": "<a id='comment:24'></a>I'm new to this ticket, thus please forgive me if some comments are out of scope.\n\nAbout Mulders' algorithm, using a fixed cutoff point k = 25/36*n is not optimal in\npractice, where it is better to tune the best k for each n (up to say n=1024) as we do in GNU MPFR.\n\nSince truncated (polynomial) multiplication is potentially useful in other parts of Sage, it would make sense to have the code implementing truncated multiplication and the one using it for power series in two different tickets, no?\n\nPaul",
    "created_at": "2014-04-22T11:21:29Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112451",
    "user": "https://github.com/zimmermann6"
}
```

<a id='comment:24'></a>I'm new to this ticket, thus please forgive me if some comments are out of scope.

About Mulders' algorithm, using a fixed cutoff point k = 25/36*n is not optimal in
practice, where it is better to tune the best k for each n (up to say n=1024) as we do in GNU MPFR.

Since truncated (polynomial) multiplication is potentially useful in other parts of Sage, it would make sense to have the code implementing truncated multiplication and the one using it for power series in two different tickets, no?

Paul



---

archive/issue_events_026837.json:
```json
{
    "actor": "https://trac.sagemath.org/admin/accounts/users/vbraun_spam",
    "created_at": "2014-05-06T15:20:58Z",
    "event": "demilestoned",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "milestone": "sage-6.2",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sagetest/issues/10480#event-26837"
}
```



---

archive/issue_events_026838.json:
```json
{
    "actor": "https://trac.sagemath.org/admin/accounts/users/vbraun_spam",
    "created_at": "2014-05-06T15:20:58Z",
    "event": "milestoned",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "milestone": "sage-6.3",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sagetest/issues/10480#event-26838"
}
```



---

archive/issue_events_026839.json:
```json
{
    "actor": "https://trac.sagemath.org/admin/accounts/users/vbraun_spam",
    "created_at": "2014-08-10T16:51:03Z",
    "event": "demilestoned",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "milestone": "sage-6.3",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sagetest/issues/10480#event-26839"
}
```



---

archive/issue_events_026840.json:
```json
{
    "actor": "https://trac.sagemath.org/admin/accounts/users/vbraun_spam",
    "created_at": "2014-08-10T16:51:03Z",
    "event": "milestoned",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "milestone": "sage-6.4",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sagetest/issues/10480#event-26840"
}
```



---

archive/issue_comments_112452.json:
```json
{
    "body": "<a id='comment:27'></a>made a git branch on 6.4.rc1\n\n---\nNew commits:",
    "created_at": "2014-11-02T17:52:18Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112452",
    "user": "https://github.com/fchapoton"
}
```

<a id='comment:27'></a>made a git branch on 6.4.rc1

---
New commits:



---

archive/issue_comments_112453.json:
```json
{
    "body": "<a id='comment:28'></a>Branch pushed to git repo; I updated commit sha1. New commits:",
    "created_at": "2015-02-18T09:16:28Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112453",
    "user": "https://trac.sagemath.org/admin/accounts/users/git"
}
```

<a id='comment:28'></a>Branch pushed to git repo; I updated commit sha1. New commits:



---

archive/issue_comments_112454.json:
```json
{
    "body": "Changing status from needs_review to needs_work.",
    "created_at": "2015-02-23T19:41:34Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112454",
    "user": "https://github.com/fchapoton"
}
```

Changing status from needs_review to needs_work.



---

archive/issue_events_026841.json:
```json
{
    "actor": "https://github.com/fchapoton",
    "created_at": "2015-02-23T19:41:34Z",
    "event": "demilestoned",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "milestone": "sage-6.4",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sagetest/issues/10480#event-26841"
}
```



---

archive/issue_events_026842.json:
```json
{
    "actor": "https://github.com/fchapoton",
    "created_at": "2015-02-23T19:41:34Z",
    "event": "milestoned",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "milestone": "sage-6.6",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sagetest/issues/10480#event-26842"
}
```



---

archive/issue_comments_112455.json:
```json
{
    "body": "<a id='comment:29'></a>Branch does not apply",
    "created_at": "2015-02-23T19:41:34Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112455",
    "user": "https://github.com/fchapoton"
}
```

<a id='comment:29'></a>Branch does not apply



---

archive/issue_comments_112456.json:
```json
{
    "body": "<a id='comment:30'></a>We do have now truncated multiplication on polynomials\n\n```\nsage: p = ZZ['x']('x^20 + 3 * x^15 - 2*x + 1')\nsage: p._mul_trunc_(p, 4)\n4*x^2 - 4*x + 1\n```",
    "created_at": "2017-12-19T10:59:40Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112456",
    "user": "https://github.com/videlec"
}
```

<a id='comment:30'></a>We do have now truncated multiplication on polynomials

```
sage: p = ZZ['x']('x^20 + 3 * x^15 - 2*x + 1')
sage: p._mul_trunc_(p, 4)
4*x^2 - 4*x + 1
```



---

archive/issue_comments_112457.json:
```json
{
    "body": "<a id='comment:31'></a>however this does not seem faster than plain multiplication (here with Sage 8.0):\n\n```\nsage: q=2^1000000-1\nsage: p=IntegerModRing(q)['x'].random_element(degree=8)\nsage: time a=p*p\nCPU times: user 473 ms, sys: 8.05 ms, total: 481 ms\nWall time: 481 ms\nsage: time b=p._mul_trunc_(p,8)\nCPU times: user 478 ms, sys: 3.93 ms, total: 482 ms\nWall time: 482 ms\n```",
    "created_at": "2017-12-19T17:36:39Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112457",
    "user": "https://github.com/zimmermann6"
}
```

<a id='comment:31'></a>however this does not seem faster than plain multiplication (here with Sage 8.0):

```
sage: q=2^1000000-1
sage: p=IntegerModRing(q)['x'].random_element(degree=8)
sage: time a=p*p
CPU times: user 473 ms, sys: 8.05 ms, total: 481 ms
Wall time: 481 ms
sage: time b=p._mul_trunc_(p,8)
CPU times: user 478 ms, sys: 3.93 ms, total: 482 ms
Wall time: 482 ms
```



---

archive/issue_comments_112458.json:
```json
{
    "body": "<a id='comment:32'></a>Replying to [comment:31 zimmerma]:\n> however this does not seem faster than plain multiplication (here with Sage 8.0):\n\n\nIt does depend on the base ring\n\n```\nsage: p = ZZ['x'].random_element(degree=20)\nsage: %time a = p*p\nCPU times: user 31 \u00b5s, sys: 2 \u00b5s, total: 33 \u00b5s\nWall time: 35 \u00b5s\nsage: %time b = p._mul_trunc_(p,8)\nCPU times: user 23 \u00b5s, sys: 1 \u00b5s, total: 24 \u00b5s\nWall time: 27.9 \u00b5s\n```\nBut you are right that the generic version of `_mul_truc_` is nothing more than multiply and truncate.",
    "created_at": "2017-12-19T20:14:50Z",
    "issue": "https://github.com/sagemath/sagetest/issues/10480",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/10480#issuecomment-112458",
    "user": "https://github.com/videlec"
}
```

<a id='comment:32'></a>Replying to [comment:31 zimmerma]:
> however this does not seem faster than plain multiplication (here with Sage 8.0):


It does depend on the base ring

```
sage: p = ZZ['x'].random_element(degree=20)
sage: %time a = p*p
CPU times: user 31 Âµs, sys: 2 Âµs, total: 33 Âµs
Wall time: 35 Âµs
sage: %time b = p._mul_trunc_(p,8)
CPU times: user 23 Âµs, sys: 1 Âµs, total: 24 Âµs
Wall time: 27.9 Âµs
```
But you are right that the generic version of `_mul_truc_` is nothing more than multiply and truncate.
