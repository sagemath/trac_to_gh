# Issue 23436: Speedup generic implementation of map_coefficients

Issue created by migration from https://trac.sagemath.org/ticket/23673

Original creator: SimonKing

Original creation time: 2017-08-22 12:58:22

CC:  tscrim

Keywords: map_coefficients

The generic implementation of map_coefficients for polynomials is in a Cython file, but can be considerably improved.

Without the new commit:

```
   sage: R.<x> = SR[]
   sage: p = prod(x+i for i in range(60))
   sage: %timeit p.map_coefficients(lambda z: int(z)%123)
   100 loops, best of 3: 11 ms per loop
```

With the new commit:

```
sage: R.<x> = SR[]
sage: p = prod(x+i for i in range(60))
sage: %timeit p.map_coefficients(lambda z: int(z)%123)
100 loops, best of 3: 5.21 ms per loop
```


Note that I tested several ways of creating a new polynomial: Using a list or a dict, creating the dict in a loop or with a closure, and calling `R(data)` or `R.element_class(R, data)`. According to these tests, using list and element_class is slightly (but really not much) the fastest way. Most time is spent in calling the lambda function anyway.

In addition, I made map_coefficients cpdef, so that Cython code calling it internally will benefit.


---

Comment by SimonKing created at 2017-08-22 13:00:04

Changing status from new to needs_review.


---

Comment by SimonKing created at 2017-08-22 13:00:04

New commits:


---

Comment by mmezzarobba created at 2017-08-22 14:24:28

Isn't that going to break down with sparse polynomials?


---

Comment by tscrim created at 2017-08-22 14:59:54

Yes, and it is also a behavior change (and no longer matches its documentation). Compare with sage 8.1.beta2:

```
sage: R.<x> = ZZ[]
sage: p = x^10 + x^2 + 3
sage: p.map_coefficients(lambda x: x+1)
2*x^10 + 2*x^2 + 4
```

vs this branch

```
2*x^10 + x^9 + x^8 + x^7 + x^6 + x^5 + x^4 + x^3 + 2*x^2 + x + 4
```

This part is simple to change by adding a check for nonzero of the coefficient. However, we need to keep the old version for sparse polynomials.


---

Comment by tscrim created at 2017-08-22 15:02:02

Correction, I think this implementation is best specifically for dense polynomials.


---

Comment by tscrim created at 2017-08-22 15:03:41

I am working on this right now. Thank you Simon for doing the investigation and timings.


---

Comment by SimonKing created at 2017-08-22 16:50:20

Replying to [comment:4 tscrim]:
> Yes, and it is also a behavior change (and no longer matches its documentation).
> Compare with sage 8.1.beta2:
> {{{
> sage: R.<x> = ZZ[]
> sage: p = x^10 + x^2 + 3
> sage: p.map_coefficients(lambda x: x+1)
> 2*x^10 + 2*x^2 + 4
> }}}

OK, that's a good example. I thus need to change something.


---

Comment by SimonKing created at 2017-08-22 16:50:34

Changing status from needs_review to needs_work.


---

Comment by SimonKing created at 2017-08-22 16:55:53

Replying to [comment:4 tscrim]:
> This part is simple to change by adding a check for nonzero of the coefficient.

I guess such check did happen in the past, as the old implementation of `map_coefficients` used `self.dict()`, which does this:

```python
    def dict(self):
        """
        Return a sparse dictionary representation of this univariate
        polynomial.

        EXAMPLES::

            sage: R.<x> = QQ[]
            sage: f = x^3 + -1/7*x + 13
            sage: f.dict()
            {0: 13, 1: -1/7, 3: 1}
        """
        X = {}
        Y = self.list(copy=False)
        for i in xrange(len(Y)):
            c = Y[i]
            if c:
                X[i] = c
        return X
```


> However, we need to keep the old version for sparse polynomials.

I see, there is no `list()` method for sparse polynomials.


---

Comment by SimonKing created at 2017-08-22 17:06:50

I suppose it is impossible to provide a generic implementation and *not* use `dict()`, because that is what is common for all implementations of polynomials. Suggestion: Make `dict()` cpdef.


---

Comment by SimonKing created at 2017-08-22 17:33:05

Very strange. I just notice that I made further changes that didn't end up in the commit. Hm.


---

Comment by tscrim created at 2017-08-22 18:38:49

I've tried to do a specific implementation for `Polynomial_generic_dense` that adds the check but uses the list. However, that is *slower* than the old way (avg 6.3ms -> 7.6ms for me), which has been completely confusing me why that happens as everything tells me it should be faster. I'm still experimenting.


---

Comment by tscrim created at 2017-08-22 19:00:06

Okay, changing it from a `cpdef` to a `def` drops the run down to 6.9ms...


---

Comment by tscrim created at 2017-08-22 19:27:17

I give up. I do not understand why changing things to lists or even just directly copying in the `dict()` method causes such a slowdown. This begs to be optimized for dense polynomials, but the current version seems to be optimal. ㅜ_ㅜ


---

Comment by SimonKing created at 2017-08-23 06:20:37

Replying to [comment:13 tscrim]:
> Okay, changing it from a `cpdef` to a `def` drops the run down to 6.9ms...

Interesting.

Experimenting with the code, I made a similar experience - the current code seems optimal.

However, I will now try a potential way out for both dense and sparse polynomials: As we have seen, a generic implementation has to use `dict()`, but as we have seen as well, it eats time to create a new dict from an old one by applying the function. Idea: Change `dict(self)` to `dict(self, f=None)`, where if f is not None then it is used to map the coefficients.

Hence, I will try to modify this:

```
src/sage/rings/polynomial/multi_polynomial_element.py:    def dict(self):
src/sage/rings/polynomial/polynomial_element_generic.py:    def dict(self):
src/sage/rings/polynomial/polydict.pyx:    def dict(PolyDict self):
src/sage/rings/polynomial/multi_polynomial_libsingular.pyx:    def dict(self):
src/sage/rings/polynomial/laurent_polynomial.pyx:    def dict(self):
src/sage/rings/polynomial/laurent_polynomial.pyx:    def dict(self):
src/sage/rings/polynomial/plural.pyx:    def dict(self):
```



---

Comment by SimonKing created at 2017-08-23 09:59:32

Sometimes timings are surprising to me. For instance, I wanted to find the fastest way to convert a list into a dict, only taking into account the non-zero list items (i.e., that's exactly what the `dict()` method of dense polynomials is doing). Result:

```
sage: cython("""
....: def test1(l):
....:     cdef list L = list(l)
....:     cdef dict D = {}
....:     cdef int i
....:     for i in range(len(L)):
....:         c = L[i]
....:         if c:
....:             D[i] = c
....:     return D
....: def test2(l):
....:     cdef list L = list(l)
....:     cdef dict D = {}
....:     cdef int i
....:     for i,c in enumerate(L):
....:         if c:
....:             D[i] = c
....:     return D
....: def test3(l):
....:     cdef list L = list(l)
....:     cdef dict D = {}
....:     cdef int i
....:     for i in range(len(L)-1,-1,-1):
....:         c = L.pop()
....:         if c:
....:             D[i] = c
....:     return D
....: """)
sage: L = [i if i%2 else 0 for i in srange(5000)]
sage: test1(L)==test2(L)==test3(L)
True
sage: %timeit test1(L)
1000 loops, best of 3: 143 µs per loop
sage: %timeit test2(L)
10000 loops, best of 3: 135 µs per loop
sage: %timeit test3(L)
10000 loops, best of 3: 131 µs per loop
```


I didn't expect that modifying the list (using `.pop()`) is faster than enumerating over the list (only by a small margin, but I repeated the timings and they seem stable).


---

Comment by SimonKing created at 2017-08-23 10:11:41

Yet another implementation:

```
sage: cython("""
....: def test4(l):
....:     cdef list L = list(l)
....:     cdef int i
....:     return {i:v for i,v in enumerate(L) if v}
....: """)
sage: test1(L)==test2(L)==test3(L)==test4(L)
True
sage: %timeit test3(L)
10000 loops, best of 3: 130 µs per loop
sage: %timeit test4(L)
1000 loops, best of 3: 134 µs per loop
```



---

Comment by SimonKing created at 2017-08-23 12:03:00

It is really frustrating. What is fastest in the tests isn't fastest in reality. So far, I got no improvement to `map_coefficients` whatsoever.


---

Comment by git created at 2017-08-23 12:09:21

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by SimonKing created at 2017-08-23 12:15:24

The new commit is not tested and not sufficiently documented.

What *should* happen:
- In the old code, `map_coefficients` creates `self.dict()` (which is obtained from `self.list()`), creates its `items()`, applies a function to the values, turns the result into a new dict, and creates a polynomial from it.
- In the new code, `self.map_coefficients(f)` creates a polynomial from `self.dict(f)`, which is obtained from `self.list()` by applying `f`. Hence, no intermediate dict and no intermediate item list is involved.

Should the new code thus not be faster? Sadly, it isn't! Can you tell me why?
----
New commits:


---

Comment by SimonKing created at 2017-08-23 14:01:01

The following is what _any_ implementation of `.map_coefficients()` has to do:
1. Obtain all non-zero coefficients (e.g. via `.dict()`). This involves zero tests.
2. Map the non-zero coefficients.
3. Create a polynomial out of the result of 2.

Meanwhile it seems to me that the above essential tasks take most of the execution time. Hence, the timings of different implementations will differ only very slightly, as there is no way around the above tasks (except caching of 1., which probably is no option).

I wouldn't mind to resolve this ticket as "invalid/won't fix".

BTW: Can you tell me why Trac keeps logging me out after short time (e.g., while writing the above text)?


---

Comment by tscrim created at 2017-08-23 15:17:55

However, I believe it should be possible to speedup 3 for dense polynomials, which uses lists to store date. This should be doable by avoiding the `list -> dict -f> dict -> list` (where `-f>` is applying the map `f`) and instead directly doing `list -f> list`.

> I wouldn't mind to resolve this ticket as "invalid/won't fix". 

So I'd prefer to leave this open as a wishlist item, but I don't think we should spend more time on this right now.

> Should the new code thus not be faster? Sadly, it isn't! Can you tell me why? 

I agree that it should be. David Roe mentioned to me that in some circumstances, Cython is slower than Python and this might be one of these cases. However, it is still very confounding.

>  BTW: Can you tell me why Trac keeps logging me out after short time (e.g., while writing the above text)? 

IDK. It could be your internet connection somehow resetting, which then trac thinks you're trying from a new connection.
