# Issue 29275: Ideals for Laurent polynomial rings

Issue created by migration from https://trac.sagemath.org/ticket/29512

Original creator: kedlaya

Original creation time: 2020-04-15 17:58:59

CC:  yzh @mwageringel

Keywords: Laurent polynomial ring

Currently Laurent polynomial rings do not implement ideals. This would be relatively easy to do by converting back and forth between the corresponding ordinary polynomial ring, taking care to saturate the ideal in the polynomial ring with respect to the product of the generators.

This is just one of many instances of missing parallelism between ordinary and Laurent polynomials; but the others should go on other tickets.


---

Comment by kedlaya created at 2020-05-05 16:40:16

I ended up writing some code to do this, but at the moment it is not yet available as a patch. If someone is interested in reviewing this, let me know and I will bump this up in my queue.

One thing I learned by doing: the saturation of ideals can be quite expensive computationally, so for performance code it is useful to keep track of partial saturations and use those instead when feasible.


---

Comment by kedlaya created at 2020-05-15 21:44:05

I have attached a standalone Sage file with a class that I am using in some of my own code.


---

Comment by kedlaya created at 2020-05-15 21:44:27

Changing keywords from "Laurent polynomial ring" to "Laurent polynomial ring, ideals".


---

Comment by kedlaya created at 2020-05-25 20:59:34

I just noticed that the newest release of Singular (4-1-3) includes a new library `moddiq.lib` for ideal saturation using modular techniques. This might have a big practical impact here!


---

Attachment

Patch to implement ideals in Laurent polynomial rings


---

Comment by kedlaya created at 2020-05-28 19:18:36

I made a few minor changes to the patch, so I have posted an update.


---

Comment by kedlaya created at 2020-07-22 19:04:57

This bubbled up to the top of my queue, so here goes with a proper commit. Note the side effect related to #26421.

This should be mostly ready for review, but let's give patchbot a chance to weigh in first.
----
New commits:


---

Comment by git created at 2020-07-22 20:17:01

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by kedlaya created at 2020-07-23 19:00:54

Changing status from new to needs_review.


---

Comment by tscrim created at 2020-07-24 08:15:12

It is nice to have this feature. I have some comments:

For efficiency, do you want to be passing `dict` objects to the parent and getting `self.dict()` in `rescale_vars()` and `toric_coordinate_change()` (possibly also `toric_substitute()`)? Wouldn't it be faster to copy the `PolyDict`, manipulate the copy, and then create a new instance using the `_new_c()`?

You could simplify the comparisons by using `_richcmp_`, which also will use coercion, or perhaps `__richcmp__` if you want to avoid the coercion?

Following the Python convention:

```diff
-return ValueError("Ambient rings are not equal")
+return ValueError("ambient rings are not equal")
```



---

Comment by kedlaya created at 2020-07-24 16:03:53

Thanks for the feedback!

It looks like `self.dict()` already returns a copy, so in `rescale_vars` I could definitely just edit the return value. For the others, I'm changing both the keys and the values; I don't have enough Python intuition to discern whether I'm paying much of a penalty by creating a new dict. (Is there a good example to point to in the existing code to illustrate your suggestion?)

Re `_richcmp_` vs `__richcmp__`, I'm pretty sure I want to use the former so that I don't have to worry about the coercion myself. But would that lead to any appreciable loss of efficiency?


---

Comment by tscrim created at 2020-07-24 23:24:06

Replying to [comment:13 kedlaya]:
> It looks like `self.dict()` already returns a copy, so in `rescale_vars` I could definitely just edit the return value. For the others, I'm changing both the keys and the values; I don't have enough Python intuition to discern whether I'm paying much of a penalty by creating a new dict. (Is there a good example to point to in the existing code to illustrate your suggestion?)

When the data gets passed to the parent, it ends up recreating the data structure. So here is what happens when you create a (multivar.) Laurent polynomial `p` passing a `dict` `D`:

1. The monomial `self._mon` for the common negative exponents is determined.
2. The cleaned dict `D` is passed to the defining polynomial ring to set `self._poly`.

Then when you call `p.dict()`:

1. A `PolyDict` object `self._prod` created in `_compute_polydict` by multiplying the monomial `self._mon` with the `dict` version of `self._poly`. This is stored in `self._prod`.
2. The dictionary of `self._prod` is created.

As a specific example, lets take `rescale_vars`. Since the underlying `self._prod` only changes in the coefficients, you can simply change the appropriate coefficients in the `PolyDict` object and set the `result._prod` value (this will make it avoid the call to `_compute_polydict`).

The polynomial part is a little more tricky as you don't want to create an intermediate polynomial object. The best way would be to break the encapsulation of the polynomial and just modify the monomials on a copy, but we don't really allow that. So probably the best (and easiest) thing to do is just pass a separate (rescaled by `self._mon`) `PolyDict` object, and let the ring sort out the construction.

For the other methods, similar things can be done. I can also do these changes next time I am in my office.

Another thing I noticed. While this will have some code duplication, I would consider factoring out the `if h is None:` check to minimize the number of checks. This seems like something that might get used a lot in tight loops.

One simple thing you can do, since this is done in Cython, is to `cdef dict d, d2` and `cdef ETuple v, v1, w`. Also this is faster:

```diff
-if self == 0:
+if not self:
```


Perhaps I am also giving oversized importance to these methods. Side note, a similar change probably should be done for `_derivative` (definitely a separate ticket).

> Re `_richcmp_` vs `__richcmp__`, I'm pretty sure I want to use the former so that I don't have to worry about the coercion myself. But would that lead to any appreciable loss of efficiency?

Probably not since checking equality and containment will dominate rather than potentially creating a new object. Actually, your current equals is assuming that you are being given an ideal. I suspect if you trying doing `I == 0`, you will get an error. With the coercion, this will either check if `I` is the trivial ideal `0` (which I think the parent of ideals will properly coerce in) or return `False` (if it cannot coerce in IIRC).


---

Comment by git created at 2020-07-25 04:30:45

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2020-07-25 04:38:24

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by kedlaya created at 2020-07-25 04:38:39

I made some changes as suggested. On the ideal side, I rewrote the comparisons using `_richcmp_`. On the polynomial side, I made a few of the easy changes (using `cdef` on some of the `dict` and `ETuple` objects) but I still haven't absorbed how to deal with `PolyDict` objects directly.

Since I do want to get this right from an efficiency standpoint (my intended use case hits this code pretty hard), I would definitely appreciate a friendly amendment to avoid excessive dictionary creation.


---

Comment by git created at 2020-07-26 03:16:22

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by tscrim created at 2020-07-27 05:46:59

Timing for `rescale_vars`:

```
sage: L.<x,y> = LaurentPolynomialRing(QQ, 2)
sage: p = x^-2*y + x*y^-2
sage: %timeit p.rescale_vars({0: 2, 1: 3})
100000 loops, best of 5: 11.5 µs per loop
```

versus before

```
100000 loops, best of 5: 5.13 µs per loop
```

However, your code had two bugs: 1) the coefficients could go outside of the base ring; 2) you did not set the `ans._poly`; so this breaks:

```
sage: L.<x,y> = LaurentPolynomialRing(QQ, 2)
sage: M.<u,v> = LaurentPolynomialRing(QQ)
sage: phi = L.hom([u,v])
sage: p = x^-2*y + x*y^-2
sage: pp = p.rescale_vars({0: 3, 1: 3})
sage: phi(pp)
```

In particular, the second issue is why there is a slowdown. If I compare with 6d028fe, I get

```
100000 loops, best of 5: 14.9 µs per loop
```


----

Timing for `toric_coordinate_change`:

```
sage: L.<x,y> = LaurentPolynomialRing(QQ, 2)
sage: p = 2*x^2 + y - x*y
sage: M = Matrix([[1,-3],[1,1]])
sage: %timeit p.toric_coordinate_change(M)
100000 loops, best of 5: 18.2 µs per loop
```

versus before:

```
10000 loops, best of 5: 33 µs per loop
```

Here I made an assumption that the matrix is a dense matrix and the results will generally have the full support.

----

For `toric_substitute`:

```
sage: L.<x,y> = LaurentPolynomialRing(QQ, 2)
sage: p = x + y
sage: %timeit p.toric_substitute((2,3), (-1,1), 2)
100000 loops, best of 5: 10.1 µs per loop
```

versus before

```
100000 loops, best of 5: 14.7 µs per loop
```


I thought about adding an extra `scalar` parameter to `ETuple.eadd`, but then the worry that the extra `if` check could lead to more substantial slowdowns got the better of me. I don't like the near-duplicated code, but nearly all of the method was copied within the `if` statement.

----

Some other misc comments:

I find this a little strange and do this instead:

```diff
-lambda x, M=M: x.toric_coordinate_change(M)
+lambda x: x.toric_coordinate_change(M)
```

and other similar changes.

I made the methods above more robust if the `h` map moves you outside of your base ring (now it will raise an error).


```diff
-        - ``ring`` - the ring the ideal is defined in
-
-        - ``gens`` - a list of generators for the ideal
-
-        - ``coerce`` - coerce elements to the ring ``ring``?
+        - ``ring`` -- the ring the ideal is defined in
+        - ``gens`` -- a list of generators for the ideal
+        - ``coerce`` -- whether or not to coerce elements into ``ring``
```


Bikeshedding: I don't trust `\dots`, so I would replace them with the corresponding explicit type (in this case, `\ldots`).


```diff
-ideals in the ordinary polynomial ring `R[x_1, \ldots, x_n]` which are
+ideals in the ordinary polynomial ring `R[x_1, \ldots, x_n]`, which are
```

----
New commits:


---

Comment by kedlaya created at 2020-07-27 16:25:06

Thanks, this all looks reasonable. One quick comment:

Replying to [comment:19 tscrim]:
> I find this a little strange and do this instead:
> {{{#!diff
> -lambda x, M=M: x.toric_coordinate_change(M)
> +lambda x: x.toric_coordinate_change(M)
> }}}
> and other similar changes.
> 
I got into the habit of using this syntax after getting burned by the following Python scoping rule: non-local variables referenced in a lambda function are defined in the scope where they are created, but at the time the lambda function is *executed* rather than when it is created. A minimal example:

```
sage: l = [(lambda x: x+i) for i in range(5)]
sage: print([i(3) for i in l])
[7, 7, 7, 7, 7]
sage: l = [(lambda x,i=i: x+i) for i in range(5)]
sage: print([i(3) for i in l])
[3, 4, 5, 6, 7]
```

That said, I don't think this issue arises here because (as in typical Python code) the lambda functions are being created individually and used right away.


---

Comment by tscrim created at 2020-07-27 22:56:10

That is quite interesting, slightly surprising on first glance, but it makes sense from what the interpreter knows (although I might argue that particular example should raise an error since it is out of scope as Python3 has scope for variables IIRC, but it does illustrate the issue nicely).

Once those doc changes are done (assuming you agree with them; I can also do them quickly too), then this can be positively reviewed. There is a morally green patchbot run too.


---

Comment by git created at 2020-07-27 23:56:03

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by kedlaya created at 2020-07-27 23:58:11

I believe I made the doc changes you suggested, but do check to see if I missed any. I left the lambda functions alone because I didn't have a chance to test carefully whether they still work without the default argument (I suspect yes but would want to be sure; the last bug I had to fix regarding this issue was painful to diagnose).


---

Comment by tscrim created at 2020-07-28 01:04:00

Changing status from needs_review to positive_review.


---

Comment by tscrim created at 2020-07-28 01:04:00

LGTM. Thank you.


---

Comment by vbraun created at 2020-08-02 08:20:54

Resolution: fixed
