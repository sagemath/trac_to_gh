# Issue 15363: Exact computations in QQbar spend unreasonable amounts of time in do_polred

Issue created by migration from https://trac.sagemath.org/ticket/15600

Original creator: mmezzarobba

Original creation time: 2013-12-28 11:13:58

CC:  jdemeyer gagern vdelecroix cheuberg

Zero-tests in `QQbar` and `AA` are very slow—slower than can be reasonably expected of exact computations with algebraic numbers IMHO.

On some examples, it turns out that 80% or more of the time is spent calling PARI's `polredbest`. The current implementation apparently calls `polredbest` each time exact computations in a new extension are required, which can be pretty expensive. It does so in the hope of finding a "nice" primitive element whose use will speed up subsequent computations (and perhaps also make the descriptions of the elements slightly more readable?), but otherwise my understanding is that this step is completely optional.

Let's try to disable it except for small degrees (the value of `max_deg` was chosen to avoid changing the output of the tests in `qqbar.py`):

```diff
--- a/src/sage/rings/qqbar.py
+++ b/src/sage/rings/qqbar.py
@@ -1510,7 +1510,7 @@ def clear_denominators(poly):
     poly = poly(poly.parent().gen() / change)
     return change, poly
 
-def do_polred(poly):
+def do_polred(poly, max_deg=8):
     r"""
     Find a polynomial of reasonably small discriminant that generates
     the same number field as ``poly``, using the PARI ``polredbest``
@@ -1554,9 +1554,12 @@ def do_polred(poly):
         sage: do_polred(x^4 - 4294967296*x^2 + 54265257667816538374400)
         (1/4*x, 4*x, x^4 - 268435456*x^2 + 211973662764908353025)
     """
+    parent = poly.parent()
+    if poly.degree() > max_deg:
+        return parent.gen(), parent.gen(), poly
+
     new_poly, elt_back = poly._pari_().polredbest(flag=1)
 
-    parent = poly.parent()
     elt_fwd = elt_back.modreverse()
     return parent(elt_fwd.lift()), parent(elt_back.lift()), parent(new_poly)
 }}}
Before (`master` as of a few days ago):
{{{
    sage -t --long src/sage/rings/qqbar.py
        [1355 tests, 34.81 s]
    ----------------------------------------------------------------------
    All tests passed!
    ----------------------------------------------------------------------
    Total time for all tests: 35.2 seconds
        cpu time: 34.8 seconds
        cumulative wall time: 34.8 seconds
}}}
After:
{{{
    sage -t --long src/sage/rings/qqbar.py
        [1355 tests, 6.09 s]
    ----------------------------------------------------------------------
    All tests passed!
    ----------------------------------------------------------------------
    Total time for all tests: 6.4 seconds
        cpu time: 6.1 seconds
        cumulative wall time: 6.1 seconds
}}}

Now these examples may not be representative of anything, and the above patch is a very naive solution. But it should certainly be possible to come up with a better strategy than calling `polredbest` every time!


---

Comment by jdemeyer created at 2013-12-28 11:57:06

I don't think this is the right solution, using caching would be a better idea I think. In fact, in the code there are various places with

```
# XXX need more caching here
```



---

Comment by mmezzarobba created at 2013-12-28 12:42:44

I agree that QQbar _also_ needs more caching. (And not only in the marked places. For instance, look how many times `nfinit` is called by `sage_input(pol.roots(...,ring=QQbar), verify=True)`: it seems to me that lots of expensive purely algebraic computations could be performed only once when we have `AlgebraicGenerator`s corresponding to several roots of the same irreducible polynomial.)

But even with caching, is it reasonable to spend tens of seconds optimizing the representation of an extension that may be used only once to check that some expression is zero?


---

Comment by mmezzarobba created at 2014-01-15 17:57:13

I asked Karim Belabas. Here is what I understand of his answer:
* the cost of `polredbest` for a polynomial of degree `n` with coefficients of bit size `B` is roughly `n^5 B^2`;
* the best it can do is to reduce the cost of subsequent computations in the extension by a factor of roughly `B^2`;
* it is essentially never worth calling it on polynomials of moderately large degree;
* ...except before performing very expensive operations (typically `bnfinit()`) on the extension, when there is reason to expect that it will find a defining polynomial of very small height.

On a related note, I noticed that `QQbar` often calls `polredbest` on polynomials of the form `p(x^k)` where `k` can be pretty large. Karim suggested that the Pari function `rnfpolredbest` could be useful in this case.


---

Comment by gagern created at 2015-04-18 19:43:23

I agree that dropping that function seems a reasonable approach to the problem at hand. In particular, if we follow the idea from #17886 then operations within a single number field would become even rarer, so the benefit of a reduced basis would be less as well.

As a middle ground, it might be possible to do the reduction lazily, once it looks as if there would be a sufficient number of operations performed in the same number field to justify the time spent for this computation. But since implementing this could be a major effort, I'm not really suggesting this approach, just mentioning it as an idea if there is too much objection to dropping the reduction altogether.

Here is one example which doesn't complete in over 6 hours, due to the call to `polredbest`. I had this as the motivating example for #17896 which looks like a duplicate of this one here.


```
sage: x,y = polygens(QQ,"x,y")
sage: p1 = x^5 + 6*x^4 - 42*x^3 - 142*x^2 + 467*x + 422
sage: p2 = p1(x=(x-1)^2)
sage: p3 = p2(x=x*y).resultant(p2,x).univariate_polynomial()
sage: p4, = [f[0] for f in p3.factor() if f[0].degree() == 80]
sage: ival = CIF((0.77, 0.78), (-0.08, -0.07))
sage: z, = [r for r in p4.roots(QQbar, False) if r in ival]
sage: %time z.exactify()
```



---

Comment by mmezzarobba created at 2018-12-23 08:02:36

Changing status from new to needs_review.


---

Comment by mmezzarobba created at 2018-12-23 08:02:36

I'd like to revive this ticket. It's been five years, and (in spite of a bit of progress on related issues), there is still no other viable solution. While the change suggested here will not make QQbar very fast, it can at least make it usable.
----
New commits:


---

Comment by mmezzarobba created at 2018-12-23 08:08:31

Replying to [comment:3 mmezzarobba]:
> On a related note, I noticed that `QQbar` often calls `polredbest` on polynomials of the form `p(x^k)` where `k` can be pretty large.

As we realized with Pascal Molin, this is related in particular to #26898. What used to happen is that hashing an algebraic number α would trigger the exact computation, not just of α itself, but of the _real and imaginary parts_ of α _+ β_ for some β ∈ ℚ[i]...


---

Comment by vdelecroix created at 2018-12-23 09:12:29

Just a copy of the example in #21095 that never terminates

```
sage: x = polygen(ZZ)
sage: p = 67*x^4 - 33*x^3 + 94*x^2 - 30*x + 57
sage: r = p.roots(QQbar, multiplicities=False)
sage: r[0].abs().exactify()  # <- takes forever
```



---

Comment by vdelecroix created at 2018-12-23 09:15:06

Do you have some timings that make you decide about this threshold?


---

Comment by mmezzarobba created at 2018-12-23 10:02:17

Replying to [comment:11 vdelecroix]:
> Do you have some timings that make you decide about this threshold?

Nothing rigorous. But for instance, degree 40 with 30-bit coefficients seems to take a second or two, degree 60 (still with 30-bit coeffs) ~9s, and  degree 80 more than 30s.


---

Comment by git created at 2018-12-25 10:13:44

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by vdelecroix created at 2018-12-31 08:19:18

This is a good move! Thanks.


---

Comment by vdelecroix created at 2018-12-31 08:19:18

Changing status from needs_review to positive_review.


---

Comment by vbraun created at 2019-01-01 09:51:24

Resolution: fixed
