# Issue 18960: LatticePoset: add breadth()

archive/issues_018960.json:
```json
{
    "body": "Add a function to compute the breadth of a lattice.\n\nIssue created by migration from https://trac.sagemath.org/ticket/19197\n\n",
    "created_at": "2015-09-13T07:31:35Z",
    "labels": [
        "component: combinatorics"
    ],
    "milestone": "https://github.com/sagemath/sagetest/milestones/sage-6.9",
    "title": "LatticePoset: add breadth()",
    "type": "issue",
    "url": "https://github.com/sagemath/sagetest/issues/18960",
    "user": "https://github.com/jm58660"
}
```
Add a function to compute the breadth of a lattice.

Issue created by migration from https://trac.sagemath.org/ticket/19197





---

archive/issue_comments_259773.json:
```json
{
    "body": "Hello Jori,\n\nHere is a way to improve the algorithm a bit:\n\nLet us say that a set `S` is \"locally_minimal\" if the join of the elements in `S` is different from the join of the elements in <any proper subset in `S`>. What you are looking for is the set `locally_mininal` set of maximum cardinality.\n\nWhy do you iterate on antichains? You iterate on antichains, because you know that in *any* \"locally_minimal\" set `S`, any 2-subset of `S` must be locally minimal. And the sets of locally minimal sets of cardinality 2 are precisely the antichains.\n\nWhy wouldn't you go further? Indeed, the same works for anything greater than 2: in any locally minimal set, *any* proper subset is also locally minimal.\n\nYour implementation, however, does not use that. You test all antichains, but when testing those of size 5 you do not use the information obtained from those of size 4.\n\nSo here is a way out: enumerate all locally minimal sets directly, in increasing order of size. This can be done with `subsets_with_hereditary_property` [1], to which you can feed a function that detects if a given set of points is locally minimal (when you remove only one element).\n\nThis should do the trick, and *use* the information that <some given set of size 3 is not locally minimal> when trying to figure out one of size 4.\n\nNote: It may be slower for small cases, but better above.\n\nAdditionally, your code may spend a lot of time hashing your elements: it may be better to work directly with the integer ID of the poset's elements (and to access the matrix directly).\n\nAlso, could you be a bit more formal in the definition of 'breadth'? I did not follow it at first (english is not a well-paenthesized language). It would also be cool if you could redirect toward a textbook/paper that defines it: I found it in \"Semimodular Lattices Theory and Applications\" where it is said to originate from \"Lattice Theory\" by Birkhoff.\n\nNathann\n\n[1] http://doc.sagemath.org/html/en/reference/combinat/sage/combinat/subsets_hereditary.html\n\n---\nNew commits:",
    "created_at": "2015-09-13T10:40:53Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259773",
    "user": "https://github.com/nathanncohen"
}
```

Hello Jori,

Here is a way to improve the algorithm a bit:

Let us say that a set `S` is "locally_minimal" if the join of the elements in `S` is different from the join of the elements in <any proper subset in `S`>. What you are looking for is the set `locally_mininal` set of maximum cardinality.

Why do you iterate on antichains? You iterate on antichains, because you know that in *any* "locally_minimal" set `S`, any 2-subset of `S` must be locally minimal. And the sets of locally minimal sets of cardinality 2 are precisely the antichains.

Why wouldn't you go further? Indeed, the same works for anything greater than 2: in any locally minimal set, *any* proper subset is also locally minimal.

Your implementation, however, does not use that. You test all antichains, but when testing those of size 5 you do not use the information obtained from those of size 4.

So here is a way out: enumerate all locally minimal sets directly, in increasing order of size. This can be done with `subsets_with_hereditary_property` [1], to which you can feed a function that detects if a given set of points is locally minimal (when you remove only one element).

This should do the trick, and *use* the information that <some given set of size 3 is not locally minimal> when trying to figure out one of size 4.

Note: It may be slower for small cases, but better above.

Additionally, your code may spend a lot of time hashing your elements: it may be better to work directly with the integer ID of the poset's elements (and to access the matrix directly).

Also, could you be a bit more formal in the definition of 'breadth'? I did not follow it at first (english is not a well-paenthesized language). It would also be cool if you could redirect toward a textbook/paper that defines it: I found it in "Semimodular Lattices Theory and Applications" where it is said to originate from "Lattice Theory" by Birkhoff.

Nathann

[1] http://doc.sagemath.org/html/en/reference/combinat/sage/combinat/subsets_hereditary.html

---
New commits:



---

archive/issue_comments_259774.json:
```json
{
    "body": "Branch pushed to git repo; I updated commit sha1. New commits:",
    "created_at": "2015-09-13T11:20:20Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259774",
    "user": "https://trac.sagemath.org/admin/accounts/users/git"
}
```

Branch pushed to git repo; I updated commit sha1. New commits:



---

archive/issue_comments_259775.json:
```json
{
    "body": "Technical correction committed. Now the code should work and Sphinx should not complain.\n\nI will try Nathann's suggestion later. I would have marked this as *needs_work*, but the system does not allow it.",
    "created_at": "2015-09-13T11:23:43Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259775",
    "user": "https://github.com/jm58660"
}
```

Technical correction committed. Now the code should work and Sphinx should not complain.

I will try Nathann's suggestion later. I would have marked this as *needs_work*, but the system does not allow it.



---

archive/issue_comments_259776.json:
```json
{
    "body": "Replying to [comment:2 ncohen]:\n\n> So here is a way out: enumerate all locally minimal sets directly, in increasing order of size. This can be done with `subsets_with_hereditary_property` [1], to which you can feed a function that detects if a given set of points is locally minimal (when you remove only one element).\n> \n> This should do the trick, and *use* the information that <some given set of size 3 is not locally minimal> when trying to figure out one of size 4.\n\n\nOK... So you think something like\n\n```\nf = lambda ac: self.is_antichain_of_poset(ac) and self.join(ac) not in\n  [self.join(set(ac).difference(set([e]))) for e in ac]\nl = list(subsets_with_hereditary_property(f, self))\nlen(l[-1])\n```\n\n? Seems faster, but still stucks for 132-element `Posets.TamariLattice(6).canonical_label()`. Btw, what is faster way to iterate over \"list `L` minus an element for every element\"?",
    "created_at": "2015-09-13T15:57:03Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259776",
    "user": "https://github.com/jm58660"
}
```

Replying to [comment:2 ncohen]:

> So here is a way out: enumerate all locally minimal sets directly, in increasing order of size. This can be done with `subsets_with_hereditary_property` [1], to which you can feed a function that detects if a given set of points is locally minimal (when you remove only one element).
> 
> This should do the trick, and *use* the information that <some given set of size 3 is not locally minimal> when trying to figure out one of size 4.


OK... So you think something like

```
f = lambda ac: self.is_antichain_of_poset(ac) and self.join(ac) not in
  [self.join(set(ac).difference(set([e]))) for e in ac]
l = list(subsets_with_hereditary_property(f, self))
len(l[-1])
```

? Seems faster, but still stucks for 132-element `Posets.TamariLattice(6).canonical_label()`. Btw, what is faster way to iterate over "list `L` minus an element for every element"?



---

archive/issue_comments_259777.json:
```json
{
    "body": "> OK... So you think something like\n\n\nThere is no need to check that it is an antichain. Also, if you do not write it as a lambda function you have more freedom and do not need to create sets at each test, test.\n\n>btw, what is faster way to iterate over \"list `L` minus an element for every element\"?\n\n\nWhat's wrong with `L[:i] + L[i+1:]` ?\n\nNathann",
    "created_at": "2015-09-13T16:03:10Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259777",
    "user": "https://github.com/nathanncohen"
}
```

> OK... So you think something like


There is no need to check that it is an antichain. Also, if you do not write it as a lambda function you have more freedom and do not need to create sets at each test, test.

>btw, what is faster way to iterate over "list `L` minus an element for every element"?


What's wrong with `L[:i] + L[i+1:]` ?

Nathann



---

archive/issue_comments_259778.json:
```json
{
    "body": "Just a random thought: Can the thinking be reversed? I mean that for a certificate `A` there is the element `j=join(A)`. What kind of element that can be? Can we somehow go back from it/those, i.e. have algorithm `j -> A` instead of `A -> j`?\n\nIf this is not possible, is this an NP-problem?",
    "created_at": "2015-09-13T17:18:58Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259778",
    "user": "https://github.com/jm58660"
}
```

Just a random thought: Can the thinking be reversed? I mean that for a certificate `A` there is the element `j=join(A)`. What kind of element that can be? Can we somehow go back from it/those, i.e. have algorithm `j -> A` instead of `A -> j`?

If this is not possible, is this an NP-problem?



---

archive/issue_comments_259779.json:
```json
{
    "body": "Replying to [comment:2 ncohen]:\n\n> Also, could you be a bit more formal in the definition of 'breadth'? I did not follow it at first (english is not a well-paenthesized language). It would also be cool if you could redirect toward a textbook/paper that defines it: I found it in \"Semimodular Lattices Theory and Applications\" where it is said to originate from \"Lattice Theory\" by Birkhoff.\n\n\nTrue. \"- - of the *breadth* of a lattice *L*, - - as the least positive integer *b = b[L]* such that any meet *x_1 `^` . . . `^` x_n [n > b]* is always a meet of a subset of *b* of the *x_i*. This is on p. 99. Not very intuitive definition... So let's try from scratch:\n\nLet `E` be an `n`-element subset of elements of the lattice, `j` be a join of `E`, and join of every proper subset of `E` be not equal `j`. The *breadth* of lattice is number of elements in a largest such subset `E`.\n\n? Hmm... not best possible.",
    "created_at": "2015-09-14T07:41:37Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259779",
    "user": "https://github.com/jm58660"
}
```

Replying to [comment:2 ncohen]:

> Also, could you be a bit more formal in the definition of 'breadth'? I did not follow it at first (english is not a well-paenthesized language). It would also be cool if you could redirect toward a textbook/paper that defines it: I found it in "Semimodular Lattices Theory and Applications" where it is said to originate from "Lattice Theory" by Birkhoff.


True. "- - of the *breadth* of a lattice *L*, - - as the least positive integer *b = b[L]* such that any meet *x_1 `^` . . . `^` x_n [n > b]* is always a meet of a subset of *b* of the *x_i*. This is on p. 99. Not very intuitive definition... So let's try from scratch:

Let `E` be an `n`-element subset of elements of the lattice, `j` be a join of `E`, and join of every proper subset of `E` be not equal `j`. The *breadth* of lattice is number of elements in a largest such subset `E`.

? Hmm... not best possible.



---

archive/issue_comments_259780.json:
```json
{
    "body": "To me the first definition you gave is good. The one from the branch, however, was harder to parse. If you find this first definition not very intuitive, it may be because it defines it as \"the smallest integer\" instead as a \"largest integer\"? If that is the problem you can probably adapt it.\n\nNathann",
    "created_at": "2015-09-14T08:46:57Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259780",
    "user": "https://github.com/nathanncohen"
}
```

To me the first definition you gave is good. The one from the branch, however, was harder to parse. If you find this first definition not very intuitive, it may be because it defines it as "the smallest integer" instead as a "largest integer"? If that is the problem you can probably adapt it.

Nathann



---

archive/issue_comments_259781.json:
```json
{
    "body": "Here is, if I thinked this right, the smallest lattice with breadth 4:\n\n```\nn = 4\nl = [[0,i] for i in range(1,n+1)]\n\nl += [[i, i+n] for i in range(1,n+1)]\nl += [[i, i+n+1] for i in range(1,n)]\nl += [[n, n+1]]\n\nl += [[i, i+n] for i in range(n+1, 2*n+1)]\nl += [[i, i+n+1] for i in range(n+1,n*2)]\nl += [[n*2, n*2+1]]\n\nl += [[i, n*3+1] for i in range(2*n+1, 3*n+1)]\n\nL = Poset(( [], l)).completion_by_cuts().canonical_label()\n```\n\nThis is not easily generalized. `n=5` will not make a lattice of breadth 5.\n\nHowever, can this be used as a part of test for a lattice to have breadht 4? If br(L)=4, there must be an antichain `A` of `4` elements with join `j`. Element `j` must cover at least four element. They can not be the set `A`. They can not directly cover `A`, because it is just impossible to make the lattice so that three element from `A` would not have meet `j`.\n\nSo to check take one element a time and try to put in as a `j` in this structure. If the element covers less than four element, it is not right one. If it does, take all four-element subsets of the lower covers of `j`-candidate. For those... somehow continue a-kind-of backtracking.\n\nWe can remove all doubly irreducible elements, as removing thme won't change the breadth, except from 2 to 1 in a diamond-like stucture.",
    "created_at": "2015-09-14T18:37:33Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259781",
    "user": "https://github.com/jm58660"
}
```

Here is, if I thinked this right, the smallest lattice with breadth 4:

```
n = 4
l = [[0,i] for i in range(1,n+1)]

l += [[i, i+n] for i in range(1,n+1)]
l += [[i, i+n+1] for i in range(1,n)]
l += [[n, n+1]]

l += [[i, i+n] for i in range(n+1, 2*n+1)]
l += [[i, i+n+1] for i in range(n+1,n*2)]
l += [[n*2, n*2+1]]

l += [[i, n*3+1] for i in range(2*n+1, 3*n+1)]

L = Poset(( [], l)).completion_by_cuts().canonical_label()
```

This is not easily generalized. `n=5` will not make a lattice of breadth 5.

However, can this be used as a part of test for a lattice to have breadht 4? If br(L)=4, there must be an antichain `A` of `4` elements with join `j`. Element `j` must cover at least four element. They can not be the set `A`. They can not directly cover `A`, because it is just impossible to make the lattice so that three element from `A` would not have meet `j`.

So to check take one element a time and try to put in as a `j` in this structure. If the element covers less than four element, it is not right one. If it does, take all four-element subsets of the lower covers of `j`-candidate. For those... somehow continue a-kind-of backtracking.

We can remove all doubly irreducible elements, as removing thme won't change the breadth, except from 2 to 1 in a diamond-like stucture.



---

archive/issue_comments_259782.json:
```json
{
    "body": "I do not know what you are looking for, but if I wanted to build posets of arbitrarily high breadth I'd try booleanlattices.\n\nNathann",
    "created_at": "2015-09-14T20:38:24Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259782",
    "user": "https://github.com/nathanncohen"
}
```

I do not know what you are looking for, but if I wanted to build posets of arbitrarily high breadth I'd try booleanlattices.

Nathann



---

archive/issue_comments_259783.json:
```json
{
    "body": "I am thinking about better algorithm to compute the breadth.\n\nAs an example: to a lattice have breadth `k` there must be an element that covers `k` elements. It does not suffice that it has an antichain of `k` elements.\n\nBut I'll continue thinking and try to make some example code.",
    "created_at": "2015-09-15T03:44:31Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259783",
    "user": "https://github.com/jm58660"
}
```

I am thinking about better algorithm to compute the breadth.

As an example: to a lattice have breadth `k` there must be an element that covers `k` elements. It does not suffice that it has an antichain of `k` elements.

But I'll continue thinking and try to make some example code.



---

archive/issue_comments_259784.json:
```json
{
    "body": "Branch pushed to git repo; I updated commit sha1. This was a forced push. New commits:",
    "created_at": "2015-09-16T14:22:36Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259784",
    "user": "https://trac.sagemath.org/admin/accounts/users/git"
}
```

Branch pushed to git repo; I updated commit sha1. This was a forced push. New commits:



---

archive/issue_comments_259785.json:
```json
{
    "body": "Changing status from new to needs_review.",
    "created_at": "2015-09-16T14:30:58Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259785",
    "user": "https://github.com/jm58660"
}
```

Changing status from new to needs_review.



---

archive/issue_comments_259786.json:
```json
{
    "body": "Ready for review. I did some timings, and for example `Posets.TamariLattice(8)`, which has 1430 elements, it takes 4,5 seconds to compute the breadth. I know that there is places for optimization, but at least this should be working code and fast enought to be usable.",
    "created_at": "2015-09-16T14:30:58Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259786",
    "user": "https://github.com/jm58660"
}
```

Ready for review. I did some timings, and for example `Posets.TamariLattice(8)`, which has 1430 elements, it takes 4,5 seconds to compute the breadth. I know that there is places for optimization, but at least this should be working code and fast enought to be usable.



---

archive/issue_comments_259787.json:
```json
{
    "body": "Hello Jori,\n\nHere is a first-pass review while on the bus.\n\n- I was very surprised to see a 'distance' argument in the depth-first-search\n  function. You do not compute the 'distance' when running a\n  depth-first-search. At least not the usual notion of distance in graph\n  theory. We should probably remove it, as it is *highly* dangerous to advertise\n  it this way `O_o`\n\n- In your code, please use breadth-first-search instead.\n\n- Definition of 'elems': this line often test for containment in 'too_close'. Do\n  not run containment tests in a list. use a 'set' for that: containment is\n  faster.\n\n- Anyway, you probably should do this differently, i.e. with\n  `breadth_first_search(report_distance=True)` while filtering 'too close'\n  elements according to their distance.\n\n- I still believe that it would be faster to use\n  'subsets_with_hereditary_property' inside of your code. It would also make the\n  code slightly clearer, as the test you perfom on each antichain would be an\n  independent function.\n\n- Why do you deal with breadth 2 differently from the rest? That could mean a\n  couple more operations, but compared to everything else that should not mean\n  much.\n\nBesides that, congratulations for this algorithm. It works, and it works well.\n\nNathann",
    "created_at": "2015-09-16T18:46:49Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259787",
    "user": "https://github.com/nathanncohen"
}
```

Hello Jori,

Here is a first-pass review while on the bus.

- I was very surprised to see a 'distance' argument in the depth-first-search
  function. You do not compute the 'distance' when running a
  depth-first-search. At least not the usual notion of distance in graph
  theory. We should probably remove it, as it is *highly* dangerous to advertise
  it this way `O_o`

- In your code, please use breadth-first-search instead.

- Definition of 'elems': this line often test for containment in 'too_close'. Do
  not run containment tests in a list. use a 'set' for that: containment is
  faster.

- Anyway, you probably should do this differently, i.e. with
  `breadth_first_search(report_distance=True)` while filtering 'too close'
  elements according to their distance.

- I still believe that it would be faster to use
  'subsets_with_hereditary_property' inside of your code. It would also make the
  code slightly clearer, as the test you perfom on each antichain would be an
  independent function.

- Why do you deal with breadth 2 differently from the rest? That could mean a
  couple more operations, but compared to everything else that should not mean
  much.

Besides that, congratulations for this algorithm. It works, and it works well.

Nathann



---

archive/issue_comments_259788.json:
```json
{
    "body": "Replying to [comment:15 ncohen]:\n\n> - I was very surprised to see a 'distance' argument in the depth-first-search\n>   function. You do not compute the 'distance' when running a\n>   depth-first-search. At least not the usual notion of distance in graph\n>   theory. We should probably remove it, as it is *highly* dangerous to advertise\n>   it this way `O_o`\n\n\nFor me the parameter name `distance` feels very clear. But could like also `max_depth`. I think that it is useful to have a function that tells for example to what cities you can reach using max three bus.\n\n> - In your code, please use breadth-first-search instead.\n\n\nWhy? Doesn't it use more memory?\n\n> - Definition of 'elems': this line often test for containment in 'too_close'. Do\n>   not run containment tests in a list. use a 'set' for that: containment is\n>   faster.\n\n\nOK.\n\n> - Anyway, you probably should do this differently, i.e. with\n>   `breadth_first_search(report_distance=True)` while filtering 'too close'\n>   elements according to their distance.\n\n\nI can test and see what happens. But I must make some test lattices, maybe some ordinal sum of ordinal products.\n\n> - I still believe that it would be faster to use\n>   'subsets_with_hereditary_property' inside of your code.\n\n\nI am not sure about that. If I am right, it will make all 2-element antichains, then all 3-element antichains and so on. There will be many of them, only one is needed. (But the one must be the right one, of course...)\n\n> - Why do you deal with breadth 2 differently from the rest?\n\n\nThere was some complication with breadth 2. Maybe it is not needed now in the near-to-final version.\n\nAnd then, this depends on what one is doing. I guess it makes no difference for a big lattice, but for `10^4` small it might be different thing.\n\n> Besides that, congratulations for this algorithm. It works, and it works well.\n\n\nThanks! And thanks for the comments.",
    "created_at": "2015-09-16T19:05:50Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259788",
    "user": "https://github.com/jm58660"
}
```

Replying to [comment:15 ncohen]:

> - I was very surprised to see a 'distance' argument in the depth-first-search
>   function. You do not compute the 'distance' when running a
>   depth-first-search. At least not the usual notion of distance in graph
>   theory. We should probably remove it, as it is *highly* dangerous to advertise
>   it this way `O_o`


For me the parameter name `distance` feels very clear. But could like also `max_depth`. I think that it is useful to have a function that tells for example to what cities you can reach using max three bus.

> - In your code, please use breadth-first-search instead.


Why? Doesn't it use more memory?

> - Definition of 'elems': this line often test for containment in 'too_close'. Do
>   not run containment tests in a list. use a 'set' for that: containment is
>   faster.


OK.

> - Anyway, you probably should do this differently, i.e. with
>   `breadth_first_search(report_distance=True)` while filtering 'too close'
>   elements according to their distance.


I can test and see what happens. But I must make some test lattices, maybe some ordinal sum of ordinal products.

> - I still believe that it would be faster to use
>   'subsets_with_hereditary_property' inside of your code.


I am not sure about that. If I am right, it will make all 2-element antichains, then all 3-element antichains and so on. There will be many of them, only one is needed. (But the one must be the right one, of course...)

> - Why do you deal with breadth 2 differently from the rest?


There was some complication with breadth 2. Maybe it is not needed now in the near-to-final version.

And then, this depends on what one is doing. I guess it makes no difference for a big lattice, but for `10^4` small it might be different thing.

> Besides that, congratulations for this algorithm. It works, and it works well.


Thanks! And thanks for the comments.



---

archive/issue_comments_259789.json:
```json
{
    "body": "Hello,\n\n> For me the parameter name `distance` feels very clear.\n\n\nAnd it is not the graph-theoretic distance in the graph, right? Plus there may be vertices at distance 2 from your start vertex that *never* get explored because you set distance=3. Do we also agree there? This is due to the fact that a vertex is at 'distance' k from the source vertex in a DFS if \"there exists a path of length k from the source vertex to it\" (possibly a *very long* path) and that if this vertex is once discovered at 'distance' 10 000 it may not be 'rediscovered' again at distance 2.\n\n> Why? Doesn't it use more memory?\n\n\nno reason to. It may be trigger additional copies of the 'queue' list (unless we implement a deque), but that's all. Additionally, if this cost worries you then you probably shouldn't use list-comprehension in your code `:-P`\n\n> I am not sure about that. If I am right, it will make all 2-element antichains, then all 3-element antichains and so on. There will be many of them, only one is needed. (But the one must be the right one, of course...)\n\n\nWith your algorithm: if the antichain {a,b,c} is not \"locally minimal\", then your code will test all antichains which contain the antichain {a,b,c} too. With `subset_with_hereditary_property` it would be filtered out.\n\nNathann",
    "created_at": "2015-09-16T19:15:05Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259789",
    "user": "https://github.com/nathanncohen"
}
```

Hello,

> For me the parameter name `distance` feels very clear.


And it is not the graph-theoretic distance in the graph, right? Plus there may be vertices at distance 2 from your start vertex that *never* get explored because you set distance=3. Do we also agree there? This is due to the fact that a vertex is at 'distance' k from the source vertex in a DFS if "there exists a path of length k from the source vertex to it" (possibly a *very long* path) and that if this vertex is once discovered at 'distance' 10 000 it may not be 'rediscovered' again at distance 2.

> Why? Doesn't it use more memory?


no reason to. It may be trigger additional copies of the 'queue' list (unless we implement a deque), but that's all. Additionally, if this cost worries you then you probably shouldn't use list-comprehension in your code `:-P`

> I am not sure about that. If I am right, it will make all 2-element antichains, then all 3-element antichains and so on. There will be many of them, only one is needed. (But the one must be the right one, of course...)


With your algorithm: if the antichain {a,b,c} is not "locally minimal", then your code will test all antichains which contain the antichain {a,b,c} too. With `subset_with_hereditary_property` it would be filtered out.

Nathann



---

archive/issue_comments_259790.json:
```json
{
    "body": "> > For me the parameter name `distance` feels very clear.\n\n\nSaid differently: if I make no mistake, the set of vertices returned by `depth_first_search(v,distance=k)` is not defined in theory, and in practice is architecture-dependent.\n\nNathann",
    "created_at": "2015-09-16T19:17:20Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259790",
    "user": "https://github.com/nathanncohen"
}
```

> > For me the parameter name `distance` feels very clear.


Said differently: if I make no mistake, the set of vertices returned by `depth_first_search(v,distance=k)` is not defined in theory, and in practice is architecture-dependent.

Nathann



---

archive/issue_comments_259791.json:
```json
{
    "body": "More comments later (getting late here), but for this one:\n\nReplying to [comment:17 ncohen]:\n\n> Plus there may be vertices at distance 2 from your start vertex that *never* get explored because you set distance=3. Do we also agree there? This is due to the fact that a vertex is at 'distance' k from the source vertex in a DFS if \"there exists a path of length k from the source vertex to it\" (possibly a *very long* path) and that if this vertex is once discovered at 'distance' 10 000 it may not be 'rediscovered' again at distance 2.\n\n\nNo. The vertex was not discovered at distance 10 000, because search in that path was stopped at distance 3.\n\nI can see nothing complicated here, except maybe on terms to use. Just \"Go back when there is no more unseen vertices as neighbours.\" is changed to \"Go back when there is no more unseen vertices as neighbours or if the maximum distance has already been reached.\"",
    "created_at": "2015-09-16T20:00:32Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259791",
    "user": "https://github.com/jm58660"
}
```

More comments later (getting late here), but for this one:

Replying to [comment:17 ncohen]:

> Plus there may be vertices at distance 2 from your start vertex that *never* get explored because you set distance=3. Do we also agree there? This is due to the fact that a vertex is at 'distance' k from the source vertex in a DFS if "there exists a path of length k from the source vertex to it" (possibly a *very long* path) and that if this vertex is once discovered at 'distance' 10 000 it may not be 'rediscovered' again at distance 2.


No. The vertex was not discovered at distance 10 000, because search in that path was stopped at distance 3.

I can see nothing complicated here, except maybe on terms to use. Just "Go back when there is no more unseen vertices as neighbours." is changed to "Go back when there is no more unseen vertices as neighbours or if the maximum distance has already been reached."



---

archive/issue_comments_259792.json:
```json
{
    "body": "> I can see nothing complicated here, except maybe on terms to use. \n\n\nLet us say that you have a path of length 10 on {0,1,...,9}, and that you add a path of length 3 from 0 to 1, i.e. {0,a,1}.\n\nIf you want all vertices at distance 2 through a DFS starting from 0, you may discover 'a' first (at distance 1) then 1 (at distance 2). You will not explore 2 (because it would be a distance 3).\n\nWhen next you will test edge (0,1) and re-discover 1 (this time at distance 1), you will stop there because '1' has already been discovered.\n\nThus you will never discover vertex '2'.\n\nIf, on the other hand, the algorithm discovered 1 first, then you would proceed to 2 without any problem.\n\nThis is what is wrong.\n\nNathann",
    "created_at": "2015-09-16T20:06:47Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259792",
    "user": "https://github.com/nathanncohen"
}
```

> I can see nothing complicated here, except maybe on terms to use. 


Let us say that you have a path of length 10 on {0,1,...,9}, and that you add a path of length 3 from 0 to 1, i.e. {0,a,1}.

If you want all vertices at distance 2 through a DFS starting from 0, you may discover 'a' first (at distance 1) then 1 (at distance 2). You will not explore 2 (because it would be a distance 3).

When next you will test edge (0,1) and re-discover 1 (this time at distance 1), you will stop there because '1' has already been discovered.

Thus you will never discover vertex '2'.

If, on the other hand, the algorithm discovered 1 first, then you would proceed to 2 without any problem.

This is what is wrong.

Nathann



---

archive/issue_comments_259793.json:
```json
{
    "body": "Replying to [comment:20 ncohen]:\n\n> When next you will test edge (0,1) and re-discover 1 (this time at distance 1), you will stop there because '1' has already been discovered.\n\n\nTrue. Now I understand.\n\nSo vertices at exactly the limit distance should be handled differently. They must be on different list, from where they will be moved to \"normal\" `already_seen` list if they are re-discovered by smaller distance.",
    "created_at": "2015-09-16T20:16:45Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259793",
    "user": "https://github.com/jm58660"
}
```

Replying to [comment:20 ncohen]:

> When next you will test edge (0,1) and re-discover 1 (this time at distance 1), you will stop there because '1' has already been discovered.


True. Now I understand.

So vertices at exactly the limit distance should be handled differently. They must be on different list, from where they will be moved to "normal" `already_seen` list if they are re-discovered by smaller distance.



---

archive/issue_comments_259794.json:
```json
{
    "body": "> So vertices at exactly the limit distance should be handled differently. They must be on different list, from where they will be moved to \"normal\" `already_seen` list if they are re-discovered by smaller distance.\n\n\nThat's going too far. I don't think that we need to 'fix' that, it probably shouldn't even exist. What you want to use in this case is a BFS. Or, actually, `Graph.shortest_path_lengths` (whose name is awful).\n\nNathann",
    "created_at": "2015-09-16T20:20:47Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259794",
    "user": "https://github.com/nathanncohen"
}
```

> So vertices at exactly the limit distance should be handled differently. They must be on different list, from where they will be moved to "normal" `already_seen` list if they are re-discovered by smaller distance.


That's going too far. I don't think that we need to 'fix' that, it probably shouldn't even exist. What you want to use in this case is a BFS. Or, actually, `Graph.shortest_path_lengths` (whose name is awful).

Nathann



---

archive/issue_comments_259795.json:
```json
{
    "body": "I opened a new ticket for the DFS `distance`-bug: #19227.",
    "created_at": "2015-09-17T04:23:03Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259795",
    "user": "https://github.com/jm58660"
}
```

I opened a new ticket for the DFS `distance`-bug: #19227.



---

archive/issue_comments_259796.json:
```json
{
    "body": "Replying to [comment:15 ncohen]:\n\n> - Definition of 'elems': this line often test for containment in 'too_close'. Do\n>   not run containment tests in a list. use a 'set' for that: containment is\n>   faster.\n\n\nTrue. This gave a sligth benefit to speed.\n\n> - Anyway, you probably should do this differently, i.e. with\n>   `breadth_first_search(report_distance=True)` while filtering 'too close'\n>   elements according to their distance.\n\n\nFalse. After\n\n```\nelems = [e[0] for e in H.breadth_first_search(j, neighbors=H.neighbors_in, report_distance=True) if e[1] > B-2]` \n```\n\nit took about infinite time to compute breadth of `TamariLattice(6)`, whereas\n\n```\ntoo_close = set(H.breadth_first_search(j, neighbors=H.neighbors_in,  distance=B-2))\nelems = [e for e in H.order_ideal([j]) if e not in too_close]\n```\n\ndid it in 40 milliseconds.\n\n> - I still believe that it would be faster to use\n>   'subsets_with_hereditary_property' inside of your code.\n\n\nDon't know. Please not that this code tries first with maximal breadth and then goes down one by one. subsets_with_hereditary_property would work to other direction. I guess that it will stuck with too many pairs, triples and so on.\n\n> - Why do you deal with breadth 2 differently from the rest? That could mean a\n>   couple more operations, but compared to everything else that should not mean\n>   much.\n\n\nTrue. This only slowed down the code like `sum(L.breadth() for L in L10)`, where `L10` is a list of 10-element lattices. And even it was very slight loss.\n\nAnyways, I did some tests with product lattices and so. This code seems to be \"fast enought\". For example it takes 4,4 seconds to create a Tamari lattice, and 4,6 seconds to compute it's breadth. So this should not be a bottleneck.",
    "created_at": "2015-09-17T06:08:40Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259796",
    "user": "https://github.com/jm58660"
}
```

Replying to [comment:15 ncohen]:

> - Definition of 'elems': this line often test for containment in 'too_close'. Do
>   not run containment tests in a list. use a 'set' for that: containment is
>   faster.


True. This gave a sligth benefit to speed.

> - Anyway, you probably should do this differently, i.e. with
>   `breadth_first_search(report_distance=True)` while filtering 'too close'
>   elements according to their distance.


False. After

```
elems = [e[0] for e in H.breadth_first_search(j, neighbors=H.neighbors_in, report_distance=True) if e[1] > B-2]` 
```

it took about infinite time to compute breadth of `TamariLattice(6)`, whereas

```
too_close = set(H.breadth_first_search(j, neighbors=H.neighbors_in,  distance=B-2))
elems = [e for e in H.order_ideal([j]) if e not in too_close]
```

did it in 40 milliseconds.

> - I still believe that it would be faster to use
>   'subsets_with_hereditary_property' inside of your code.


Don't know. Please not that this code tries first with maximal breadth and then goes down one by one. subsets_with_hereditary_property would work to other direction. I guess that it will stuck with too many pairs, triples and so on.

> - Why do you deal with breadth 2 differently from the rest? That could mean a
>   couple more operations, but compared to everything else that should not mean
>   much.


True. This only slowed down the code like `sum(L.breadth() for L in L10)`, where `L10` is a list of 10-element lattices. And even it was very slight loss.

Anyways, I did some tests with product lattices and so. This code seems to be "fast enought". For example it takes 4,4 seconds to create a Tamari lattice, and 4,6 seconds to compute it's breadth. So this should not be a bottleneck.



---

archive/issue_comments_259797.json:
```json
{
    "body": "Branch pushed to git repo; I updated commit sha1. New commits:",
    "created_at": "2015-09-17T06:14:51Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259797",
    "user": "https://trac.sagemath.org/admin/accounts/users/git"
}
```

Branch pushed to git repo; I updated commit sha1. New commits:



---

archive/issue_comments_259798.json:
```json
{
    "body": "Helloooooooooooo,\n\nI've got only one thing to add to this code: `self[e]` looks dangerous to me, just because I do not know what exactly it does. The `__getitem__` function defined on posets seems to be inherited and (very) generic. In particular, I suspect that `self[e]` may be as \"efficient\" as `list(self)[e]`. I think that you should prefer `_element_to_vertex(x)` in this situation.\n\nNathann",
    "created_at": "2015-09-18T13:29:22Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259798",
    "user": "https://github.com/nathanncohen"
}
```

Helloooooooooooo,

I've got only one thing to add to this code: `self[e]` looks dangerous to me, just because I do not know what exactly it does. The `__getitem__` function defined on posets seems to be inherited and (very) generic. In particular, I suspect that `self[e]` may be as "efficient" as `list(self)[e]`. I think that you should prefer `_element_to_vertex(x)` in this situation.

Nathann



---

archive/issue_comments_259799.json:
```json
{
    "body": "Branch pushed to git repo; I updated commit sha1. New commits:",
    "created_at": "2015-09-18T14:26:33Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259799",
    "user": "https://trac.sagemath.org/admin/accounts/users/git"
}
```

Branch pushed to git repo; I updated commit sha1. New commits:



---

archive/issue_comments_259800.json:
```json
{
    "body": "Replying to [comment:26 ncohen]:>\n\n> I think that you should prefer `_element_to_vertex(x)` in this situation.\n\n\nCorrected. (To `_vertex_to_element` of course, not `_element_to_vertex`.)",
    "created_at": "2015-09-18T14:28:10Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259800",
    "user": "https://github.com/jm58660"
}
```

Replying to [comment:26 ncohen]:>

> I think that you should prefer `_element_to_vertex(x)` in this situation.


Corrected. (To `_vertex_to_element` of course, not `_element_to_vertex`.)



---

archive/issue_comments_259801.json:
```json
{
    "body": "Changing status from needs_review to positive_review.",
    "created_at": "2015-09-18T14:31:12Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259801",
    "user": "https://github.com/nathanncohen"
}
```

Changing status from needs_review to positive_review.



---

archive/issue_comments_259802.json:
```json
{
    "body": "OOps, right. Good to go then. Good work, really.\n\nNathann",
    "created_at": "2015-09-18T14:31:12Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259802",
    "user": "https://github.com/nathanncohen"
}
```

OOps, right. Good to go then. Good work, really.

Nathann



---

archive/issue_comments_259803.json:
```json
{
    "body": "By the way: it seems to me that, theoretically speaking, having breadth `>=b` is equivalent to:\n\n```\nsage: G1 = my_lattice.hasse_diagram().transitive_closure()\nsage: G2 = posets.BooleanLattice(p).hasse_diagram().transitive_closure()\nsage: G1.subgraph_search(G2,induced=True)\nTrue\n```\n\nBut well. Does not seem like it would help on the computational side.\n\nNathann",
    "created_at": "2015-09-18T14:34:15Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259803",
    "user": "https://github.com/nathanncohen"
}
```

By the way: it seems to me that, theoretically speaking, having breadth `>=b` is equivalent to:

```
sage: G1 = my_lattice.hasse_diagram().transitive_closure()
sage: G2 = posets.BooleanLattice(p).hasse_diagram().transitive_closure()
sage: G1.subgraph_search(G2,induced=True)
True
```

But well. Does not seem like it would help on the computational side.

Nathann



---

archive/issue_comments_259804.json:
```json
{
    "body": "Replying to [comment:30 ncohen]:\n> By the way: it seems to me that, theoretically speaking, having breadth `>=b` is equivalent to:\n> \n> \n> ```\n> sage: G1 = my_lattice.hasse_diagram().transitive_closure()\n> sage: G2 = posets.BooleanLattice(p).hasse_diagram().transitive_closure()\n> sage: G1.subgraph_search(G2,induced=True)\n> True\n> ```\n\n\nAnd that is same as `L.has_isomorphic_subposet(Posets.BooleanLattice(b))`. I guess you are right. (But not sure - must think about this.)\n\nI made an example of smallest lattice with breadth 4 with `completion_by_cuts()` and did not notice that the result was just `BooleanLattice(4)`. Oops.\n\nAnd that means that my example of lattice with breadth 4 is stupid, as it hides the structure to dig6 string.",
    "created_at": "2015-09-18T15:59:44Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259804",
    "user": "https://github.com/jm58660"
}
```

Replying to [comment:30 ncohen]:
> By the way: it seems to me that, theoretically speaking, having breadth `>=b` is equivalent to:
> 
> 
> ```
> sage: G1 = my_lattice.hasse_diagram().transitive_closure()
> sage: G2 = posets.BooleanLattice(p).hasse_diagram().transitive_closure()
> sage: G1.subgraph_search(G2,induced=True)
> True
> ```


And that is same as `L.has_isomorphic_subposet(Posets.BooleanLattice(b))`. I guess you are right. (But not sure - must think about this.)

I made an example of smallest lattice with breadth 4 with `completion_by_cuts()` and did not notice that the result was just `BooleanLattice(4)`. Oops.

And that means that my example of lattice with breadth 4 is stupid, as it hides the structure to dig6 string.



---

archive/issue_comments_259805.json:
```json
{
    "body": "Hello,\n\n> And that is same as `L.has_isomorphic_subposet(Posets.BooleanLattice(b))`\n\n\nOh, sorry. I tend to turn everything into graphs, and work with that.\n\n> I made an example of smallest lattice with breadth 4 with `completion_by_cuts()` and did not notice that the result was just `BooleanLattice(4)`. Oops.\n> \n> And that means that my example of lattice with breadth 4 is stupid, as it hides the structure to dig6 string.\n\n\nI see. Well, you can fix this in any other ticket if you wish anyway.\n\nNathann",
    "created_at": "2015-09-18T16:57:34Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259805",
    "user": "https://github.com/nathanncohen"
}
```

Hello,

> And that is same as `L.has_isomorphic_subposet(Posets.BooleanLattice(b))`


Oh, sorry. I tend to turn everything into graphs, and work with that.

> I made an example of smallest lattice with breadth 4 with `completion_by_cuts()` and did not notice that the result was just `BooleanLattice(4)`. Oops.
> 
> And that means that my example of lattice with breadth 4 is stupid, as it hides the structure to dig6 string.


I see. Well, you can fix this in any other ticket if you wish anyway.

Nathann



---

archive/issue_comments_259806.json:
```json
{
    "body": "Replying to [comment:32 ncohen]:\n\n> I see. Well, you can fix this in any other ticket if you wish anyway.\n\n\nI'll do that after #19123 on #19190.",
    "created_at": "2015-09-18T17:22:12Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259806",
    "user": "https://github.com/jm58660"
}
```

Replying to [comment:32 ncohen]:

> I see. Well, you can fix this in any other ticket if you wish anyway.


I'll do that after #19123 on #19190.



---

archive/issue_events_053302.json:
```json
{
    "actor": "https://github.com/vbraun",
    "created_at": "2015-09-18T19:10:41Z",
    "event": "closed",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sagetest/issues/18960#event-53302"
}
```



---

archive/issue_comments_259807.json:
```json
{
    "body": "Resolution: fixed",
    "created_at": "2015-09-18T19:10:41Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18960",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18960#issuecomment-259807",
    "user": "https://github.com/vbraun"
}
```

Resolution: fixed
