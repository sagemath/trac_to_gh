# Issue 20009: Use with strict_equality to work around hashing of p-adics

archive/issues_020009.json:
```json
{
    "body": "CC:  @roed314\n\nHere are some timings. In all these examples, `X = toric_varieties.dP8()` and we consider `%timeit [X.cohomology_basis(1) for i in range(1000)]`.\n\nThe current `cachefunc.pyx` (using `_cache_key` in a try-finally-block):\n\n```\n1000 loops, best of 3: 419 \u00b5s per loop\n```\n\nThe old version which does not handle unhashable objects at all:\n\n```\n1000 loops, best of 3: 387 \u00b5s per loop\n```\n\nThe proposed implementation:\n\n```\n1000 loops, best of 3: 395 \u00b5s per loop\n```\n\n\nIssue created by migration from https://trac.sagemath.org/ticket/20246\n\n",
    "created_at": "2016-03-22T02:06:25Z",
    "labels": [
        "component: padics"
    ],
    "milestone": "https://github.com/sagemath/sagetest/milestones/sage-duplicate/invalid/wontfix",
    "title": "Use with strict_equality to work around hashing of p-adics",
    "type": "issue",
    "url": "https://github.com/sagemath/sagetest/issues/20009",
    "user": "https://github.com/saraedum"
}
```
CC:  @roed314

Here are some timings. In all these examples, `X = toric_varieties.dP8()` and we consider `%timeit [X.cohomology_basis(1) for i in range(1000)]`.

The current `cachefunc.pyx` (using `_cache_key` in a try-finally-block):

```
1000 loops, best of 3: 419 µs per loop
```

The old version which does not handle unhashable objects at all:

```
1000 loops, best of 3: 387 µs per loop
```

The proposed implementation:

```
1000 loops, best of 3: 395 µs per loop
```


Issue created by migration from https://trac.sagemath.org/ticket/20246





---

archive/issue_comments_275320.json:
```json
{
    "body": "Branch pushed to git repo; I updated commit sha1. New commits:",
    "created_at": "2016-03-24T00:26:02Z",
    "issue": "https://github.com/sagemath/sagetest/issues/20009",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/20009#issuecomment-275320",
    "user": "https://trac.sagemath.org/admin/accounts/users/git"
}
```

Branch pushed to git repo; I updated commit sha1. New commits:



---

archive/issue_comments_275321.json:
```json
{
    "body": "Branch pushed to git repo; I updated commit sha1. New commits:",
    "created_at": "2016-03-24T00:26:44Z",
    "issue": "https://github.com/sagemath/sagetest/issues/20009",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/20009#issuecomment-275321",
    "user": "https://trac.sagemath.org/admin/accounts/users/git"
}
```

Branch pushed to git repo; I updated commit sha1. New commits:



---

archive/issue_comments_275322.json:
```json
{
    "body": "Branch pushed to git repo; I updated commit sha1. New commits:",
    "created_at": "2016-03-24T02:17:41Z",
    "issue": "https://github.com/sagemath/sagetest/issues/20009",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/20009#issuecomment-275322",
    "user": "https://trac.sagemath.org/admin/accounts/users/git"
}
```

Branch pushed to git repo; I updated commit sha1. New commits:



---

archive/issue_comments_275323.json:
```json
{
    "body": "Changing keywords from \"\" to \"days71\".",
    "created_at": "2016-03-24T02:20:16Z",
    "issue": "https://github.com/sagemath/sagetest/issues/20009",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/20009#issuecomment-275323",
    "user": "https://github.com/saraedum"
}
```

Changing keywords from "" to "days71".



---

archive/issue_comments_275324.json:
```json
{
    "body": "We should remove the changes to fraction field elements again and move them to #20271.",
    "created_at": "2016-03-24T03:13:02Z",
    "issue": "https://github.com/sagemath/sagetest/issues/20009",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/20009#issuecomment-275324",
    "user": "https://github.com/saraedum"
}
```

We should remove the changes to fraction field elements again and move them to #20271.



---

archive/issue_comments_275325.json:
```json
{
    "body": "Branch pushed to git repo; I updated commit sha1. New commits:",
    "created_at": "2016-03-25T00:06:43Z",
    "issue": "https://github.com/sagemath/sagetest/issues/20009",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/20009#issuecomment-275325",
    "user": "https://trac.sagemath.org/admin/accounts/users/git"
}
```

Branch pushed to git repo; I updated commit sha1. New commits:



---

archive/issue_comments_275326.json:
```json
{
    "body": "The branch seems to not merge against develop.",
    "created_at": "2016-03-25T00:36:36Z",
    "issue": "https://github.com/sagemath/sagetest/issues/20009",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/20009#issuecomment-275326",
    "user": "https://github.com/roed314"
}
```

The branch seems to not merge against develop.



---

archive/issue_comments_275327.json:
```json
{
    "body": "Branch pushed to git repo; I updated commit sha1. New commits:",
    "created_at": "2016-03-25T10:35:17Z",
    "issue": "https://github.com/sagemath/sagetest/issues/20009",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/20009#issuecomment-275327",
    "user": "https://trac.sagemath.org/admin/accounts/users/git"
}
```

Branch pushed to git repo; I updated commit sha1. New commits:



---

archive/issue_comments_275328.json:
```json
{
    "body": "Ok. Fixed.",
    "created_at": "2016-03-25T10:35:56Z",
    "issue": "https://github.com/sagemath/sagetest/issues/20009",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/20009#issuecomment-275328",
    "user": "https://github.com/saraedum"
}
```

Ok. Fixed.



---

archive/issue_comments_275329.json:
```json
{
    "body": "So, how close is this to Needs Review?",
    "created_at": "2016-03-25T10:51:27Z",
    "issue": "https://github.com/sagemath/sagetest/issues/20009",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/20009#issuecomment-275329",
    "user": "https://github.com/roed314"
}
```

So, how close is this to Needs Review?



---

archive/issue_comments_275330.json:
```json
{
    "body": "Changing status from new to needs_review.",
    "created_at": "2016-03-25T13:35:16Z",
    "issue": "https://github.com/sagemath/sagetest/issues/20009",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/20009#issuecomment-275330",
    "user": "https://github.com/saraedum"
}
```

Changing status from new to needs_review.



---

archive/issue_comments_275331.json:
```json
{
    "body": "You can have a look. A few doctests fail. Let's have the patchbot run it. Most seem to be in the projective minimal model we looked at which seems to be incorrect (i.e., dependent on input formatting.)",
    "created_at": "2016-03-25T13:35:16Z",
    "issue": "https://github.com/sagemath/sagetest/issues/20009",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/20009#issuecomment-275331",
    "user": "https://github.com/saraedum"
}
```

You can have a look. A few doctests fail. Let's have the patchbot run it. Most seem to be in the projective minimal model we looked at which seems to be incorrect (i.e., dependent on input formatting.)



---

archive/issue_comments_275332.json:
```json
{
    "body": "Changing status from needs_review to needs_work.",
    "created_at": "2016-03-26T02:20:16Z",
    "issue": "https://github.com/sagemath/sagetest/issues/20009",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/20009#issuecomment-275332",
    "user": "https://github.com/saraedum"
}
```

Changing status from needs_review to needs_work.



---

archive/issue_comments_275333.json:
```json
{
    "body": "It seems that I missed quite a few doctests. Mostly trivial changes in printing it seems.",
    "created_at": "2016-03-26T02:20:16Z",
    "issue": "https://github.com/sagemath/sagetest/issues/20009",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/20009#issuecomment-275333",
    "user": "https://github.com/saraedum"
}
```

It seems that I missed quite a few doctests. Mostly trivial changes in printing it seems.



---

archive/issue_comments_275334.json:
```json
{
    "body": "It would seem to me that storing data keyed by \"imprecise\" data like p-adic numbers is likely a program error. Are we sure that allowing cached data keyed by p-adics is essential?\n\nThe solution proposed here -- introducing a global flag to change the semantics of comparison -- scares me. It sounds like a horrible bugtrap to me. Note that python allows for multiple threads. Changing a global flag like this would not only make the particular thread this happens in non-threadsafe, but it would change the behaviour of other threads too (that may otherwise think they are threadsafe).\n\nI thin it's even worse: whenever one uses `with strict_precision(True):` one would need to know exactly what code gets executed inside to know if any code there depends on the semantics of equality testing. That's virtually impossible to do. It would certainly mean that one cannot put that command anywhere where any remotely generic code gets executed (because you need to *check* all the code that might get executed).\n\nI think it's worth quite a bit to avoid having to put in this horrible hack, including looking at the scenarios that seem to need this feature and see how they can be rewritten to not need p-adics to be hashable.\n\nI would suggest that going the `cache_key` route is the most promissing. p-adic numbers are then not hashable (as they are supposed to be) and hence composite objects that hash by hashing their constituents, are not hashable either if they contain p-adic numbers. Those objects should have a cache_key method as a fall-back, if they are required to be \"cacheable\".\n\nI agree it's ugly, but it's a lot less error-prone than making equality semantics depend on a global flag.",
    "created_at": "2016-03-26T03:35:18Z",
    "issue": "https://github.com/sagemath/sagetest/issues/20009",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/20009#issuecomment-275334",
    "user": "https://github.com/nbruin"
}
```

It would seem to me that storing data keyed by "imprecise" data like p-adic numbers is likely a program error. Are we sure that allowing cached data keyed by p-adics is essential?

The solution proposed here -- introducing a global flag to change the semantics of comparison -- scares me. It sounds like a horrible bugtrap to me. Note that python allows for multiple threads. Changing a global flag like this would not only make the particular thread this happens in non-threadsafe, but it would change the behaviour of other threads too (that may otherwise think they are threadsafe).

I thin it's even worse: whenever one uses `with strict_precision(True):` one would need to know exactly what code gets executed inside to know if any code there depends on the semantics of equality testing. That's virtually impossible to do. It would certainly mean that one cannot put that command anywhere where any remotely generic code gets executed (because you need to *check* all the code that might get executed).

I think it's worth quite a bit to avoid having to put in this horrible hack, including looking at the scenarios that seem to need this feature and see how they can be rewritten to not need p-adics to be hashable.

I would suggest that going the `cache_key` route is the most promissing. p-adic numbers are then not hashable (as they are supposed to be) and hence composite objects that hash by hashing their constituents, are not hashable either if they contain p-adic numbers. Those objects should have a cache_key method as a fall-back, if they are required to be "cacheable".

I agree it's ugly, but it's a lot less error-prone than making equality semantics depend on a global flag.



---

archive/issue_comments_275335.json:
```json
{
    "body": "Replying to [comment:21 nbruin]:\n> It would seem to me that storing data keyed by \"imprecise\" data like p-adic numbers is likely a program error. Are we sure that allowing cached data keyed by p-adics is essential?\n\nYes.  The main application is for cached methods, which use dictionaries to store the results.\n\nIn other contexts, I agree that using p-adics as keys for a dictionary is likely a program error.  But dicts and hashing are sufficiently central to Python's idioms that being able to use them if you really need to is convenient.  I think that forcing the user to use a context is a good compromise between not allowing dicts at all and letting them shoot themselves in the foot by allowing inexact keys.\n\n> The solution proposed here -- introducing a global flag to change the semantics of comparison -- scares me. It sounds like a horrible bugtrap to me. Note that python allows for multiple threads. Changing a global flag like this would not only make the particular thread this happens in non-threadsafe, but it would change the behaviour of other threads too (that may otherwise think they are threadsafe).\n\nI agree that it's a little scary, and Julian and I talked about threading.  Is Sage actually threadsafe?  Is anyone using threading with Sage?\n\n> I think it's even worse: whenever one uses `with strict_precision(True):` one would need to know exactly what code gets executed inside to know if any code there depends on the semantics of equality testing. That's virtually impossible to do. It would certainly mean that one cannot put that command anywhere where any remotely generic code gets executed (because you need to *check* all the code that might get executed).\n\nYes: `strict_equality` should only be turned on for actually inserting an object into a dictionary.  And the reason that it's a stack is so that you can turn it off when calling back into generic code.  But just because you can't wrap large blocks of code in `strict_equality(True)` doesn't mean that it's not useful.  And the documentation on the context clearly explains the dangers of using it.\n\n> I think it's worth quite a bit to avoid having to put in this horrible hack, including looking at the scenarios that seem to need this feature and see how they can be rewritten to not need p-adics to be hashable.\n>\n> I would suggest that going the `cache_key` route is the most promissing. p-adic numbers are then not hashable (as they are supposed to be) and hence composite objects that hash by hashing their constituents, are not hashable either if they contain p-adic numbers. Those objects should have a cache_key method as a fall-back, if they are required to be \"cacheable\".\n> \n> I agree it's ugly, but it's a lot less error-prone than making equality semantics depend on a global flag.\n\nThe huge problem with `cache_key` is that any object that can recursively contain an inexact element needs to now define a `cache_key`.  Polynomials, matrices, parents that are defined by polynomials....  It's a nightmare to add all of these `cache_keys`.\n\nAnd if `strict_equality` is used sparingly, I don't think it's that bad.",
    "created_at": "2016-03-26T13:33:31Z",
    "issue": "https://github.com/sagemath/sagetest/issues/20009",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/20009#issuecomment-275335",
    "user": "https://github.com/roed314"
}
```

Replying to [comment:21 nbruin]:
> It would seem to me that storing data keyed by "imprecise" data like p-adic numbers is likely a program error. Are we sure that allowing cached data keyed by p-adics is essential?

Yes.  The main application is for cached methods, which use dictionaries to store the results.

In other contexts, I agree that using p-adics as keys for a dictionary is likely a program error.  But dicts and hashing are sufficiently central to Python's idioms that being able to use them if you really need to is convenient.  I think that forcing the user to use a context is a good compromise between not allowing dicts at all and letting them shoot themselves in the foot by allowing inexact keys.

> The solution proposed here -- introducing a global flag to change the semantics of comparison -- scares me. It sounds like a horrible bugtrap to me. Note that python allows for multiple threads. Changing a global flag like this would not only make the particular thread this happens in non-threadsafe, but it would change the behaviour of other threads too (that may otherwise think they are threadsafe).

I agree that it's a little scary, and Julian and I talked about threading.  Is Sage actually threadsafe?  Is anyone using threading with Sage?

> I think it's even worse: whenever one uses `with strict_precision(True):` one would need to know exactly what code gets executed inside to know if any code there depends on the semantics of equality testing. That's virtually impossible to do. It would certainly mean that one cannot put that command anywhere where any remotely generic code gets executed (because you need to *check* all the code that might get executed).

Yes: `strict_equality` should only be turned on for actually inserting an object into a dictionary.  And the reason that it's a stack is so that you can turn it off when calling back into generic code.  But just because you can't wrap large blocks of code in `strict_equality(True)` doesn't mean that it's not useful.  And the documentation on the context clearly explains the dangers of using it.

> I think it's worth quite a bit to avoid having to put in this horrible hack, including looking at the scenarios that seem to need this feature and see how they can be rewritten to not need p-adics to be hashable.
>
> I would suggest that going the `cache_key` route is the most promissing. p-adic numbers are then not hashable (as they are supposed to be) and hence composite objects that hash by hashing their constituents, are not hashable either if they contain p-adic numbers. Those objects should have a cache_key method as a fall-back, if they are required to be "cacheable".
> 
> I agree it's ugly, but it's a lot less error-prone than making equality semantics depend on a global flag.

The huge problem with `cache_key` is that any object that can recursively contain an inexact element needs to now define a `cache_key`.  Polynomials, matrices, parents that are defined by polynomials....  It's a nightmare to add all of these `cache_keys`.

And if `strict_equality` is used sparingly, I don't think it's that bad.



---

archive/issue_comments_275336.json:
```json
{
    "body": "Replying to [comment:22 roed]:\n> The huge problem with `cache_key` is that any object that can recursively contain an inexact element needs to now define a `cache_key`.  Polynomials, matrices, parents that are defined by polynomials....  It's a nightmare to add all of these `cache_keys`.\n\nOnly the ones that actually get used as cache keys need one. Using a p-adic number as a dictionary key (including a cache) is likely a programming/logic error, so the only places where you need to allow it is where you think the convenience of being able to do it is sufficiently important. There's no need to universally announce that any object containing p-adics can be used as a cache key.\n\nAnd if I understand correctly, the cache_key can be implemented quite high in the hierarchy, so you wouldn't need to so terribly many of them, and their implementations are trivial. I can see how it might seem like a nightmare, but actually doing it for the cases where you need it might not be so bad. The remaining cases will get pretty good error messages because it's just a hashing failure.\n\n(As an example for how seemingly nightmarish changes turn out to be not so bad, look at #20028. In the end that wasn't nearly as bad as it seemed when we started out. The main thing was changing doctests, and that would not be an issue here)\n\n> And if `strict_equality` is used sparingly, I don't think it's that bad.\n\nI think that qualification already relegates it to a last resort solution, only to be implemented if the others are thoroughly unworkable. And implementing `cache_key` routines in strategic places as the need arises should be quite workable.\n\nI really think making the meaning of equality tests depend on the program state is a very undesirable step to make and compared to that, implementing some `cache_key` routines doesn't seem so bad.",
    "created_at": "2016-03-26T16:07:13Z",
    "issue": "https://github.com/sagemath/sagetest/issues/20009",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/20009#issuecomment-275336",
    "user": "https://github.com/nbruin"
}
```

Replying to [comment:22 roed]:
> The huge problem with `cache_key` is that any object that can recursively contain an inexact element needs to now define a `cache_key`.  Polynomials, matrices, parents that are defined by polynomials....  It's a nightmare to add all of these `cache_keys`.

Only the ones that actually get used as cache keys need one. Using a p-adic number as a dictionary key (including a cache) is likely a programming/logic error, so the only places where you need to allow it is where you think the convenience of being able to do it is sufficiently important. There's no need to universally announce that any object containing p-adics can be used as a cache key.

And if I understand correctly, the cache_key can be implemented quite high in the hierarchy, so you wouldn't need to so terribly many of them, and their implementations are trivial. I can see how it might seem like a nightmare, but actually doing it for the cases where you need it might not be so bad. The remaining cases will get pretty good error messages because it's just a hashing failure.

(As an example for how seemingly nightmarish changes turn out to be not so bad, look at #20028. In the end that wasn't nearly as bad as it seemed when we started out. The main thing was changing doctests, and that would not be an issue here)

> And if `strict_equality` is used sparingly, I don't think it's that bad.

I think that qualification already relegates it to a last resort solution, only to be implemented if the others are thoroughly unworkable. And implementing `cache_key` routines in strategic places as the need arises should be quite workable.

I really think making the meaning of equality tests depend on the program state is a very undesirable step to make and compared to that, implementing some `cache_key` routines doesn't seem so bad.



---

archive/issue_comments_275337.json:
```json
{
    "body": "Replying to [comment:23 nbruin]:\n> Replying to [comment:22 roed]:\n> > The huge problem with `cache_key` is that any object that can recursively contain an inexact element needs to now define a `cache_key`.  Polynomials, matrices, parents that are defined by polynomials....  It's a nightmare to add all of these `cache_keys`.\n> \n> Only the ones that actually get used as cache keys need one.\nHowever, most parents get used as cache keys in our factories and `UniqueRepresentation`. And parents may depend on p-adic numbers in some way.\n\n> Using a p-adic number as a dictionary key (including a cache) is likely a programming/logic error, so the only places where you need to allow it is where you think the convenience of being able to do it is sufficiently important.\nI agree that it is usually a programming error. Therefore, you want to make sure that people explicitly select the right notion of equality to use them. Note that this is also a problem for fraction field elements.\n\n> There's no need to universally announce that any object containing p-adics can be used as a cache key.\nNo but a lot of our code assumes that everything is usable as a key in a dictionary for the sake of caching. I believe that this is a reasonable assumption: Running a method on indistinguishable inputs should produce the same output. And in some cases it should even produce the exact same object, for example when creating parents; in those cases you can not do without caching.\n\n> And if I understand correctly, the cache_key can be implemented quite high in the hierarchy, so you wouldn't need to so terribly many of them, and their implementations are trivial.\nI am not sure what you mean with \"high up\". For correctness you have to implement it in any class that gets instantiated with a parameter that may depend (in some way) on something unhashable, because essentially you just need to write this as a method that produces the constructor parameters that serve to produce an indistinguishable element.\n\n> I can see how it might seem like a nightmare, but actually doing it for the cases where you need it might not be so bad. The remaining cases will get pretty good error messages because it's just a hashing failure.\nThough I originally implemented `_cache_key` what I dislike about it is that you just have to add silly boilerplate to many classes. The new approach is much better in that sense. The changes are where the actual problem arises, namely in the classes that can not define a usual `__hash__`. For everybody else it just works and it is actually correct. The current `_cache_key` is calling for trouble in the long run: People add a constructor parameter but don't add it to `_cache_key`; the doctests pass but caching eventually produces incorrect results.\nOf course, if the end user decides to run all its code `with strict_equality(True)` then many things break. But the docstring tries to be clear about this.\n\n> > And if `strict_equality` is used sparingly, I don't think it's that bad.\n> I think that qualification already relegates it to a last resort solution, only to be implemented if the others are thoroughly unworkable. And implementing `cache_key` routines in strategic places as the need arises should be quite workable.\nI think the \"strategic places\" is a problem here. What this says it that using p-adics (or fraction field elements) just works in places where there happened to be a doctest that implied p-adics (and usually extension fields to actually trigger `__hash__`.) Why not make it work everywhere?\n\n> I really think making the meaning of equality tests depend on the program state is a very undesirable step to make and compared to that, implementing some `cache_key` routines doesn't seem so bad.\nYes, global state is bad. The implementation is very clear on that and I can elaborate on this further in the docstrings. If you enable strict equality and then call into other code you are calling for trouble. That is why you only enable it very locally and can even disable it again more locally if you need to call out.",
    "created_at": "2016-03-28T13:40:55Z",
    "issue": "https://github.com/sagemath/sagetest/issues/20009",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/20009#issuecomment-275337",
    "user": "https://github.com/saraedum"
}
```

Replying to [comment:23 nbruin]:
> Replying to [comment:22 roed]:
> > The huge problem with `cache_key` is that any object that can recursively contain an inexact element needs to now define a `cache_key`.  Polynomials, matrices, parents that are defined by polynomials....  It's a nightmare to add all of these `cache_keys`.
> 
> Only the ones that actually get used as cache keys need one.
However, most parents get used as cache keys in our factories and `UniqueRepresentation`. And parents may depend on p-adic numbers in some way.

> Using a p-adic number as a dictionary key (including a cache) is likely a programming/logic error, so the only places where you need to allow it is where you think the convenience of being able to do it is sufficiently important.
I agree that it is usually a programming error. Therefore, you want to make sure that people explicitly select the right notion of equality to use them. Note that this is also a problem for fraction field elements.

> There's no need to universally announce that any object containing p-adics can be used as a cache key.
No but a lot of our code assumes that everything is usable as a key in a dictionary for the sake of caching. I believe that this is a reasonable assumption: Running a method on indistinguishable inputs should produce the same output. And in some cases it should even produce the exact same object, for example when creating parents; in those cases you can not do without caching.

> And if I understand correctly, the cache_key can be implemented quite high in the hierarchy, so you wouldn't need to so terribly many of them, and their implementations are trivial.
I am not sure what you mean with "high up". For correctness you have to implement it in any class that gets instantiated with a parameter that may depend (in some way) on something unhashable, because essentially you just need to write this as a method that produces the constructor parameters that serve to produce an indistinguishable element.

> I can see how it might seem like a nightmare, but actually doing it for the cases where you need it might not be so bad. The remaining cases will get pretty good error messages because it's just a hashing failure.
Though I originally implemented `_cache_key` what I dislike about it is that you just have to add silly boilerplate to many classes. The new approach is much better in that sense. The changes are where the actual problem arises, namely in the classes that can not define a usual `__hash__`. For everybody else it just works and it is actually correct. The current `_cache_key` is calling for trouble in the long run: People add a constructor parameter but don't add it to `_cache_key`; the doctests pass but caching eventually produces incorrect results.
Of course, if the end user decides to run all its code `with strict_equality(True)` then many things break. But the docstring tries to be clear about this.

> > And if `strict_equality` is used sparingly, I don't think it's that bad.
> I think that qualification already relegates it to a last resort solution, only to be implemented if the others are thoroughly unworkable. And implementing `cache_key` routines in strategic places as the need arises should be quite workable.
I think the "strategic places" is a problem here. What this says it that using p-adics (or fraction field elements) just works in places where there happened to be a doctest that implied p-adics (and usually extension fields to actually trigger `__hash__`.) Why not make it work everywhere?

> I really think making the meaning of equality tests depend on the program state is a very undesirable step to make and compared to that, implementing some `cache_key` routines doesn't seem so bad.
Yes, global state is bad. The implementation is very clear on that and I can elaborate on this further in the docstrings. If you enable strict equality and then call into other code you are calling for trouble. That is why you only enable it very locally and can even disable it again more locally if you need to call out.



---

archive/issue_comments_275338.json:
```json
{
    "body": "Replying to [comment:24 saraedum]:\n> However, most parents get used as cache keys in our factories and `UniqueRepresentation`. And parents may depend on p-adic numbers in some way.\n\nParents that are used as cache-keys are usually not a problem: they are usually `EqualityByID`, so they can basically hash by their ID. If p-adics are part of the construction parameters (e.g., a p-adic extension field, perhaps?) of a `unique` parent structure, a little more is needed, of course. There either we would need `cache_key` or we'd need to transform the construction parameters into something that can be hashed. For extension fields, that's actually not such an unreasonable thing to do: fields defined by a minimal polynomial that is only known to limited precision is a real pain. It's much more convenient to lift it to an exact polynomial.\n\nIn any case, I would be very surprised if there are any structures out there that depend on anything else than sequences, polynomials, and matrices. If those have cache_key strategies, we'd be OK.\n\n> No but a lot of our code assumes that everything is usable as a key in a dictionary for the sake of caching. I believe that this is a reasonable assumption: Running a method on indistinguishable inputs should produce the same output. And in some cases it should even produce the exact same object, for example when creating parents; in those cases you can not do without caching.\n\nBut I am pretty sure this is limited to polynomials and matrices.\n\n> I am not sure what you mean with \"high up\". For correctness you have to implement it in any class that gets instantiated with a parameter that may depend (in some way) on something unhashable, because essentially you just need to write this as a method that produces the constructor parameters that serve to produce an indistinguishable element.\n\nI meant: you could start sticking implementations into the more generic classes for polynomials and matrices. I don't think we need to define \"correctness\" as \"p-adic numbers are hashable\".\n\n> Though I originally implemented `_cache_key` what I dislike about it is that you just have to add silly boilerplate to many classes. The new approach is much better in that sense. The changes are where the actual problem arises, namely in the classes that can not define a usual `__hash__`. For everybody else it just works and it is actually correct. The current `_cache_key` is calling for trouble in the long run: People add a constructor parameter but don't add it to `_cache_key`; the doctests pass but caching eventually produces incorrect results.\n\nMost parents do not need a `_cache_key`, because they are actually hashable thanks to `EqualityByID`. I'd expect that only some element classes need a `_cache_key`. So the scenario you sketch would only play out if the identity-determining components of an element change.\n\n> Of course, if the end user decides to run all its code `with strict_equality(True)` then many things break. But the docstring tries to be clear about this.\n\nThe fundamental point is that you make equality context dependent. It means you now need to know global state in order to reason about code that otherwise looks completely local. I think that's an incredibly big complexification and a major step back in the understandability and maintainability of sage code. Whatever you write in the docstring doesn't change that fact. You can't fix bad design by good documentation.\n\n> I think the \"strategic places\" is a problem here. What this says it that using p-adics (or fraction field elements) just works in places where there happened to be a doctest that implied p-adics (and usually extension fields to actually trigger `__hash__`.) Why not make it work everywhere?\n\nI think you are too pessimistic about the multitude of ways in which padic numbers can end up being hashed in legitimate ways. I think you can get this covered pretty quickly (polys and matrices). Plus: a lot of places where p-adics aren't initially foreseen will actually break with p-adics, because they are imprecise objects. That usually breaks algorithms that weren't built with that in mind.\n\nre. why not everywhere: because the proposed solution (making equality testing depend on global state) incurs too high a price on the maintainability of sage.\n\n> Yes, global state is bad. The implementation is very clear on that and I can elaborate on this further in the docstrings.\n\nBeing clear about it doesn't fix a bad design decision (an, I think, justified technical qualification of the proposal which in no way reflects on the proposers)\n\nI'm sympathetic about the problem. The issue is really that equality tests for p-adics are probably bad in all cases. We're finding two interpretations that sort-of work in some circumstances:\n- difference is indistinguishable from 0: if you start out with sufficient starting precision, you can sort-of run \"precise\" algorithms and get a more-or-less correct answer\n- equal only if numbers are functionally the same: the safer notion for hashing.\n\nOption 1 at least allows us to do naive linear algebra on small systems, with a ridiculous amount of excess precision. (in a way that works better than with floats, say)\n\nOption 2 is required to sort-of properly handle routines that assume hashability.\n\nWe can't have both. Option 1 is what people expect when they start working with p-adics initially. For option 2 we have a work-around in the form of `cache_key` (which I thought was a stroke of brilliance!). So I think the best way forward is to try and make `cache_key` work.\n\nI agree it would be nicer to have another solution, but we're dealing with two different concepts of equality here, and we can't cram them into the same interface.",
    "created_at": "2016-03-28T19:06:20Z",
    "issue": "https://github.com/sagemath/sagetest/issues/20009",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/20009#issuecomment-275338",
    "user": "https://github.com/nbruin"
}
```

Replying to [comment:24 saraedum]:
> However, most parents get used as cache keys in our factories and `UniqueRepresentation`. And parents may depend on p-adic numbers in some way.

Parents that are used as cache-keys are usually not a problem: they are usually `EqualityByID`, so they can basically hash by their ID. If p-adics are part of the construction parameters (e.g., a p-adic extension field, perhaps?) of a `unique` parent structure, a little more is needed, of course. There either we would need `cache_key` or we'd need to transform the construction parameters into something that can be hashed. For extension fields, that's actually not such an unreasonable thing to do: fields defined by a minimal polynomial that is only known to limited precision is a real pain. It's much more convenient to lift it to an exact polynomial.

In any case, I would be very surprised if there are any structures out there that depend on anything else than sequences, polynomials, and matrices. If those have cache_key strategies, we'd be OK.

> No but a lot of our code assumes that everything is usable as a key in a dictionary for the sake of caching. I believe that this is a reasonable assumption: Running a method on indistinguishable inputs should produce the same output. And in some cases it should even produce the exact same object, for example when creating parents; in those cases you can not do without caching.

But I am pretty sure this is limited to polynomials and matrices.

> I am not sure what you mean with "high up". For correctness you have to implement it in any class that gets instantiated with a parameter that may depend (in some way) on something unhashable, because essentially you just need to write this as a method that produces the constructor parameters that serve to produce an indistinguishable element.

I meant: you could start sticking implementations into the more generic classes for polynomials and matrices. I don't think we need to define "correctness" as "p-adic numbers are hashable".

> Though I originally implemented `_cache_key` what I dislike about it is that you just have to add silly boilerplate to many classes. The new approach is much better in that sense. The changes are where the actual problem arises, namely in the classes that can not define a usual `__hash__`. For everybody else it just works and it is actually correct. The current `_cache_key` is calling for trouble in the long run: People add a constructor parameter but don't add it to `_cache_key`; the doctests pass but caching eventually produces incorrect results.

Most parents do not need a `_cache_key`, because they are actually hashable thanks to `EqualityByID`. I'd expect that only some element classes need a `_cache_key`. So the scenario you sketch would only play out if the identity-determining components of an element change.

> Of course, if the end user decides to run all its code `with strict_equality(True)` then many things break. But the docstring tries to be clear about this.

The fundamental point is that you make equality context dependent. It means you now need to know global state in order to reason about code that otherwise looks completely local. I think that's an incredibly big complexification and a major step back in the understandability and maintainability of sage code. Whatever you write in the docstring doesn't change that fact. You can't fix bad design by good documentation.

> I think the "strategic places" is a problem here. What this says it that using p-adics (or fraction field elements) just works in places where there happened to be a doctest that implied p-adics (and usually extension fields to actually trigger `__hash__`.) Why not make it work everywhere?

I think you are too pessimistic about the multitude of ways in which padic numbers can end up being hashed in legitimate ways. I think you can get this covered pretty quickly (polys and matrices). Plus: a lot of places where p-adics aren't initially foreseen will actually break with p-adics, because they are imprecise objects. That usually breaks algorithms that weren't built with that in mind.

re. why not everywhere: because the proposed solution (making equality testing depend on global state) incurs too high a price on the maintainability of sage.

> Yes, global state is bad. The implementation is very clear on that and I can elaborate on this further in the docstrings.

Being clear about it doesn't fix a bad design decision (an, I think, justified technical qualification of the proposal which in no way reflects on the proposers)

I'm sympathetic about the problem. The issue is really that equality tests for p-adics are probably bad in all cases. We're finding two interpretations that sort-of work in some circumstances:
- difference is indistinguishable from 0: if you start out with sufficient starting precision, you can sort-of run "precise" algorithms and get a more-or-less correct answer
- equal only if numbers are functionally the same: the safer notion for hashing.

Option 1 at least allows us to do naive linear algebra on small systems, with a ridiculous amount of excess precision. (in a way that works better than with floats, say)

Option 2 is required to sort-of properly handle routines that assume hashability.

We can't have both. Option 1 is what people expect when they start working with p-adics initially. For option 2 we have a work-around in the form of `cache_key` (which I thought was a stroke of brilliance!). So I think the best way forward is to try and make `cache_key` work.

I agree it would be nicer to have another solution, but we're dealing with two different concepts of equality here, and we can't cram them into the same interface.



---

archive/issue_comments_275339.json:
```json
{
    "body": "Replying to [comment:25 nbruin]:\n> Replying to [comment:24 saraedum]:\n> > However, most parents get used as cache keys in our factories and `UniqueRepresentation`. And parents may depend on p-adic numbers in some way.\nSorry. I meant: Most parents *use* caching in our factories and \u2026\n\n> In any case, I would be very surprised if there are any structures out there that depend on anything else than sequences, polynomials, and matrices. If those have cache_key strategies, we'd be OK.\nWell, apparently elements depend on an overconvergent modular form and a hyperbolic point which in turn depend on p-adics. So you need to implement `_cache_key` there.\n\n> > No but a lot of our code assumes that everything is usable as a key in a dictionary for the sake of caching. I believe that this is a reasonable assumption: Running a method on indistinguishable inputs should produce the same output. And in some cases it should even produce the exact same object, for example when creating parents; in those cases you can not do without caching.\n> But I am pretty sure this is limited to polynomials and matrices.\nI guess most things that have coefficients. Polynomials and matrices sure are the most popular ones. But then there are things that wrap these, like linear maps, finite sets, \u2026\n\n> > I am not sure what you mean with \"high up\". For correctness you have to implement it in any class that gets instantiated with a parameter that may depend (in some way) on something unhashable, because essentially you just need to write this as a method that produces the constructor parameters that serve to produce an indistinguishable element.\n> I meant: you could start sticking implementations into the more generic classes for polynomials and matrices. I don't think we need to define \"correctness\" as \"p-adic numbers are hashable\".\nI meant to define correctness of caching as \"indistinguishable input => indistinguishable output\".\n\n> > Though I originally implemented `_cache_key` what I dislike about it is that you just have to add silly boilerplate to many classes. The new approach is much better in that sense. The changes are where the actual problem arises, namely in the classes that can not define a usual `__hash__`. For everybody else it just works and it is actually correct. The current `_cache_key` is calling for trouble in the long run: People add a constructor parameter but don't add it to `_cache_key`; the doctests pass but caching eventually produces incorrect results.\n> Most parents do not need a `_cache_key`, because they are actually hashable thanks to `EqualityByID`. I'd expect that only some element classes need a `_cache_key`. So the scenario you sketch would only play out if the identity-determining components of an element change.\nI did not mean to focus that much on parents.\n\n> > Of course, if the end user decides to run all its code `with strict_equality(True)` then many things break. But the docstring tries to be clear about this.\n> The fundamental point is that you make equality context dependent. It means you now need to know global state in order to reason about code that otherwise looks completely local. I think that's an incredibly big complexification and a major step back in the understandability and maintainability of sage code. Whatever you write in the docstring doesn't change that fact. You can't fix bad design by good documentation.\nI don't think it is bad design. It is as much bad design as say a mutex. If used incorrectly it creates deadlocks, however it is very hard to certain things without it (double locking, memory barriers, \u2026) So, people are aware of these things and they try to write code that does not need it. But sometimes it just makes sense to do so. And that is my understanding why you should use `with strict_equality(True)` as locally as possible. I think it is just fine like that.\n\n> > I think the \"strategic places\" is a problem here. What this says it that using p-adics (or fraction field elements) just works in places where there happened to be a doctest that implied p-adics (and usually extension fields to actually trigger `__hash__`.) Why not make it work everywhere? \n> I think you are too pessimistic about the multitude of ways in which padic numbers can end up being hashed in legitimate ways. I think you can get this covered pretty quickly (polys and matrices). Plus: a lot of places where p-adics aren't initially foreseen will actually break with p-adics, because they are imprecise objects. That usually breaks algorithms that weren't built with that in mind.\nMany algorithms that do not take imprecise objects into account break. But now they still break explicitly by raising a TypeError: not hashable. Nothing changes there. However, many very trivial algorithms don't break if what they do does not depend on the p-adic object (because they only look at the dimensions of a matrix, or the spaces from to which a linear map maps, ...)\n\n> re. why not everywhere: because the proposed solution (making equality testing depend on global state) incurs too high a price on the maintainability of sage.\nI disagree. I still think that forcing people into keeping constructors and `_cache_key` in sync is not going to work. Those not concerned about imprecise objects won't think about it when they modify a constructor and then you get incorrect (cached) results.\n\n> > Yes, global state is bad. The implementation is very clear on that and I can elaborate on this further in the docstrings.\n> Being clear about it doesn't fix a bad design decision (an, I think, justified technical qualification of the proposal which in no way reflects on the proposers)\nNot sure what you are trying to say here\u2026\n\n> [Different notions of equality]\nIt is unfortunate that sage did not start with many notions of equality. In an \"ideal\" (but probably unusable) computer algebra system `==` would just throw an exception unless all reasonable notions of equality are the same for both sides of the equation (taking into account precision, properties that are outside of mathematics like printing, coercion, \u2026) and would require you to be precise about what equality should mean here.",
    "created_at": "2016-03-28T20:16:39Z",
    "issue": "https://github.com/sagemath/sagetest/issues/20009",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/20009#issuecomment-275339",
    "user": "https://github.com/saraedum"
}
```

Replying to [comment:25 nbruin]:
> Replying to [comment:24 saraedum]:
> > However, most parents get used as cache keys in our factories and `UniqueRepresentation`. And parents may depend on p-adic numbers in some way.
Sorry. I meant: Most parents *use* caching in our factories and …

> In any case, I would be very surprised if there are any structures out there that depend on anything else than sequences, polynomials, and matrices. If those have cache_key strategies, we'd be OK.
Well, apparently elements depend on an overconvergent modular form and a hyperbolic point which in turn depend on p-adics. So you need to implement `_cache_key` there.

> > No but a lot of our code assumes that everything is usable as a key in a dictionary for the sake of caching. I believe that this is a reasonable assumption: Running a method on indistinguishable inputs should produce the same output. And in some cases it should even produce the exact same object, for example when creating parents; in those cases you can not do without caching.
> But I am pretty sure this is limited to polynomials and matrices.
I guess most things that have coefficients. Polynomials and matrices sure are the most popular ones. But then there are things that wrap these, like linear maps, finite sets, …

> > I am not sure what you mean with "high up". For correctness you have to implement it in any class that gets instantiated with a parameter that may depend (in some way) on something unhashable, because essentially you just need to write this as a method that produces the constructor parameters that serve to produce an indistinguishable element.
> I meant: you could start sticking implementations into the more generic classes for polynomials and matrices. I don't think we need to define "correctness" as "p-adic numbers are hashable".
I meant to define correctness of caching as "indistinguishable input => indistinguishable output".

> > Though I originally implemented `_cache_key` what I dislike about it is that you just have to add silly boilerplate to many classes. The new approach is much better in that sense. The changes are where the actual problem arises, namely in the classes that can not define a usual `__hash__`. For everybody else it just works and it is actually correct. The current `_cache_key` is calling for trouble in the long run: People add a constructor parameter but don't add it to `_cache_key`; the doctests pass but caching eventually produces incorrect results.
> Most parents do not need a `_cache_key`, because they are actually hashable thanks to `EqualityByID`. I'd expect that only some element classes need a `_cache_key`. So the scenario you sketch would only play out if the identity-determining components of an element change.
I did not mean to focus that much on parents.

> > Of course, if the end user decides to run all its code `with strict_equality(True)` then many things break. But the docstring tries to be clear about this.
> The fundamental point is that you make equality context dependent. It means you now need to know global state in order to reason about code that otherwise looks completely local. I think that's an incredibly big complexification and a major step back in the understandability and maintainability of sage code. Whatever you write in the docstring doesn't change that fact. You can't fix bad design by good documentation.
I don't think it is bad design. It is as much bad design as say a mutex. If used incorrectly it creates deadlocks, however it is very hard to certain things without it (double locking, memory barriers, …) So, people are aware of these things and they try to write code that does not need it. But sometimes it just makes sense to do so. And that is my understanding why you should use `with strict_equality(True)` as locally as possible. I think it is just fine like that.

> > I think the "strategic places" is a problem here. What this says it that using p-adics (or fraction field elements) just works in places where there happened to be a doctest that implied p-adics (and usually extension fields to actually trigger `__hash__`.) Why not make it work everywhere? 
> I think you are too pessimistic about the multitude of ways in which padic numbers can end up being hashed in legitimate ways. I think you can get this covered pretty quickly (polys and matrices). Plus: a lot of places where p-adics aren't initially foreseen will actually break with p-adics, because they are imprecise objects. That usually breaks algorithms that weren't built with that in mind.
Many algorithms that do not take imprecise objects into account break. But now they still break explicitly by raising a TypeError: not hashable. Nothing changes there. However, many very trivial algorithms don't break if what they do does not depend on the p-adic object (because they only look at the dimensions of a matrix, or the spaces from to which a linear map maps, ...)

> re. why not everywhere: because the proposed solution (making equality testing depend on global state) incurs too high a price on the maintainability of sage.
I disagree. I still think that forcing people into keeping constructors and `_cache_key` in sync is not going to work. Those not concerned about imprecise objects won't think about it when they modify a constructor and then you get incorrect (cached) results.

> > Yes, global state is bad. The implementation is very clear on that and I can elaborate on this further in the docstrings.
> Being clear about it doesn't fix a bad design decision (an, I think, justified technical qualification of the proposal which in no way reflects on the proposers)
Not sure what you are trying to say here…

> [Different notions of equality]
It is unfortunate that sage did not start with many notions of equality. In an "ideal" (but probably unusable) computer algebra system `==` would just throw an exception unless all reasonable notions of equality are the same for both sides of the equation (taking into account precision, properties that are outside of mathematics like printing, coercion, …) and would require you to be precise about what equality should mean here.



---

archive/issue_comments_275340.json:
```json
{
    "body": "OK, finally I've found why making objects only hashable part of the time is a no-go: Regardless of threading, python does have non-synchronous code execution due to handling of signals, weakref callbacks, and deletion finalizers. These can lead to arbitrary code execution, so they will be executing code in an environment where equality testing doesn't have a well-defined meaning anymore (if equality testing semantics depend on a globally settable flag). \n\nIn particular, making hashability depend on a global flag is a no-go, because callback code can trigger key lookup:\n\n```\nclass T(object):\n    def __init__(self,V):\n        self.V=V\n    def __repr__(self):\n        return \"<T(%s)>\"%V\n    def __hash__(self):\n        if hashflag:\n            return hash(self.V)\n        else:\n            raise TypeError(\"T is not hashable at the moment\")\n    def __eq__(self,other):\n        return isinstance(other,T) and self.V == other.V\n    def __ne__(self,other):\n        return not(self==other)\n```\n\nYou get this:\n\n```\nsage: v=T(0) #this just needs to be a weakreffable object\nsage: k=T(1)\nsage: D=weakref.WeakValueDictionary()\nsage: hashflag=True\nsage: D[k]=v\nsage: hashflag=False\nsage: del v\nException TypeError: TypeError('T is not hashable at the moment',) in <function remove at 0x7f384da9a0c8> ignored\n```\n\n(and yes, particularly the cache for `UniqueRepresetation` is a `WeakValueDictionary`. That particular one is a slightly safer one than what comes bundled with python by default, so this particular issue isn't triggered there, but I think it illustrates that in python it's illegal to have a hashable object that becomes unhashable afterwards).\n\nSo it's not even a question of of design preferences: the design is not according to the behaviour that python objects are expected to adhere to, so it's a no-go unless we decide that sage isn't python anymore.",
    "created_at": "2016-03-29T01:33:54Z",
    "issue": "https://github.com/sagemath/sagetest/issues/20009",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/20009#issuecomment-275340",
    "user": "https://github.com/nbruin"
}
```

OK, finally I've found why making objects only hashable part of the time is a no-go: Regardless of threading, python does have non-synchronous code execution due to handling of signals, weakref callbacks, and deletion finalizers. These can lead to arbitrary code execution, so they will be executing code in an environment where equality testing doesn't have a well-defined meaning anymore (if equality testing semantics depend on a globally settable flag). 

In particular, making hashability depend on a global flag is a no-go, because callback code can trigger key lookup:

```
class T(object):
    def __init__(self,V):
        self.V=V
    def __repr__(self):
        return "<T(%s)>"%V
    def __hash__(self):
        if hashflag:
            return hash(self.V)
        else:
            raise TypeError("T is not hashable at the moment")
    def __eq__(self,other):
        return isinstance(other,T) and self.V == other.V
    def __ne__(self,other):
        return not(self==other)
```

You get this:

```
sage: v=T(0) #this just needs to be a weakreffable object
sage: k=T(1)
sage: D=weakref.WeakValueDictionary()
sage: hashflag=True
sage: D[k]=v
sage: hashflag=False
sage: del v
Exception TypeError: TypeError('T is not hashable at the moment',) in <function remove at 0x7f384da9a0c8> ignored
```

(and yes, particularly the cache for `UniqueRepresetation` is a `WeakValueDictionary`. That particular one is a slightly safer one than what comes bundled with python by default, so this particular issue isn't triggered there, but I think it illustrates that in python it's illegal to have a hashable object that becomes unhashable afterwards).

So it's not even a question of of design preferences: the design is not according to the behaviour that python objects are expected to adhere to, so it's a no-go unless we decide that sage isn't python anymore.



---

archive/issue_comments_275341.json:
```json
{
    "body": "The problem pointed out in this ticket -- that caching combines poorly with the relaxed concept of equality -- does need solving. Given that hashability cannot safely change during the lifetime of an object, it would seem `_cache_key` is only remaining viable solution. Is there useful work on the branch here that can be used towards removing `__hash__` for capped p-adic elements?",
    "created_at": "2016-03-31T05:33:01Z",
    "issue": "https://github.com/sagemath/sagetest/issues/20009",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/20009#issuecomment-275341",
    "user": "https://github.com/nbruin"
}
```

The problem pointed out in this ticket -- that caching combines poorly with the relaxed concept of equality -- does need solving. Given that hashability cannot safely change during the lifetime of an object, it would seem `_cache_key` is only remaining viable solution. Is there useful work on the branch here that can be used towards removing `__hash__` for capped p-adic elements?



---

archive/issue_comments_275342.json:
```json
{
    "body": "Replying to [comment:27 nbruin]:\n> [strict_equality() does not work in weak dicts]\nI thought that this is a common problem in sage and that is why we use `sage.misc.weak_dict` which uses equality by id to delete objects.",
    "created_at": "2016-03-31T13:38:39Z",
    "issue": "https://github.com/sagemath/sagetest/issues/20009",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/20009#issuecomment-275342",
    "user": "https://github.com/saraedum"
}
```

Replying to [comment:27 nbruin]:
> [strict_equality() does not work in weak dicts]
I thought that this is a common problem in sage and that is why we use `sage.misc.weak_dict` which uses equality by id to delete objects.



---

archive/issue_comments_275343.json:
```json
{
    "body": "Replying to [comment:29 saraedum]:\n> Replying to [comment:27 nbruin]:\n> > [strict_equality() does not work in weak dicts]\n> I thought that this is a common problem in sage and that is why we use `sage.misc.weak_dict` which uses equality by id to delete objects.\n\nNot quite. The problem that triggered writing the safer weakvaluedict was that equality testing on *defunct objects in to process of being deleted* is sometimes not supported anymore. This is because some objects depend on circular references to have their equality testing defined and we can't control the state of teardown present when the callback gets executed. It turned out that it was too much to ask that the key object under which the weakref is stored was still in a valid state during callback.\n\nOtherwise these objects have (or at least as supposed to have) well-defined equality tests during their lifetimes, and there is no particular reason to ban equality testing in callbacks.\n\nFor p-adics, the equality testing would change with time during their useful lifetime. That means a new rule would come in place in sage: make sure your callback code does not depend on equality testing state between p-adics, because their equality-testing state is ill-defined.\n\nIt would place a huge burden on callback writing: any callback would need to ensure to enforce the right equality testing regime around any place where it might be possible that p-adics get compared. For most callbacks it would be very hard to know this for certain, so basically any callback would need to have a `with strictequality(False):` around its body. And we'd still be unsafe in the face of threading (in a way we would never be able to fix later).\n\nSo I think the scenario that lead to writing `weak_dict` is quite different from what we're facing here.",
    "created_at": "2016-03-31T14:37:25Z",
    "issue": "https://github.com/sagemath/sagetest/issues/20009",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/20009#issuecomment-275343",
    "user": "https://github.com/nbruin"
}
```

Replying to [comment:29 saraedum]:
> Replying to [comment:27 nbruin]:
> > [strict_equality() does not work in weak dicts]
> I thought that this is a common problem in sage and that is why we use `sage.misc.weak_dict` which uses equality by id to delete objects.

Not quite. The problem that triggered writing the safer weakvaluedict was that equality testing on *defunct objects in to process of being deleted* is sometimes not supported anymore. This is because some objects depend on circular references to have their equality testing defined and we can't control the state of teardown present when the callback gets executed. It turned out that it was too much to ask that the key object under which the weakref is stored was still in a valid state during callback.

Otherwise these objects have (or at least as supposed to have) well-defined equality tests during their lifetimes, and there is no particular reason to ban equality testing in callbacks.

For p-adics, the equality testing would change with time during their useful lifetime. That means a new rule would come in place in sage: make sure your callback code does not depend on equality testing state between p-adics, because their equality-testing state is ill-defined.

It would place a huge burden on callback writing: any callback would need to ensure to enforce the right equality testing regime around any place where it might be possible that p-adics get compared. For most callbacks it would be very hard to know this for certain, so basically any callback would need to have a `with strictequality(False):` around its body. And we'd still be unsafe in the face of threading (in a way we would never be able to fix later).

So I think the scenario that lead to writing `weak_dict` is quite different from what we're facing here.



---

archive/issue_comments_275344.json:
```json
{
    "body": "I am slightly confused now. So the scenario you described about weak references does not happen with `weak_dict`, right?\nI do not understand what you mean with \"your callback code\". Are we just talking about weakref callback code?",
    "created_at": "2016-03-31T23:54:15Z",
    "issue": "https://github.com/sagemath/sagetest/issues/20009",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/20009#issuecomment-275344",
    "user": "https://github.com/saraedum"
}
```

I am slightly confused now. So the scenario you described about weak references does not happen with `weak_dict`, right?
I do not understand what you mean with "your callback code". Are we just talking about weakref callback code?



---

archive/issue_comments_275345.json:
```json
{
    "body": "Replying to [comment:31 saraedum]:\n> I am slightly confused now. So the scenario you described about weak references does not happen with `weak_dict`, right?\n> I do not understand what you mean with \"your callback code\". Are we just talking about weakref callback code?\n\nNo, any callback code that may exist in sage, may be used by a user, or may be written in the future.\n\nIt's part of Python that various events (deallocation of weakreffed objects, finalizers for objects, signals) can have code attached to them. Python will perform callbacks when the relevant events occur. These callbacks may be triggered within a `with strictequality(true):` block, because we don't have a way to make these blocks atomic. Thus, callbacks run with an undefined `strictequality` state. That means that, in order to verify correctness of code, you would need to prove that no code that executes during the callback depends on the strictequality state. That's a highly nonlocal check to make. A real-world example of code that does not satisfy this requirement is `weakref.WeakValueDictionary`, which is part of Python's standard lib.\n\nIf we were to introduce `strictequality` state, we would invalidate the use of part of the python standard lib in sage. I don't think it is wise, from a future development and from a maintenance point of view, to do this.\n\nCallback code is always precarious to write. I don't think we want to make it even more difficult to get it right in sage than it already is in normal python.",
    "created_at": "2016-04-01T02:19:15Z",
    "issue": "https://github.com/sagemath/sagetest/issues/20009",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/20009#issuecomment-275345",
    "user": "https://github.com/nbruin"
}
```

Replying to [comment:31 saraedum]:
> I am slightly confused now. So the scenario you described about weak references does not happen with `weak_dict`, right?
> I do not understand what you mean with "your callback code". Are we just talking about weakref callback code?

No, any callback code that may exist in sage, may be used by a user, or may be written in the future.

It's part of Python that various events (deallocation of weakreffed objects, finalizers for objects, signals) can have code attached to them. Python will perform callbacks when the relevant events occur. These callbacks may be triggered within a `with strictequality(true):` block, because we don't have a way to make these blocks atomic. Thus, callbacks run with an undefined `strictequality` state. That means that, in order to verify correctness of code, you would need to prove that no code that executes during the callback depends on the strictequality state. That's a highly nonlocal check to make. A real-world example of code that does not satisfy this requirement is `weakref.WeakValueDictionary`, which is part of Python's standard lib.

If we were to introduce `strictequality` state, we would invalidate the use of part of the python standard lib in sage. I don't think it is wise, from a future development and from a maintenance point of view, to do this.

Callback code is always precarious to write. I don't think we want to make it even more difficult to get it right in sage than it already is in normal python.



---

archive/issue_comments_275346.json:
```json
{
    "body": "So is there any callback code other than the weakrefs in sage? Right now this seems somewhat artificial to me.",
    "created_at": "2016-04-01T02:35:30Z",
    "issue": "https://github.com/sagemath/sagetest/issues/20009",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/20009#issuecomment-275346",
    "user": "https://github.com/saraedum"
}
```

So is there any callback code other than the weakrefs in sage? Right now this seems somewhat artificial to me.



---

archive/issue_comments_275347.json:
```json
{
    "body": "I don't know which callbacks there are exactly in sage. However, for me it's really an interface design issue. p-adic numbers are very useful and I think we should be able to model them using normal python objects. Introducing `strictequality` state would depart from that.\n\nAs an example, we'd end up with objects that somehow can be stuck into a dictionary but then don't behave as one would expect. We'd end up with dictionaries for which things like\n\n```\nall(d in D for d in D)\n```\n\ndoesn't hold. That is unnecessarily complicating the language. TO give some examples of unexpected things: dictionaries (and hence objects containing such dictionaries) won't pickle anymore:\n\n```\nloads(dumps(D))\n```\n\nrequires hash to work. So you'd end up having to inject `with(strictequality):` blocks throughout the (un)pickling code.\n\nMore surprisingly,\n\n```\nD1.update(D2)\n```\n\nwill *not* throw an error: dictionary entries do store the hash of their key, so `update` doesn't need to recompute hashes. However, it does need to use equality testing on the keys in case of hash collisions, so `D1.update(D2)` would run without raising an exception outside a `strictequality(True)` block, but would produce results distinct from what would happen otherwise.\n\nWe'd furthermore have objects that we can stick into a data structure supplied by the standard library (`weakref.WeakValueDictionary`) but don't behave properly in it.\n\nIt's not just a matter of what is in sage now. It's about ensuring that we make sure that the objects we create in sage are relatively easy to reason about. Making equality depend on global state is a serious departure from that. I'm sure that p-adic numbers aren't special enough to warrant such a complication. Either we have an equality concept that's compatible with hashing and p-adic numbers are hashable, or we have an equality concept that's not, and then p-adics are not hashable. A hybrid model causes problems in python, as illustrated.",
    "created_at": "2016-04-01T05:51:37Z",
    "issue": "https://github.com/sagemath/sagetest/issues/20009",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/20009#issuecomment-275347",
    "user": "https://github.com/nbruin"
}
```

I don't know which callbacks there are exactly in sage. However, for me it's really an interface design issue. p-adic numbers are very useful and I think we should be able to model them using normal python objects. Introducing `strictequality` state would depart from that.

As an example, we'd end up with objects that somehow can be stuck into a dictionary but then don't behave as one would expect. We'd end up with dictionaries for which things like

```
all(d in D for d in D)
```

doesn't hold. That is unnecessarily complicating the language. TO give some examples of unexpected things: dictionaries (and hence objects containing such dictionaries) won't pickle anymore:

```
loads(dumps(D))
```

requires hash to work. So you'd end up having to inject `with(strictequality):` blocks throughout the (un)pickling code.

More surprisingly,

```
D1.update(D2)
```

will *not* throw an error: dictionary entries do store the hash of their key, so `update` doesn't need to recompute hashes. However, it does need to use equality testing on the keys in case of hash collisions, so `D1.update(D2)` would run without raising an exception outside a `strictequality(True)` block, but would produce results distinct from what would happen otherwise.

We'd furthermore have objects that we can stick into a data structure supplied by the standard library (`weakref.WeakValueDictionary`) but don't behave properly in it.

It's not just a matter of what is in sage now. It's about ensuring that we make sure that the objects we create in sage are relatively easy to reason about. Making equality depend on global state is a serious departure from that. I'm sure that p-adic numbers aren't special enough to warrant such a complication. Either we have an equality concept that's compatible with hashing and p-adic numbers are hashable, or we have an equality concept that's not, and then p-adics are not hashable. A hybrid model causes problems in python, as illustrated.



---

archive/issue_comments_275348.json:
```json
{
    "body": "Changing status from needs_work to positive_review.",
    "created_at": "2016-12-20T21:53:16Z",
    "issue": "https://github.com/sagemath/sagetest/issues/20009",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/20009#issuecomment-275348",
    "user": "https://github.com/saraedum"
}
```

Changing status from needs_work to positive_review.



---

archive/issue_comments_275349.json:
```json
{
    "body": "Ok. I am convinced that this is not the way to go. I am essentially out of ideas on how to solve our `==` mess\u2026",
    "created_at": "2016-12-20T21:53:16Z",
    "issue": "https://github.com/sagemath/sagetest/issues/20009",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/20009#issuecomment-275349",
    "user": "https://github.com/saraedum"
}
```

Ok. I am convinced that this is not the way to go. I am essentially out of ideas on how to solve our `==` mess…



---

archive/issue_comments_275350.json:
```json
{
    "body": "Well, fixed mod and floating point p-adics can be hashed reasonably.  Maybe disable hashing for interval-type p-adics (capped-rel and capped-abs) and add a cache_key?\n\nOn a related note, real intervals in Sage are currently hashable with similar consequences.",
    "created_at": "2016-12-23T07:20:32Z",
    "issue": "https://github.com/sagemath/sagetest/issues/20009",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/20009#issuecomment-275350",
    "user": "https://github.com/roed314"
}
```

Well, fixed mod and floating point p-adics can be hashed reasonably.  Maybe disable hashing for interval-type p-adics (capped-rel and capped-abs) and add a cache_key?

On a related note, real intervals in Sage are currently hashable with similar consequences.



---

archive/issue_comments_275351.json:
```json
{
    "body": "Resolution: invalid",
    "created_at": "2017-01-21T18:03:11Z",
    "issue": "https://github.com/sagemath/sagetest/issues/20009",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/20009#issuecomment-275351",
    "user": "https://github.com/vbraun"
}
```

Resolution: invalid
