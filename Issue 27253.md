# Issue 27253: Simplistic multiprocessing.Pool replacement for parallel docbuild on older Cygwin

Issue created by migration from https://trac.sagemath.org/ticket/27490

Original creator: embray

Original creation time: 2019-03-15 10:49:36

CC:  jdemeyer

For Cygwin versions less than 3.0.0 (and only Cygwin) this replaces the use of `multiprocessing.Pool` in the `sage_setup.docbuild.build_many` function, with a naÃ¯ve but "good enough" (it works in general) parallel process pool that does not rely on starting processes from threads.

This is needed for #27214, because the specific combination of using `MAP_NORESERVE` `mmap`s and forking processes from a thread can result in a bug in Cygwin (fixed in 3.0.0) which causes unhandled segfaults to occur in any code that is run during the docbuild which uses libgap.

So this is really only needed so that the docs can continue to be built on systems (including my primary development environment, as well as the buildbot) that do not yet have Cygwin >= 3.0.0 once #27214 is applied.


---

Comment by embray created at 2019-03-15 11:08:02

Changing status from new to needs_review.


---

Comment by embray created at 2019-03-15 11:08:02

Jeroen, you will likely have thoughts about this.  Keep in mind, it's not meant to be at all robust--just a quick workaround so I don't have to spend too much more time on it.  But if you have any thoughts on straightforward improvements to this I'm all for it.

Obviously a better workaround, if it were possible, would be to use the much talked-about idea for generalizing the parallel processing loop from the Sage doctester. But since we don't have that yet this will do for now.
----
New commits:


---

Comment by jdemeyer created at 2019-03-15 13:13:42

I'm just wondering why you even bother with parallel docbuilding in the first place. The obvious solution is just using a single process.


---

Comment by jdemeyer created at 2019-03-15 13:33:56

Also, in general I don't like code of the form

```
if A_is_not_broken:
    A()
else:
    B()
```

If `B` works well enough to replace `A`, then why don't we just use `B` unconditionally?

This is especially relevant when `A` involves `multiprocessing.Pool` which has other issues (that's why I didn't use it in the doctester).

So I would like to know if there is a good reason to not use your "simplistic multiprocessing.Pool replacement" on all systems.


---

Comment by jdemeyer created at 2019-03-15 13:59:21

Changing status from needs_review to needs_work.


---

Comment by jdemeyer created at 2019-03-15 13:59:21

Some comments on the code:

1. This should use `os.wait()` instead of `time.sleep(5)`. Unless I'm missing something, this should be robust.

2. A few comments would be helpful.

3. `not any(filter(None, workers))` is not an easy condition to understand. I would write it as `all(w is None for w in workers)`.

4. I don't think that there is a need to gracefully shutdown the workers in the `finally` block. A hard kill `os.kill(w.pid, signal.SIGKILL)` may be better because it guarantees to kill the process (cysignals catches `SIGTERM` which does `sys.exit()` but that might not actually kill the process in a sufficiently messed up state). For extra safety, maybe call `is_alive()` before killing the process.

In general, I like it. It's simple but the use case is sufficiently simple that we don't need anything more complicated. And it says a lot about `multiprocess.Pool` that this might actually work better than `multiprocessing.Pool`.


---

Comment by embray created at 2019-03-15 14:52:02

Thanks for having a look.

Replying to [comment:4 jdemeyer]:
> Some comments on the code:
> 
> 1. This should use `os.wait()` instead of `time.sleep(5)`. Unless I'm missing something, this should be robust.

Yes, that should be much better.

> 2. A few comments would be helpful.

+1

> 3. `not any(filter(None, workers))` is not an easy condition to understand. I would write it as `all(w is None for w in workers)`.

I thought it was pretty straightforward, but I guess the `not any` is a little confusing.

> 4. I don't think that there is a need to gracefully shutdown the workers in the `finally` block. A hard kill `os.kill(w.pid, signal.SIGKILL)` may be better because it guarantees to kill the process (cysignals catches `SIGTERM` which does `sys.exit()` but that might not actually kill the process in a sufficiently messed up state). For extra safety, maybe call `is_alive()` before killing the process.

I think there is: Or at least to try to SIGTERM first. Reason being this block can be reached if one process exits in error, while other processes are still working perfectly fine.  You want to gracefully shut them down and ensure that their atexit handlers run, clean up temp files, etc.

> In general, I like it. It's simple but the use case is sufficiently simple that we don't need anything more complicated. And it says a lot about `multiprocess.Pool` that this might actually work better than `multiprocessing.Pool`.

I don't know that it says a lot. I don't think it actually works "better" on the whole, just in this one case. Keep in mind also that `multiprocessing.Pool` implements a lot of generic functionality (e.g. multiple simultaneous `map_async` jobs) that simply aren't needed for this simpler use case.

One downside to this approach is that there is no data returned from the child processes to the parent. So for example an exception raised in a worker cannot be re-raised from the parent.  Instead I just raise a generic `RuntimeError` if the process exited with an error code.  I simulated this case in testing and you can still see the worker's exception and traceback printed to stderr, so that was good-enough for my purposes.


---

Comment by embray created at 2019-03-15 14:56:10

Replying to [comment:3 jdemeyer]:
> Also, in general I don't like code of the form
> {{{
> if A_is_not_broken:
>     A()
> else:
>     B()
> }}}
> If `B` works well enough to replace `A`, then why don't we just use `B` unconditionally?
> 
> This is especially relevant when `A` involves `multiprocessing.Pool` which has other issues (that's why I didn't use it in the doctester).
> 
> So I would like to know if there is a good reason to not use your "simplistic multiprocessing.Pool replacement" on all systems.

Partly for the reason I mentioned at the end of my previous comment, and partly just because I need this _now_ and although I'm convinced it's robust-enough for my use it's still not well-tested.

How about for now we special-case this, and then for the next release make it a priority to finally get at least an initial version of the doctest forker code released and replace it with that?


---

Comment by embray created at 2019-03-15 15:00:17

Replying to [comment:2 jdemeyer]:
> I'm just wondering why you even bother with parallel docbuilding in the first place. The obvious solution is just using a single process.

At first I did just replace this with just plain `map(target, args)` but I wasn't satisfied: It was slow (obviously) and made memory usage even worse than it already is, over time.  It still seems better, if not kind of brushing other problems under the rug, to build each sub-doc in its own process that can easily be cleaned up when it's done.

The parallel version only took about 20 minutes to get working.


---

Comment by git created at 2019-03-15 15:24:14

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by embray created at 2019-03-15 15:26:24

Changing status from needs_work to needs_review.


---

Comment by embray created at 2019-03-15 15:26:24

I addressed most of your comments, but I still have the big `if/else`.  Since that `sage_setup.docbuild.__init__` module is already quite large, perhaps I could move that code to a utility module at least.

I'd still be open to just using it on all platforms, but I'm wary, given that this isn't battle-tested.


---

Comment by jdemeyer created at 2019-03-15 15:55:39

Replying to [comment:9 embray]:
> I'd still be open to just using it on all platforms, but I'm wary, given that this isn't battle-tested.

I see your point.


---

Comment by jdemeyer created at 2019-03-15 16:01:48

Changing status from needs_review to positive_review.


---

Comment by jdemeyer created at 2019-03-15 16:01:48

I'm willing to give this the benefit of the doubt. You'll probably be the only user of this code anyway.

I'm sure that there is room for improvement (I still don't like the `finally` block for example), but we can defer that to the point that we decide to use this code for all systems.


---

Comment by embray created at 2019-03-15 16:05:50

Changing status from positive_review to needs_work.


---

Comment by embray created at 2019-03-15 16:05:50

Thanks.  However, I need to double back now since my last change broke something.  It's not starting new processes up after previous ones finish.


---

Comment by embray created at 2019-03-15 16:55:31

This sort-of makes sense: It turns out of you `os.wait()` a process run by `multiprocessing.Process()` it breaks, because it wants to `os.waitpid()` on itself so it can get its return code.  So wait()-ing that process manually means it never finds out that it itself finished (and it doesn't check for the correct error code that would indicate as much) so it always just returns `None` for its exitcode.  This is a bit buggy but understandable.


---

Comment by jdemeyer created at 2019-03-15 17:01:05

I see. In the doctester, we solve this by checking for the `SIGCHLD` signal instead of `os.wait()`. Now I know why.


---

Comment by embray created at 2019-03-15 17:12:24

I thought of doing that as a solution, but then you start involving signal handling and basically reimplementing parts of the doctester.  I have another solution that's a bit ugly but simpler.

It would be nice if there were a sort of `multiprocessing.wait()` that could wait for any one `multiprocessing.Process` to finish (or maybe one out of a specific list thereof).  Since multiprocessing already tracks its child processes this could be done.  Maybe I'll propose it...


---

Comment by git created at 2019-03-15 17:39:46

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by embray created at 2019-03-15 17:40:33

One can see how quickly more complex this _can_ become.


---

Comment by embray created at 2019-03-15 17:40:33

Changing status from needs_work to needs_review.


---

Comment by embray created at 2019-03-15 17:58:17

Changing status from needs_review to positive_review.


---

Comment by embray created at 2019-03-15 17:58:17

Setting back to positive review since Jeroen was okay with (or at least resigned to) the current approach.  I've tested the updated code several times with different numbers of processes and am satisfied with it for now.


---

Comment by vbraun created at 2019-03-15 18:00:52

Can we move that abomination at least into a separate file


---

Comment by vbraun created at 2019-03-16 14:42:56

Changing status from positive_review to needs_work.


---

Comment by embray created at 2019-03-18 11:00:40

Changing status from needs_work to needs_info.


---

Comment by embray created at 2019-03-18 11:00:40

Which "abomination"?  I'm not necessarily going to do anything at your behest if you put it in such negative terms.


---

Comment by embray created at 2019-03-18 11:32:08

(Which is not not say I necessarily think this is pretty as-is but it's still not even clear exactly what you're asking to move).


---

Comment by vbraun created at 2019-03-18 16:28:44

Im asking you to move the parallel implementation of multiprocessing into a separate file, ideally with a small doctstring explaining what is going on here.


---

Comment by embray created at 2019-03-19 08:51:28

But both versions? Just the one I added?


---

Comment by vbraun created at 2019-03-19 09:24:13

At least for now just the one you added in the else branch. Thanks.


---

Comment by embray created at 2019-03-19 10:22:05

Okay, I'll do that.


---

Comment by git created at 2019-03-19 11:12:20

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2019-03-19 11:31:30

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2019-03-19 11:31:54

Branch pushed to git repo; I updated commit sha1. This was a forced push. New commits:


---

Comment by embray created at 2019-03-19 11:32:10

(Just removed an unused import.)


---

Comment by embray created at 2019-03-19 11:32:10

Changing status from needs_info to needs_review.


---

Comment by vbraun created at 2019-03-19 14:27:08

Changing status from needs_review to positive_review.


---

Comment by vbraun created at 2019-03-19 21:26:13

Resolution: fixed


---

Comment by vbraun created at 2019-03-19 21:28:27

Followup at #27514
