# Issue 22720: Faster implementation for has_perfect_matching

Issue created by migration from Trac.

Original creator: tmonteil

Original creation time: 2017-05-07 16:43:54

CC:  dcoudert dkrenn mkoeppe

This ticket is a quick follow-up of #22898.

The implementation of `has_perfect_matching` in #22898 is very inneficient, since it relies on a brute force search of all possible matchings until it finds one (can take an exponential time).

Try with, e.g.:


```
sage: R = graphs.RandomBipartite(1000, 1000, 1/100)
sage: R.has_perfect_matching()
```


Edmonds algorithm finds a maximal matching in polynomial time, then it suffices to check whether it has n/2 edges.


---

Comment by tmonteil created at 2017-05-07 17:32:00

Note that for the LP formulation, there is a simpler (perhaps faster) formulation for perfect matching which does not rely on maximal matching. However, this ticket is basically a quick fix for #22898 which hangs too often.
----
New commits:


---

Comment by tmonteil created at 2017-05-07 17:32:00

Changing status from new to needs_review.


---

Comment by dcoudert created at 2017-05-07 18:43:01

Passes all tests and is effectively much faster. Good to go.

Which LP formulation have you in mind ?


---

Comment by dcoudert created at 2017-05-07 18:43:01

Changing status from needs_review to positive_review.


---

Comment by tmonteil created at 2017-05-07 20:10:07

Replying to [comment:3 dcoudert]:
> Passes all tests and is effectively much faster. Good to go.
> 
> Which LP formulation have you in mind ?

The straightforward one : put binary variables on the edges, and for each vertex, the sum of the edges incident to it is 1, no objective. I just implemented it, and it is significantly faster than the one using the `matching` method, let me add it to avoid a new ticket.


---

Comment by tmonteil created at 2017-05-07 20:10:07

Changing status from positive_review to needs_work.


---

Comment by git created at 2017-05-07 20:11:48

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by tmonteil created at 2017-05-07 20:18:16

Changing status from needs_work to needs_review.


---

Comment by tmonteil created at 2017-05-07 20:27:38

Changing status from needs_review to needs_work.


---

Comment by tmonteil created at 2017-05-07 20:27:38

OK, sorry again, actually, both formulations have good and bad instances, so let me allow both (but it requires some documentation to explain).


---

Comment by dcoudert created at 2017-05-07 20:33:25

The proposed LP is roughly the same (no weight, no minimization, just feasibility), but its focused so interesting.

Cplex is usually very fast to say that the problem is unfeasible, but Cplex remains a mystery and it's not easy to say which instance is the best.


```
sage: G = graphs.CycleGraph(500)
sage: %time L = G.matching(algorithm='LP')
CPU times: user 30.7 ms, sys: 2.33 ms, total: 33 ms
Wall time: 28.1 ms
sage: %time G.has_perfect_matching(algorithm='LP')
CPU times: user 33.5 ms, sys: 2.18 ms, total: 35.7 ms
Wall time: 34.7 ms
True
sage: G = graphs.CycleGraph(501)
sage: %time L = G.matching(algorithm='LP')
CPU times: user 31.2 ms, sys: 2.35 ms, total: 33.6 ms
Wall time: 28.3 ms
sage: %time G.has_perfect_matching(algorithm='LP')
CPU times: user 34.6 ms, sys: 2.33 ms, total: 36.9 ms
Wall time: 35.8 ms
False
sage: G = graphs.RandomGNP(1000, .1)
sage: %time L = G.matching(algorithm='LP')
CPU times: user 4.02 s, sys: 440 ms, total: 4.46 s
Wall time: 3.02 s
sage: %time G.has_perfect_matching(algorithm='LP')
CPU times: user 1.95 s, sys: 97.5 ms, total: 2.05 s
Wall time: 2.02 s
True
```



---

Comment by git created at 2017-05-07 21:43:06

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by tmonteil created at 2017-05-07 21:54:28

Changing status from needs_work to needs_review.


---

Comment by tmonteil created at 2017-05-07 21:54:28

The LP formulations look similar, but the polytopes are very different (in particular, the LP_matching one is kind of "relaxed" and always has integer points). I am not specialist at all, but there might be some theoretical results on which shapes are better handled by which solver strategies (perhaps Matthias can tell more about this).

Here, the best strategy seems to depend on the solver (i do not have Cplex installed):


```
sage: G = graphs.RandomBipartite(1000, 1000, 1/100)
sage: %time G.has_perfect_matching(algorithm='LP_matching', solver='Glpk')
CPU times: user 2.54 s, sys: 16 ms, total: 2.56 s
Wall time: 2.51 s
True
sage: %time G.has_perfect_matching(algorithm='LP', solver='Glpk')
CPU times: user 2 s, sys: 8 ms, total: 2.01 s
Wall time: 1.97 s
True

sage: %time G.has_perfect_matching(algorithm='LP', solver='Coin')
CPU times: user 5.27 s, sys: 48 ms, total: 5.32 s
Wall time: 5.26 s
True
sage: %time G.has_perfect_matching(algorithm='LP_matching', solver='Coin')
CPU times: user 7.59 s, sys: 48 ms, total: 7.64 s
Wall time: 7.56 s
True
```



---

Comment by dcoudert created at 2017-05-08 10:19:22

Some corrections:
1. add test for trivial case: `if self.order() % 2: return False`
2. don't use `p.add_constraint(sum([b[e] for e in edges]) == 1)` but `p.add_constraint(p.sum(b[e] for e in edges) == 1)`, so `p.sum` instead of `sum` and no `[..]`
3. after `sage: all(G.has_perfect_matching(algorithm=algo) for algo in ['Edmonds', 'LP_matching', 'LP'])` you must add `True`

Concerning the default method, it seems that the "LP" method is in average slightly faster.

```
def pm_time(n, p, nbr):
    algorithms = ["Edmonds", "LP_matching", "LP"]
    time = {algo:list() for algo in algorithms}
    for i in range(nbr):
        G = graphs.RandomGNP(n, p)
        for algo in algorithms:
            t = walltime()
            _ = G.has_perfect_matching(algorithm=algo)
            time[algo].append(walltime() -t)
    return {algo:mean(time[algo]) for algo in algorithms}
```



```
sage: for n in [10, 20, 50, 100, 200]:
....:     for p in [0.01, 0.05, 0.1]:
....:         print("{}\t{}\t{}".format(n,round(p,2),pm_time(n, p, 100)))
....:         
10	0.01	{'LP_matching': 0.00059, 'LP': 0.00011, 'Edmonds': 8e-05}
10	0.05	{'LP_matching': 0.00101, 'LP': 0.00019, 'Edmonds': 0.00021}
10	0.1	{'LP_matching': 0.00114, 'LP': 0.00024, 'Edmonds': 0.00021}
20	0.01	{'LP_matching': 0.00105, 'LP': 0.00011, 'Edmonds': 0.00014}
20	0.05	{'LP_matching': 0.00149, 'LP': 0.00027, 'Edmonds': 0.00035}
20	0.1	{'LP_matching': 0.00266, 'LP': 0.00066, 'Edmonds': 0.00062}
50	0.01	{'LP_matching': 0.0018, 'LP': 0.00016, 'Edmonds': 0.00051}
50	0.05	{'LP_matching': 0.0063, 'LP': 0.00107, 'Edmonds': 0.00216}
50	0.1	{'LP_matching': 0.01115, 'LP': 0.0056, 'Edmonds': 0.00676}
100	0.01	{'LP_matching': 0.00357, 'LP': 0.00028, 'Edmonds': 0.00254}
100	0.05	{'LP_matching': 0.01831, 'LP': 0.00717, 'Edmonds': 0.03603}
100	0.1	{'LP_matching': 0.03172, 'LP': 0.0172, 'Edmonds': 0.01836}
200	0.01	{'LP_matching': 0.01729, 'LP': 0.00065, 'Edmonds': 0.01549}
200	0.05	{'LP_matching': 0.05328, 'LP': 0.03297, 'Edmonds': 0.06735}
200	0.1	{'LP_matching': 0.07782, 'LP': 0.05421, 'Edmonds': 0.06175}
```



---

Comment by dcoudert created at 2017-05-08 10:19:22

Changing status from needs_review to needs_work.


---

Comment by dcoudert created at 2017-05-08 12:26:55

You can also try the following to handle non connected graphs.

```
def has_perfect_matching(G, solver=None, verbose=False):
    """
    """
    if G.order() % 2:
        return False

    from sage.numerical.mip import MixedIntegerLinearProgram, MIPSolverException
    L = G.connected_components()
    if any(len(cc) % 2 for cc in L):
        return False
    for cc in L:
        p = MixedIntegerLinearProgram(solver=solver)
        b = p.new_variable(binary=True)
        for v in cc:
            p.add_constraint(p.sum(b[e] for e in G.edges_incident(v, labels=False, sort=False)) == 1)
        try:
            p.solve(log=verbose)
            continue
        except MIPSolverException:
            return False
    return True
```



---

Comment by git created at 2017-05-13 09:26:26

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by dcoudert created at 2017-05-13 09:31:02

using `p.sum` is better than `sum` when adding constraints.


---

Comment by tmonteil created at 2017-05-13 09:34:11

Replying to [comment:11 dcoudert]:
> Some corrections:
> 1. add test for trivial case: `if self.order() % 2: return False`
> 2. don't use `p.add_constraint(sum([b[e] for e in edges]) == 1)` but `p.add_constraint(p.sum(b[e] for e in edges) == 1)`, so `p.sum` instead of `sum` and no `[..]`
> 3. after `sage: all(G.has_perfect_matching(algorithm=algo) for algo in ['Edmonds', 'LP_matching', 'LP'])` you must add `True`

Thanks for the corrections. Regarding the second one, i removed the `[..]`, so that this is more readeable than both other possibilities. I do not see the benefit in calling `p.sum` instead `sum` since MILP can handle that.

> Concerning the default method, it seems that the "LP" method is in average slightly faster.

Well, this is with the commercial software CPLEX, which we can not assume to be installed on the user's machine. With `cbc` (which is not installed by default), Edomonds is faster for the dense graphs:


```
10	0.01	{'LP_matching': 0.002830798625946045, 'LP': 0.0004676508903503418, 'Edmonds': 0.005202703475952149}
10	0.05	{'LP_matching': 0.002872939109802246, 'LP': 0.0006479811668395996, 'Edmonds': 0.00037740230560302736}
10	0.1	{'LP_matching': 0.0034116864204406737, 'LP': 0.0009398722648620606, 'Edmonds': 0.0005422520637512207}
20	0.01	{'LP_matching': 0.0041153025627136235, 'LP': 0.00047693490982055666, 'Edmonds': 0.000349271297454834}
20	0.05	{'LP_matching': 0.00487368106842041, 'LP': 0.0009178662300109863, 'Edmonds': 0.0009983134269714354}
20	0.1	{'LP_matching': 0.0056728792190551755, 'LP': 0.0020548200607299807, 'Edmonds': 0.0017203617095947266}
50	0.01	{'LP_matching': 0.0073078107833862305, 'LP': 0.0007153725624084472, 'Edmonds': 0.0014888262748718262}
50	0.05	{'LP_matching': 0.01255603551864624, 'LP': 0.004998214244842529, 'Edmonds': 0.0067977094650268554}
50	0.1	{'LP_matching': 0.027002482414245604, 'LP': 0.023311057090759278, 'Edmonds': 0.02096151351928711}
100	0.01	{'LP_matching': 0.014859480857849121, 'LP': 0.0009170055389404296, 'Edmonds': 0.008162569999694825}
100	0.05	{'LP_matching': 0.10298776865005493, 'LP': 0.038913648128509525, 'Edmonds': 0.07995342016220093}
100	0.1	{'LP_matching': 0.11406001806259156, 'LP': 0.15457019090652466, 'Edmonds': 0.05536278963088989}
200	0.01	{'LP_matching': 0.040724358558654784, 'LP': 0.002662522792816162, 'Edmonds': 0.050573115348815915}
200	0.05	{'LP_matching': 0.35171021938323976, 'LP': 0.2127785062789917, 'Edmonds': 0.16411977291107177}
200	0.1	{'LP_matching': 0.7039063048362731, 'LP': 0.39927724838256834, 'Edmonds': 0.1540844440460205}
```



---

Comment by tmonteil created at 2017-05-13 09:34:34

Replying to [comment:14 dcoudert]:
> using `p.sum` is better than `sum` when adding constraints.

Why ?


---

Comment by tmonteil created at 2017-05-13 09:43:04

Replying to [comment:16 tmonteil]:
> Replying to [comment:14 dcoudert]:
> > using `p.sum` is better than `sum` when adding constraints.
> 
> Why ?

OK i did some timings.


---

Comment by git created at 2017-05-13 09:43:59

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by dcoudert created at 2017-05-13 09:45:04

This is actually discussed in #9061 and #13646 (at least).


---

Comment by dcoudert created at 2017-05-13 09:48:40

Passes all tests on top of 8.0.beta6. For me this is good to go.


---

Comment by dcoudert created at 2017-05-13 09:48:40

Changing status from needs_work to positive_review.


---

Comment by tmonteil created at 2017-05-13 09:53:31

OK great, thanks for the review.

Regarding connected components, i guess this should be timed first, since i am pretty sure that Edmonds takes care of that already, and for the LP, the polytope will be a product of polytopes, and i guess that the solvers take advantage of that too. Let us see in a further iteration.


---

Comment by dcoudert created at 2017-05-13 10:01:19

I fully agree. My timing were not convincing, so it's not crucial to care about connected components so far.

Concerning your timing with `Coin`, be aware that although the solver is generally faster than `GLPK`, the time needed to write the LP is way longer with `Coin` than with `GLPK` or `Cplex`. I don't know why. It is also quite long with `Gurobi`.


---

Comment by dkrenn created at 2017-05-14 12:52:11

Changing status from positive_review to needs_review.


---

Comment by dkrenn created at 2017-05-14 12:52:11

I've added a small PEP8 reviewer patch, please cross-review the changes.
In particular, I've rewritten the lambda expression to a function (PEP8) and have also rewritten the if-statement; if you're unhappy with the if-rewriting, then feel free to change it back.

Apart from PEP8, this patch looks good and clearly is a positive review from my side. Thank you for your work.
----
New commits:


---

Comment by dcoudert created at 2017-05-14 13:19:47

Changing status from needs_review to positive_review.


---

Comment by dcoudert created at 2017-05-14 13:19:47

Passes all tests and doc build properly.


---

Comment by vbraun created at 2017-05-16 22:21:58

Resolution: fixed
