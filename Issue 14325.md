# Issue 14325: Drastic performance improvement of computing the chromatic polynomial

Issue created by migration from Trac.

Original creator: azi

Original creation time: 2013-05-04 11:26:03

Assignee: jason, ncohen, rlm

CC:  ncohen stefan slani rbeezer mjo

Hello!

I am not sure I have the energy to do that at the moment but its a nice task that we might want to address at some point. Hence I am leaving some stuff here for further reference.

The current implementation of the chromatic_polynomial uses the deletion-contraction recurrence directly. This gives us an exponential branching tree. The neat thing is that at some point some of the branches compute the chromatic polynomial for the same graphs (multiple - exponential) times!

A very dumb implementation in Python (see below) is already faster on graphs of order 13 than the C code. It takes 2ms to compute the chromatic polynomial with this code and 1 minute with the one we have now!

Of course this code needs more work and can be optimized even further  (perhaps by calling the C implementation under a threshold) but for now here it is.



```
global cache
cache = {}
def chrompoly(G):
        
    global cache 

    s = G.canonical_label().sparse6_string()

    if s in cache:
        return cache[s]
    if not G.is_connected():
        return prod([chrompoly(C) for C in G.connected_components_subgraphs()])
    R = ZZ['x']
    x = R.gen()
    if G.is_tree():
        return x*(x-1)**(G.order()-1)

    u,v = G.edges(labels=False)[0]    

    G.delete_edge(u,v)

    p1 = chrompoly(G)

    G.add_edge(u,v)

    ret = p1 - chrompoly(contract_edge(G, u,v))
        
    cache[s] = ret 

    return ret 

def contract_edge(G, u,v):
    Gret = G.copy()
    Gret.add_edges([(u,x) for x in G.neighbors(v)])
    Gret.delete_vertex(v)
    return Gret
```



---

Comment by azi created at 2013-05-04 11:34:53

Hm... Maybe I am being too fast with the time results. I should really check what happens if I delete the cache after each run


---

Comment by azi created at 2013-05-04 11:46:31

Looks fine!! 


```
sage: G = graphs.RandomGNP(14,0.8)
sage: %timeit G.chromatic_polynomial()
1 loops, best of 3: 50.7 s per loop

sage: %timeit chrompoly(G)
1 loops, best of 3: 790 us per loop
```



---

Comment by azi created at 2013-05-05 10:26:26

Does anyone of you guys sees a reason not to remove the current Cython implementation and adding this code


---

Comment by ncohen created at 2013-05-05 10:29:39

Yep : the authors of the Cython code may be so impressed by your caching that they may want to adapt their code to it. Worth sending an email. Otherwise, if the results are better and the code clearer.... `:-P`

Nathann


---

Comment by azi created at 2013-05-05 10:51:18

Good! 

How do you think we should handle the global cache if this is to be made into a proper patch?

What I would like to do is have a global `____sage_very_very_private__cache__chrompoly___dict = {} ` variable outside the function and delete the cache each time the computation is over. In addition I would have a parameter keep_cache that keeps the cache alive (convenient when you're computing the polynomial in a loop)

What do you think?

Also whom would you send an email to?


---

Comment by ncohen created at 2013-05-05 10:59:08

Helloooooooo !

> How do you think we should handle the global cache if this is to be made into a proper patch?

Hmmm... Well, there is the `@`cached_method decorator, that automatically manages the cache of any function. But you can't empty it automatically when the computations are done though.

Technically, what you can do is write a function A (without the decorator) which call function B (the real one, with the cached_method decorator). Before returning B's result, A would clear the cache of B.

I wouldn't go to such lengths before there is a real need, actually... If somebody computes one chromatic polynomial perhaps he will compute two, and ... well. It's up to you. To me caching the method with the cached_method decorator would do the job. and you can add in its documentation an explanation of how the cache can be cleared manually, with the `clear_cache` method.

http://www.sagemath.org/doc/reference/misc/sage/misc/cachefunc.html

> Also whom would you send an email to?

The file seems to have been written by Robert Miller and Gordon Royle (just reading the copyright in the file itself). Robert Miller does not work on Sage anymore but should be interested (he's the one who initially wrote all the graph-related stuff in Sage. Backends included). And Gordon Royle may be interested too, though I probably never wrote to him `:-)` 

Nathann


---

Comment by azi created at 2013-05-05 11:32:13

Great thanks for the info! I'll read through that stuff and produce a proper patch. 

As for the "compute one or two,.." I would for example like to test the Birkhoff-Lewis conjecture for all planar graphs of some order and having such a cache alive through all the computation would be very nice.


---

Comment by mhansen created at 2013-05-05 13:20:16

There is some similar code for caching, etc. in "tutte.sage" at #1314 .


---

Attachment

Attached it is a proposed patch for the chromatic polynomial.

The new code is short, self-explanatory and incorrect. Due to the nature of the incorrectness I suspect that the edge contraction part of the code may not be correct.

Anyone happens to see the issue?


---

Comment by ncohen created at 2013-08-17 11:43:03

How do you know that the graph is connected, recursively ? `O_o`

Nathann


---

Attachment


---

Comment by azi created at 2013-08-17 12:04:25

I don't.. It looks like I removed that check (which is present in the above code) when merging the patches.. FML... TNX for the spot on!

The code now works correctly!


---

Comment by azi created at 2013-08-17 22:43:07

Changing status from new to needs_review.


---

Comment by darij created at 2013-08-18 15:12:48

Needs some adjustments:


```
darij`@`travis-virtualbox:~/sage-5.11.beta3/devel/sage-main$ hg qpush
applying trac_14592_chrompoly.patch
patching file sage/graphs/chrompoly.pyx
Hunk #1 FAILED at 0
1 out of 1 hunks FAILED -- saving rejects to file sage/graphs/chrompoly.pyx.rej
patch failed, unable to continue (try -v)
patch failed, rejects left in working dir
errors during apply, please fix and refresh trac_14592_chrompoly.patch
```


It looks like undeleting the deleted pyx file does the trick.


---

Comment by darij created at 2013-08-18 15:52:45

The chromatic polynomial of the empty graph should be 1, not x as your code returns (nor should it throw a LookupError as the original code did). While you might want to wait until the `is_connected()` method correctly recognizes the empty graph as disconnected, please make sure that the returned value is actually the polynomial 1, not the integer 1 (so use `ZZ['x'].prod` instead of `prod`).

Nice speedup, though it would be better to take the best of both worlds and redo it in Cython. I'm getting slowdowns on small graphs (up to 6 vertices), which might be an issue with the combinatorics I'm doing (combinatorial Hopf algebras have me work with many many little graphs rather than few large ones); but I think the added speedup of Cython will get rid of these slowdowns easily.


---

Comment by darij created at 2013-08-19 11:10:58

`is_connected()` is probably not going to handle the empty graph nicely, so it is best if you check for the empty graph explicitly.


---

Comment by ncohen created at 2013-09-05 09:33:23

Changing status from needs_review to needs_info.


---

Comment by ncohen created at 2013-09-05 09:33:23

Helloooooooooooooooo Jernej !

Would it be possible to keep the old implementation too, and have the two reachable through the same function ? Something like ``g.chromatic_polynomial(implementation="Python/C")`` ?

We would be able to check correction of each of them with the other, and if we ever notice that we can do better by caching inside of the C function.

Nathann


---

Comment by dcoudert created at 2021-09-01 14:52:43

Changing status from needs_info to needs_review.


---

Comment by dcoudert created at 2021-09-01 14:52:43

I have refreshed this ticket in a new branch. 

For caching, I prefer to avoid the `cached_function` tool as it forces repeated conversions between mutable and immutable graphs. So I use a method similar to the one used in `tutte_polynomial.py`. The only difference is the use a frozenset of edges instead of a sorted list (not sure if it's faster or not).

Concerning potential speed up, the new code is fast on graphs like `graphs.RandomGNP(14,0.8)` but very slow on `graphs.LCFGraph(24, [12,7,-7], 8)`. I have therefore let the previous implementation as default.
----
New commits:


---

Comment by git created at 2021-12-02 09:06:36

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by dcoudert created at 2021-12-02 09:10:31

I have rebased the ticket on 9.5.beta7 to fix a merge conflict.


---

Comment by mjo created at 2021-12-07 15:20:30

Nitpick: if you put the new "algorithm" argument at the end of the list, then existing code using e.g. `chromatic_polynomial(G, True)` won't suddenly start trying to pass in `algorithm=True`.

But my main question is: does cython optimize the tail call for a python "def" function in a pyx file? Since performance is the goal here... python itself will not turn the recursive call `return p - chromatic_polynomial_with_cache(H)` into something efficient. Instead, for large graphs, it will build up all of those function calls on the stack, and only evaluate them all when the entire computation is done. In short, it's just plain slow.

Cython may do better, since it compiles to C, and the C compiler is pretty smart. But does it in this case? I have no idea but I think it's worth investigating. If not, I would suggest rewriting the recursive call as a loop, since it's guaranteed to be much faster.


---

Comment by git created at 2021-12-07 15:35:18

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by dcoudert created at 2021-12-07 15:41:39

I will do some tests for avoiding the recursive calls (and the easy to use cache). Let's hope the resulting code will not be too complicated.


---

Comment by mjo created at 2021-12-07 15:54:50

Replying to [comment:28 dcoudert]:
> I will do some tests for avoiding the recursive calls (and the easy to use cache). Let's hope the resulting code will not be too complicated.

I still think the cache is still a good idea, but it probably won't be possible to keep your nice decorator implementation inside of a loop.


---

Comment by dcoudert created at 2021-12-07 15:56:36

Actually, I'm not even sure how to make the loop and a decent data structure encoding the various operations (*, -). Not easy.


---

Comment by mjo created at 2021-12-07 16:16:00

You can almost do it mechanically, although it looks pretty ugly at first. At the end of the function, you can imagine setting `G=H` and then replacing `chromatic_polynomial_with_cache(H)` with the body of the `chromatic_polynomial_with_cache` function. Then you'll be looking at two copies of the same code, and at the end, you can replace `chromatic_polynomial_with_cache(H)` once again with the body of the function; now you've got three copies of the code... and so on. "Stare long enough" and it will begin to look like something that can be written as a loop.

Which makes it sound easier than it usually is. I can give it a try. I've had to do this plenty of times to avoid running into python's recursion limit.


---

Comment by dcoudert created at 2021-12-07 18:09:56

I pushed a new branch with a version without recursion.
It can certainly be improved, but it's so far the easiest solution I found.
It's faster than the recursive version, but still not competitive with the cython version.
----
New commits:


---

Comment by mjo created at 2021-12-07 23:20:34

Replying to [comment:32 dcoudert]:
> I pushed a new branch with a version without recursion.
> It can certainly be improved, but it's so far the easiest solution I found.
> It's faster than the recursive version, but still not competitive with the cython version.

I really like this version, I think using a digraph to track the computation is rather elegant. And it performs much better than the recursive version on my machine.

I ran the non-recursive version under `%prun`, and found that much of the time is spent in `canonical_label()`. As a result, I was able to speed it up even more by installing bliss. That may be worth mentioning in the docs.

You might also want to reinstate the `cache` parameter, to allow the user to pass in his own cache? I haven't checked, but being able to maintain the same cache across multiple computations sounds like it would help, and it was specifically requested in comment:8.

Finally, here are some micro-optimizations that don't really make a noticeable difference, but help in theory -- you can take them or leave them:


```patch
diff --git a/src/sage/graphs/chrompoly.pyx b/src/sage/graphs/chrompoly.pyx
index 7f4554502c..c6bddaa512 100644
--- a/src/sage/graphs/chrompoly.pyx
+++ b/src/sage/graphs/chrompoly.pyx
`@``@` -30,6 +30,9 `@``@` from memory_allocator cimport MemoryAllocator
 from sage.libs.gmp.mpz cimport *
 from sage.rings.integer_ring import ZZ
 from sage.rings.integer cimport Integer
+from sage.rings.ring cimport Algebra
+from sage.rings.polynomial.polynomial_integer_dense_flint cimport Polynomial_integer_dense_flint
+from sage.rings.polynomial.polynomial_ring_constructor import PolynomialRing
 
 
 def chromatic_polynomial(G, return_tree_basis=False, algorithm='C'):
`@``@` -142,7 +145,7 `@``@` def chromatic_polynomial(G, return_tree_basis=False, algorithm='C'):
     if G.has_loops():
         return R.zero()
     if not G.is_connected():
-        return R.prod([chromatic_polynomial(g) for g in G.connected_components_subgraphs()])
+        return R.prod( chromatic_polynomial(g) for g in G.connected_components_subgraphs() )
     x = R.gen()
     if G.is_tree():
         return x * (x - 1) ** (G.num_verts() - 1)
`@``@` -400,12 +403,18 `@``@` def chromatic_polynomial_with_cache(G):
         sage: chromatic_polynomial_with_cache(Graph([This is the Trac macro *1, 1* that was inherited from the migration](https://trac.sagemath.org/wiki/WikiMacros#1, 1-macro), loops=True))
         0
     """
+    cdef Algebra R = PolynomialRing(ZZ, "x", implementation="FLINT")
+    cdef Polynomial_integer_dense_flint one, zero, x
+    one = R.one()
+    zero = R.zero()
+    x = R.gen()
+
     if not G:
-        return ZZ['x'].one()
+        return one
     if G.has_loops():
-        return ZZ['x'].zero()
+        return zero
 
-    # We ensure that the graph is labeled in [0..n-1]
+    # Make a copy of the input graph and ensure that it's labeled [0..n-1]
     G = G.relabel(inplace=False)
     G.remove_multiple_edges()
 
`@``@` -419,8 +428,14 `@``@` def chromatic_polynomial_with_cache(G):
     # isomorphic graphs
     cdef dict cache = {}
 
+    cdef int op_none = 0
+    cdef int op_mult = 1
+    cdef int op_diff = 2
+
     # We use a stack to order operation in a depth first search fashion
-    cdef list stack = [(True, 0, ('_', ))]
+    from collections import deque
+    stack = deque()
+    stack.append((True, 0, (op_none, )))
     cdef bint firstseen
     cdef int u, v, w, a, b
     cdef tuple com
`@``@` -436,28 +451,27 `@``@` def chromatic_polynomial_with_cache(G):
                 D.set_vertex(v, cache[key])
 
             elif not g:
-                D.set_vertex(v, ZZ['x'].one())
+                D.set_vertex(v, one)
                 cache[key] = D.get_vertex(v)
 
             elif g.has_loops():
-                D.set_vertex(v, ZZ['x'].zero())
+                D.set_vertex(v, zero)
                 cache[key] = D.get_vertex(v)
 
             elif not g.is_connected():
                 # We have to compute the product of the chromatic polynomials of
                 # the connected components
                 D.set_vertex(v, key)
-                stack.append((False, v, ('*', )))
+                stack.append((False, v, (op_mult, )))
                 for h in g.connected_components_subgraphs():
                     w = D.add_vertex()
                     D.set_vertex(w, h)
                     D.add_edge(v, w)
-                    stack.append((True, w, ('_', )))
+                    stack.append((True, w, (op_none, )))
 
             elif g.order() == g.size() + 1:
                 # g is a tree
-                x = ZZ['x'].gen()
-                D.set_vertex(v, x*(x - 1)**(g.order() - 1))
+                D.set_vertex(v, x*(x - one)**(g.order() - 1))
                 cache[key] = D.get_vertex(v)
 
             else:
`@``@` -469,7 +483,7 `@``@` def chromatic_polynomial_with_cache(G):
                 D.add_edge(v, a)
                 D.add_edge(v, b)
                 D.set_vertex(v, key)
-                stack.append((False, v, ('-', a, b)))
+                stack.append((False, v, (op_diff, a, b)))
                 # We try to select an edge that could disconnect the graph
                 for u, w in g.bridges(labels=False):
                     break
`@``@` -478,22 +492,22 `@``@` def chromatic_polynomial_with_cache(G):
 
                 g.delete_edge(u, w)
                 D.set_vertex(a, g.copy())
-                stack.append((True, a, ('_', )))
+                stack.append((True, a, (op_none, )))
                 g.add_edge(u, w)
                 g.merge_vertices([u, w])
                 g.remove_multiple_edges()
                 D.set_vertex(b, g)
-                stack.append((True, b, ('_', )))
+                stack.append((True, b, (op_none, )))
 
-        elif com[0] == '*':
+        elif com[0] == op_mult:
             # We compute the product of the connected components of the graph
             # and delete the children from D
             key = D.get_vertex(v)
-            cache[key] = ZZ['x'].prod([D.get_vertex(w) for w in D.neighbor_out_iterator(v)])
+            cache[key] = R.prod( D.get_vertex(w) for w in D.neighbor_out_iterator(v) )
             D.set_vertex(v, cache[key])
             D.delete_vertices(D.neighbor_out_iterator(v))
 
-        elif com[0] == '-':
+        elif com[0] == op_diff:
             # We compute the difference of the chromatic polynomials of the 2
             # children and remove them from D
             key = D.get_vertex(v)
```



---

Comment by git created at 2021-12-08 11:13:25

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by dcoudert created at 2021-12-08 11:14:18

I have implemented all your comments and added some doctests.


---

Comment by mjo created at 2021-12-08 15:19:50

Looks good, thanks. Re-using the cache does indeed (after enough runs) make this faster than the "C" algorithm.

I think we can save another millisecond by not computing the key or caching the value for `G` when `cache=None` (since we can't possible encounter the entire graph again?), but that may be overcomplicating things.


---

Comment by mjo created at 2021-12-08 15:19:50

Changing status from needs_review to positive_review.


---

Comment by dcoudert created at 2021-12-08 15:28:47

Thanks for the review. It's a nice algorithm that can be useful to some users.


---

Comment by mjo created at 2021-12-10 13:30:01

Replying to [comment:37 dcoudert]:
> Thanks for the review. It's a nice algorithm that can be useful to some users.

It is often faster than the original implementation, even without reusing the cache. And recursive algorithms are IMO easier to teach and verify... not to mention the sanity check that it provides on the original implementation.

I have a confession to make: when I suggested removing the tail recursion, I was only talking about the _final_ recursive call, not the earlier one. That would have provided less of a speedup, in exchange for being much easier to implement. So I feel a bit guilty that you spent so much time rewriting the whole thing. But your version is much faster than it would have with a recursive call remaining, and I learned a very nice way to model these computations in the future (that I intend to steal). So not that guilty =)

Anyway, thank you.


---

Comment by dcoudert created at 2021-12-10 13:56:22

Don't feel guilty, it was fun to search for this solution and I' happy with it.

Something not explained in the code. It's very convenient to use `DiGraph` as method `add_vertex()` returns the smallest integer that is available. Since we add an remove vertices, it ensures that the numbers we use are roughly at most the maximum depth of the stack. Furthermore, we use `set_vertex` which stores in a dictionary keyed by vertices some object (here graphs, keys, polynomials). Since we reuse integers to name new vertices, we overwrite previously stored data and so somehow limit the memory consumption. We could do without `DiGraph` but it would be much more complicated.


---

Comment by vbraun created at 2021-12-19 11:47:58

Resolution: fixed
