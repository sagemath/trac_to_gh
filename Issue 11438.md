# Issue 11438: Reduce memory consumption of generic Strassen-Winograd implementation

archive/issues_011438.json:
```json
{
    "body": "Assignee: jason, was\n\nCC:  hedtke\n\nKeywords: Strassen  Winograd matrix multiplication\n\nsage.matrix.strassen provides a framework for implementing fast matrix multiplication \u00e0 la Strassen-Winograd.\n\nIn the current implementation, the number of arithmetic operations per iteration is quite alright: 7 matrix multiplications and 15 additions/subtractions. However, there is a lot of temporary memory allocated; that's bad, both for the memory consumption and the computation time.\n\nI am well aware that, even though Strassen-Winograd is asymptotically fast and practically a lot better than the default multiplication of dense matrices over GF(n) (n not prime) in Sage, the additional memory consumption can be a real problem. So, I am *not* suggesting to use Strassen-Winograd by default for `Matrix_modn_dense`.\n\nHowever, I believe that it would be good to make the generic Strassen-Winograd implementation more useful. \n\n[Ivo Hedtke](http://groups.google.com/group/sage-devel/browse_thread/thread/8a988a2f5d997a5a) pointed to \"Boyer, Dumans, Pernet and Zhou: Memory efficient scheduling of Strassen-Winograd's matrix multiplication algorithm. International Symposium on Symbolic and Algebraic Computation 2009.\" They showed that in fact by improving the scheduling, no temporary memory needs to be allocated. The price to pay is that the input matrices are destroyed.\n\nHowever, there is a schedule, apparently due to an article of Douglas-Heroux-Slishman-Smith (but also appearing in the Boyer-Dumans-Pernet-Zhou article) that preserves the input matrices but requiress only rather little additional temporary memory.\nThe attached patch implements that non-destructive schedule.\n\nHere is a small benchmark: Multiplication of two 2000x2000 matrices over GF(125), using Strassen-Winograd with a cutoff of 20. I measure the memory consumption during computation using \"top\", and express it in \"percentage of my computer's memory\".\n\nWithout any patches:\n 12.3% memory,\n 437.50 s\n\nWith the new patch:\n 7.2% memory,\n 439.92 s\n\nWith #11589 and the new patch:\n 6.9% memory,\n 425.28 s\n\nThe comparison with the default multiplication in this case is quite impressive: Even with #11589, one obtains\n 6.3% memory,\n 903.98 s\n\nI did some smaller examples to determine a good cutoff - it seems to me that something between 15 and 25 is optimal on my machine and using `sage.matrix.matrix_modn_dense.Matrix_modn_dense`. Note that  `MeatAxe` only needs 12 seconds even *without* Strassen-Winograd, and Magma even needs half of that.\n\nIssue created by migration from https://trac.sagemath.org/ticket/11610\n\n",
    "created_at": "2011-07-18T21:22:51Z",
    "labels": [
        "linear algebra",
        "major",
        "enhancement"
    ],
    "title": "Reduce memory consumption of generic Strassen-Winograd implementation",
    "type": "issue",
    "url": "https://github.com/sagemath/sagetest/issues/11438",
    "user": "SimonKing"
}
```
Assignee: jason, was

CC:  hedtke

Keywords: Strassen  Winograd matrix multiplication

sage.matrix.strassen provides a framework for implementing fast matrix multiplication Ã  la Strassen-Winograd.

In the current implementation, the number of arithmetic operations per iteration is quite alright: 7 matrix multiplications and 15 additions/subtractions. However, there is a lot of temporary memory allocated; that's bad, both for the memory consumption and the computation time.

I am well aware that, even though Strassen-Winograd is asymptotically fast and practically a lot better than the default multiplication of dense matrices over GF(n) (n not prime) in Sage, the additional memory consumption can be a real problem. So, I am *not* suggesting to use Strassen-Winograd by default for `Matrix_modn_dense`.

However, I believe that it would be good to make the generic Strassen-Winograd implementation more useful. 

[Ivo Hedtke](http://groups.google.com/group/sage-devel/browse_thread/thread/8a988a2f5d997a5a) pointed to "Boyer, Dumans, Pernet and Zhou: Memory efficient scheduling of Strassen-Winograd's matrix multiplication algorithm. International Symposium on Symbolic and Algebraic Computation 2009." They showed that in fact by improving the scheduling, no temporary memory needs to be allocated. The price to pay is that the input matrices are destroyed.

However, there is a schedule, apparently due to an article of Douglas-Heroux-Slishman-Smith (but also appearing in the Boyer-Dumans-Pernet-Zhou article) that preserves the input matrices but requiress only rather little additional temporary memory.
The attached patch implements that non-destructive schedule.

Here is a small benchmark: Multiplication of two 2000x2000 matrices over GF(125), using Strassen-Winograd with a cutoff of 20. I measure the memory consumption during computation using "top", and express it in "percentage of my computer's memory".

Without any patches:
 12.3% memory,
 437.50 s

With the new patch:
 7.2% memory,
 439.92 s

With #11589 and the new patch:
 6.9% memory,
 425.28 s

The comparison with the default multiplication in this case is quite impressive: Even with #11589, one obtains
 6.3% memory,
 903.98 s

I did some smaller examples to determine a good cutoff - it seems to me that something between 15 and 25 is optimal on my machine and using `sage.matrix.matrix_modn_dense.Matrix_modn_dense`. Note that  `MeatAxe` only needs 12 seconds even *without* Strassen-Winograd, and Magma even needs half of that.

Issue created by migration from https://trac.sagemath.org/ticket/11610





---

archive/issue_comments_127658.json:
```json
{
    "body": "Improve memory efficiency of generic Strassen-Winograd implementation",
    "created_at": "2011-07-18T21:25:49Z",
    "issue": "https://github.com/sagemath/sagetest/issues/11438",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/11438#issuecomment-127658",
    "user": "SimonKing"
}
```

Improve memory efficiency of generic Strassen-Winograd implementation



---

archive/issue_comments_127659.json:
```json
{
    "body": "Changing status from new to needs_review.",
    "created_at": "2011-07-18T21:27:27Z",
    "issue": "https://github.com/sagemath/sagetest/issues/11438",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/11438#issuecomment-127659",
    "user": "SimonKing"
}
```

Changing status from new to needs_review.



---

archive/issue_comments_127660.json:
```json
{
    "body": "Attachment [trac11610_strassen.patch](tarball://root/attachments/some-uuid/ticket11610/trac11610_strassen.patch) by SimonKing created at 2011-07-18 21:27:27",
    "created_at": "2011-07-18T21:27:27Z",
    "issue": "https://github.com/sagemath/sagetest/issues/11438",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/11438#issuecomment-127660",
    "user": "SimonKing"
}
```

Attachment [trac11610_strassen.patch](tarball://root/attachments/some-uuid/ticket11610/trac11610_strassen.patch) by SimonKing created at 2011-07-18 21:27:27



---

archive/issue_comments_127661.json:
```json
{
    "body": "First of all: A nive piece of work. Thank you Simon!\n\n* OK: Compiles without any problems or warnings on my 64-bit 4.7 sage on my Mac 10.6.8. \n* OK: Made a little test with 10000 random matrices. result is always correct ;-)\n* OK: doctests in the directory sage/matrix are ok, \"All tests passed!\"\n* OK: long doctests ok, \"All tests passed!\"\n* OK: no changes in the documentation, therfore nothing to check\n* OK: doctest coverage 100%\n* OK: docbuild ok\n\n* OK: code is well written and documented.\n* OK: source (paper) for the method is given.\n\n* OK: the implemented method is the same method as in the paper\n\n* Memory Requirements (measured with XCode Instruments): 1000x1000 GF(125) matrices\n  * with patch: 197.11 MB (93.97 seconds)\n  * without patch: 836.12 MB (98.49 seconds)\n  This is a fantastic reduction of the memory consumption!!!",
    "created_at": "2011-07-19T20:08:42Z",
    "issue": "https://github.com/sagemath/sagetest/issues/11438",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/11438#issuecomment-127661",
    "user": "hedtke"
}
```

First of all: A nive piece of work. Thank you Simon!

* OK: Compiles without any problems or warnings on my 64-bit 4.7 sage on my Mac 10.6.8. 
* OK: Made a little test with 10000 random matrices. result is always correct ;-)
* OK: doctests in the directory sage/matrix are ok, "All tests passed!"
* OK: long doctests ok, "All tests passed!"
* OK: no changes in the documentation, therfore nothing to check
* OK: doctest coverage 100%
* OK: docbuild ok

* OK: code is well written and documented.
* OK: source (paper) for the method is given.

* OK: the implemented method is the same method as in the paper

* Memory Requirements (measured with XCode Instruments): 1000x1000 GF(125) matrices
  * with patch: 197.11 MB (93.97 seconds)
  * without patch: 836.12 MB (98.49 seconds)
  This is a fantastic reduction of the memory consumption!!!



---

archive/issue_comments_127662.json:
```json
{
    "body": "Changing status from needs_review to positive_review.",
    "created_at": "2011-07-19T20:08:42Z",
    "issue": "https://github.com/sagemath/sagetest/issues/11438",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/11438#issuecomment-127662",
    "user": "hedtke"
}
```

Changing status from needs_review to positive_review.



---

archive/issue_comments_127663.json:
```json
{
    "body": "Resolution: fixed",
    "created_at": "2011-08-18T22:04:52Z",
    "issue": "https://github.com/sagemath/sagetest/issues/11438",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/11438#issuecomment-127663",
    "user": "jdemeyer"
}
```

Resolution: fixed
