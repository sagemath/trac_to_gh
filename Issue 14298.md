# Issue 14298: Improvements of hyperbolicity procedures

Issue created by migration from Trac.

Original creator: dcoudert

Original creation time: 2013-04-28 16:22:31

Assignee: jason, ncohen, rlm

CC:  ncohen

This patch simplifies some tests in the hyperbolicity procedure and clarifies parts of the documentation.


---

Comment by dcoudert created at 2013-04-28 17:21:12

Changing status from new to needs_review.


---

Comment by ncohen created at 2013-05-01 10:34:58

Changing status from needs_review to needs_work.


---

Comment by ncohen created at 2013-05-01 10:34:58

Yoooooooooooooo !

* You probably want to sort the vertices .... in the other direction.
* I am not sure that the ordering of the degrees in `.degree()` is the same as `g.vertices()`. You probably want to use `g.degree(labels =True)`.
* seen is a set, not a dictionary
* Why do you need 32 bits for each vertex of a pair ? The algorithm uses distance_all_pairs which does not work when the vertices cannot be stored on short int.
* Why do you remove all this `h>=2` code ?
* Why do you replace a call to `relabel` with a call to `my_subgraph` ? Is it because `.relabel()` is too slow ? The speed of this function has been changed *a LOT* by #14000. You can also set `check_input=False` if you are sure that there is no problem with the new labels.

Nathann


---

Comment by dcoudert created at 2013-05-01 12:09:46

> * You probably want to sort the vertices .... in the other direction.

right. I have added a reverse=True.

> * I am not sure that the ordering of the degrees in `.degree()` is the same as `g.vertices()`. You probably want to use `g.degree(labels =True)`.

That's of course safer. I'm now using the degree_iterator instead since .degree(labels=True) returns a dictionary. 

> * seen is a set, not a dictionary

I was wondering if it is faster to use a dict or a set in this case. I'm now using a set.

> * Why do you need 32 bits for each vertex of a pair ? The algorithm uses distance_all_pairs which does not work when the vertices cannot be stored on short int.

changed

> * Why do you remove all this `h>=2` code ?

What we had before was incorrect. We were assuming that as soon as h>=2 it was not necessary to consider some vertices anymore (hence the h>=2 code). Since, we have proved that this is not true due to (a|b1,b2,b3) 4-tuples.

Now, the method is given a distance matrix and a set of vertices that we should not considered during computations. We order the pairs in such a way that pairs incident to vertices that should not be considered are above last_pair in the arrays. Observe that these orderings are done in linear time (in the number of pairs).

The other option was extract from the distance matrix the submatrix containing only distances between vertices we want to consider. I don't know which method is the fastest, but it was trivial to update the code the way I did it.



> * Why do you replace a call to `relabel` with a call to `my_subgraph` ? Is it because `.relabel()` is too slow ? The speed of this function has been changed *a LOT* by #14000. You can also set `check_input=False` if you are sure that there is no problem with the new labels.

I'm just combining the cost of taking the subgraph with the cost of relabeling the vertices. I think it's overall faster than splitting the calls, even if the new relabel method is fast.


I'm now also improving upper bounds since delta <= D/2.

Thanks,

David.


---

Comment by dcoudert created at 2013-05-01 12:10:20

Changing status from needs_work to needs_review.


---

Comment by ncohen created at 2013-05-01 15:37:28

Why do you replace this line and ignore the value of additive_gap and approximation_factor ?

```
hh, certif, hh_UB = __hyperbolicity__(N, distances, D, hyp, approximation_factor, 2*additive_gap, elim, verbose)
```


Nathann


---

Comment by dcoudert created at 2013-05-01 15:57:24

I assume you are speaking about

```
hh_UB = min( hh_UB, D)
```

We know that delta is upper bounded by D/2. So if hh_UB is larger than D/2 because the algorithm we have used gives hh_UB = hh+8 for instance, then we know that the upper bound higher than what we really have. So reducing hh_UB will not violate the requirement for an additive or multiplicative approx (we have a better solution).

But may be I'm missing something ?


---

Comment by ncohen created at 2013-05-01 18:02:15

Your patch replaces this line 

```
hh, certif, hh_UB = __hyperbolicity__(N, distances, D, hyp, approximation_factor, 2*additive_gap, elim, verbose) 
```

with this line

```
hh, certif, hh_UB = __hyperbolicity__(N, distances, D, hyp, 1.0, 0.0, elim, verbose) 
```


Why ?

Nathann


---

Comment by dcoudert created at 2013-05-01 18:24:26

The "cuts+" algorithm is an approximation algorithm with additive constant one (ALG <= OPT <= ALG+1). Therefore, additive/multiplicative approx factors are irrelevant in this case.
However, these parameters are still used with the "cuts" version.

We could may be combine additive approx with "cuts+", for instance asking for "2*(additive_gap-1)". I'm not sure it is really interesting.

Does it make more sense?


---

Comment by ncohen created at 2013-05-01 18:37:44

> Does it make more sense?

No, I still don't get it. When you remove simplicial vertices and compute the hyperbolicity on what is left you make an error of at most 1. Now, if you do not compute the hyperbolicity of what is left but if you just want an approximation of the hyperbolicity on what is left then you will compute this approximate hyperbolicity FASTER (because you do not have to go through all pairs), and you will get a lower bound `hyp` and an upper bound `ub`. Hence, because you first removed simplicial vertices, what you can say for sure is that the hyperbolicity of your graph is between `hyp` andd `ub+1`.

With what you do, it looks like you force the computation of the exact hyperbolicity on the reduced graph, which can take a lot of time. And isn't what the user wanted.

Nathann


---

Comment by dcoudert created at 2013-05-01 18:45:34

For additive gap I agree and I can add it. But for the multiplicative gap, I don't know how to change the parameter. If one asks for a 2-approximation, he will not be satisfied with a 2*OPT+1 approx. Any proposal?


---

Comment by ncohen created at 2013-05-01 18:51:14

> For additive gap I agree and I can add it. But for the multiplicative gap, I don't know how to change the parameter. If one asks for a 2-approximation, he will not be satisfied with a 2*OPT+1 approx. Any proposal?

None. But an exception has to be raised in this case. Or anything to tell the user that when he asks for a 2-approx, the exact number will be computed and so may take muuuuuch longer than he expected.

As it is just a reason for slowness, and not for wrong results, it can just stay as a comment in the documentation of `cuts+` if you want.

Nathann


---

Comment by dcoudert created at 2013-05-02 07:29:55

Well, I had already modified the description of the 'cuts+' algorithm to explain that it provides an approx with additive constant one, but apparently it is not written clearly enough. I will update the description.


---

Comment by ncohen created at 2013-05-02 07:48:25

Well, before it was wrong because the approximation given by "cuts+" was wrong (additive_gap and approximation_factor were forwarded to the subcall), and now it is still wrong for you can still use additive_gap to get a +20 approximation even though you use "cuts+". Actually, the user should have no way to know that the decomposition method yields a +1 approximation, for as far as he is concerned the only difference that cuts+ has with the normal method is that with cuts+ he cannot use approximation_factor.

Nathann


---

Comment by dcoudert created at 2013-05-02 12:32:12

Your arguments a quite unfair since it was clearly indicated that approximation_factor and additive_gap where only used by the 'cuts' algo and that 'cuts+' was an approx with additive constant one. So the "user" was aware. 

I have now implemented a set of modifications to use the additive_gap with 'cuts+' and updated documentation accordingly.

D.


---

Comment by ncohen created at 2013-05-02 12:56:54

Replying to [comment:14 dcoudert]:
> Your arguments a quite unfair since it was clearly indicated that approximation_factor and additive_gap where only used by the 'cuts' algo and that 'cuts+' was an approx with additive constant one. So the "user" was aware. 

Yep. But the code did something different.

> I have now implemented a set of modifications to use the additive_gap with 'cuts+' and updated documentation accordingly.

Cool. Could you also add a doctest for `algorithm="dom"` ? It looks like there's a bug there :

```
sage: g = graphs.PetersenGraph()
sage: hyperbolicity(g,algorithm="dom")
(0, [], 0)
```


I would say that the dominating set has `<4` vertices. Note that it isn't a problem per se, but the upper bound is clearly wrong.

Nathann


---

Comment by ncohen created at 2013-05-02 12:56:54

Changing status from needs_review to needs_work.


---

Comment by dcoudert created at 2013-05-02 14:40:02

Bloody hell, the Petersen!

The `__hyperbolicity__` method was implicitly assuming that delta(G)>0 since graphs such that delta(G)=0 are tested before. But with 'dom' the situation may happen. I have added what is needed to prevent such problem (also with cuts+).

Should be better now.


---

Comment by ncohen created at 2013-05-02 14:46:27

> Bloody hell, the Petersen!

It really is a counter-example to everything !

> The `__hyperbolicity__` method was implicitly assuming that delta(G)>0 since graphs such that delta(G)=0 are tested before. But with 'dom' the situation may happen. I have added what is needed to prevent such problem (also with cuts+).
> 
> Should be better now.

Why do you add more code ? I don't get it. The fact that there is no quadruple in the answer to Petersen's graph hyperbolicity is not a problem as the lower bound is zero. The only problem is that the upper bound is 8 ! You just had to test this case before returning the result, didn't you ?

Nathann


---

Comment by ncohen created at 2013-05-02 14:51:54

> Why do you add more code ? I don't get it. The fact that there is no quadruple in the answer to Petersen's graph hyperbolicity is not a problem as the lower bound is zero. The only problem is that the upper bound is 8 ! You just had to test this case before returning the result, didn't you ?

And if you *REALLY* want to return a 4-tuple, take `g.vertices()[:4]` and return their hyperbolicity, without changing the upper bound. But to me you could also return `[0,0,0,0]` as a certificate that the hyperbolicity is at least 0 and it would do, too ... Or even nothing, as it is now. The only problem was with the upper bound, really !

Nathann


---

Comment by ncohen created at 2013-05-02 14:53:19

Oh, this is what you do in "dom", sorry...

Nathann


---

Comment by dcoudert created at 2013-05-02 15:04:18

Exactly, whatever the method, at some point we need a certificate. So either I ensure that __hyperbolicity__ always returns a solution, or I have to test the result afterward, or both.

I think the code is safer now and it returns correct result. Some parts could be simplified if we had a nice implementation for delta <=1, or a nice decomposition by clique separators, etc. But this is another story.

David.


---

Comment by ncohen created at 2013-05-02 15:07:09

> Exactly, whatever the method, at some point we need a certificate. So either I ensure that __hyperbolicity__ always returns a solution, or I have to test the result afterward, or both.

And I take it that you do not like the certificate `[g.vertex_iterator().next()]*4` for hyperbolicity 0 ? It looks like it would reduce the amount of code ...

Nathann


---

Attachment

I don't like it because it gives 4 times the same vertex. I prefer G.vertices()[:4], although certainly less efficient (but compared to n^4...).


---

Comment by ncohen created at 2013-05-02 16:08:37

Changing status from needs_work to positive_review.


---

Comment by ncohen created at 2013-05-02 16:08:37

Well theeeeeeeenn....`:-P`

Nathann


---

Comment by dcoudert created at 2013-05-02 16:09:20

Thanks,
D.


---

Comment by jdemeyer created at 2013-05-07 09:07:31

Resolution: fixed
