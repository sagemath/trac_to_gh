# Issue 27207: Expose multithreaded fflas-ffpack features

Issue created by migration from https://trac.sagemath.org/ticket/27444

Original creator: @ZHG2017

Original creation time: 2019-03-08 09:49:11

CC:  cpernet

Dense linear algebra mod small p uses fflas-ffpack over float or double.
This library support multithreading for some routines: 
 - matrix-matrix multiplication
 - PLUQ decomposition
 - etc.

This ticket proposes to expose these parallel variants to Sage user.


---

Comment by git created at 2019-03-15 11:01:39

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2019-03-15 14:49:47

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2019-03-20 17:28:10

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2019-03-21 13:59:47

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2019-03-21 17:04:29

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2019-03-21 17:10:35

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2019-03-22 08:03:51

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by cpernet created at 2019-03-22 10:14:05

For the record: matrix multiplication over finite field works in parallel. The following experiment is on a 12 cores Intel skylake-x server:

```
pernet@retourdest:~/soft/sage$ export OMP_NUM_THREADS=12;./sage 
┌────────────────────────────────────────────────────────────────────┐
│ SageMath version 8.7.beta7, Release Date: 2019-03-10               │
│ Using Python 2.7.15. Type "help()" for help.                       │
└────────────────────────────────────────────────────────────────────┘
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Warning: this is a prerelease version, and it may be unstable.     ┃
┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛
sage: a=random_matrix(GF(11),10000)
sage: time b=a*a
CPU times: user 23.3 s, sys: 405 ms, total: 23.7 s
Wall time: 3.3 s
```

while on the same machine, on master we get:

```
sage: a=random_matrix(GF(11),10000)
sage: time b=a*a
CPU times: user 18.4 s, sys: 211 ms, total: 18.6 s
Wall time: 18.7 s
```


The speed-up of 6 for a 12 core machine is below what a self-standing fflas-ffpack achieves.
We need to investigate the reasons: alignment, strassen-winograd threshold, numa placement, etc.


---

Comment by embray created at 2019-03-25 10:56:15

Ticket retargeted after milestone closed (if you don't believe this ticket is appropriate for the Sage 8.8 release please retarget manually)


---

Comment by git created at 2019-03-26 09:48:29

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2019-03-27 12:37:37

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by embray created at 2019-06-14 14:54:19

As the Sage-8.8 release milestone is pending, we should delete the sage-8.8 milestone for tickets that are not actively being worked on or that still require significant work to move forward.  If you feel that this ticket should be included in the next Sage release at the soonest please set its milestone to the next release milestone (sage-8.9).


---

Comment by git created at 2019-06-20 13:12:04

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by cpernet created at 2019-06-27 11:33:10

I confirm that the branch successfullly parallizes det, rank and echelonize. However, in the current version of the branch, the matrix product is no longer parallelized. Could you revert the call to pfgemm?


---

Comment by git created at 2019-06-27 12:15:12

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by cpernet created at 2019-08-26 18:59:53

Changing status from new to needs_review.


---

Comment by cpernet created at 2019-08-27 08:22:50

I pushed a fix to a misplaced "noefd" algorithm specification. This seems to fix the broken doctests.
----
New commits:


---

Comment by defeo created at 2019-08-27 19:09:16

I'm curious about these:


```
if m*n > 100000: sig_on()
```


Any reason not to always call `sig_on()`?


---

Comment by defeo created at 2019-08-27 20:44:45

Docs need updating.

In `parallelism.py`:

> EXAMPLES:
>
> The number of processes is initialized to 1 (no parallelization) for each field **(only tensor computations are implemented at the moment)**:

Also, it would be good to document in the matrix reference the availability of parallelism, like it is done in http://doc.sagemath.org/html/en/reference/tensor_free_modules/sage/tensor/modules/free_module_tensor.html#sage.tensor.modules.free_module_tensor.FreeModuleTensor.disp


---

Comment by defeo created at 2019-08-27 21:29:08

Otherwise, I confirm there is no regression with Python 3. If you can fix the docs, this ticket is good for me.


---

Comment by cpernet created at 2019-08-28 07:33:00

Replying to [comment:24 defeo]:
> I'm curious about these:
> 
> {{{
> if m*n > 100000: sig_on()
> }}}
> 
> Any reason not to always call `sig_on()`?

I guess the reason is to avoid the overhead of using the sigs when the call is with a tiny instance which runs almost instantly and will therefore have no chance of being interrupted.


---

Comment by git created at 2019-08-28 15:44:52

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by cpernet created at 2019-08-28 15:46:26

`@`defeo: Doc fixed in the above commit. Should be good to go now.


---

Comment by defeo created at 2019-08-28 16:31:01

The ticket has no authors?


---

Comment by defeo created at 2019-08-28 16:31:01

Changing status from needs_review to positive_review.


---

Comment by chapoton created at 2019-08-28 19:00:24

and no milestone ?


---

Comment by vbraun created at 2019-09-02 21:41:23

Resolution: fixed


---

Comment by embray created at 2019-10-07 16:11:20

I don't think this ticket should have removed `--disable-openmp` from the fflas_ffpack build without mention, because now it requires OpenMP support in any modules which link to it, and this doesn't seem to work properly.
