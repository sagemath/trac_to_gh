# Issue 20082: patchbot failure sagedev when running inside docker

Issue created by migration from https://trac.sagemath.org/ticket/20319

Original creator: nthiery

Original creation time: 2016-03-29 21:07:21

CC:  embray jdemeyer chapoton tmonteil

When running the patchbot inside the sagemath/sagemath-develop docker container of
https://github.com/sagemath/docker-images, we get the following error:


```
sage -t --long src/sage/dev/sagedev.py
**********************************************************************
File "src/sage/dev/sagedev.py", line 902, in sage.dev.sagedev.SageDev.checkout_branch
Failed example:
    dev.git.echo.stash('apply')
Exception raised:
    Traceback (most recent call last):
      File "/opt/sage/local/lib/python2.7/site-packages/sage/doctest/forker.py", line 496, in _run
        self.compile_and_execute(example, compiler, test.globs)
      File "/opt/sage/local/lib/python2.7/site-packages/sage/doctest/forker.py", line 858, in compile_and_execute
        exec(compiled, globs)
      File "<doctest sage.dev.sagedev.SageDev.checkout_branch[18]>", line 1, in <module>
        dev.git.echo.stash('apply')
      File "/opt/sage/local/lib/python2.7/site-packages/sage/dev/git_interface.py", line 1179, in meth
        return self(git_cmd, *args, **kwds)
      File "/opt/sage/local/lib/python2.7/site-packages/sage/dev/git_interface.py", line 218, in _execute
        raise GitError(exit_code, cmd, stdout, stderr)
    GitError: git returned with non-zero exit code (1) for "git -c user.email=doc@test.test -c user.name=doctest stash apply".
    output to stderr: refs/stash@{0} is not a valid reference
**********************************************************************
File "src/sage/dev/sagedev.py", line 920, in sage.dev.sagedev.SageDev.checkout_branch
Failed example:
    dev.checkout(branch="branch1")
Expected:
    The following files in your working directory contain uncommitted changes:
    <BLANKLINE>
         tracked
    <BLANKLINE>
    Discard changes? [discard/Cancel/stash] discard
    On local branch "branch1" without associated ticket.
    <BLANKLINE>
    #  Use "sage --dev merge" to include another ticket/branch.
    #  Use "sage --dev commit" to save changes into a new commit.
Got:
    On local branch "branch1" without associated ticket.
    <BLANKLINE>
    # Use "sage --dev merge" to include another ticket/branch.
    # Use "sage --dev commit" to save changes into a new commit.

```


To reproduce (not double checked; we get that error when building the sagemath-patchot docker image; but that should be equivalent):

- install docker
- `docker run -ti sagemath-develop bash`
- install and run the patchbot as usual

No idea at this point on why this fails in this context, but not otherwise.


---

Comment by jdemeyer created at 2016-03-30 07:51:07

For the record: are these the only failures that you get?


---

Comment by chapoton created at 2016-03-30 07:53:23

For the log, see http://patchbot.sagemath.org/log/0/Ubuntu/15.10/x86_64/3.13.0-43-generic/62744a2b1a07/2016-03-28%2022:18:21

ending with

```
    [549 tests, 5.12 s]
----------------------------------------------------------------------
sage -t --long src/sage/dev/sagedev.py  # 2 doctests failed
sage -t --long src/sage/tests/cmdline.py  # 2 doctests failed
----------------------------------------------------------------------
```

I think I have seen these failures before, but where ?


---

Comment by chapoton created at 2016-03-30 08:09:16

`@`nthiery, do these tests pass in the same docker but not using the bot ?

Wild guess, it could be due to multithreading ?

```
Doctesting entire Sage library.
Sorting sources by runtime so that slower doctests are run first....
Doctesting 3390 files using 3 threads.
```



---

Comment by nthiery created at 2016-03-30 12:13:17

Hi!

Those are indeed the only tests failing.

The sagedev tests are not failing when run inside the bot but outside of the container.

The cmdline test is also failing outside of the bot, but that's now analyzed and should be an easy fix
(https://github.com/sagemath/docker-images/issues/11).

No idea about the potential influence of multithreading.

For the sake of completeness, I just started a new sagemath/sagemath-develop docker image, installed the patchbot, and ran the sagedev tests with:

```
    sage -tp 3 src/sage/dev/
```


They passed smoothly. The failing tests only appear when running:

```
    sage -patchbot --count=0
```


Cheers,
                              Nicolas


---

Comment by chapoton created at 2016-04-01 19:45:58

Here is a previous discussion on the very same problem in may 2015:

https://groups.google.com/d/topic/sage-devel/NzS6MKnXbMQ/discussion


---

Comment by chapoton created at 2016-04-02 08:15:44

Could some of you please launch your docker/VM patchbots on #14974 and report the results ?

I have included in the branch there some more tests in the sagedev scripts, hoping that
this could shed some light on the problem.


---

Comment by embray created at 2016-04-02 21:02:55

I'll see if I can work on this, just as soon as I reproduce it.


---

Comment by tmonteil created at 2016-04-03 08:52:49

Hi, started the patchbot in one of my VM's, and got some doctest failures, see http://patchbot.sagemath.org/log/0/debian/8.3/i686/3.16.0-4-586/tmonteil-debian-jessie-32/2016-04-03%2001:14:53?short so i could not pass ticket 0.


---

Comment by tmonteil created at 2016-04-03 09:10:24

After a closer look:
- some failures are due to some locale issue (i could probably fix that within the VM, let me check again)
- some failure are due to the fact that i installed some optional packages, whose doctests are broken and nobody notice it (can be fixed as well).
- there is still a failure for `sagedev.py` which always existed and prevented me to run the patchbot from within a VM (i still have no idea on how to fix it)


---

Comment by chapoton created at 2016-04-03 09:17:43

hello Thierry,

could you please run

```
sage -patchbot --skip-base --ticket=14974
```

to help me debug this sagedev issue ?

EDIT: maybe you need to add the "author" of this ticket to your trust list temporarily. Otherwise, you can run the patchbot inside an ipython session
as explained at the bottom of https://wiki.sagemath.org/buildbot/details


---

Comment by tmonteil created at 2016-04-03 17:29:28

It seems i could fix the locale issue. I just launched the patchbot for ticket #14974 so that you can learn more.


---

Comment by tmonteil created at 2016-04-03 21:12:31

I did 


```
./sage -patchbot --skip-base --ticket=14974
```


but it still tested ticket 0, see http://patchbot.sagemath.org/ticket/0/


---

Comment by embray created at 2016-04-04 11:18:47

I'm having an orthogonal issue when I try to test this issue.

When I run `sage -patchbot --count=0` in the docker container to runs the docbuild plugin for patchbot.  It starts building the docs and seems to get a long ways through it and when it gets to:


```
[tensor   ] building [html]: targets for 4 source files that are out of date
[tensor   ] preparing documents... done
[tensor   ] writing output... [ 25%] index
[history_a] building [html]: targets for 1 source files that are out of date
[history_a] preparing documents... done
[history_a] writing output... [100%] index
[tensor   ] writing output... [ 50%] sage/tensor/coordinate_patch
[tensor   ] writing output... [ 75%] sage/tensor/differential_form_element
[history_a] writing additional files... genindex search
[history_a] linking _static directory.
[history_a] copying extra files... done
[history_a] dumping search index... done
[history_a] dumping object inventory... done
[history_a] build succeeded.
Build finished.  The built documents can be found in /opt/sage/local/share/doc/sage/html/en/reference/histor
[tensor   ] writing output... [100%] sage/tensor/differential_forms
[tensor   ] writing additional files... genindex py-modindex search
[tensor   ] linking _static directory.
[tensor   ] copying extra files... done
[tensor   ] dumping search index... done
[tensor   ] dumping object inventory... done
[tensor   ] build succeeded.
Build finished.  The built documents can be found in /opt/sage/local/share/doc/sage/html/en/reference/tensor
```


it seems to just hang, with no output, for a very long time.  Is it waiting on something else that's running in parallel?  I can't seem to get past this. (I could disable the docbuild plugin, but it's still a problem)


---

Comment by embray created at 2016-04-04 11:23:34

Relatedly, the output of ps at this point:

```
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
sage         1  0.0  0.0  18224     4 ?        Ss   Apr03   0:00 /bin/bash
sage     20301  0.0  0.0  65476     8 ?        S+   10:43   0:00 python /opt/sage/local/bin/patchbot/patchbot.py --count=0
sage     20410  0.0  0.0   4376    28 ?        S+   10:43   0:00 tee /opt/sage/logs/patchbot/0-log.txt
sage     28733  0.0  0.2  51264  2284 ?        S+   10:45   0:00 python /opt/sage/src/bin/sage-cleaner
sage     30490  0.0  0.0   4476     0 ?        S+   10:46   0:00 sh -c make -j3 doc
sage     30491  0.0  0.0   7392     4 ?        S+   10:46   0:00 make -j3 doc
sage     30494  0.0  0.0   4476     0 ?        S+   10:46   0:00 /bin/sh -c build/bin/sage-logger \ ."cd build/make && ./install 'doc'" logs/install.log
sage     30495  0.0  0.0   9576     8 ?        S+   10:46   0:00 bash build/bin/sage-logger cd build/make && ./install 'doc' logs/install.log
sage     30498  0.0  0.0   9576     4 ?        S+   10:46   0:00 bash build/bin/sage-logger cd build/make && ./install 'doc' logs/install.log
sage     30499  0.0  0.0   9576     4 ?        S+   10:46   0:00 bash build/bin/sage-logger cd build/make && ./install 'doc' logs/install.log
sage     30500  0.0  0.0   4376    28 ?        S+   10:46   0:00 tee -a logs/install.log
sage     30501  0.0  0.0   9584     8 ?        S+   10:46   0:00 bash ./install doc
sage     30546  0.0  0.0   8260     8 ?        S+   10:46   0:00 make doc
sage     30596  0.0  0.0   9576     0 ?        S+   10:46   0:00 /bin/bash -c cd ../.. && sage-logger './sage --docbuild --no-pdf-links all html ' logs/dochtml.log
sage     30597  0.0  0.0   9580     8 ?        S+   10:46   0:00 bash /opt/sage/build/bin/sage-logger ./sage --docbuild --no-pdf-links all html  logs/dochtml.log
sage     30600  0.0  0.0   9580     4 ?        S+   10:46   0:00 bash /opt/sage/build/bin/sage-logger ./sage --docbuild --no-pdf-links all html  logs/dochtml.log
sage     30601  0.0  0.0   9580     4 ?        S+   10:46   0:00 bash /opt/sage/build/bin/sage-logger ./sage --docbuild --no-pdf-links all html  logs/dochtml.log
sage     30602  0.0  0.0   4376    32 ?        S+   10:46   0:00 tee -a logs/dochtml.log
sage     30603  1.1  0.8 2670860 8200 ?        Sl+  10:46   0:25 python -m sage_setup.docbuild --no-pdf-links all html
sage     30787  0.0  0.9 2670860 9292 ?        S+   11:02   0:00 python -m sage_setup.docbuild --no-pdf-links all html
sage     30788  0.0  0.9 2670860 9292 ?        S+   11:02   0:00 python -m sage_setup.docbuild --no-pdf-links all html
sage     30789  0.0  0.3  18220  3220 ?        Ss   11:19   0:00 /bin/bash
sage     30805  0.0  0.2  15600  2208 ?        R+   11:22   0:00 ps -aux
```


All the python and make processes are asleep.  It's not clear what they're waiting on.


---

Comment by chapoton created at 2016-04-04 19:05:50

I am not available right now for work on the patchbot. It should be easy to
disactivate the utf8 banner, I will take care of that later, when I am back home.


---

Comment by embray created at 2016-04-04 22:11:21

Well, after long struggling with getting a usable setup, I can at least confirm one thing, which is that the original issue has nothing to do with running the tests in parallel. Even after setting parallelism: 1 in the patchbot config this failure occurs.

In fact, even after hand-patching the patchbot to run the tests in only sage/dev/sagedev.py and nothing else, the test still fails, even though when I run it directly, instead of through the patchbot, it passes.


---

Comment by embray created at 2016-04-04 22:33:43

Well this is interesting--somehow it's one or more of the `GIT_` environment variables set by the patchbot that's breaking it.  These include:

```
 'GIT_AUTHOR_DATE': '1970-01-01T00:00:00',
 'GIT_AUTHOR_EMAIL': 'patchbot@localhost',
 'GIT_AUTHOR_NAME': 'patchbot',
 'GIT_COMMITTER_DATE': '1970-01-01T00:00:00',
 'GIT_COMMITTER_EMAIL': 'patchbot@localhost',
 'GIT_COMMITTER_NAME': 'patchbot',
```


If I hack in something to delete those variables just before the patchbot runs the test it passes.


---

Comment by embray created at 2016-04-05 11:32:20

FWIW: http://permalink.gmane.org/gmane.comp.version-control.git/290775

Still complete mystery as to why this wasn't seen before on the patchbot until running it in the docker container?  AFAICT this issue in git is very old.


---

Comment by chapoton created at 2016-04-06 19:31:30

How should I change the `GIT` environnement variables, so that the failing doctest
disappear ?

(so that we do no have to wait until git behaviour is corrected)


---

Comment by embray created at 2016-04-07 08:44:14

Just the `GIT_COMMITTER_DATE` needs to be changed I think. If its value is increased by one second then it should work around the problem.


---

Comment by slelievre created at 2016-04-07 09:49:47

Changing keywords from "" to "days77".


---

Comment by chapoton created at 2016-04-07 20:14:43

I have changed that in patchbot 2.5.5, that needs review at #20313


---

Comment by tmonteil created at 2016-04-08 16:31:31

Changing status from new to needs_review.


---

Comment by tmonteil created at 2016-04-08 16:35:13

Fixed by #20313 !


---

Comment by tmonteil created at 2016-04-08 16:35:13

Changing status from needs_review to positive_review.


---

Comment by vbraun created at 2016-06-12 12:02:30

Resolution: fixed
