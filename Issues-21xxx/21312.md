# Issue 21312: Can't interrupt cleanly RecursivelyEnumeratedSet.graded_component

archive/issues_021075.json:
```json
{
    "body": "CC:  @hivert\n\nFrom the [Iterators and KeyboardInterrupt](https://groups.google.com/forum/#!topic/sage-devel/-VdAiudU6o0) discussion on  sage-devel, here is a reproducable bug:\n\n```\nsage: def f(a):\n....:    sleep(0.1)\n....:    return [a-1,a+1]\nsage: C = RecursivelyEnumeratedSet([0], f, structure='symmetric')\nsage: from cysignals.alarm import alarm\nsage: alarm(0.45); C.graded_component(10)\nTraceback (most recent call last):\n...\nAlarmInterrupt: \nsage: C.graded_component(1)\n{-1, 1}\nsage: C.graded_component(2)\n{-2, 2}\nsage: C.graded_component(3)\nTraceback (most recent call last):\n...\nStopIteration: \nsage: C.graded_component(4)\nTraceback (most recent call last):\n...\nStopIteration: \n```\n\nIssue created by migration from https://trac.sagemath.org/ticket/21312\n\n",
    "closed_at": "2016-08-27T08:36:18Z",
    "created_at": "2016-08-23T08:58:29Z",
    "labels": [
        "component: combinatorics",
        "bug"
    ],
    "milestone": "https://github.com/sagemath/sagetest/milestones/sage-7.4",
    "title": "Can't interrupt cleanly RecursivelyEnumeratedSet.graded_component",
    "type": "issue",
    "url": "https://github.com/sagemath/sagetest/issues/21312",
    "user": "https://github.com/seblabbe"
}
```
CC:  @hivert

From the [Iterators and KeyboardInterrupt](https://groups.google.com/forum/#!topic/sage-devel/-VdAiudU6o0) discussion on  sage-devel, here is a reproducable bug:

```
sage: def f(a):
....:    sleep(0.1)
....:    return [a-1,a+1]
sage: C = RecursivelyEnumeratedSet([0], f, structure='symmetric')
sage: from cysignals.alarm import alarm
sage: alarm(0.45); C.graded_component(10)
Traceback (most recent call last):
...
AlarmInterrupt: 
sage: C.graded_component(1)
{-1, 1}
sage: C.graded_component(2)
{-2, 2}
sage: C.graded_component(3)
Traceback (most recent call last):
...
StopIteration: 
sage: C.graded_component(4)
Traceback (most recent call last):
...
StopIteration: 
```

Issue created by migration from https://trac.sagemath.org/ticket/21312





---

archive/issue_comments_291623.json:
```json
{
    "body": "Maybe using `sig_check`, we can fix this?\n\nhttps://github.com/sagemath/cysignals/blob/master/docs/source/index.rst#using-sig_check",
    "created_at": "2016-08-23T09:04:21Z",
    "issue": "https://github.com/sagemath/sagetest/issues/21312",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/21312#issuecomment-291623",
    "user": "https://github.com/seblabbe"
}
```

Maybe using `sig_check`, we can fix this?

https://github.com/sagemath/cysignals/blob/master/docs/source/index.rst#using-sig_check



---

archive/issue_comments_291624.json:
```json
{
    "body": "It goes down to `graded_component_iterator` method:\n\n```python\nsage: def f(a):\n....:     sleep(0.05)\n....:     return [a-1,a+1]\nsage: C = RecursivelyEnumeratedSet([0], f, structure='symmetric')\nsage: it = C.graded_component_iterator()\nsage: next(it)\n{0}\nsage: next(it)\n{-1, 1}\nsage: next(it)\n{-2, 2}\nsage: next(it)\n{-3, 3}\nsage: from cysignals.alarm import alarm\nsage: alarm(0.02); next(it)\nTraceback (most recent call last):\n...\nAlarmInterrupt: \nsage: next(it)\nTraceback (most recent call last):\n...\nStopIteration: \n```",
    "created_at": "2016-08-23T09:17:13Z",
    "issue": "https://github.com/sagemath/sagetest/issues/21312",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/21312#issuecomment-291624",
    "user": "https://github.com/seblabbe"
}
```

It goes down to `graded_component_iterator` method:

```python
sage: def f(a):
....:     sleep(0.05)
....:     return [a-1,a+1]
sage: C = RecursivelyEnumeratedSet([0], f, structure='symmetric')
sage: it = C.graded_component_iterator()
sage: next(it)
{0}
sage: next(it)
{-1, 1}
sage: next(it)
{-2, 2}
sage: next(it)
{-3, 3}
sage: from cysignals.alarm import alarm
sage: alarm(0.02); next(it)
Traceback (most recent call last):
...
AlarmInterrupt: 
sage: next(it)
Traceback (most recent call last):
...
StopIteration: 
```



---

archive/issue_comments_291625.json:
```json
{
    "body": "In essence this seems to be the same issue I came with in sage-devel: \ngraded_component_iterator constructs an iterator using yield and these do not behave nicely when they get interrupted.",
    "created_at": "2016-08-23T09:34:02Z",
    "issue": "https://github.com/sagemath/sagetest/issues/21312",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/21312#issuecomment-291625",
    "user": "https://github.com/etn40ff"
}
```

In essence this seems to be the same issue I came with in sage-devel: 
graded_component_iterator constructs an iterator using yield and these do not behave nicely when they get interrupted.



---

archive/issue_comments_291626.json:
```json
{
    "body": "I think I have an idea. We simply need to get rid of the `graded_component_iterator` in the code of `graded_component`. Then, this will not be the same code for structure graded and structure symmetric. I will try this as soon as I get a compiled sage in a few minutes.",
    "created_at": "2016-08-23T09:41:44Z",
    "issue": "https://github.com/sagemath/sagetest/issues/21312",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/21312#issuecomment-291626",
    "user": "https://github.com/seblabbe"
}
```

I think I have an idea. We simply need to get rid of the `graded_component_iterator` in the code of `graded_component`. Then, this will not be the same code for structure graded and structure symmetric. I will try this as soon as I get a compiled sage in a few minutes.



---

archive/issue_comments_291627.json:
```json
{
    "body": "Changing status from new to needs_review.",
    "created_at": "2016-08-23T11:05:35Z",
    "issue": "https://github.com/sagemath/sagetest/issues/21312",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/21312#issuecomment-291627",
    "user": "https://github.com/seblabbe"
}
```

Changing status from new to needs_review.



---

archive/issue_comments_291628.json:
```json
{
    "body": "New commits:",
    "created_at": "2016-08-23T11:05:35Z",
    "issue": "https://github.com/sagemath/sagetest/issues/21312",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/21312#issuecomment-291628",
    "user": "https://github.com/seblabbe"
}
```

New commits:



---

archive/issue_comments_291629.json:
```json
{
    "body": "Thanks for this fix; at first glance it looks ok to me, I will try to give it a more in-depth review soon.\n\nOn a related topic: in my usual testing example I get a major slowdown replacing my custom made iterator with a `RecursivelyEnumeratedSet`. To explore a 8-regular graph with 25080 vertices it takes 54.6 seconds as opposed to 29.9. I am not sure if this depends on the `__hash__` function I implemented or to the fact that I am a little bit more careful on which edges I travel along and which I can disregard a priori.\n\nAnother thing: maybe `depth_first_search_iterator` can be tweaked not to compute a whole graded component before returning. I have half and idea on how to do this, let me carefully think if it is feasible.",
    "created_at": "2016-08-23T12:36:40Z",
    "issue": "https://github.com/sagemath/sagetest/issues/21312",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/21312#issuecomment-291629",
    "user": "https://github.com/etn40ff"
}
```

Thanks for this fix; at first glance it looks ok to me, I will try to give it a more in-depth review soon.

On a related topic: in my usual testing example I get a major slowdown replacing my custom made iterator with a `RecursivelyEnumeratedSet`. To explore a 8-regular graph with 25080 vertices it takes 54.6 seconds as opposed to 29.9. I am not sure if this depends on the `__hash__` function I implemented or to the fact that I am a little bit more careful on which edges I travel along and which I can disregard a priori.

Another thing: maybe `depth_first_search_iterator` can be tweaked not to compute a whole graded component before returning. I have half and idea on how to do this, let me carefully think if it is feasible.



---

archive/issue_comments_291630.json:
```json
{
    "body": "> I will try to give it a more in-depth review soon. \n\n\nGreat. Also, I created #21311 just this morning while looking at the code on github if you can have a look at it.\n\n> On a related topic: in my usual testing example I get a major slowdown\n\n\nIf you can provide a working example illustrating this, I will be curious in investigating it.\n \n> Another thing: maybe `depth_first_search_iterator` can be tweaked not to compute a whole graded component before returning. I have half and idea on how to do this, let me carefully think if it is feasible.\n\n\nGreat! Tell me you think it works.",
    "created_at": "2016-08-23T12:58:37Z",
    "issue": "https://github.com/sagemath/sagetest/issues/21312",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/21312#issuecomment-291630",
    "user": "https://github.com/seblabbe"
}
```

> I will try to give it a more in-depth review soon. 


Great. Also, I created #21311 just this morning while looking at the code on github if you can have a look at it.

> On a related topic: in my usual testing example I get a major slowdown


If you can provide a working example illustrating this, I will be curious in investigating it.
 
> Another thing: maybe `depth_first_search_iterator` can be tweaked not to compute a whole graded component before returning. I have half and idea on how to do this, let me carefully think if it is feasible.


Great! Tell me you think it works.



---

archive/issue_comments_291631.json:
```json
{
    "body": "> On a related topic: in my usual testing example I get a major slowdown\n> > If you can provide a working example illustrating this, I will be curious in investigating it.\n\n\nTo get the example I am thinking about you need to merge in #21254 and #19538.\nThen\n\n```\nsage: A = ClusterAlgebra(['E',8])\nsage: %time A.explore_to_depth(infinity)\nCPU times: user 27.1 s, sys: 215 ms, total: 27.3 s\nWall time: 27.2 s\n```\nand\n\n```\nsage: A = ClusterAlgebra(['E',8])\nsage: seeds = RecursivelyEnumeratedSet([A.initial_seed()], lambda S:\n[S.mutate(i,inplace=False) for i in range(8)], structure='symmetric')\nsage: %time  len(list(seeds))\nCPU times: user 54.1 s, sys: 68 ms, total: 54.1 s\nWall time: 54.1 s\n25080\n```\n(you need to recreate `A` because it keeps track of few computationally\nintense bits).\n\nThe speedup I get, I think, depend mostly on line 1961 and partly on line 1968\nof cluster_algebra.py. The first makes sure that once an edge is known we do not\nwalk it twice, the second enforces the fact that we only need to walk three\nsides of a square.",
    "created_at": "2016-08-23T13:23:32Z",
    "issue": "https://github.com/sagemath/sagetest/issues/21312",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/21312#issuecomment-291631",
    "user": "https://github.com/etn40ff"
}
```

> On a related topic: in my usual testing example I get a major slowdown
> > If you can provide a working example illustrating this, I will be curious in investigating it.


To get the example I am thinking about you need to merge in #21254 and #19538.
Then

```
sage: A = ClusterAlgebra(['E',8])
sage: %time A.explore_to_depth(infinity)
CPU times: user 27.1 s, sys: 215 ms, total: 27.3 s
Wall time: 27.2 s
```
and

```
sage: A = ClusterAlgebra(['E',8])
sage: seeds = RecursivelyEnumeratedSet([A.initial_seed()], lambda S:
[S.mutate(i,inplace=False) for i in range(8)], structure='symmetric')
sage: %time  len(list(seeds))
CPU times: user 54.1 s, sys: 68 ms, total: 54.1 s
Wall time: 54.1 s
25080
```
(you need to recreate `A` because it keeps track of few computationally
intense bits).

The speedup I get, I think, depend mostly on line 1961 and partly on line 1968
of cluster_algebra.py. The first makes sure that once an edge is known we do not
walk it twice, the second enforces the fact that we only need to walk three
sides of a square.



---

archive/issue_comments_291632.json:
```json
{
    "body": "> The speedup I get, I think, depend mostly on line 1961 and partly on line 1968\n> of cluster_algebra.py. The first makes sure that once an edge is known we do not\n> walk it twice, the second enforces the fact that we only need to walk three\n> sides of a square.\n\n\nIn my experience, this kind of thing can be done by adding information into the nodes:\n\n```\nA = ClusterAlgebra(['E',8])\ninitial_node = tuple(A.initial_seed(), -1)\ninitial_nodes = [initial_node]\ndef succ(node):\n    S, i = node\n    allowed_directions = range(i+1, 8)\n    return [(S.mutate(j,inplace=False),j) for j in allowed_directions]\nseeds = RecursivelyEnumeratedSet(initial_nodes, succ, structure='symmetric')\n```\nThen `post_process` can return only the interesting part (at least now for forest, it works) of each node.\n\nBut I can't say if such an approach could work in your case.",
    "created_at": "2016-08-23T13:53:37Z",
    "issue": "https://github.com/sagemath/sagetest/issues/21312",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/21312#issuecomment-291632",
    "user": "https://github.com/seblabbe"
}
```

> The speedup I get, I think, depend mostly on line 1961 and partly on line 1968
> of cluster_algebra.py. The first makes sure that once an edge is known we do not
> walk it twice, the second enforces the fact that we only need to walk three
> sides of a square.


In my experience, this kind of thing can be done by adding information into the nodes:

```
A = ClusterAlgebra(['E',8])
initial_node = tuple(A.initial_seed(), -1)
initial_nodes = [initial_node]
def succ(node):
    S, i = node
    allowed_directions = range(i+1, 8)
    return [(S.mutate(j,inplace=False),j) for j in allowed_directions]
seeds = RecursivelyEnumeratedSet(initial_nodes, succ, structure='symmetric')
```
Then `post_process` can return only the interesting part (at least now for forest, it works) of each node.

But I can't say if such an approach could work in your case.



---

archive/issue_comments_291633.json:
```json
{
    "body": "> The speedup I get, I think, depend mostly on line 1961 and partly on line 1968\n> of cluster_algebra.py. The first makes sure that once an edge is known we do not\n> walk it twice, the second enforces the fact that we only need to walk three\n> sides of a square.\n\n\nThe speedup seems to be very close to a factor of 2.\n\n```\nsage: table([\"E8(yours) E6 E7 E8\".split(),[54.1/27.2, 2.97/1.59, 19.2/9.57, 143./72]])\n  E8(yours)          E6                 E7                 E8\n  1.98897058823529   1.86792452830189   2.00626959247649   1.98611111111111\n```\n\nI would guess this is not a coincidence... I still do not see how lines 1961 or 1968 give a improvement by a factor of 2 ?",
    "created_at": "2016-08-23T19:58:45Z",
    "issue": "https://github.com/sagemath/sagetest/issues/21312",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/21312#issuecomment-291633",
    "user": "https://github.com/seblabbe"
}
```

> The speedup I get, I think, depend mostly on line 1961 and partly on line 1968
> of cluster_algebra.py. The first makes sure that once an edge is known we do not
> walk it twice, the second enforces the fact that we only need to walk three
> sides of a square.


The speedup seems to be very close to a factor of 2.

```
sage: table(["E8(yours) E6 E7 E8".split(),[54.1/27.2, 2.97/1.59, 19.2/9.57, 143./72]])
  E8(yours)          E6                 E7                 E8
  1.98897058823529   1.86792452830189   2.00626959247649   1.98611111111111
```

I would guess this is not a coincidence... I still do not see how lines 1961 or 1968 give a improvement by a factor of 2 ?



---

archive/issue_comments_291634.json:
```json
{
    "body": "Can you try with my code but with line 1961 commented out and j!= i instead of j>i in line 1968?\nI think I ran this once for E8 and runtime almost doubled.",
    "created_at": "2016-08-23T22:49:31Z",
    "issue": "https://github.com/sagemath/sagetest/issues/21312",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/21312#issuecomment-291634",
    "user": "https://github.com/etn40ff"
}
```

Can you try with my code but with line 1961 commented out and j!= i instead of j>i in line 1968?
I think I ran this once for E8 and runtime almost doubled.



---

archive/issue_comments_291635.json:
```json
{
    "body": "Commenting out line 1961 and changing line 1968 as you suggest makes `explore_to_depth` slower but not 2 times slower. With this change, using `RecursivelyEnumeratedSet` is about 15% slower :\n\n```python\nsage: from pandas import DataFrame\nsage: df = DataFrame(index=\"E6 E7 E8\".split())\nsage: df['explore_to_depth'] = [2.53, 15.8, 124.]\nsage: df['rec_enum_set'] = [2.91, 18.5, 141.]\nsage: df['ratio'] = df.rec_enum_set / df.explore_to_depth\nsage: df\n    explore_to_depth      rec_enum_set             ratio\nE6  2.53000000000000  2.91000000000000  1.15019762845850\nE7  15.8000000000000  18.5000000000000  1.17088607594937\nE8  124.000000000000  141.000000000000  1.13709677419355\n```\n\nAre there other hypothesis you are using on the structure of the graph?",
    "created_at": "2016-08-24T07:11:22Z",
    "issue": "https://github.com/sagemath/sagetest/issues/21312",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/21312#issuecomment-291635",
    "user": "https://github.com/seblabbe"
}
```

Commenting out line 1961 and changing line 1968 as you suggest makes `explore_to_depth` slower but not 2 times slower. With this change, using `RecursivelyEnumeratedSet` is about 15% slower :

```python
sage: from pandas import DataFrame
sage: df = DataFrame(index="E6 E7 E8".split())
sage: df['explore_to_depth'] = [2.53, 15.8, 124.]
sage: df['rec_enum_set'] = [2.91, 18.5, 141.]
sage: df['ratio'] = df.rec_enum_set / df.explore_to_depth
sage: df
    explore_to_depth      rec_enum_set             ratio
E6  2.53000000000000  2.91000000000000  1.15019762845850
E7  15.8000000000000  18.5000000000000  1.17088607594937
E8  124.000000000000  141.000000000000  1.13709677419355
```

Are there other hypothesis you are using on the structure of the graph?



---

archive/issue_comments_291636.json:
```json
{
    "body": "I do not think I am using any other assumption.\n\nNote that the main loop I would write without using the assumptions above would be\n\n```\nwhile gets_bigger and depth_counter < kwargs.get('depth', infinity):\n     # remember if we got a new seed\n     gets_bigger = False\n\n     for key in clusters.keys():\n         sd, directions = clusters[key]\n         while directions:\n             # we can mutate in some direction\n             i = directions.pop()\n             new_sd  = sd.mutate(i, inplace=False, mutating_F=mutating_F)\n             new_cl = frozenset(new_sd.g_vectors())\n             if not new_cl in clusters:\n                 # we got a new seed\n                 gets_bigger = True\n                 # next round do not mutate back to sd and do commuting mutations only in directions j > i\n                 new_directions = [ j for j in allowed_dirs if j != i ]\n                 clusters[new_cl] = [ new_sd, new_directions ]\n                 yield new_sd\n     # we went one step deeper\n     depth_counter += 1\n```\nwhich should be slightly faster than the version you tested because it does not\nrun the useless line\n\n```\nj = map(tuple,clusters[new_cl][0].g_vectors()).index(new_sd.g_vector(i))\n```",
    "created_at": "2016-08-24T07:46:12Z",
    "issue": "https://github.com/sagemath/sagetest/issues/21312",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/21312#issuecomment-291636",
    "user": "https://github.com/etn40ff"
}
```

I do not think I am using any other assumption.

Note that the main loop I would write without using the assumptions above would be

```
while gets_bigger and depth_counter < kwargs.get('depth', infinity):
     # remember if we got a new seed
     gets_bigger = False

     for key in clusters.keys():
         sd, directions = clusters[key]
         while directions:
             # we can mutate in some direction
             i = directions.pop()
             new_sd  = sd.mutate(i, inplace=False, mutating_F=mutating_F)
             new_cl = frozenset(new_sd.g_vectors())
             if not new_cl in clusters:
                 # we got a new seed
                 gets_bigger = True
                 # next round do not mutate back to sd and do commuting mutations only in directions j > i
                 new_directions = [ j for j in allowed_dirs if j != i ]
                 clusters[new_cl] = [ new_sd, new_directions ]
                 yield new_sd
     # we went one step deeper
     depth_counter += 1
```
which should be slightly faster than the version you tested because it does not
run the useless line

```
j = map(tuple,clusters[new_cl][0].g_vectors()).index(new_sd.g_vector(i))
```



---

archive/issue_comments_291637.json:
```json
{
    "body": "Ah! I am not sure how `RecursivelyEnumeratedSet` does things but there is one\nlast assumption I am using:\nI know which is the last direction I walked to get to any vertex so at the next pass I am not travelling in that direction.",
    "created_at": "2016-08-24T07:56:55Z",
    "issue": "https://github.com/sagemath/sagetest/issues/21312",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/21312#issuecomment-291637",
    "user": "https://github.com/etn40ff"
}
```

Ah! I am not sure how `RecursivelyEnumeratedSet` does things but there is one
last assumption I am using:
I know which is the last direction I walked to get to any vertex so at the next pass I am not travelling in that direction.



---

archive/issue_comments_291638.json:
```json
{
    "body": "> which should be slightly faster than the version you tested because it does not run the \n> useless line `j = map(tuple,clusters[new_cl][0].g_vectors()).index(new_sd.g_vector(i))`\n\n\nI had already commented that line in my previous post, also since commenting only line 1961 gives a syntax error. The only difference with your suggestion was that I was using\n\n```python\nnew_directions = [ j for j in allowed_dirs if j != i or new_sd.b_matrix()[j,i] != 0 ]\n```\ninstead of\n\n```python\nnew_directions = [ j for j in allowed_dirs if j != i ]\n```\n\n\nReplying to [comment:15 etn40ff]:\n> Ah! I am not sure how `RecursivelyEnumeratedSet` does things but there is one\n> last assumption I am using:\n> I know which is the last direction I walked to get to any vertex so at the next pass I am not travelling in that direction.\n\n\nAn hypothesis that we can't do right now inside the code of `RecursivelyEnumeratedSet` with symmetric structure since if `y in succ(x)`, then we can't assume that\n\n```python\nlist(succ(x)).index(y) == list(succ(y)).index(x)\n```\nAlso, the graph might not be k-regular (to make sure, that is the number of outgoing edges being constant).\n\nBut we can use that hypothesis in the `succ` function:\n\n```python\nsage: A = ClusterAlgebra(['E',6])\nsage: def succ(S):\n....:     p = S.path_from_initial_seed()\n....:     i = p[-1] if p else -1\n....:     return [S.mutate(j,inplace=False) for j in range(6) if j != i]\nsage: seeds = RecursivelyEnumeratedSet([A.initial_seed()], succ, structure='symmetric')\nsage: %time len(list(seeds))\nCPU times: user 2.69 s, sys: 200 ms, total: 2.89 s\nWall time: 2.75 s\n833\n```\n\nWith this new `succ` function and removing the part `or new_sd.b_matrix()[j,i] != 0`, the ratio become about 5% slower using `RecursivelyEnumeratedSet` :\n\n```python\nsage: from pandas import DataFrame\nsage: df = DataFrame(index=\"E6 E7 E8\".split())\nsage: df['explore_to_depth'] = [2.61, 16.1, 121.]\nsage: df['rec_enum_set'] = [2.75, 16.9, 128.]\nsage: df['ratio'] = df.rec_enum_set / df.explore_to_depth\nsage: df\n    explore_to_depth      rec_enum_set             ratio\nE6  2.61000000000000  2.75000000000000  1.05363984674330\nE7  16.1000000000000  16.9000000000000  1.04968944099379\nE8  121.000000000000  128.000000000000  1.05785123966942\n```",
    "created_at": "2016-08-24T19:38:48Z",
    "issue": "https://github.com/sagemath/sagetest/issues/21312",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/21312#issuecomment-291638",
    "user": "https://github.com/seblabbe"
}
```

> which should be slightly faster than the version you tested because it does not run the 
> useless line `j = map(tuple,clusters[new_cl][0].g_vectors()).index(new_sd.g_vector(i))`


I had already commented that line in my previous post, also since commenting only line 1961 gives a syntax error. The only difference with your suggestion was that I was using

```python
new_directions = [ j for j in allowed_dirs if j != i or new_sd.b_matrix()[j,i] != 0 ]
```
instead of

```python
new_directions = [ j for j in allowed_dirs if j != i ]
```


Replying to [comment:15 etn40ff]:
> Ah! I am not sure how `RecursivelyEnumeratedSet` does things but there is one
> last assumption I am using:
> I know which is the last direction I walked to get to any vertex so at the next pass I am not travelling in that direction.


An hypothesis that we can't do right now inside the code of `RecursivelyEnumeratedSet` with symmetric structure since if `y in succ(x)`, then we can't assume that

```python
list(succ(x)).index(y) == list(succ(y)).index(x)
```
Also, the graph might not be k-regular (to make sure, that is the number of outgoing edges being constant).

But we can use that hypothesis in the `succ` function:

```python
sage: A = ClusterAlgebra(['E',6])
sage: def succ(S):
....:     p = S.path_from_initial_seed()
....:     i = p[-1] if p else -1
....:     return [S.mutate(j,inplace=False) for j in range(6) if j != i]
sage: seeds = RecursivelyEnumeratedSet([A.initial_seed()], succ, structure='symmetric')
sage: %time len(list(seeds))
CPU times: user 2.69 s, sys: 200 ms, total: 2.89 s
Wall time: 2.75 s
833
```

With this new `succ` function and removing the part `or new_sd.b_matrix()[j,i] != 0`, the ratio become about 5% slower using `RecursivelyEnumeratedSet` :

```python
sage: from pandas import DataFrame
sage: df = DataFrame(index="E6 E7 E8".split())
sage: df['explore_to_depth'] = [2.61, 16.1, 121.]
sage: df['rec_enum_set'] = [2.75, 16.9, 128.]
sage: df['ratio'] = df.rec_enum_set / df.explore_to_depth
sage: df
    explore_to_depth      rec_enum_set             ratio
E6  2.61000000000000  2.75000000000000  1.05363984674330
E7  16.1000000000000  16.9000000000000  1.04968944099379
E8  121.000000000000  128.000000000000  1.05785123966942
```



---

archive/issue_comments_291639.json:
```json
{
    "body": "ok 5% may depend on your code being more general or storing more info. I'd be happy to live with it. Now the problem is: how do I enforce the other two assumptions?\n\nPS: This ticket was meant to solve an issue and we are discussing something else. I guess we better leave this open till we are done.",
    "created_at": "2016-08-24T19:51:11Z",
    "issue": "https://github.com/sagemath/sagetest/issues/21312",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/21312#issuecomment-291639",
    "user": "https://github.com/etn40ff"
}
```

ok 5% may depend on your code being more general or storing more info. I'd be happy to live with it. Now the problem is: how do I enforce the other two assumptions?

PS: This ticket was meant to solve an issue and we are discussing something else. I guess we better leave this open till we are done.



---

archive/issue_comments_291640.json:
```json
{
    "body": "Meanwhile, I was managed to use the second assumption (if I am not mistaken):\n\n```python\nsage: A = ClusterAlgebra(['E',8])\nsage: allowed_dirs = range(8)\nsage: def succ(S):\n....:     p = S.path_from_initial_seed()\n....:     if p:\n....:         i = p[-1]\n....:         L = []\n....:         for j in allowed_dirs:\n....:              new_sd = S.mutate(j, inplace=False)\n....:              if j > i or new_sd.b_matrix()[j,i] != 0:\n....:                  L.append(new_sd)\n....:         return L\n....:     else:\n....:         return [S.mutate(j,inplace=False) for j in allowed_dirs]\nsage: seeds = RecursivelyEnumeratedSet([A.initial_seed()], succ) # not symmetric anymore right?\n```\n\nbut I do not get any significant improvement compare to just avoid branches `j!=i` :\n\n```python\nsage: %time len(list(seeds))\nCPU times: user 2min 8s, sys: 605 ms, total: 2min 8s\nWall time: 2min 8s\n25080\n```\n\nwhich is the same (128 s) as above.",
    "created_at": "2016-08-24T20:18:42Z",
    "issue": "https://github.com/sagemath/sagetest/issues/21312",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/21312#issuecomment-291640",
    "user": "https://github.com/seblabbe"
}
```

Meanwhile, I was managed to use the second assumption (if I am not mistaken):

```python
sage: A = ClusterAlgebra(['E',8])
sage: allowed_dirs = range(8)
sage: def succ(S):
....:     p = S.path_from_initial_seed()
....:     if p:
....:         i = p[-1]
....:         L = []
....:         for j in allowed_dirs:
....:              new_sd = S.mutate(j, inplace=False)
....:              if j > i or new_sd.b_matrix()[j,i] != 0:
....:                  L.append(new_sd)
....:         return L
....:     else:
....:         return [S.mutate(j,inplace=False) for j in allowed_dirs]
sage: seeds = RecursivelyEnumeratedSet([A.initial_seed()], succ) # not symmetric anymore right?
```

but I do not get any significant improvement compare to just avoid branches `j!=i` :

```python
sage: %time len(list(seeds))
CPU times: user 2min 8s, sys: 605 ms, total: 2min 8s
Wall time: 2min 8s
25080
```

which is the same (128 s) as above.



---

archive/issue_comments_291641.json:
```json
{
    "body": "Replying to [comment:17 etn40ff]:\n> ok 5% may depend on your code being more general or storing more info. I'd be happy to live with it. Now the problem is: how do I enforce the other two assumptions?\n\n\nI don't know if we can make the first assumption cleanly into the function `succ` (difficult to understand line 1959), but maybe the Recursively Enumerated Set class can be changed (or copied and changed) so that  the [line](https://github.com/sagemath/sage/blob/master/src/sage/sets/recursively_enumerated_set.pyx#L1032) does: if `y in B` then change `y` so that we do not go to `x` when we visit `y`.\n\nWe should test if it works and if it is worth it, and if so, create a new ticket for it.\n\n> PS: This ticket was meant to solve an issue and we are discussing something else. I guess we better leave this open till we are done.\n\n\nI agree. I wait for a review of this ticket then:)",
    "created_at": "2016-08-24T21:00:00Z",
    "issue": "https://github.com/sagemath/sagetest/issues/21312",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/21312#issuecomment-291641",
    "user": "https://github.com/seblabbe"
}
```

Replying to [comment:17 etn40ff]:
> ok 5% may depend on your code being more general or storing more info. I'd be happy to live with it. Now the problem is: how do I enforce the other two assumptions?


I don't know if we can make the first assumption cleanly into the function `succ` (difficult to understand line 1959), but maybe the Recursively Enumerated Set class can be changed (or copied and changed) so that  the [line](https://github.com/sagemath/sage/blob/master/src/sage/sets/recursively_enumerated_set.pyx#L1032) does: if `y in B` then change `y` so that we do not go to `x` when we visit `y`.

We should test if it works and if it is worth it, and if so, create a new ticket for it.

> PS: This ticket was meant to solve an issue and we are discussing something else. I guess we better leave this open till we are done.


I agree. I wait for a review of this ticket then:)



---

archive/issue_comments_291642.json:
```json
{
    "body": "I had a look at the code and it seems good to me. I am waiting for sage to finish building before running `sage -t --long` to give a positive review.\n\nOn the other topic discussed in the comments of this ticket: I ended up keeping the implementation I had in #21254 with a `try` statement to catch `KeyboardIntterrupt`. At the moment it is faster and I do not have much time to refactor the code to use `RecursivelyEnumeratedSet`. I will probably leave this as a task for a future ticket.",
    "created_at": "2016-08-26T08:49:10Z",
    "issue": "https://github.com/sagemath/sagetest/issues/21312",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/21312#issuecomment-291642",
    "user": "https://github.com/etn40ff"
}
```

I had a look at the code and it seems good to me. I am waiting for sage to finish building before running `sage -t --long` to give a positive review.

On the other topic discussed in the comments of this ticket: I ended up keeping the implementation I had in #21254 with a `try` statement to catch `KeyboardIntterrupt`. At the moment it is faster and I do not have much time to refactor the code to use `RecursivelyEnumeratedSet`. I will probably leave this as a task for a future ticket.



---

archive/issue_comments_291643.json:
```json
{
    "body": "No problem. `RecursivelyEnumeratedSet` should be fast so that people really want to use it. So your example raises good questions.",
    "created_at": "2016-08-26T09:19:05Z",
    "issue": "https://github.com/sagemath/sagetest/issues/21312",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/21312#issuecomment-291643",
    "user": "https://github.com/seblabbe"
}
```

No problem. `RecursivelyEnumeratedSet` should be fast so that people really want to use it. So your example raises good questions.



---

archive/issue_comments_291644.json:
```json
{
    "body": "Positive review.\n\nIt does make sense for code such as #21254 to use `RecursivelyEnumeratedSet` just because it is useless to keep reinventing the wheel each time. Moreover it offers quite a lot of useful features. \n\nTwo consideration about speed: \n\n1) I guess there are several use cases in which the function `succ` is expensive but it is not too expensive, once a duplicate element has been found, to trim the directions in which `succ` is computed. This is the case, for example, of the code we discussed. It could be useful if `RecursivelyEnumeratedSet` could take a second function as input that is called each time a new element in the set is found and that takes care of pruning the search tree accordingly.\n\n2) how essential is the `'forest'` requirement to the parallelized map/reduce? The code we discussed could benefit much from this.",
    "created_at": "2016-08-26T13:26:39Z",
    "issue": "https://github.com/sagemath/sagetest/issues/21312",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/21312#issuecomment-291644",
    "user": "https://github.com/etn40ff"
}
```

Positive review.

It does make sense for code such as #21254 to use `RecursivelyEnumeratedSet` just because it is useless to keep reinventing the wheel each time. Moreover it offers quite a lot of useful features. 

Two consideration about speed: 

1) I guess there are several use cases in which the function `succ` is expensive but it is not too expensive, once a duplicate element has been found, to trim the directions in which `succ` is computed. This is the case, for example, of the code we discussed. It could be useful if `RecursivelyEnumeratedSet` could take a second function as input that is called each time a new element in the set is found and that takes care of pruning the search tree accordingly.

2) how essential is the `'forest'` requirement to the parallelized map/reduce? The code we discussed could benefit much from this.



---

archive/issue_comments_291645.json:
```json
{
    "body": "Changing status from needs_review to positive_review.",
    "created_at": "2016-08-26T13:26:39Z",
    "issue": "https://github.com/sagemath/sagetest/issues/21312",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/21312#issuecomment-291645",
    "user": "https://github.com/etn40ff"
}
```

Changing status from needs_review to positive_review.



---

archive/issue_comments_291646.json:
```json
{
    "body": "I will keep your comment 1) in mind for future evolvement of RecEnumSet.\n\n> 2) how essential is the `'forest'` requirement to the parallelized map/reduce? The code we discussed could benefit much from this.\n\n\nWell you can set `structure='forest'` and see what happens. You will get elements generated twice in different trees and the independant workers will assume their element is new and will continue their search pruning its successors. Depending on the case, you can get an iterator that never halts even if the graph is finite...\n\nTo adapt the parallel map reduce code to work on graphs that are not forest, some communication should be added between workers. But then, it becomes less easy to get efficient parallel computations. That question should be asked to Florent:\n\n  Could their be a common set of already known nodes that is shared among the workers so that they could know if they find a new node or not?",
    "created_at": "2016-08-26T15:16:16Z",
    "issue": "https://github.com/sagemath/sagetest/issues/21312",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/21312#issuecomment-291646",
    "user": "https://github.com/seblabbe"
}
```

I will keep your comment 1) in mind for future evolvement of RecEnumSet.

> 2) how essential is the `'forest'` requirement to the parallelized map/reduce? The code we discussed could benefit much from this.


Well you can set `structure='forest'` and see what happens. You will get elements generated twice in different trees and the independant workers will assume their element is new and will continue their search pruning its successors. Depending on the case, you can get an iterator that never halts even if the graph is finite...

To adapt the parallel map reduce code to work on graphs that are not forest, some communication should be added between workers. But then, it becomes less easy to get efficient parallel computations. That question should be asked to Florent:

  Could their be a common set of already known nodes that is shared among the workers so that they could know if they find a new node or not?



---

archive/issue_comments_291647.json:
```json
{
    "body": "> Well you can set structure='forest' and see what happens.\n\n\nNothing good: say your function is symmetric then it will continuously bounce in between two elements. If I am not mistaken `'forest'` does not check for already produced elements.",
    "created_at": "2016-08-26T15:36:26Z",
    "issue": "https://github.com/sagemath/sagetest/issues/21312",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/21312#issuecomment-291647",
    "user": "https://github.com/etn40ff"
}
```

> Well you can set structure='forest' and see what happens.


Nothing good: say your function is symmetric then it will continuously bounce in between two elements. If I am not mistaken `'forest'` does not check for already produced elements.



---

archive/issue_comments_291648.json:
```json
{
    "body": "Replying to [comment:22 etn40ff]:\n\n> 2) how essential is the `'forest'` requirement to the parallelized\n\n  map/reduce? The code we discussed could benefit much from this.\n\nIt is essential. I'm planning to write some analogous code for directed\nacyclic graph, but this need to completely rethink the algorithm. If I manage,\nthere certainly will be two independent codes for forests and DAGs. And there\nis a good change that the DAG code will be less efficient.\n\nUsing the forest hypothesis, a work stealing algorithm allows the perform the\ncomputation with minimal communications. This is crucial because in Python,\ncommunication are done interprocess through pickling, so that they are quite\nslow. For DAGs, you need a strategy to ensure that two differents processes\nare not computing the same nodes...",
    "created_at": "2016-08-26T22:47:21Z",
    "issue": "https://github.com/sagemath/sagetest/issues/21312",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/21312#issuecomment-291648",
    "user": "https://github.com/hivert"
}
```

Replying to [comment:22 etn40ff]:

> 2) how essential is the `'forest'` requirement to the parallelized

  map/reduce? The code we discussed could benefit much from this.

It is essential. I'm planning to write some analogous code for directed
acyclic graph, but this need to completely rethink the algorithm. If I manage,
there certainly will be two independent codes for forests and DAGs. And there
is a good change that the DAG code will be less efficient.

Using the forest hypothesis, a work stealing algorithm allows the perform the
computation with minimal communications. This is crucial because in Python,
communication are done interprocess through pickling, so that they are quite
slow. For DAGs, you need a strategy to ensure that two differents processes
are not computing the same nodes...



---

archive/issue_comments_291649.json:
```json
{
    "body": "Resolution: fixed",
    "created_at": "2016-08-27T08:36:18Z",
    "issue": "https://github.com/sagemath/sagetest/issues/21312",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/21312#issuecomment-291649",
    "user": "https://github.com/vbraun"
}
```

Resolution: fixed



---

archive/issue_events_056742.json:
```json
{
    "actor": "https://github.com/vbraun",
    "created_at": "2016-08-27T08:36:18Z",
    "event": "closed",
    "issue": "https://github.com/sagemath/sagetest/issues/21312",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sagetest/issues/21312#event-56742"
}
```



---

archive/issue_comments_291650.json:
```json
{
    "body": "Replying to [comment:25 hivert]:\n> This is crucial because in Python,\n> communication are done interprocess through pickling, so that they are quite\n> slow.\n\n\nThat's a bummer! I am not sure DAGs would could be used in my case either.\n\nOne stray thought: can you use hashes for communication rather than the whole objects? You could get some mileage from the fact that you will be pickling a smaller amount of data.",
    "created_at": "2016-08-27T16:59:39Z",
    "issue": "https://github.com/sagemath/sagetest/issues/21312",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/21312#issuecomment-291650",
    "user": "https://github.com/etn40ff"
}
```

Replying to [comment:25 hivert]:
> This is crucial because in Python,
> communication are done interprocess through pickling, so that they are quite
> slow.


That's a bummer! I am not sure DAGs would could be used in my case either.

One stray thought: can you use hashes for communication rather than the whole objects? You could get some mileage from the fact that you will be pickling a smaller amount of data.
