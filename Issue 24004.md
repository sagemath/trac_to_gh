# Issue 24004: unstopped MapReduce workers

Issue created by migration from Trac.

Original creator: vdelecroix

Original creation time: 2017-11-19 12:38:09

CC:  hivert

Some patchbots report unstopped workers

```
sage -t --long src/sage/parallel/map_reduce.py
**********************************************************************
File "src/sage/parallel/map_reduce.py", line 1090, in sage.parallel.map_reduce.RESetMapReduce.start_workers
Failed example:
    all(w.is_alive() for w in S._workers)
Expected:
    True
Got:
    False
**********************************************************************
1 item had failures:
   1 of   9 in sage.parallel.map_reduce.RESetMapReduce.start_workers
    [296 tests, 1 failure, 28.70 s]
----------------------------------------------------------------------
sage -t --long src/sage/parallel/map_reduce.py  # 1 doctest failed
----------------------------------------------------------------------
```

see
- [this sardonis log](https://patchbot.sagemath.org/log/24215/Ubuntu/16.04/ppc64le/4.4.0-57-generic/sardonis/2017-11-18%2015:55:51?short)


---

Comment by embray created at 2017-11-22 12:26:46

I'm not sure an obvious way to reproduce this, but maybe we could go ahead and merge #21233 and see if that fixes it?  I've been waiting forever for someone to just give it positive review (which it had previously but Volker removed it...)


---

Comment by vdelecroix created at 2017-11-22 14:30:51

Replying to [comment:2 embray]:
> I'm not sure an obvious way to reproduce this, but maybe we could go ahead and merge #21233 and see if that fixes it?

+1. And I would love to have a way to grep through the patchbot reports easily!


---

Comment by embray created at 2017-11-22 15:54:22

Replying to [comment:3 vdelecroix]:
> Replying to [comment:2 embray]:
> > I'm not sure an obvious way to reproduce this, but maybe we could go ahead and merge #21233 and see if that fixes it?
> 
> +1. And I would love to have a way to grep through the patchbot reports easily!

Open an issue on the patchbot GitHub project for that.  I would love that too but it's probably not entirely trivial (if nothing else we'd want to index the report logs).


---

Comment by embray created at 2017-12-21 10:22:03

I'm not totally sure this was fixed by #21233.  Now, on several of my Cygwin patchbot runs, this module fails on the initial test run, not quite in the way reported by this ticket, but possibly similar.  I get `sage -t --long src/sage/parallel/map_reduce.py  # Timed out after testing finished` which is something I've never seen before...


---

Comment by vbraun created at 2017-12-25 18:17:04

I'm also seeing this on the buildbot


---

Comment by vbraun created at 2017-12-25 18:17:04

Changing keywords from "" to "random_fail".


---

Comment by jdemeyer created at 2018-07-12 11:35:33

This is just to say that I got this again.


---

Comment by jdemeyer created at 2018-07-12 11:41:54

The doctest looks like a race condition. If I'm understanding things correctly, the workers are started and will then stop naturally (after an unspecified amount of time). If they stop really quickly, then this doctest will fail:

```
            sage: from sage.parallel.map_reduce import RESetMapReduce
            sage: S = RESetMapReduce(roots=[])
            sage: S.setup_workers(2)
            sage: S.start_workers()
            sage: all(w.is_alive() for w in S._workers)
            True
```



---

Comment by jdemeyer created at 2018-07-12 11:47:49

I can make this test fail pretty consistently with

```
sage: sleep(0.02); all(w.is_alive() for w in S._workers)
```


If a doctest is sensitive to 20ms delays, it's a bad test.


---

Comment by embray created at 2018-07-12 12:51:44

Indeed; I see the problem here.  When I originally commented on this ticket, I admit, I don't think I looked very closely at the exact test that was failing.

If there's no work for the workers to do, then there's no guarantee that you'll ever find them all running simultaneously.

If you really wanted to test this, one possibility might be to set up a test logger that collects all log messages in a list, and then checks that the expected log messages are found (e.g. one "Started" and one "Exiting" for each worker started.


---

Comment by hivert created at 2018-07-12 14:23:28

Replying to [comment:11 embray]:
> If you really wanted to test this, one possibility might be to set up a test logger that collects all log messages in a list, and then checks that the expected log messages are found (e.g. one "Started" and one "Exiting" for each worker started.

Thanks to all of you for catching this one. I'm confirming jdemeyer analysis. If there is no work to do, there is no robust lower bound for the time the worker stays alive. 

`@`embray: there is a logger is the code but the level is normally set too low to see the message. Another possibilities would be to give as work to the worker a `sleep(1)` instruction.


---

Comment by hivert created at 2018-07-12 14:27:45

Sorry based my file on the wrong branch... Fixing it


---

Comment by jdemeyer created at 2018-07-12 14:31:10

The doctest fix looks good on first sight, I would still keep the `sleep(1)` in the last test though.

I cannot really comment on the other changes, which seem to be related to Python 3.
----
New commits:


---

Comment by git created at 2018-07-12 14:35:20

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by hivert created at 2018-07-12 14:35:42

Replying to [comment:14 jdemeyer]:
> The doctest fix looks good on first sight, I would still keep the `sleep(1)` in the last test though.
> 
> I cannot really comment on the other changes, which seem to be related to Python 3.

Sorry based my file on the wrong branch... Should be fixed now
----
New commits:


---

Comment by git created at 2018-07-12 16:04:30

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by hivert created at 2018-07-12 16:14:03

Changing status from new to needs_review.


---

Comment by jdemeyer created at 2018-07-13 09:08:31

Changing status from needs_review to positive_review.


---

Comment by hivert created at 2018-07-13 14:12:20

Replying to [comment:19 jdemeyer]:
Thanks Jeroen


---

Comment by vbraun created at 2018-08-05 08:43:32

Resolution: fixed
