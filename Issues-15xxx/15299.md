# Issue 15299: Incorrect results for analytic Sha due to low precision

archive/issues_015062.json:
```json
{
    "body": "See [https://groups.google.com/forum/#!topic/sage-support/rYQ4rWyncG4](https://groups.google.com/forum/#!topic/sage-support/rYQ4rWyncG4)\n\n```\nsage: E = EllipticCurve(QQ,[0, 0, 1, -79, 342]); E.sha().an(),E.sha().an_numerical()\n(0, 1.00000000000000)\nsage: E.lseries().deriv_at1(100*sqrt(E.conductor()) + 10)  # L1, error_bound\n(1.94655218772191e-15, 1.82478252135394e-270)\n```\n\nThis seems to be due to inappropriate use of Python floats instead of more precise real numbers. After the patch:\n\n```\nsage: E = EllipticCurve(QQ,[0, 0, 1, -79, 342]); E.sha().an(),E.sha().an_numerical()\n(1.00000000000000, 1.00000000000000)\nsage: E.lseries().deriv_at1(100*sqrt(E.conductor()) + 10)  # L1, error_bound\n(-4.32787398660869448751904675450772492666840247314688171540527473331725818170217268435223462033366791557160872926179439894639315476270837428785657638252738603056742447337636326343956370276624493916496382120766160023620812331280787034239648552009947468067829864968026720015203778821069593806584e-277,\n 1.82478252137476307223140369768561190028055347258560054363485475966241792307587640145132294203994875344783110100551912347495775160520204557245032474939095251969168953786545612090565728262067746413119194690260652692254781091147749697957445424152473292233020112755190503925812425294821095313979e-270)\n```\n\nWhile working on this, we found an upstream PARI bug: the precision for `exponential_integal_1()` was not as good as it could be.\n\nApply: [attachment:15299_lseries_prec.patch], [attachment:15299_reviewer.patch]\n\n\n**CC:**  @JohnCremona @williamstein\n\n**Upstream:** Fixed upstream, but not in a stable release.\n\n**Reviewer:** Peter Bruin\n\n**Author:** Jeroen Demeyer\n\n**Merged:** sage-5.13.beta4\n\n**Dependencies:** #15337, #15402\n\nIssue created by migration from https://trac.sagemath.org/ticket/15299\n\n",
    "closed_at": "2013-11-24T17:26:13Z",
    "created_at": "2013-10-16T21:05:51Z",
    "labels": [
        "component: elliptic curves",
        "bug"
    ],
    "milestone": "https://github.com/sagemath/sagetest/milestones/sage-5.13",
    "title": "Incorrect results for analytic Sha due to low precision",
    "type": "issue",
    "url": "https://github.com/sagemath/sagetest/issues/15299",
    "user": "https://github.com/jdemeyer"
}
```
See [https://groups.google.com/forum/#!topic/sage-support/rYQ4rWyncG4](https://groups.google.com/forum/#!topic/sage-support/rYQ4rWyncG4)

```
sage: E = EllipticCurve(QQ,[0, 0, 1, -79, 342]); E.sha().an(),E.sha().an_numerical()
(0, 1.00000000000000)
sage: E.lseries().deriv_at1(100*sqrt(E.conductor()) + 10)  # L1, error_bound
(1.94655218772191e-15, 1.82478252135394e-270)
```

This seems to be due to inappropriate use of Python floats instead of more precise real numbers. After the patch:

```
sage: E = EllipticCurve(QQ,[0, 0, 1, -79, 342]); E.sha().an(),E.sha().an_numerical()
(1.00000000000000, 1.00000000000000)
sage: E.lseries().deriv_at1(100*sqrt(E.conductor()) + 10)  # L1, error_bound
(-4.32787398660869448751904675450772492666840247314688171540527473331725818170217268435223462033366791557160872926179439894639315476270837428785657638252738603056742447337636326343956370276624493916496382120766160023620812331280787034239648552009947468067829864968026720015203778821069593806584e-277,
 1.82478252137476307223140369768561190028055347258560054363485475966241792307587640145132294203994875344783110100551912347495775160520204557245032474939095251969168953786545612090565728262067746413119194690260652692254781091147749697957445424152473292233020112755190503925812425294821095313979e-270)
```

While working on this, we found an upstream PARI bug: the precision for `exponential_integal_1()` was not as good as it could be.

Apply: [attachment:15299_lseries_prec.patch], [attachment:15299_reviewer.patch]


**CC:**  @JohnCremona @williamstein

**Upstream:** Fixed upstream, but not in a stable release.

**Reviewer:** Peter Bruin

**Author:** Jeroen Demeyer

**Merged:** sage-5.13.beta4

**Dependencies:** #15337, #15402

Issue created by migration from https://trac.sagemath.org/ticket/15299





---

archive/issue_comments_232289.json:
```json
{
    "body": "**Description changed:**\n``````diff\n--- \n+++ \n@@ -1 +1,9 @@\n See [https://groups.google.com/forum/#!topic/sage-support/rYQ4rWyncG4](https://groups.google.com/forum/#!topic/sage-support/rYQ4rWyncG4)\n+\n+```\n+sage: E=EllipticCurve(QQ,[0, 0, 1, -79, 342]); E.sha().an(),E.sha().an_numerical()\n+(0, 1.00000000000000)\n+sage: E.lseries().deriv_at1(100*sqrt(E.conductor()) + 10)  # L1, error_bound\n+```\n+\n+This seems to be due to inappropriate use of Python floats instead of more precise objects.\n``````\n",
    "created_at": "2013-10-16T21:07:31Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232289",
    "user": "https://github.com/jdemeyer"
}
```

**Description changed:**
``````diff
--- 
+++ 
@@ -1 +1,9 @@
 See [https://groups.google.com/forum/#!topic/sage-support/rYQ4rWyncG4](https://groups.google.com/forum/#!topic/sage-support/rYQ4rWyncG4)
+
+```
+sage: E=EllipticCurve(QQ,[0, 0, 1, -79, 342]); E.sha().an(),E.sha().an_numerical()
+(0, 1.00000000000000)
+sage: E.lseries().deriv_at1(100*sqrt(E.conductor()) + 10)  # L1, error_bound
+```
+
+This seems to be due to inappropriate use of Python floats instead of more precise objects.
``````




---

archive/issue_comments_232290.json:
```json
{
    "body": "<a id='comment:2'></a>\nIt gets worse!\n\n```\nsage: E = EllipticCurve('11a')\nsage: E.lseries().deriv_at1()\n0\nsage: E.lseries().dokchitser().derivative(1)\n0.308708533963172\n```\n\nI.e., it is wrong for all curves of rank 0 too...  (This isn't what we wrote the code for.  Ugh.)",
    "created_at": "2013-10-16T21:11:27Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232290",
    "user": "https://github.com/williamstein"
}
```

<a id='comment:2'></a>
It gets worse!

```
sage: E = EllipticCurve('11a')
sage: E.lseries().deriv_at1()
0
sage: E.lseries().dokchitser().derivative(1)
0.308708533963172
```

I.e., it is wrong for all curves of rank 0 too...  (This isn't what we wrote the code for.  Ugh.)



---

archive/issue_comments_232291.json:
```json
{
    "body": "<a id='comment:3'></a>\nSo this is plain wrong then (I don't know enough mathematics to judge this):\n\n```\n        if self.__E.root_number() == 1:\n            return 0\n```",
    "created_at": "2013-10-16T22:20:17Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232291",
    "user": "https://github.com/jdemeyer"
}
```

<a id='comment:3'></a>
So this is plain wrong then (I don't know enough mathematics to judge this):

```
        if self.__E.root_number() == 1:
            return 0
```



---

archive/issue_comments_232292.json:
```json
{
    "body": "<a id='comment:4'></a>\nI don't know about `11a1`, but this at least fixes the original problem.",
    "created_at": "2013-10-16T22:32:54Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232292",
    "user": "https://github.com/jdemeyer"
}
```

<a id='comment:4'></a>
I don't know about `11a1`, but this at least fixes the original problem.



---

archive/issue_comments_232293.json:
```json
{
    "body": "<a id='comment:5'></a>\nReplying to [jdemeyer](#comment%3A3):\n> So this is plain wrong then (I don't know enough mathematics to judge this):\n> \n> ```\n>         if self.__E.root_number() == 1:\n>             return 0\n> ```\n\nThe root number is the sign of the functional equation so is +1 for even analytic rank and -1 for odd.  This function computes the first derivative.  *In practice* this is something one would only want to do if the 0'th derivative was already known to be 0, in which case the code you quote would be OK since if the value is 0 and the order is even then the order is at least 2 so the first derivative is exactly 0.  But of course this function then lies in wait for the user who decides they want the first derivative's value even when the value is nonzero (as for 11a1).  The trouble is that (1) Formulas for the r'th derivative which are implemented are *only* valid under the assumption that all previous derivatives are 0;  and of course (2) proving the earlier derivatives are exactly 0 is usually impossible with current theory.\n\nWhere does that leave this deriv_at1 function?  At the very least it should come with a huge warning about all this.  And it really should return 0 when the root number is +1 unless the user has made an explicit assumption (assume_order_of_vanishing_is_positive=True, say) and otherwise raise a NotImplemented error (or attempt to prove that L(1)=0).",
    "created_at": "2013-10-17T08:52:52Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232293",
    "user": "https://github.com/JohnCremona"
}
```

<a id='comment:5'></a>
Replying to [jdemeyer](#comment%3A3):
> So this is plain wrong then (I don't know enough mathematics to judge this):
> 
> ```
>         if self.__E.root_number() == 1:
>             return 0
> ```

The root number is the sign of the functional equation so is +1 for even analytic rank and -1 for odd.  This function computes the first derivative.  *In practice* this is something one would only want to do if the 0'th derivative was already known to be 0, in which case the code you quote would be OK since if the value is 0 and the order is even then the order is at least 2 so the first derivative is exactly 0.  But of course this function then lies in wait for the user who decides they want the first derivative's value even when the value is nonzero (as for 11a1).  The trouble is that (1) Formulas for the r'th derivative which are implemented are *only* valid under the assumption that all previous derivatives are 0;  and of course (2) proving the earlier derivatives are exactly 0 is usually impossible with current theory.

Where does that leave this deriv_at1 function?  At the very least it should come with a huge warning about all this.  And it really should return 0 when the root number is +1 unless the user has made an explicit assumption (assume_order_of_vanishing_is_positive=True, say) and otherwise raise a NotImplemented error (or attempt to prove that L(1)=0).



---

archive/issue_comments_232294.json:
```json
{
    "body": "**Changing status** from new to needs_review.",
    "created_at": "2013-10-17T19:16:34Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232294",
    "user": "https://github.com/jdemeyer"
}
```

**Changing status** from new to needs_review.



---

archive/issue_comments_232295.json:
```json
{
    "body": "**Description changed:**\n``````diff\n--- \n+++ \n@@ -4,6 +4,7 @@\n sage: E=EllipticCurve(QQ,[0, 0, 1, -79, 342]); E.sha().an(),E.sha().an_numerical()\n (0, 1.00000000000000)\n sage: E.lseries().deriv_at1(100*sqrt(E.conductor()) + 10)  # L1, error_bound\n+(1.94655218772191e-15, 1.82478252135394e-270)\n ```\n \n-This seems to be due to inappropriate use of Python floats instead of more precise objects.\n+This seems to be due to inappropriate use of Python floats instead of more precise real numbers.\n``````\n",
    "created_at": "2013-10-17T20:23:57Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232295",
    "user": "https://github.com/jdemeyer"
}
```

**Description changed:**
``````diff
--- 
+++ 
@@ -4,6 +4,7 @@
 sage: E=EllipticCurve(QQ,[0, 0, 1, -79, 342]); E.sha().an(),E.sha().an_numerical()
 (0, 1.00000000000000)
 sage: E.lseries().deriv_at1(100*sqrt(E.conductor()) + 10)  # L1, error_bound
+(1.94655218772191e-15, 1.82478252135394e-270)
 ```
 
-This seems to be due to inappropriate use of Python floats instead of more precise objects.
+This seems to be due to inappropriate use of Python floats instead of more precise real numbers.
``````




---

archive/issue_comments_232296.json:
```json
{
    "body": "**Description changed:**\n``````diff\n--- \n+++ \n@@ -1,10 +1,18 @@\n See [https://groups.google.com/forum/#!topic/sage-support/rYQ4rWyncG4](https://groups.google.com/forum/#!topic/sage-support/rYQ4rWyncG4)\n \n ```\n-sage: E=EllipticCurve(QQ,[0, 0, 1, -79, 342]); E.sha().an(),E.sha().an_numerical()\n+sage: E = EllipticCurve(QQ,[0, 0, 1, -79, 342]); E.sha().an(),E.sha().an_numerical()\n (0, 1.00000000000000)\n sage: E.lseries().deriv_at1(100*sqrt(E.conductor()) + 10)  # L1, error_bound\n (1.94655218772191e-15, 1.82478252135394e-270)\n ```\n \n-This seems to be due to inappropriate use of Python floats instead of more precise real numbers.\n+This seems to be due to inappropriate use of Python floats instead of more precise real numbers. After the patch:\n+\n+```\n+sage: E = EllipticCurve(QQ,[0, 0, 1, -79, 342]); E.sha().an(),E.sha().an_numerical()\n+(1.00000000000000, 1.00000000000000)\n+sage: E.lseries().deriv_at1(100*sqrt(E.conductor()) + 10)  # L1, error_bound\n+(-4.32787398660869448751904675450772492666840247314688171540527473331725818170217268435223462033366791557160872926179439894639315476270837428785657638252738603056742447337636326343956370276624493916496382120766160023620812331280787034239648552009947468067829864968026720015203778821069593806584e-277,\n+ 1.82478252137476307223140369768561190028055347258560054363485475966241792307587640145132294203994875344783110100551912347495775160520204557245032474939095251969168953786545612090565728262067746413119194690260652692254781091147749697957445424152473292233020112755190503925812425294821095313979e-270)\n+```\n``````\n",
    "created_at": "2013-10-17T21:39:06Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232296",
    "user": "https://github.com/jdemeyer"
}
```

**Description changed:**
``````diff
--- 
+++ 
@@ -1,10 +1,18 @@
 See [https://groups.google.com/forum/#!topic/sage-support/rYQ4rWyncG4](https://groups.google.com/forum/#!topic/sage-support/rYQ4rWyncG4)
 
 ```
-sage: E=EllipticCurve(QQ,[0, 0, 1, -79, 342]); E.sha().an(),E.sha().an_numerical()
+sage: E = EllipticCurve(QQ,[0, 0, 1, -79, 342]); E.sha().an(),E.sha().an_numerical()
 (0, 1.00000000000000)
 sage: E.lseries().deriv_at1(100*sqrt(E.conductor()) + 10)  # L1, error_bound
 (1.94655218772191e-15, 1.82478252135394e-270)
 ```
 
-This seems to be due to inappropriate use of Python floats instead of more precise real numbers.
+This seems to be due to inappropriate use of Python floats instead of more precise real numbers. After the patch:
+
+```
+sage: E = EllipticCurve(QQ,[0, 0, 1, -79, 342]); E.sha().an(),E.sha().an_numerical()
+(1.00000000000000, 1.00000000000000)
+sage: E.lseries().deriv_at1(100*sqrt(E.conductor()) + 10)  # L1, error_bound
+(-4.32787398660869448751904675450772492666840247314688171540527473331725818170217268435223462033366791557160872926179439894639315476270837428785657638252738603056742447337636326343956370276624493916496382120766160023620812331280787034239648552009947468067829864968026720015203778821069593806584e-277,
+ 1.82478252137476307223140369768561190028055347258560054363485475966241792307587640145132294203994875344783110100551912347495775160520204557245032474939095251969168953786545612090565728262067746413119194690260652692254781091147749697957445424152473292233020112755190503925812425294821095313979e-270)
+```
``````




---

archive/issue_comments_232297.json:
```json
{
    "body": "<a id='comment:9'></a>\n...review in progress...and all works fine, including docbuilding.  the changes look good to the human eye (this one at least).  Oops, forgot the --long when testing..... and it's still all good.  Thanks, Jeroen!",
    "created_at": "2013-10-18T14:06:37Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232297",
    "user": "https://github.com/JohnCremona"
}
```

<a id='comment:9'></a>
...review in progress...and all works fine, including docbuilding.  the changes look good to the human eye (this one at least).  Oops, forgot the --long when testing..... and it's still all good.  Thanks, Jeroen!



---

archive/issue_comments_232298.json:
```json
{
    "body": "<a id='comment:10'></a>\nCorrected the error computation for `at1()`. I believe this is rigorous now:\n\n```\n        for n in xrange(1,k+1):\n            term = (zpow * an[n])/n\n            zpow *= z\n            L += term\n            # 8n+1 is the relative error in half-ulps to compute term.\n            # For addition, multiplication, division, sqrt, this is\n            # bounded by the number of operations. exp(x) multiplies the\n            # relative error by abs(x) and adds 1 half-ulp. The relative\n            # error for -2*pi/sqrtN is 3 half-ulps. Assuming that\n            # 2*pi/sqrtN <= 2, the relative error for z is 7 half-ulps.\n            # This implies a relative error of 8n-1 half-ulps for zpow.\n            # Adding 2 for the computation of term gives:\n            error += term.ulp()*(8*n+1) + L.ulp()\n```",
    "created_at": "2013-10-20T21:48:02Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232298",
    "user": "https://github.com/jdemeyer"
}
```

<a id='comment:10'></a>
Corrected the error computation for `at1()`. I believe this is rigorous now:

```
        for n in xrange(1,k+1):
            term = (zpow * an[n])/n
            zpow *= z
            L += term
            # 8n+1 is the relative error in half-ulps to compute term.
            # For addition, multiplication, division, sqrt, this is
            # bounded by the number of operations. exp(x) multiplies the
            # relative error by abs(x) and adds 1 half-ulp. The relative
            # error for -2*pi/sqrtN is 3 half-ulps. Assuming that
            # 2*pi/sqrtN <= 2, the relative error for z is 7 half-ulps.
            # This implies a relative error of 8n-1 half-ulps for zpow.
            # Adding 2 for the computation of term gives:
            error += term.ulp()*(8*n+1) + L.ulp()
```



---

archive/issue_comments_232299.json:
```json
{
    "body": "<a id='comment:11'></a>\nReplying to [jdemeyer](#comment%3A10):\n> Corrected the error computation for `at1()`. I believe this is rigorous now:\n> \n> ```\n>         for n in xrange(1,k+1):\n>             term = (zpow * an[n])/n\n>             zpow *= z\n>             L += term\n>             # 8n+1 is the relative error in half-ulps to compute term.\n>             # For addition, multiplication, division, sqrt, this is\n>             # bounded by the number of operations. exp(x) multiplies the\n>             # relative error by abs(x) and adds 1 half-ulp. The relative\n>             # error for -2*pi/sqrtN is 3 half-ulps. Assuming that\n>             # 2*pi/sqrtN <= 2, the relative error for z is 7 half-ulps.\n>             # This implies a relative error of 8n-1 half-ulps for zpow.\n>             # Adding 2 for the computation of term gives:\n>             error += term.ulp()*(8*n+1) + L.ulp()\n> ```\n\n\nI can see where this is in the code -- can you say how it affects any doctest outputs?  I am not a numerical analyst...",
    "created_at": "2013-10-21T08:43:22Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232299",
    "user": "https://github.com/JohnCremona"
}
```

<a id='comment:11'></a>
Replying to [jdemeyer](#comment%3A10):
> Corrected the error computation for `at1()`. I believe this is rigorous now:
> 
> ```
>         for n in xrange(1,k+1):
>             term = (zpow * an[n])/n
>             zpow *= z
>             L += term
>             # 8n+1 is the relative error in half-ulps to compute term.
>             # For addition, multiplication, division, sqrt, this is
>             # bounded by the number of operations. exp(x) multiplies the
>             # relative error by abs(x) and adds 1 half-ulp. The relative
>             # error for -2*pi/sqrtN is 3 half-ulps. Assuming that
>             # 2*pi/sqrtN <= 2, the relative error for z is 7 half-ulps.
>             # This implies a relative error of 8n-1 half-ulps for zpow.
>             # Adding 2 for the computation of term gives:
>             error += term.ulp()*(8*n+1) + L.ulp()
> ```


I can see where this is in the code -- can you say how it affects any doctest outputs?  I am not a numerical analyst...



---

archive/issue_comments_232300.json:
```json
{
    "body": "<a id='comment:12'></a>\nReplying to [cremona](#comment%3A11):\n> can you say how it affects any doctest outputs?\n\nI would only make the `error` results slightly larger than before. Perhaps more importantly, I believe the error computation is now rigorous, in the sense that one could *prove* that the actual error is bound by the `error` result.",
    "created_at": "2013-10-21T09:52:53Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232300",
    "user": "https://github.com/jdemeyer"
}
```

<a id='comment:12'></a>
Replying to [cremona](#comment%3A11):
> can you say how it affects any doctest outputs?

I would only make the `error` results slightly larger than before. Perhaps more importantly, I believe the error computation is now rigorous, in the sense that one could *prove* that the actual error is bound by the `error` result.



---

archive/issue_comments_232301.json:
```json
{
    "body": "<a id='comment:13'></a>\nIf you care less about speed, I could also write a version using interval arithmetic, which will be simpler but slower.",
    "created_at": "2013-10-28T12:06:08Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232301",
    "user": "https://github.com/jdemeyer"
}
```

<a id='comment:13'></a>
If you care less about speed, I could also write a version using interval arithmetic, which will be simpler but slower.



---

archive/issue_comments_232302.json:
```json
{
    "body": "<a id='comment:14'></a>\nAdded tolerance to `E.lseries().twist_values(1, -12, -4)` doctest to account for doctest failure on ia64.",
    "created_at": "2013-10-31T08:14:57Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232302",
    "user": "https://github.com/jdemeyer"
}
```

<a id='comment:14'></a>
Added tolerance to `E.lseries().twist_values(1, -12, -4)` doctest to account for doctest failure on ia64.



---

archive/issue_comments_232303.json:
```json
{
    "body": "<a id='comment:15'></a>\nPasses tests on the buildbots now.",
    "created_at": "2013-11-04T07:24:31Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232303",
    "user": "https://github.com/jdemeyer"
}
```

<a id='comment:15'></a>
Passes tests on the buildbots now.



---

archive/issue_comments_232304.json:
```json
{
    "body": "<a id='comment:16'></a>\nReplying to [cremona](#comment%3A5):\n> Where does that leave this deriv_at1 function?  At the very least it should come with a huge warning about all this.  And it really should return 0 when the root number is +1 unless the user has made an explicit assumption (assume_order_of_vanishing_is_positive=True, say) and otherwise raise a NotImplemented error (or attempt to prove that L(1)=0).\n\nThe `Lseries_ell` class has a method `L1_vanishes()`, written by William Stein.  According to the documentation, it is provably correct if the Manin constant is <= 2 for the optimal quotient in the isogeny class.  This method is used in some places, but not currently in `deriv_at1()`, where we might use it to check the assumption *L*(*E*, 1) = 0.  If that is too slow, a `check=False` flag could be added.",
    "created_at": "2013-11-04T17:30:32Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232304",
    "user": "https://github.com/pjbruin"
}
```

<a id='comment:16'></a>
Replying to [cremona](#comment%3A5):
> Where does that leave this deriv_at1 function?  At the very least it should come with a huge warning about all this.  And it really should return 0 when the root number is +1 unless the user has made an explicit assumption (assume_order_of_vanishing_is_positive=True, say) and otherwise raise a NotImplemented error (or attempt to prove that L(1)=0).

The `Lseries_ell` class has a method `L1_vanishes()`, written by William Stein.  According to the documentation, it is provably correct if the Manin constant is <= 2 for the optimal quotient in the isogeny class.  This method is used in some places, but not currently in `deriv_at1()`, where we might use it to check the assumption *L*(*E*, 1) = 0.  If that is too slow, a `check=False` flag could be added.



---

archive/issue_comments_232305.json:
```json
{
    "body": "<a id='comment:17'></a>\nJeroen, do you have a particular reason for writing `QQ()` and `R()` instead of `QQ(0)` and `R(0)`?  It saves one character, but is less readable.",
    "created_at": "2013-11-04T17:32:58Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232305",
    "user": "https://github.com/pjbruin"
}
```

<a id='comment:17'></a>
Jeroen, do you have a particular reason for writing `QQ()` and `R()` instead of `QQ(0)` and `R(0)`?  It saves one character, but is less readable.



---

archive/issue_comments_232306.json:
```json
{
    "body": "<a id='comment:18'></a>\nReplying to [pbruin](#comment%3A17):\n> Jeroen, do you have a particular reason for writing `QQ()` and `R()` instead of `QQ(0)` and `R(0)`?  It saves one character, but is less readable.\n\nNo reason, it's just a habit to think in term of default constructors (I guess this is my C++ background). I just benchmarked `QQ()`, `QQ(0)` and `QQ.zero()` and the latter is the fastest, so perhaps we should use that.",
    "created_at": "2013-11-04T19:34:23Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232306",
    "user": "https://github.com/jdemeyer"
}
```

<a id='comment:18'></a>
Replying to [pbruin](#comment%3A17):
> Jeroen, do you have a particular reason for writing `QQ()` and `R()` instead of `QQ(0)` and `R(0)`?  It saves one character, but is less readable.

No reason, it's just a habit to think in term of default constructors (I guess this is my C++ background). I just benchmarked `QQ()`, `QQ(0)` and `QQ.zero()` and the latter is the fastest, so perhaps we should use that.



---

archive/issue_comments_232307.json:
```json
{
    "body": "<a id='comment:19'></a>\nReplying to [pbruin](#comment%3A16):\n> The `Lseries_ell` class has a method `L1_vanishes()`, written by William Stein.  According to the documentation, it is provably correct if the Manin constant is <= 2 for the optimal quotient in the isogeny class.  This method is used in some places, but not currently in `deriv_at1()`, where we might use it to check the assumption *L*(*E*, 1) = 0.  If that is too slow, a `check=False` flag could be added.\n\n\nDo you propose that this change should be made, or is it just an observation? Given that the function `deriv_at1()` is in practice only called when we know that `L(E,1) = 0`, I personally think the warning suffices.",
    "created_at": "2013-11-04T20:23:16Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232307",
    "user": "https://github.com/jdemeyer"
}
```

<a id='comment:19'></a>
Replying to [pbruin](#comment%3A16):
> The `Lseries_ell` class has a method `L1_vanishes()`, written by William Stein.  According to the documentation, it is provably correct if the Manin constant is <= 2 for the optimal quotient in the isogeny class.  This method is used in some places, but not currently in `deriv_at1()`, where we might use it to check the assumption *L*(*E*, 1) = 0.  If that is too slow, a `check=False` flag could be added.


Do you propose that this change should be made, or is it just an observation? Given that the function `deriv_at1()` is in practice only called when we know that `L(E,1) = 0`, I personally think the warning suffices.



---

archive/issue_comments_232308.json:
```json
{
    "body": "<a id='comment:20'></a>\nReplying to [jdemeyer](#comment%3A19):\n> Do you propose that this change should be made, or is it just an observation? Given that the function `deriv_at1()` is in practice only called when we know that `L(E,1) = 0`, I personally think the warning suffices.\n\nI agree, it was more an observation that we could in principle use `L1_vanishes()` here than a proposal to actually do it.\n\nThere is a formula for the *r*-th derivative which is valid when all lower derivatives vanish.  As far as I know, only for the 0-th derivative is there a known way to prove that it vanishes by a numerical computation.  For parity reasons (the root number), this means that if the order of vanishing is 0, 1 or 2, then we can prove this.  If the order of vanishing is 3, then in general we don't know how to prove that it is not 1.\n\nThis means that if and when the formula mentioned above is implemented, we won't be able to verify the condition \"all lower derivatives are 0\" when *r* is at least 3.  Hence we should probably not insist on verifying it when *r* = 1.",
    "created_at": "2013-11-04T21:12:54Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232308",
    "user": "https://github.com/pjbruin"
}
```

<a id='comment:20'></a>
Replying to [jdemeyer](#comment%3A19):
> Do you propose that this change should be made, or is it just an observation? Given that the function `deriv_at1()` is in practice only called when we know that `L(E,1) = 0`, I personally think the warning suffices.

I agree, it was more an observation that we could in principle use `L1_vanishes()` here than a proposal to actually do it.

There is a formula for the *r*-th derivative which is valid when all lower derivatives vanish.  As far as I know, only for the 0-th derivative is there a known way to prove that it vanishes by a numerical computation.  For parity reasons (the root number), this means that if the order of vanishing is 0, 1 or 2, then we can prove this.  If the order of vanishing is 3, then in general we don't know how to prove that it is not 1.

This means that if and when the formula mentioned above is implemented, we won't be able to verify the condition "all lower derivatives are 0" when *r* is at least 3.  Hence we should probably not insist on verifying it when *r* = 1.



---

archive/issue_comments_232309.json:
```json
{
    "body": "<a id='comment:21'></a>\nAnother question: is it necessary to compute the error bound to the same precision as the result, i.e. in `RealField(prec)`?  It seems sufficient, and more efficient, to compute it in a lower-precision `RealField` or even just using Python floats.",
    "created_at": "2013-11-04T22:34:01Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232309",
    "user": "https://github.com/pjbruin"
}
```

<a id='comment:21'></a>
Another question: is it necessary to compute the error bound to the same precision as the result, i.e. in `RealField(prec)`?  It seems sufficient, and more efficient, to compute it in a lower-precision `RealField` or even just using Python floats.



---

archive/issue_comments_232310.json:
```json
{
    "body": "<a id='comment:22'></a>\nReplying to [pbruin](#comment%3A20):\n> Replying to [jdemeyer](#comment%3A19):\n> > Do you propose that this change should be made, or is it just an observation? Given that the function `deriv_at1()` is in practice only called when we know that `L(E,1) = 0`, I personally think the warning suffices.\n\n> I agree, it was more an observation that we could in principle use `L1_vanishes()` here than a proposal to actually do it.\n> \n> There is a formula for the *r*-th derivative which is valid when all lower derivatives vanish.  As far as I know, only for the 0-th derivative is there a known way to prove that it vanishes by a numerical computation.  For parity reasons (the root number), this means that if the order of vanishing is 0, 1 or 2, then we can prove this.  If the order of vanishing is 3, then in general we don't know how to prove that it is not 1.\n\n\nYou can go one step further thanks to Gross-Zagier:  if the parity is odd and L'(1) looks zero then you can prove it, since if in fact L'(1)!=0 then the curve would have rank 1, but you can disprove that by finding three (or oeven only 2) independent points. See by talk http://homepages.warwick.ac.uk/staff/J.E.Cremona/papers/bsd50.pdf if you want to read more!\n\n> \n> This means that if and when the formula mentioned above is implemented, we won't be able to verify the condition \"all lower derivatives are 0\" when *r* is at least 3.  Hence we should probably not insist on verifying it when *r* = 1.\n",
    "created_at": "2013-11-05T09:31:38Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232310",
    "user": "https://github.com/JohnCremona"
}
```

<a id='comment:22'></a>
Replying to [pbruin](#comment%3A20):
> Replying to [jdemeyer](#comment%3A19):
> > Do you propose that this change should be made, or is it just an observation? Given that the function `deriv_at1()` is in practice only called when we know that `L(E,1) = 0`, I personally think the warning suffices.

> I agree, it was more an observation that we could in principle use `L1_vanishes()` here than a proposal to actually do it.
> 
> There is a formula for the *r*-th derivative which is valid when all lower derivatives vanish.  As far as I know, only for the 0-th derivative is there a known way to prove that it vanishes by a numerical computation.  For parity reasons (the root number), this means that if the order of vanishing is 0, 1 or 2, then we can prove this.  If the order of vanishing is 3, then in general we don't know how to prove that it is not 1.


You can go one step further thanks to Gross-Zagier:  if the parity is odd and L'(1) looks zero then you can prove it, since if in fact L'(1)!=0 then the curve would have rank 1, but you can disprove that by finding three (or oeven only 2) independent points. See by talk http://homepages.warwick.ac.uk/staff/J.E.Cremona/papers/bsd50.pdf if you want to read more!

> 
> This means that if and when the formula mentioned above is implemented, we won't be able to verify the condition "all lower derivatives are 0" when *r* is at least 3.  Hence we should probably not insist on verifying it when *r* = 1.




---

archive/issue_comments_232311.json:
```json
{
    "body": "<a id='comment:23'></a>\nReplying to [cremona](#comment%3A22):\n> You can go one step further thanks to Gross-Zagier:  if the parity is odd and L'(1) looks zero then you can prove it, since if in fact L'(1)!=0 then the curve would have rank 1, but you can disprove that by finding three (or oeven only 2) independent points.\n\nThat is true (in fact I seem to remember learning this from the talk you linked to).  However, it does require you to search for points; there seems to be no \"analytic\" way of proving that L'(1) = 0 by computing it to finite precision, like the `L1_vanishes()` function.",
    "created_at": "2013-11-06T12:18:39Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232311",
    "user": "https://github.com/pjbruin"
}
```

<a id='comment:23'></a>
Replying to [cremona](#comment%3A22):
> You can go one step further thanks to Gross-Zagier:  if the parity is odd and L'(1) looks zero then you can prove it, since if in fact L'(1)!=0 then the curve would have rank 1, but you can disprove that by finding three (or oeven only 2) independent points.

That is true (in fact I seem to remember learning this from the talk you linked to).  However, it does require you to search for points; there seems to be no "analytic" way of proving that L'(1) = 0 by computing it to finite precision, like the `L1_vanishes()` function.



---

archive/issue_comments_232312.json:
```json
{
    "body": "<a id='comment:24'></a>\nReplying to [pbruin](#comment%3A21):\n> Another question: is it necessary to compute the error bound to the same precision as the result, i.e. in `RealField(prec)`?  It seems sufficient, and more efficient, to compute it in a lower-precision `RealField`\nDone. Needs #15337.\n\n> or even just using Python floats.\n\nNot a good idea, as these have limited range and it's a lot harder (maybe even impossible) to control the rounding. One doctest has an error of 2.74997188336901e-449, which would be rounded to 0.0 as Python `float`.",
    "created_at": "2013-11-08T16:06:04Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232312",
    "user": "https://github.com/jdemeyer"
}
```

<a id='comment:24'></a>
Replying to [pbruin](#comment%3A21):
> Another question: is it necessary to compute the error bound to the same precision as the result, i.e. in `RealField(prec)`?  It seems sufficient, and more efficient, to compute it in a lower-precision `RealField`
Done. Needs #15337.

> or even just using Python floats.

Not a good idea, as these have limited range and it's a lot harder (maybe even impossible) to control the rounding. One doctest has an error of 2.74997188336901e-449, which would be rounded to 0.0 as Python `float`.



---

archive/issue_comments_232313.json:
```json
{
    "body": "**Reviewer:** Peter Bruin",
    "created_at": "2013-11-08T23:46:41Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232313",
    "user": "https://github.com/pjbruin"
}
```

**Reviewer:** Peter Bruin



---

archive/issue_comments_232314.json:
```json
{
    "body": "**Dependencies:** #15337",
    "created_at": "2013-11-08T23:46:41Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232314",
    "user": "https://github.com/pjbruin"
}
```

**Dependencies:** #15337



---

archive/issue_comments_232315.json:
```json
{
    "body": "**Changing status** from needs_review to positive_review.",
    "created_at": "2013-11-08T23:46:41Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232315",
    "user": "https://github.com/pjbruin"
}
```

**Changing status** from needs_review to positive_review.



---

archive/issue_comments_232316.json:
```json
{
    "body": "<a id='comment:25'></a>\nThis looks very good now.  The error analysis appears to be completely rigorous for `at1()` and almost completely rigorous for `deriv_at1()`, the only source of non-rigorousness being due to the unknown error in the exponential integral function `eint1()` from PARI.  This ticket is not the place to try to fix this, though.\n\nAre the PARI developers aware of this precision issue?  Should it be regarded it as a bug, or does PARI not strive for proven error bounds for functions such as `eint1()`?",
    "created_at": "2013-11-08T23:46:41Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232316",
    "user": "https://github.com/pjbruin"
}
```

<a id='comment:25'></a>
This looks very good now.  The error analysis appears to be completely rigorous for `at1()` and almost completely rigorous for `deriv_at1()`, the only source of non-rigorousness being due to the unknown error in the exponential integral function `eint1()` from PARI.  This ticket is not the place to try to fix this, though.

Are the PARI developers aware of this precision issue?  Should it be regarded it as a bug, or does PARI not strive for proven error bounds for functions such as `eint1()`?



---

archive/issue_comments_232317.json:
```json
{
    "body": "<a id='comment:26'></a>\nReplying to [pbruin](#comment%3A25):\n> Are the PARI developers aware of this precision issue?\n\nNo idea. I might report it.\n\n> does PARI not strive for proven error bounds for functions such as `eint1()`?\n\nI don't think PARI does. However, the errors are quite large (over 30 bits can be wrong), so perhaps that's a bug indeed.",
    "created_at": "2013-11-09T14:26:56Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232317",
    "user": "https://github.com/jdemeyer"
}
```

<a id='comment:26'></a>
Replying to [pbruin](#comment%3A25):
> Are the PARI developers aware of this precision issue?

No idea. I might report it.

> does PARI not strive for proven error bounds for functions such as `eint1()`?

I don't think PARI does. However, the errors are quite large (over 30 bits can be wrong), so perhaps that's a bug indeed.



---

archive/issue_events_050998.json:
```json
{
    "actor": "https://github.com/jdemeyer",
    "created_at": "2013-11-09T14:26:56Z",
    "event": "milestoned",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "milestone": "sage-pending",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sagetest/issues/15299#event-50998"
}
```



---

archive/issue_comments_232318.json:
```json
{
    "body": "**Changing upstream** from \"N/A\" to \"Fixed upstream, but not in a stable release.\".",
    "created_at": "2013-11-09T23:09:47Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232318",
    "user": "https://github.com/jdemeyer"
}
```

**Changing upstream** from "N/A" to "Fixed upstream, but not in a stable release.".



---

archive/issue_comments_232319.json:
```json
{
    "body": "**Description changed:**\n``````diff\n--- \n+++ \n@@ -16,3 +16,5 @@\n (-4.32787398660869448751904675450772492666840247314688171540527473331725818170217268435223462033366791557160872926179439894639315476270837428785657638252738603056742447337636326343956370276624493916496382120766160023620812331280787034239648552009947468067829864968026720015203778821069593806584e-277,\n  1.82478252137476307223140369768561190028055347258560054363485475966241792307587640145132294203994875344783110100551912347495775160520204557245032474939095251969168953786545612090565728262067746413119194690260652692254781091147749697957445424152473292233020112755190503925812425294821095313979e-270)\n ```\n+\n+While working on this, we found an upstream PARI bug: the precision for `exponential_integal_1()` was not as good as it could be.\n``````\n",
    "created_at": "2013-11-09T23:09:47Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232319",
    "user": "https://github.com/jdemeyer"
}
```

**Description changed:**
``````diff
--- 
+++ 
@@ -16,3 +16,5 @@
 (-4.32787398660869448751904675450772492666840247314688171540527473331725818170217268435223462033366791557160872926179439894639315476270837428785657638252738603056742447337636326343956370276624493916496382120766160023620812331280787034239648552009947468067829864968026720015203778821069593806584e-277,
  1.82478252137476307223140369768561190028055347258560054363485475966241792307587640145132294203994875344783110100551912347495775160520204557245032474939095251969168953786545612090565728262067746413119194690260652692254781091147749697957445424152473292233020112755190503925812425294821095313979e-270)
 ```
+
+While working on this, we found an upstream PARI bug: the precision for `exponential_integal_1()` was not as good as it could be.
``````




---

archive/issue_comments_232320.json:
```json
{
    "body": "<a id='comment:27'></a>\nReported the precision issue, they fixed it. There is supposed to be an absolute error bound (not relative), but I don't know what the bound is...",
    "created_at": "2013-11-09T23:09:47Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232320",
    "user": "https://github.com/jdemeyer"
}
```

<a id='comment:27'></a>
Reported the precision issue, they fixed it. There is supposed to be an absolute error bound (not relative), but I don't know what the bound is...



---

archive/issue_comments_232321.json:
```json
{
    "body": "**Changing dependencies** from \"#15337\" to \"#15337, #15402\".",
    "created_at": "2013-11-12T23:47:36Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232321",
    "user": "https://github.com/jdemeyer"
}
```

**Changing dependencies** from "#15337" to "#15337, #15402".



---

archive/issue_comments_232322.json:
```json
{
    "body": "<a id='comment:28'></a>\nMoved part of the patch to #15402.",
    "created_at": "2013-11-12T23:47:36Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232322",
    "user": "https://github.com/jdemeyer"
}
```

<a id='comment:28'></a>
Moved part of the patch to #15402.



---

archive/attachments_020371.json:
```json
{
    "asset_content_type": "application/octet-stream",
    "asset_name": "15299_lseries_prec.patch",
    "asset_url": "tarball://root/attachments/some-uuid/ticket15299/15299_lseries_prec.patch",
    "created_at": "2013-11-13T16:44:43Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "attachment",
    "url": "https://github.com/assets/some-id/some-uuid.patch",
    "user": "https://github.com/jdemeyer"
}
```



---

archive/issue_comments_232323.json:
```json
{
    "body": "<a id='comment:29'></a>\nChanged error bounds because of #15402, needs review.",
    "created_at": "2013-11-13T16:44:43Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232323",
    "user": "https://github.com/jdemeyer"
}
```

<a id='comment:29'></a>
Changed error bounds because of #15402, needs review.



---

archive/issue_comments_232324.json:
```json
{
    "body": "**Changing status** from positive_review to needs_review.",
    "created_at": "2013-11-13T16:44:43Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232324",
    "user": "https://github.com/jdemeyer"
}
```

**Changing status** from positive_review to needs_review.



---

archive/issue_comments_232325.json:
```json
{
    "body": "**Changing status** from needs_review to positive_review.",
    "created_at": "2013-11-19T18:20:04Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232325",
    "user": "https://github.com/pjbruin"
}
```

**Changing status** from needs_review to positive_review.



---

archive/issue_comments_232326.json:
```json
{
    "body": "<a id='comment:30'></a>\nLooks even better than before, the precision is now much better under control thanks to #15402, and the remaining \"arbitrary\" precision increase is clearly motivated.\n\nAs in #15402, just a trivial review patch to refer to a section instead of a page number in Cohen's book.",
    "created_at": "2013-11-19T18:20:04Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232326",
    "user": "https://github.com/pjbruin"
}
```

<a id='comment:30'></a>
Looks even better than before, the precision is now much better under control thanks to #15402, and the remaining "arbitrary" precision increase is clearly motivated.

As in #15402, just a trivial review patch to refer to a section instead of a page number in Cohen's book.



---

archive/attachments_020372.json:
```json
{
    "asset_content_type": "application/octet-stream",
    "asset_name": "15299_reviewer.patch",
    "asset_url": "tarball://root/attachments/some-uuid/ticket15299/15299_reviewer.patch",
    "created_at": "2013-11-19T18:21:41Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "attachment",
    "url": "https://github.com/assets/some-id/some-uuid.patch",
    "user": "https://github.com/pjbruin"
}
```



---

archive/issue_comments_232327.json:
```json
{
    "body": "replace page number by section number in Cohen reference",
    "created_at": "2013-11-19T18:21:41Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232327",
    "user": "https://github.com/pjbruin"
}
```

replace page number by section number in Cohen reference



---

archive/issue_comments_232328.json:
```json
{
    "body": "**Description changed:**\n``````diff\n--- \n+++ \n@@ -18,3 +18,6 @@\n ```\n \n While working on this, we found an upstream PARI bug: the precision for `exponential_integal_1()` was not as good as it could be.\n+\n+Apply: [attachment:15299_lseries_prec.patch], [attachment:15299_reviewer.patch]\n+\n``````\n",
    "created_at": "2013-11-19T18:22:41Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232328",
    "user": "https://github.com/pjbruin"
}
```

**Description changed:**
``````diff
--- 
+++ 
@@ -18,3 +18,6 @@
 ```
 
 While working on this, we found an upstream PARI bug: the precision for `exponential_integal_1()` was not as good as it could be.
+
+Apply: [attachment:15299_lseries_prec.patch], [attachment:15299_reviewer.patch]
+
``````




---

archive/issue_events_050999.json:
```json
{
    "actor": "https://github.com/jdemeyer",
    "created_at": "2013-11-22T15:50:22Z",
    "event": "demilestoned",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "milestone": "sage-pending",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sagetest/issues/15299#event-50999"
}
```



---

archive/issue_events_051000.json:
```json
{
    "actor": "https://github.com/jdemeyer",
    "created_at": "2013-11-22T15:50:22Z",
    "event": "milestoned",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "milestone": "sage-5.13",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sagetest/issues/15299#event-51000"
}
```



---

archive/issue_comments_232329.json:
```json
{
    "body": "**Merged:** sage-5.13.beta4",
    "created_at": "2013-11-24T17:26:13Z",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/15299#issuecomment-232329",
    "user": "https://github.com/jdemeyer"
}
```

**Merged:** sage-5.13.beta4



---

archive/issue_events_051001.json:
```json
{
    "actor": "https://github.com/jdemeyer",
    "created_at": "2013-11-24T17:26:13Z",
    "event": "closed",
    "issue": "https://github.com/sagemath/sagetest/issues/15299",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sagetest/issues/15299#event-51001"
}
```
