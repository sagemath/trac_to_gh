# Issue 15069: Make `MonoDictEraser` and `TripleDictEraser` safe against "recursion depth exceeded"

archive/issues_014832.json:
```json
{
    "body": "The following happens both with Sage's `MonoDict` and with Python's `weakref.WeakKeyDictionary`:\n\n```\nfrom sage.structure.coerce_dict import MonoDict\nM = MonoDict(11)\n\nclass A: pass\na = A()\nprev = a\n\nfor i in range(1000):\n    newA = A()\n    M[prev] = newA\n    prev = newA\n\nlen(M)\ndel a\nException RuntimeError: 'maximum recursion depth exceeded while calling a Python object' in <sage.structure.coerce_dict.MonoDictEraser object at 0x5a13788> ignored\n```\nReplace `M = MonoDict(11)` by `M = weakref.WeakKeyDictionary()`, and you get essentially the same error:\n\n```\nsage: del a\nException RuntimeError: 'maximum recursion depth exceeded while calling a Python object' in <function remove at 0x5f9d578> ignored\n```\n\nHowever, a `weakref.WeakValueDictionary` seems safe:\n\n```\nsage: class A: pass\nsage: M = weakref.WeakValueDictionary()\nsage: a = A()\n....: prev = a\n....: for i in range(1000):\n....:     newA = A()\n....:     M[newA] = prev\n....:     prev = newA\n....:     \nsage: len(M)\n1000\nsage: del a\nsage: len(M)\n0\n```\neven though the recursive deletion of dictionary items seems similar.\n\nAim of this ticket: Make it so that the erasers of `MonoDict` and `TripleDict` are not recursively called and thus the dreaded 'maximum recursion depth exceeded ... ignored' finally vanishes.\n\n**CC:**  @nthiery @nbruin @vbraun\n\n**Reviewer:** Volker Braun\n\n**Author:** Simon King\n\n**Merged:** sage-5.12.beta4\n\nIssue created by migration from https://trac.sagemath.org/ticket/15069\n\n",
    "closed_at": "2013-08-28T06:55:06Z",
    "created_at": "2013-08-20T20:37:57Z",
    "labels": [
        "component: performance",
        "bug"
    ],
    "milestone": "https://github.com/sagemath/sage/milestones/sage-5.12",
    "title": "Make `MonoDictEraser` and `TripleDictEraser` safe against \"recursion depth exceeded\"",
    "type": "issue",
    "url": "https://github.com/sagemath/sage/issues/15069",
    "user": "https://github.com/simon-king-jena"
}
```
The following happens both with Sage's `MonoDict` and with Python's `weakref.WeakKeyDictionary`:

```
from sage.structure.coerce_dict import MonoDict
M = MonoDict(11)

class A: pass
a = A()
prev = a

for i in range(1000):
    newA = A()
    M[prev] = newA
    prev = newA

len(M)
del a
Exception RuntimeError: 'maximum recursion depth exceeded while calling a Python object' in <sage.structure.coerce_dict.MonoDictEraser object at 0x5a13788> ignored
```
Replace `M = MonoDict(11)` by `M = weakref.WeakKeyDictionary()`, and you get essentially the same error:

```
sage: del a
Exception RuntimeError: 'maximum recursion depth exceeded while calling a Python object' in <function remove at 0x5f9d578> ignored
```

However, a `weakref.WeakValueDictionary` seems safe:

```
sage: class A: pass
sage: M = weakref.WeakValueDictionary()
sage: a = A()
....: prev = a
....: for i in range(1000):
....:     newA = A()
....:     M[newA] = prev
....:     prev = newA
....:     
sage: len(M)
1000
sage: del a
sage: len(M)
0
```
even though the recursive deletion of dictionary items seems similar.

Aim of this ticket: Make it so that the erasers of `MonoDict` and `TripleDict` are not recursively called and thus the dreaded 'maximum recursion depth exceeded ... ignored' finally vanishes.

**CC:**  @nthiery @nbruin @vbraun

**Reviewer:** Volker Braun

**Author:** Simon King

**Merged:** sage-5.12.beta4

Issue created by migration from https://trac.sagemath.org/ticket/15069





---

archive/issue_comments_187489.json:
```json
{
    "body": "<a id='comment:1'></a>\nComments 97--102 at #10963 provide some ideas how to solve the problem.\n\nActually I originally thought that the solution is easy: When the eraser of a `MonoDict` key is called, the to-be-deleted value shall be assigned to a temporary variable and thus be prevented from being deleted while the corresponding items from the bucket of the `MonoDict` are deleted; the value can only be deleted (causing a new invocation of the eraser) when the original call to the eraser is done and the temporary variable vanishes.\n\nInserting print statements shows that in unpatched Sage the eraser calls are nested, which explains the \"recursion depth exceeded\". And in fact, the trick with the temporary variable has the effect that the eraser calls are now neatly ordered and not nested. And now comes the punch-line: The \"recursion depth exceeded\" error does *not* vanish!!!\n\nThe comments at #10963 seem to show that the error behaves different if the class A in the example from the ticket description is a Python or a Cython class. But there is a recursion depth problem in either case.",
    "created_at": "2013-08-20T20:46:24Z",
    "issue": "https://github.com/sagemath/sage/issues/15069",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/15069#issuecomment-187489",
    "user": "https://github.com/simon-king-jena"
}
```

<a id='comment:1'></a>
Comments 97--102 at #10963 provide some ideas how to solve the problem.

Actually I originally thought that the solution is easy: When the eraser of a `MonoDict` key is called, the to-be-deleted value shall be assigned to a temporary variable and thus be prevented from being deleted while the corresponding items from the bucket of the `MonoDict` are deleted; the value can only be deleted (causing a new invocation of the eraser) when the original call to the eraser is done and the temporary variable vanishes.

Inserting print statements shows that in unpatched Sage the eraser calls are nested, which explains the "recursion depth exceeded". And in fact, the trick with the temporary variable has the effect that the eraser calls are now neatly ordered and not nested. And now comes the punch-line: The "recursion depth exceeded" error does *not* vanish!!!

The comments at #10963 seem to show that the error behaves different if the class A in the example from the ticket description is a Python or a Cython class. But there is a recursion depth problem in either case.



---

archive/issue_comments_187490.json:
```json
{
    "body": "<a id='comment:2'></a>\nDefining\n\n```\nclass A:                  \n    def __del__(self):\n        print \"__del__\",id(self)\n```\nand keeping track of the order in which the elements are created by\n\n```\nL = []\na = A()\nprev = a\nfor i in range(1000):\n    L.append(id(prev))\n    newA = A()\n    M[prev] = newA\n    prev = newA\ndel a\n```\nI see that the n-th element created (the first one is `a`) is the \"last but n\"-th element for which `__del__` is called. This comes as a surprise. One should think that `del a` first makes `a` disappear, which then triggers a call to the \"eraser\" callback, which then makes M[a] disappear, which triggers the next \"eraser\" callback.",
    "created_at": "2013-08-20T21:34:51Z",
    "issue": "https://github.com/sagemath/sage/issues/15069",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/15069#issuecomment-187490",
    "user": "https://github.com/simon-king-jena"
}
```

<a id='comment:2'></a>
Defining

```
class A:                  
    def __del__(self):
        print "__del__",id(self)
```
and keeping track of the order in which the elements are created by

```
L = []
a = A()
prev = a
for i in range(1000):
    L.append(id(prev))
    newA = A()
    M[prev] = newA
    prev = newA
del a
```
I see that the n-th element created (the first one is `a`) is the "last but n"-th element for which `__del__` is called. This comes as a surprise. One should think that `del a` first makes `a` disappear, which then triggers a call to the "eraser" callback, which then makes M[a] disappear, which triggers the next "eraser" callback.



---

archive/issue_comments_187491.json:
```json
{
    "body": "<a id='comment:3'></a>\nReplying to [@simon-king-jena](#comment%3A2):\n> I see that the n-th element created (the first one is `a`) is the \"last but n\"-th element for which `__del__` is called. This comes as a surprise.\n\nOr not? The weakref module says:\n\n Weak references to an object are cleared before the object's `__del__()` is called, to ensure that the weak reference callback (if any) finds the object still alive.\n\nHm. I understand that `a.__del__()` is executed only after the callback of the weak reference to `a` has finished. But by print statements I found that the callback for `a` is done before the callback for `M[a]` is invoked! So, why is `a.__del__()` not executed directly after the first callback?",
    "created_at": "2013-08-20T21:44:30Z",
    "issue": "https://github.com/sagemath/sage/issues/15069",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/15069#issuecomment-187491",
    "user": "https://github.com/simon-king-jena"
}
```

<a id='comment:3'></a>
Replying to [@simon-king-jena](#comment%3A2):
> I see that the n-th element created (the first one is `a`) is the "last but n"-th element for which `__del__` is called. This comes as a surprise.

Or not? The weakref module says:

 Weak references to an object are cleared before the object's `__del__()` is called, to ensure that the weak reference callback (if any) finds the object still alive.

Hm. I understand that `a.__del__()` is executed only after the callback of the weak reference to `a` has finished. But by print statements I found that the callback for `a` is done before the callback for `M[a]` is invoked! So, why is `a.__del__()` not executed directly after the first callback?



---

archive/issue_comments_187492.json:
```json
{
    "body": "<a id='comment:4'></a>\nIt seems that it is not enough to keep a reference to the value of the key-value pair being deleted by the eraser---but if the eraser *returns* the value, then I see the recursion depth error disappear. Hence, with this patch\n\n```diff\ndiff --git a/sage/structure/coerce_dict.pyx b/sage/structure/coerce_dict.pyx\n--- a/sage/structure/coerce_dict.pyx\n+++ b/sage/structure/coerce_dict.pyx\n@@ -187,14 +187,17 @@\n         h,offset = r.key\n         cdef list bucket = <object>PyList_GET_ITEM(buckets, (<size_t>h) % PyList_GET_SIZE(buckets))\n         cdef Py_ssize_t i\n+        cdef object val\n         for i from 0 <= i < PyList_GET_SIZE(bucket) by 3:\n             if PyInt_AsSsize_t(PyList_GET_ITEM(bucket,i))==h:\n                 if PyList_GET_ITEM(bucket,i+offset)==<void *>r:\n+                    val = <object>PyList_GET_ITEM(bucket,i+2)\n                     del bucket[i:i+3]\n                     D._size -= 1\n                     break\n                 else:\n                     break\n+        return val\n \n```\nseems to work. Doing tests now...",
    "created_at": "2013-08-20T22:07:27Z",
    "issue": "https://github.com/sagemath/sage/issues/15069",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/15069#issuecomment-187492",
    "user": "https://github.com/simon-king-jena"
}
```

<a id='comment:4'></a>
It seems that it is not enough to keep a reference to the value of the key-value pair being deleted by the eraser---but if the eraser *returns* the value, then I see the recursion depth error disappear. Hence, with this patch

```diff
diff --git a/sage/structure/coerce_dict.pyx b/sage/structure/coerce_dict.pyx
--- a/sage/structure/coerce_dict.pyx
+++ b/sage/structure/coerce_dict.pyx
@@ -187,14 +187,17 @@
         h,offset = r.key
         cdef list bucket = <object>PyList_GET_ITEM(buckets, (<size_t>h) % PyList_GET_SIZE(buckets))
         cdef Py_ssize_t i
+        cdef object val
         for i from 0 <= i < PyList_GET_SIZE(bucket) by 3:
             if PyInt_AsSsize_t(PyList_GET_ITEM(bucket,i))==h:
                 if PyList_GET_ITEM(bucket,i+offset)==<void *>r:
+                    val = <object>PyList_GET_ITEM(bucket,i+2)
                     del bucket[i:i+3]
                     D._size -= 1
                     break
                 else:
                     break
+        return val
 
```
seems to work. Doing tests now...



---

archive/issue_comments_187493.json:
```json
{
    "body": "**Author:** Simon King",
    "created_at": "2013-08-20T23:48:29Z",
    "issue": "https://github.com/sagemath/sage/issues/15069",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/15069#issuecomment-187493",
    "user": "https://github.com/simon-king-jena"
}
```

**Author:** Simon King



---

archive/attachments_020862.json:
```json
{
    "asset_content_type": "application/octet-stream",
    "asset_name": "trac15069-recursion_safe_callback.patch",
    "asset_url": "tarball://root/attachments/ticket15069/trac15069-recursion_safe_callback.patch",
    "created_at": "2013-08-20T23:48:29Z",
    "issue": "https://github.com/sagemath/sage/issues/15069",
    "type": "attachment",
    "url": "https://github.com/sagemath/sage/files/ticket15069/trac15069-recursion_safe_callback.patch",
    "user": "https://github.com/simon-king-jena"
}
```



---

archive/issue_comments_187494.json:
```json
{
    "body": "<a id='comment:5'></a>\n**Attachment:** [trac15069-recursion_safe_callback.patch](https://github.com/sagemath/sage/files/ticket15069/trac15069-recursion_safe_callback.patch)\n\nWith the patch that I have attached, the \"recursion depth exceeded\" problem seems to vanish. Let's see if the full test suite passes.",
    "created_at": "2013-08-20T23:48:29Z",
    "issue": "https://github.com/sagemath/sage/issues/15069",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/15069#issuecomment-187494",
    "user": "https://github.com/simon-king-jena"
}
```

<a id='comment:5'></a>
**Attachment:** [trac15069-recursion_safe_callback.patch](https://github.com/sagemath/sage/files/ticket15069/trac15069-recursion_safe_callback.patch)

With the patch that I have attached, the "recursion depth exceeded" problem seems to vanish. Let's see if the full test suite passes.



---

archive/issue_comments_187495.json:
```json
{
    "body": "<a id='comment:6'></a>\nThe tests pass for me. Needs review, then!",
    "created_at": "2013-08-21T07:53:09Z",
    "issue": "https://github.com/sagemath/sage/issues/15069",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/15069#issuecomment-187495",
    "user": "https://github.com/simon-king-jena"
}
```

<a id='comment:6'></a>
The tests pass for me. Needs review, then!



---

archive/issue_events_132094.json:
```json
{
    "actor": "https://github.com/simon-king-jena",
    "created_at": "2013-08-21T07:53:09Z",
    "event": "labeled",
    "issue": "https://github.com/sagemath/sage/issues/15069",
    "label": "needs review",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sage/issues/15069#event-132094"
}
```



---

archive/issue_comments_187496.json:
```json
{
    "body": "<a id='comment:7'></a>\nI don't think Python makes any guarantees that this is safe. The issue is precisely where the object is deallocated. As you noted, a local variable doesn't cut it as it gets destroyed while we are still in the \"remove' function frame. A return value apparently works, but that is just an implementation detail of CPython. A different Python version might very well destroy returned-but-discarded values while still in the function frame.\n\nIts still better than before, so if you want to run with this workaround then that is fine with me.",
    "created_at": "2013-08-21T09:41:02Z",
    "issue": "https://github.com/sagemath/sage/issues/15069",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/15069#issuecomment-187496",
    "user": "https://github.com/vbraun"
}
```

<a id='comment:7'></a>
I don't think Python makes any guarantees that this is safe. The issue is precisely where the object is deallocated. As you noted, a local variable doesn't cut it as it gets destroyed while we are still in the "remove' function frame. A return value apparently works, but that is just an implementation detail of CPython. A different Python version might very well destroy returned-but-discarded values while still in the function frame.

Its still better than before, so if you want to run with this workaround then that is fine with me.



---

archive/issue_comments_187497.json:
```json
{
    "body": "<a id='comment:8'></a>\nReplying to [@vbraun](#comment%3A7):\n> I don't think Python makes any guarantees that this is safe. The issue is precisely where the object is deallocated. As you noted, a local variable doesn't cut it as it gets destroyed while we are still in the \"remove' function frame. A return value apparently works, but that is just an implementation detail of CPython. A different Python version might very well destroy returned-but-discarded values while still in the function frame.\n> \n> Its still better than before, so if you want to run with this workaround then that is fine with me.\n\nIn the worst case we will get an explicit recursion error, some\nobjects won't get deleted, and the calculation will proceed safely,\nright?\n\nIf yes, then I agree it's not yet perfect but safe enough to go\nahead. Thanks Simon!\n\nI don't feel quite qualified for the fine technical details. Volker,\nif you give me a green light, I am happy finishing the rest of the\nreview.\n\nCheers,\n                            Nicolas",
    "created_at": "2013-08-21T10:22:52Z",
    "issue": "https://github.com/sagemath/sage/issues/15069",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/15069#issuecomment-187497",
    "user": "https://github.com/nthiery"
}
```

<a id='comment:8'></a>
Replying to [@vbraun](#comment%3A7):
> I don't think Python makes any guarantees that this is safe. The issue is precisely where the object is deallocated. As you noted, a local variable doesn't cut it as it gets destroyed while we are still in the "remove' function frame. A return value apparently works, but that is just an implementation detail of CPython. A different Python version might very well destroy returned-but-discarded values while still in the function frame.
> 
> Its still better than before, so if you want to run with this workaround then that is fine with me.

In the worst case we will get an explicit recursion error, some
objects won't get deleted, and the calculation will proceed safely,
right?

If yes, then I agree it's not yet perfect but safe enough to go
ahead. Thanks Simon!

I don't feel quite qualified for the fine technical details. Volker,
if you give me a green light, I am happy finishing the rest of the
review.

Cheers,
                            Nicolas



---

archive/issue_events_132095.json:
```json
{
    "actor": "https://github.com/vbraun",
    "created_at": "2013-08-21T10:46:15Z",
    "event": "unlabeled",
    "issue": "https://github.com/sagemath/sage/issues/15069",
    "label": "needs review",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sage/issues/15069#event-132095"
}
```



---

archive/issue_events_132096.json:
```json
{
    "actor": "https://github.com/vbraun",
    "created_at": "2013-08-21T10:46:15Z",
    "event": "labeled",
    "issue": "https://github.com/sagemath/sage/issues/15069",
    "label": "positive review",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sage/issues/15069#event-132096"
}
```



---

archive/issue_comments_187498.json:
```json
{
    "body": "**Reviewer:** Volker Braun",
    "created_at": "2013-08-21T10:46:15Z",
    "issue": "https://github.com/sagemath/sage/issues/15069",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/15069#issuecomment-187498",
    "user": "https://github.com/vbraun"
}
```

**Reviewer:** Volker Braun



---

archive/issue_comments_187499.json:
```json
{
    "body": "<a id='comment:9'></a>\nAt least we'll have a doctest, so if it breaks in the future we'll be notified ;-)",
    "created_at": "2013-08-21T10:46:15Z",
    "issue": "https://github.com/sagemath/sage/issues/15069",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/15069#issuecomment-187499",
    "user": "https://github.com/vbraun"
}
```

<a id='comment:9'></a>
At least we'll have a doctest, so if it breaks in the future we'll be notified ;-)



---

archive/issue_events_132097.json:
```json
{
    "actor": "https://github.com/jdemeyer",
    "created_at": "2013-08-28T06:55:06Z",
    "event": "unlabeled",
    "issue": "https://github.com/sagemath/sage/issues/15069",
    "label": "positive review",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sage/issues/15069#event-132097"
}
```



---

archive/issue_events_132098.json:
```json
{
    "actor": "https://github.com/jdemeyer",
    "created_at": "2013-08-28T06:55:06Z",
    "event": "closed",
    "issue": "https://github.com/sagemath/sage/issues/15069",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sage/issues/15069#event-132098"
}
```



---

archive/issue_comments_187500.json:
```json
{
    "body": "**Merged:** sage-5.12.beta4",
    "created_at": "2013-08-28T06:55:06Z",
    "issue": "https://github.com/sagemath/sage/issues/15069",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/15069#issuecomment-187500",
    "user": "https://github.com/jdemeyer"
}
```

**Merged:** sage-5.12.beta4
