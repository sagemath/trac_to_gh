# Issue 31283: refresh similarity class

Issue created by migration from https://trac.sagemath.org/ticket/31520

Original creator: chapoton

Original creation time: 2021-03-19 10:18:54

CC:  slelievre

using autopep8 to cleanup

and make the long time doctest much shorter


---

Comment by chapoton created at 2021-03-19 10:19:21

Changing status from new to needs_review.


---

Comment by chapoton created at 2021-03-19 10:19:21

New commits:


---

Comment by slelievre created at 2021-03-19 23:17:35

Good improvements.

Optional further steps, but feel free to consider them out of scope here.

Reindex to clarify and avoid subtractions:

```diff
-    return prod(1 - q**(-i - 1) for i in range(n))
+    return prod(1 - q**i for i in range(-n, 0))
```


Use iterator rather than list for product:

```diff
-    return q**centralizer_algebra_dim(la)*prod([fq(m, q=q) for m in la.to_exp()])
+    return q**centralizer_algebra_dim(la)*prod(fq(m, q=q) for m in la.to_exp())
```

or maybe even use product with starting point:

```diff
-    return q**centralizer_algebra_dim(la)*prod([fq(m, q=q) for m in la.to_exp()])
+    return prod((fq(m, q=q) for m in la.to_exp()), q**centralizer_algebra_dim(la))
```


Use parentheses instead of end-of-line backslashes:

```diff
-        return isinstance(other, PrimarySimilarityClassType) and \
-            self.degree() == other.degree() and \
-            self.partition() == other.partition()
+        return (isinstance(other, PrimarySimilarityClassType)
+                and self.degree() == other.degree()
+                and self.partition() == other.partition())
```


Use iterator rather than list for products:

```diff
-        return prod([PT.centralizer_group_card(q=q) for PT in self])
+        return prod(PT.centralizer_group_card(q=q) for PT in self)
```



```diff
-        numerator = prod([prod([primitives(d+1, invertible=invertible, q=q)-i for i in range(list_of_degrees.count(d+1))]) for d in range(maximum_degree)])
+        numerator = prod(prod(primitives(d+1, invertible=invertible, q=q) - i
+                              for i in range(list_of_degrees.count(d + 1)))
+                         for d in range(maximum_degree))
```


In that last case, would a double comprehension be faster than a product of products?

```diff
-        numerator = prod([prod([primitives(d+1, invertible=invertible, q=q)-i for i in range(list_of_degrees.count(d+1))]) for d in range(maximum_degree)])
+        numerator = prod(primitives(d + 1, invertible=invertible, q=q) - i
+                         for d in range(maximum_degree)
+                         for i in range(list_of_degrees.count(d + 1)))
```

(or maybe a falling factorial or Pochhammer symbol?)

Iterator vs list for products and sums:

```diff
-        return prod([PT.statistic(func, q=q) for PT in self])
+        return prod(PT.statistic(func, q=q) for PT in self)
```



```diff
-            return sum([tau.statistic(stat, q=q)*tau.number_of_matrices(invertible=invertible, q=q) for tau in self])
+            return sum(tau.statistic(stat, q=q)
+                       * tau.number_of_matrices(invertible=invertible, q=q)
+                       for tau in self)
```



```diff
-            return sum([tau.statistic(stat, q=q)*tau.number_of_classes(invertible=invertible, q=q) for tau in self])
+            return sum(tau.statistic(stat, q=q)
+                       * tau.number_of_classes(invertible=invertible, q=q)
+                       for tau in self)
```



```diff
-            return sum([tau.statistic(stat, invertible=invertible, q=q) for tau in self])
+            return sum(tau.statistic(stat, invertible=invertible, q=q)
+                       for tau in self)
```


Line break:

```diff
-        yield (tau.centralizer_group_card(q=q), tau.number_of_classes(invertible=invertible, q=q))
+        yield (tau.centralizer_group_card(q=q),
+               tau.number_of_classes(invertible=invertible, q=q))
```


Iterator vs list in sums and products:

```diff
-        return prod([ext_orbits(PT, q=q, selftranspose=selftranspose) for PT in tau])
+        return prod(ext_orbits(PT, q=q, selftranspose=selftranspose)
+                    for PT in tau)
```



```diff
-    return sum([tau.number_of_classes(invertible=invertible, q=q)*ext_orbits(tau, q=q, selftranspose=selftranspose) for tau in SimilarityClassTypes(n)])
+    return sum(tau.number_of_classes(invertible=invertible, q=q)
+               * ext_orbits(tau, q=q, selftranspose=selftranspose)
+               for tau in SimilarityClassTypes(n))
```



```diff
-            size = prod([list(entry)[0] for entry in item])
-            freq = prod([list(entry)[1] for entry in item])
+            size = prod(list(entry)[0] for entry in item)
+            freq = prod(list(entry)[1] for entry in item)
```


Grab pair components at iteration:

```diff
-        for pair in ext_orbit_centralizers(tau, q=q, selftranspose=selftranspose):
-            yield (q**tau.centralizer_algebra_dim()*pair[0], tau.number_of_classes(invertible=invertible, q=q)*pair[1])
+        for a, b in ext_orbit_centralizers(tau, q=q, selftranspose=selftranspose):
+            yield (q**tau.centralizer_algebra_dim()*a,
+                   tau.number_of_classes(invertible=invertible, q=q)*b)
```



---

Comment by chapoton created at 2021-03-20 06:55:59

C'est sur, y a encore du boulot sur ce fichier. J'ai pas trop envie d'y passer plus de temps. L'objectif est surtout d'avoir un doctest plus raisonnable.


---

Comment by slelievre created at 2021-03-20 10:56:54

Changing status from needs_review to positive_review.


---

Comment by slelievre created at 2021-03-20 10:56:54

Alors restons-en l√† pour aujourd'hui.


---

Comment by vbraun created at 2021-03-20 20:54:55

Resolution: fixed
