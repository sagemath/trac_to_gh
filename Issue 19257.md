# Issue 19257: Make finite word method nb_subword_occurences_in much faster

Issue created by migration from Trac.

Original creator: slabbe

Original creation time: 2015-10-28 17:18:50

This computation takes years in Sage, but it can be done in some ms with this ticket:


```
sage: u = words.ThueMorseWord()[:1000] 
sage: w = Word([0,1,0,1])              
sage: w.nb_subword_occurrences_in(u)   
2604124996                             
```



---

Comment by slabbe created at 2015-10-28 17:22:29

Changing status from new to needs_review.


---

Comment by slabbe created at 2015-10-28 17:22:29

New commits:


---

Comment by vdelecroix created at 2015-10-29 12:15:39

Changing status from needs_review to needs_info.


---

Comment by vdelecroix created at 2015-10-29 12:15:39

If I understand correctly `u.binomial(v)` is the same thing as `v.nb_subword_occurrences_in(u)`. Why two distinct terminologies? Words currently have `is_prefix` and `has_prefix` which I found much clearer.

With your function, you are creating some `n x n` matrices where `n` is the length of the small word `v`. Could you check that `u` and `v` are roughyl of the same length (say 12 and 10 or 100 and 90) your new code is still better. In your examples there are only occurrences where `v` is much smaller than `u`.

One drawback in the above case might also be memory usage and complexity of dense matrix multiplication. You might need `n^3` space (for `n` dense matrices of size `n x n`) and if `n` is big, multiplying `n x n` dense matrices is expensive. Using sparse matrices in some corner case might be useful, e.g.

```
sage: W = Words(NN)
sage: v = W(range(100))
sage: u = W(randint(0,99) for _ in range(200))
sage: u.binomial(v)
```

In the above case, I do not expect that the result of `prod(...)` being that much dense. But perhaps I am wrong. Could you test it and if relevant add an argument `sparse` (that would be `False` by default)?

Vincent


---

Comment by git created at 2015-11-01 20:22:16

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by slabbe created at 2015-11-01 20:52:22

That binomial was introduced by Jacques Sakarovitch as the theme of a chapter in the (first?) Lothaire book. It generalizes the binomial since `a<sup>n.binomial(a</sup>k)` is equal to `n.binomial(k)`. Ok, I agree that too many methods is too many. I removed it in the last commit.

I added a new commit allowing easier reviewing and comparison of implementations. I still believe we will need one more commit to clean this up if finally we think that one implementation is useless or if one argument is useless. We will see.

About using sparse matrices. A first remark is that matrices computed are upper triangular. So using sparse will lead eventually to saving half the space at least.

If the size of the alphabet is low, using sparse matrices is about 10 times slower:


```
sage: u = words.ThueMorseWord()[:1000]                       
sage: L = list(u)                                            
sage:                                                        
sage: %time u[:20].nb_subword_occurrences_in(u, sparse=False)
CPU times: user 130 ms, sys: 1.37 ms, total: 131 ms          
Wall time: 131 ms                                            
347151814258896164694010210266438495                         
sage: %time u[:20].nb_subword_occurrences_in(u, sparse=True) 
CPU times: user 979 ms, sys: 5.88 ms, total: 984 ms          
Wall time: 986 ms                                            
347151814258896164694010210266438495                         
```


If the size of alphabet is bigger (computation done with 201x201 matrices): then sparse or not seems about the same too:

```
sage: u = Word(range(200))                     
sage: %time u.nb_subword_occurrences_in(u*u*u, sparse=True) 
CPU times: user 16.1 s, sys: 27.1 ms, total: 16.1 s         
Wall time: 16.2 s                                           
20301                                                       
sage: %time u.nb_subword_occurrences_in(u*u*u, sparse=False)
CPU times: user 16.6 s, sys: 169 ms, total: 16.7 s          
Wall time: 16.7 s                                           
20301                                                       
```


In comparison, here is the longest word (following the previous example construction) the original algorithm can handle in less then 16s:

```
sage: u = Word(range(60))                                           
sage: %time u.nb_subword_occurrences_in(u*u*u, algorithm='original')
CPU times: user 12.1 s, sys: 13 ms, total: 12.1 s                   
Wall time: 12.1 s                                                   
1891
```

I never found an example where the original implementation is better. So, that's why I would suggest to just delete it. Or we like the idea of having two distinct implementations.


---

Comment by slabbe created at 2015-11-01 20:55:00

Changing status from needs_info to needs_review.


---

Comment by vdelecroix created at 2015-11-01 21:46:34

Hola Sebastien,

Here is an example where `original` is much faster

```
sage: u = Word([randint(0,30) for _ in range(600)])
sage: v = Word(range(30))
sage: %time v.nb_subword_occurrences_in(u, algorithm='original')
CPU times: user 4 ms, sys: 0 ns, total: 4 ms
Wall time: 3.16 ms
0
sage: %time v.nb_subword_occurrences_in(u, algorithm='matrices')
CPU times: user 132 ms, sys: 0 ns, total: 132 ms
Wall time: 123 ms
0
```

So we should definitely keep it.

For sparsity of matrices I was a bit wrong. In the situation I presented, there is a big product of sparse matrices (each matrix contains exactly `n+1` ones) but the product itself will *not* be sparse. Hence using sparse matrices might not be the good strategy (depends on how the product is implemented there). From your experiments it seems that we win nothing which is definitely strange theoretically.

Note that the old implementation suffers several problems to be really competitive:
- it is recursive (which is always slow in Python)
- it constructs a lot of prefixes and suffixes of words which is costly (creation of Python objects)

What do you think?

Vincent


---

Comment by vdelecroix created at 2015-11-01 21:46:34

Changing status from needs_review to needs_info.


---

Comment by git created at 2015-11-02 13:41:11

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by slabbe created at 2015-11-02 13:46:30

Replying to [comment:7 vdelecroix]:
> Hola Sebastien,

Hola !! Como esta tu en el Chile ahora!?

> Here is an example where `original` is much faster

How did you come up with this example? I mean what should be the heuristic for when using the recursive or the matrices implementation?

> So we should definitely keep it.

I renamed it `'recursive'`.

> For sparsity of matrices I was a bit wrong. 

Ok. I removed the sparse argument.

> Note that the old implementation suffers several problems 

Yes. I have seen that...

> What do you think?

Ok, let me take a deeper look at it and see if I can remove bad Python uses.


---

Comment by vdelecroix created at 2015-11-03 02:03:42

Replying to [comment:9 slabbe]:
> Replying to [comment:7 vdelecroix]:
> > Hola Sebastien,
> 
> Hola !! Como esta tu en el Chile ahora!?
> 
> > Here is an example where `original` is much faster
> 
> How did you come up with this example? I mean what should be the heuristic for when using the recursive or the matrices implementation?

If the result is 0 then the recursive version is likely to be much faster. Roughly speaking, for matrices the computational time is independent on the size of the result whereas for the recursive version it is proportional to it.

However, the default should definitely be with matrices.

> > So we should definitely keep it.
> 
> I renamed it `'recursive'`.
> 
> > Note that the old implementation suffers several problems 
> 
> Yes. I have seen that...
> 
> > What do you think?
> 
> Ok, let me take a deeper look at it and see if I can remove bad Python uses.

Does not matter so much for the sake of this ticket. You can add a comment somewhere that the code can be improved.


---

Comment by git created at 2015-11-04 08:31:36

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by slabbe created at 2015-11-04 08:36:51

Changing status from needs_info to needs_review.


---

Comment by slabbe created at 2015-11-04 08:36:51

Found a new simple way to code it. But, it turns out to be slower. Did other improvements to the code. Folded the 4 commits into a new public branch. Needs review.
----
New commits:


---

Comment by vdelecroix created at 2015-11-04 12:17:44

All right. It is possible to compute the matrices *without* computing them ;-) See the attached branch.

Vincent
----
New commits:


---

Comment by slabbe created at 2015-11-05 09:22:40

Changing status from needs_review to needs_work.


---

Comment by slabbe created at 2015-11-05 09:22:40

For reviewing purposes, I updated my branch with your code as a fourth algorithm.

I found some cases where the matrices algorithm is faster:


```
sage: u = words.ThueMorseWord()[:10000]
sage: v = Word([0,1,0,1])
sage: %time v.nb_subword_occurrences_in(u, 'vincent')
CPU times: user 214 ms, sys: 38.9 ms, total: 253 ms
Wall time: 233 ms
26041662500000
sage: %time v.nb_subword_occurrences_in(u, 'matrices')
CPU times: user 182 ms, sys: 7.84 ms, total: 190 ms
Wall time: 192 ms
26041662500000
```



```
sage: u = words.ThueMorseWord()[:100000]
sage: %time v.nb_subword_occurrences_in(u, 'vincent')
CPU times: user 2.08 s, sys: 64.7 ms, total: 2.15 s
Wall time: 2.13 s
260416666250000000
sage: %time v.nb_subword_occurrences_in(u, 'matrices')
CPU times: user 1.82 s, sys: 86 ms, total: 1.9 s
Wall time: 1.86 s
260416666250000000
```


Why? When is your algorithm faster than the matrix algorithm?

I also found a case where the two algorithms do no return the same answer:


```
sage: v = Word([0,1,0,1,1,0])
sage: %time v.nb_subword_occurrences_in(u, 'matrices')
CPU times: user 2.23 s, sys: 72.7 ms, total: 2.31 s
Wall time: 2.27 s
21700086762157985968744680
sage: %time v.nb_subword_occurrences_in(u, 'vincent')
CPU times: user 719 ms, sys: 49 ms, total: 768 ms
Wall time: 742 ms
21702690928814235968754680L
```


You might want to use defaultdict instead which simplifies both loops:


```python
# record the position of letters in self
from collections import defaultdict
pos = defaultdict(list)
for i,a in enumerate(self):
    pos[a].append(i)

# compute the occurrences of all prefixes of self as subwords in other
occ = [0] * (len(self)+1)
occ[0] = 1
for a in other:
    for i in pos[a]:
       occ[i+1] += occ[i]

# return only the number of occurrences of self
return occ[-1]
```

----
New commits:


---

Comment by vdelecroix created at 2015-11-05 14:16:51

Note that infinite words have a cache. So `iter` is much faster the second time...


---

Comment by vdelecroix created at 2015-11-05 14:18:31

In particular your example where 'vincent' is slower is not an example

```
sage: v = Word([0,1,0,1])
sage: u = words.ThueMorseWord()[:100000]
sage: %time v.nb_subword_occurrences_in(u, 'vincent')
CPU times: user 428 ms, sys: 20 ms, total: 448 ms
Wall time: 410 ms
260416666250000000
sage: %time v.nb_subword_occurrences_in(u, 'vincent')
CPU times: user 148 ms, sys: 40 ms, total: 188 ms
Wall time: 151 ms
260416666250000000
sage: %time v.nb_subword_occurrences_in(u, 'matrices')
CPU times: user 312 ms, sys: 12 ms, total: 324 ms
Wall time: 297 ms
260416666250000000
```

Though, it would be better to make it return Sage integers instead of Python integers.


---

Comment by slabbe created at 2015-11-05 14:43:45

Replying to [comment:15 vdelecroix]:
> Note that infinite words have a cache. So `iter` is much faster the second time...

You are right. I took attention to this earlier this week but not this morning.

So we only need to fix the other issue. Maybe I would keep two implementations : yours and the matrices one. The recursive one, we can delete. And the original loop recursive one too I think.


---

Comment by vdelecroix created at 2015-11-05 14:49:21

Replying to [comment:17 slabbe]:
> Replying to [comment:15 vdelecroix]:
> > Note that infinite words have a cache. So `iter` is much faster the second time...
> 
> You are right. I took attention to this earlier this week but not this morning.
> 
> So we only need to fix the other issue. Maybe I would keep two implementations : yours and the matrices one. The recursive one, we can delete. And the original loop recursive one too I think.

Why would you like to keep the matrices? I am just applying matrices implicitely in mine. These are exactly the same computations except that I am just applying matrices to vectors instead of multiplying matrices together.


---

Comment by slabbe created at 2015-11-05 15:32:10

If you can change the code and prove that it always gives the same result as the matrices algorithm, then I agree. For now, it does not.


---

Comment by vdelecroix created at 2015-11-05 15:34:15

What is your example where it does not?


---

Comment by vdelecroix created at 2015-11-05 15:42:36

New commits:


---

Comment by vdelecroix created at 2015-11-05 15:43:56

The code is right now!


---

Comment by slabbe created at 2015-11-05 19:45:49

> What is your example where it does not?

The one in comment:14. But, it should be okay now that you use ZZ.one() and ZZ.zero(). I did not check yet.


---

Comment by slabbe created at 2015-11-05 19:55:05

5 quick comments after looking at the code:

 - I suggest to replace `'vincent'` by `'vector'`.
 - I suggest to change the default argument to `'vector'`.
 - The doctest testing all algorithms should test all algorithms.
 - How many of the four algorithms do we want to keep?
 - If only one, then none of the above comments applies.
 - Maybe better to import defaultdict inside the method?


---

Comment by vdelecroix created at 2015-11-05 20:22:27

I suggest to keep only one algorithm (now that it is right). The problem did not come from `0` vs `ZZ.zero()` but from the fact that you need the list to be sorted the other way around (I introduced a `list.reverse()`) in my commit).

It takes time to import inside a method, I would prefer to not do it. But it is possible to import the module `collections` and not `defaultdict`.

There is an interesant thing with this simple algorithm, it actually computes the number of occurrences of all prefixes of `u` in all prefixes of `v`! But we currently ignore them. People might be interested in more information... but they can also implement that by themselves.


---

Comment by slabbe created at 2015-11-05 21:20:54

Replying to [comment:25 vdelecroix]:
> I suggest to keep only one algorithm (now that it is right). 

I agree.

> The problem did not come from `0` vs `ZZ.zero()` but from the fact that you need the list to be sorted the other way around (I introduced a `list.reverse()`) in my commit).

Ok, I see! The doctest was fine because 0110 is a palindrome or something? Maybe we should change that first doctest then...

> It takes time to import inside a method, I would prefer to not do it. But it is possible to import the module `collections` and not `defaultdict`.

OK.

> There is an interesant thing with this simple algorithm, it actually computes the number of occurrences of all prefixes of `u` in all prefixes of `v`! But we currently ignore them. People might be interested in more information... but they can also implement that by themselves.

Maybe, we can add a `..NOTE::` about it.


---

Comment by vdelecroix created at 2015-11-05 23:32:15

Changing status from needs_work to needs_review.


---

Comment by vdelecroix created at 2015-11-05 23:32:15

New commits:


---

Comment by slabbe created at 2015-11-07 13:21:29

Sorry for the last two days, I needed to update my old sage installation on my personnal computer. I tested all of the tests we posted on the ticket. Your implementation is clearly efficient.

I changed the `.. NOTE::` and posted that on `public/19494` overwritting what was there.

If you agreee with my last commit, then this is a positive review.
----
New commits:


---

Comment by slabbe created at 2015-11-07 13:24:54

To justify my commit: I felt that `one can extract much more information from it rather than only the total number of occurrences` was repeating the information of the first sentence of the note.


---

Comment by vdelecroix created at 2015-11-07 13:45:52

Good! It is much clearer now.

By the way, I did remove you from the authors of the ticket and it is not very fair...


---

Comment by slabbe created at 2015-11-07 21:07:38

Replying to [comment:30 vdelecroix]:
> Good! It is much clearer now.

Ok, so I change it to positive review.

> By the way, I did remove you from the authors of the ticket and it is not very fair...

You are the author of the best implementation. So, I understood why you changed it. I'm fine either way. Let's say I was the author of the idea of improving the method and some lines of doc!?


---

Comment by slabbe created at 2015-11-07 21:07:38

Changing status from needs_review to positive_review.


---

Comment by vbraun created at 2015-11-08 15:56:04

Resolution: fixed
