# Issue 14732: Longest common subword

Issue created by migration from Trac.

Original creator: ncohen

Original creation time: 2013-07-25 09:59:51

CC:  slabbe vdelecroix

Looks like this was missing. It's a pity that there is no .pyx file for words, though `:-)`

Nathann


---

Comment by ncohen created at 2013-07-25 10:00:20

Changing status from new to needs_review.


---

Attachment


---

Comment by hthomas created at 2013-08-08 20:21:07

Hi Nathann!

Review patch uploaded.  I don't think it will be controversial.  I removed one line of code which did nothing useful.  (Please confirm.)

The commit message on the original patch should be, um, more descriptive.  Other than that, I am ready to give it a positive review if you approve my changes.  

What a nice algorithm!

The same approach could be used to find all that longest common subwords.  Do you think that would be useful?  To me it seems at least as natural.  

cheers,

Hugh


---

Comment by hthomas created at 2013-08-08 20:21:07

Changing status from needs_review to needs_work.


---

Attachment


---

Comment by ncohen created at 2013-08-09 08:22:17

Helloooooooooooo !!

> Review patch uploaded.  I don't think it will be controversial.
+1

> I removed one line of code which did nothing useful.  (Please confirm.)
+1 

> The commit message on the original patch should be, um, more descriptive.

Right. Fixed.

> Other than that, I am ready to give it a positive review if you approve my changes.
+1

> What a nice algorithm!
> 
> The same approach could be used to find all that longest common subwords.  Do you think that would be useful?  To me it seems at least as natural.  

Hmmmm. Well,  the same algorithm with the same complexity can return the number of longest common subwords too. In order to return all longest subwords, though, one would have to keep track of all `l[i,j]`, and not just `l[i,j]` and `l[i-1,j]`.

Nathann


---

Comment by ncohen created at 2013-08-09 08:22:17

Changing status from needs_work to needs_review.


---

Comment by hthomas created at 2013-08-09 11:51:09

Replying to [comment:3 ncohen]:
> 
> Hmmmm. Well,  the same algorithm with the same complexity can return the number of longest common subwords too. In order to return all longest subwords, though, one would have to keep track of all `l[i,j]`, and not just `l[i,j]` and `l[i-1,j]`.

What I was thinking of was that l[i,j] would store a list of the longest subwords of self[:i],other[:j].  Then at each step, you merge the three lists l[i,j-1], l[i-1,j], and l[i-1,j-1] with self[i] tacked onto the end of each one if self[i]==other[j], and remove the items that aren't as long as the maximum.  

This wouldn't have the same complexity as the algorithm you implemented, but that seems somehow not unreasonable, since you're asking for more output.  Is this inefficient?


---

Comment by hthomas created at 2013-08-09 11:53:12

Changing status from needs_review to positive_review.


---

Comment by ncohen created at 2013-08-09 11:56:38

Hellooooooooo !!

> What I was thinking of was that l[i,j] would store a list of the longest subwords of self[:i],other[:j].  Then at each step, you merge the three lists l[i,j-1], l[i-1,j], and l[i-1,j-1] with self[i] tacked onto the end of each one if self[i]==other[j], and remove the items that aren't as long as the maximum.  
> 
> This wouldn't have the same complexity as the algorithm you implemented, but that seems somehow not unreasonable, since you're asking for more output.  Is this inefficient?  

Well it's fine. It's just that it would be slightly better to do the computations twice : at first you only compute (and remember) all values of l[i,j] (i.e. just the size of the longest subword), then in a second pass you can actually build the list of longest subwords, from l[i,j] and recursively to the smaller values of l, only when needed, i.e. when it participates to a word of maximum length.

This way you make sure that you are not building and maintaining very long lists of words which you would throw away later `:-)`

Nathann


---

Comment by ncohen created at 2013-08-09 11:57:01

Oh, and thank for your the review !!!

Nathann


---

Comment by hthomas created at 2013-08-09 12:29:27

Replying to [comment:6 ncohen]:
 > This way you make sure that you are not building and maintaining very long lists of words which you would throw away later `:-)`

Oh, I see!  Thanks very much for the explanation.  

And as regards the review, you are very welcome -- it's fun to review efficient code!

Hugh


---

Comment by jdemeyer created at 2013-08-28 06:53:31

Resolution: fixed


---

Comment by slabbe created at 2013-09-12 15:34:45

Replying to [ticket:14969 ncohen]:
> Looks like this was missing. It's a pity that there is no .pyx file for words, though `:-)`

There is one :

sage/combinat/words/word_datatypes.pyx

Code that goes there will apply only for words on specific data type (like list, tuple, str). If a method exists in the cython file and in the `finite_word.py` file, the cython method is called instead.

I would be curious to know what is the gain... tell me if your test it.
