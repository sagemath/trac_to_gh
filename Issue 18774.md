# Issue 18774: Add Jones representation of braid groups and Jones polynomials of braid closures

Issue created by migration from Trac.

Original creator: fuglede

Original creation time: 2015-08-11 13:19:59

CC:  mmarco amitjamadagni

First off, this is my first ticket here, so please let me know about process related stuff that I missed.

As per [this discussion on sage-devel](https://groups.google.com/forum/#!topic/sage-devel/ByJURRvRgLg), these commits contain methods for Braid and BraidGroup_class to allow for the calculation of the Temperley--Lieb--Jones representations of braid groups. While interesting in their own right, this also allows for a straightforward implementation of the (uncoloured) Jones polynomial of trace closures of braids, also included, which for a fixed number of braid strands is polynomial in the number of crossings. The algorithm uses Kauffman's diagrammatic description of the Temperley--Lieb algebra.

It should be noted that there is some overlap here with [Ticket #17030](http://trac.sagemath.org/ticket/17030) but as discussed on sage-devel, this is not necessarily a problem (although of course any code that is duplicated exactly should be coordinated between that ticket and this one).

One sillily todo is to add my own name (Søren Fuglede Jørgensen) to the list of authors. No matter how I've tried to do this, the building failes; probably due to encoding issues, I would imagine (but simply translating the string to unicode does not solve the issue).

The branch also contains a small bit of code clean-up cf. [GH PR #47](https://github.com/sagemath/sage/pull/47).


---

Comment by git created at 2015-08-12 11:03:22

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2015-08-12 14:01:28

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by vdelecroix created at 2015-08-12 20:08:32

In order to build with utf-8 characters in the source you need to declare the encoding at the very top of the file. Just add as the very first line

```
# -*- coding: utf-8 -*-
```

More information on https://www.python.org/dev/peps/pep-0263/


---

Comment by tscrim created at 2015-08-12 23:48:15

In case nobody has said it yet, welcome to Sage.

I know this isn't yet set to needs review, but some quick comments from a look-over (from my curiosity):

- Could you remove the changes to `diagram_algebras.py`, this will be taken care of in #18720 (which does some large refactoring of the classes)?
- For latex, use single backticks, e.g., ``A + B \neq 5``, instead of dollar signs.
- Make the first sentence for method definitions short and succinct. For example:

```
def foo(x):
    r"""
    Return bar.

    This is where you put a longer explanation. This is a python convention and
    makes it clear what the method does and then has this information for the
    interested user who wants more details.
    """
```

- Also note the `r"""` for the beginning of the docstring, this makes it into "raw" format, where the string gets interpreted as written, whereas when you don't have it, backslash `\` gets interpreted as a special character (ex. `\n` is a newline). For what you have here, this does not appear to be necessary, but I always include it anytime I have latex code for extra safety/my paranoia.
- For `markov_trace`, I would write it like this:

```python
def markov_trace(self, variab='A', ring=IntegerRing()):
    R = LaurentPolynomialRing(ring, variab)
    A = R.gens()[0]
    delta = -A**2 - A**(-2)
    n = self.strands()

    def weighted_trace(b, d):
        return (A**(2*i) - A**(-2*i))/(A**2 - A**(-2)) * b.TL_matrix(d, variab, ring).trace()

    trace = sum(weighted_trace(self, d, variab, ring) for d in range(n+1) if (n+d) % 2 == 0)
    return trace / (-delta)**n
```

- You should try to avoid abbreviations in method names as it makes it slightly harder to detect with tab completion and can expand those out quickly using tab completion.
- For the caching of polynomials, I would have a private method which does the computation in a specific ring with a specific variable, cache that, and have the public method take that output and do a `subs` on the result from the private method. This way you can't cache the "same" polynomial over and over again (and your private methods can call each other knowing what their output will be). For an optimization, the defaults for the public method could be `None` and if they are both `None`, then return immediately the result of the private method.


---

Comment by git created at 2015-08-13 10:53:13

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2015-08-13 11:07:39

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by fuglede created at 2015-08-13 11:09:02

Replying to [comment:4 vdelecroix]:
> In order to build with utf-8 characters in the source you need to declare the encoding at the very top of the file. Just add as the very first line
> {{{
> # -*- coding: utf-8 -*-
> }}}
> More information on https://www.python.org/dev/peps/pep-0263/

Thanks, done!


---

Comment by fuglede created at 2015-08-13 11:22:30

Replying to [comment:5 tscrim]:
> In case nobody has said it yet, welcome to Sage.
> 

Thanks!

> I know this isn't yet set to needs review, but some quick comments from a look-over (from my curiosity):
Thanks for the comments! I'll go through them individually.
> 
> - Could you remove the changes to `diagram_algebras.py`, this will be taken care of in #18720 (which does some large refactoring of the classes)?
Done.
> - For latex, use single backticks, e.g., ``A + B \neq 5``, instead of dollar signs.
Done. This is also an issue in all existing methods in this module though. Moreover, the [developer guide](http://doc.sagemath.org/html/en/developer/coding_basics.html#latex-typesetting) currently allows the use of dollar signs.
> - Make the first sentence for method definitions short and succinct. For example:
> {{{
> def foo(x):
>     r"""
>     Return bar.
> 
>     This is where you put a longer explanation. This is a python convention and
>     makes it clear what the method does and then has this information for the
>     interested user who wants more details.
>     """
> }}}
I made several of them shorter.
> - Also note the `r"""` for the beginning of the docstring, this makes it into "raw" format, where the string gets interpreted as written, whereas when you don't have it, backslash `\` gets interpreted as a special character (ex. `\n` is a newline). For what you have here, this does not appear to be necessary, but I always include it anytime I have latex code for extra safety/my paranoia.
Yep, I checked those before committing. Indeed, `r"""` is not used when not necessary in the existing module documentation either.
> - For `markov_trace`, I would write it like this:
> {{{#!python
> def markov_trace(self, variab='A', ring=IntegerRing()):
>     R = LaurentPolynomialRing(ring, variab)
>     A = R.gens()[0]
>     delta = -A**2 - A**(-2)
>     n = self.strands()
> 
>     def weighted_trace(b, d):
>         return (A**(2*i) - A**(-2*i))/(A**2 - A**(-2)) * b.TL_matrix(d, variab, ring).trace()
> 
>     trace = sum(weighted_trace(self, d, variab, ring) for d in range(n+1) if (n+d) % 2 == 0)
>     return trace / (-delta)**n
> }}}
> - You should try to avoid abbreviations in method names as it makes it slightly harder to detect with tab completion and can expand those out quickly using tab completion.
Makes sense: The logic behind including `qint` as a separate function was to make the expression look both more familiar to those who know the formula, and a bit less clumsy; the abbreviation was mainly there to ensure that the expression would stay within the 79 columns of pep8. Anyway, I changed it to something more or less identical to what you suggest. Possibly worth noting is that if more quantum topology makes its way into sage, this particular method would probably be refactored as a result.

> - For the caching of polynomials, I would have a private method which does the computation in a specific ring with a specific variable, cache that, and have the public method take that output and do a `subs` on the result from the private method. This way you can't cache the "same" polynomial over and over again (and your private methods can call each other knowing what their output will be). For an optimization, the defaults for the public method could be `None` and if they are both `None`, then return immediately the result of the private method.

I'm not sure that I see for which parts of the added code you want to do this: for `Braid.jones_polynomial` in particular, or more generally? Indeed it would seem to me that no matter the answer, the same would have to be done for all existing methods in the module (and as such, doing it through decoration might prove beneficial?) Also, even though I certainly understand the point of what you're saying, I don't think I can come up with a use case where it makes a difference (but my imagination might be largely limited to what I've had to do with the classes myself already).


---

Comment by git created at 2015-08-13 12:55:38

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by tscrim created at 2015-08-13 16:24:57

The biggest thing is `create_TL_rep` (which I would perhaps call `TL_representation` if this is a common abbreviation, otherwise I'd spell it out as `temperley_leib_representation`), and suppose you create it as the default, but then you want it in a different variable name. Now it has to do the computation all over again (and caches both results, creating redundancy). This could come up if someone wants to look at this polynomial over a large range of finite fields.


---

Comment by fuglede created at 2015-08-14 10:35:58

Yeah, looking at it for a collection of different rings certainly makes sense. I don't think I've seen anyone actually consider that, though.

One thing that is common, though, is to not view the entries as elements of the Laurent polynomial ring but rather a quotient thereof (since this is what generalizes to higher genus surfaces in TQFT), so there might be a point in allowing for some freedom in that direction.

It's worth noting, also, that the calculation of the representation on the generators is reasonably fast, compared to actually manipulating the resulting matrices: I know that the point is to save both memory and time, but in my testing, it is significantly faster (roughly a factor of ~20) to calculate the representation in the desired ring to begin with, than it is to calculate it for `IntegerRing` and then use `subs` entry-wise to obtain a matrix with entries in the desired ring.

Finally, I should note that an earlier version didn't actually use the caching decorator. It's included now since it can play a role for braid groups on a large number of strings. Then the number of strings is large, it is the combinatorial part, i.e. the first loop in `create_TL_rep` that takes up most of the time (in my testing, for the braid group on 14 strings, roughly 75% of the time is spent there). Putting together these observations, to accommodate for the use case where one wants to save memory while working with a large number of base rings, it would be sensible to refactor and cache only the first part of the method, reconstructing the actual matrices on every execution. This will, though, slow down what I think is the more common use case of manipulating only the representation over `IntegerRing`, so I'm not a big fan of doing that.


---

Comment by git created at 2015-08-14 10:56:59

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2015-08-14 11:13:19

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by fuglede created at 2015-08-14 13:21:17

I ran a test to match the Jones polynomial values against known values: The values match with 2961 knots with up to 12 crossings from [KnotInfo](http://www.indiana.edu/~knotinfo/) in 69 seconds (and no mismatches were found).


---

Comment by git created at 2015-08-14 13:54:45

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by tscrim created at 2015-08-14 15:42:09

That's why I suggested doing the optimization of just returning the polynomial for the default values (rather than running a useless `subs`). Sometimes taking a slowdown in smaller examples is worth it for the significant speedup in larger examples. Without seeing your timings, I can't tell (I don't have access to Sage right now). However it sounds like refactoring the code and caching only the result of the first loop is best.

For variables/rings, from my experience it is more common to take as input the variable, rather than creating the ring itself in the method (unless there is a default input). See, e.g., `sage.combinat.q_analogues`.

Also a micro-optimization: `if len(forest) == 0:` is slower than `if not forest:`.


---

Comment by fuglede created at 2015-08-14 15:48:46

What I meant was that if we were to cache only the first loop, we would see some slowdown for the default values as well, which we do not if we cache the entire thing.


---

Comment by tscrim created at 2015-08-14 16:11:29

However I could very easily cause things to be doubly/triply cached very easily by having a division somewhere, which typically pushes things into fraction fields. Somewhere I think we have to take a slowdown for more robust code.

Side note: Doing a direct call of the polynomial should be faster than `subs` from looking at the code. However I think we need a better/faster way to simply convert a polynomial from one ring to another.


---

Comment by mmarco created at 2015-08-14 20:15:53

Some timings for conversion between univariate laurent polynomial rings:


```

sage: R.<t> = LaurentPolynomialRing(ZZ)
sage: f = (t^-2+t^2) ^2 + 5*t -1 
sage: f
t^-4 + 1 + 5*t + t^4
sage: S.<a> = LaurentPolynomialRing(IntegerModRing(7))
sage: d = f.dict()
sage: d
{-4: 1, 0: 1, 1: 5, 4: 1}
sage: %time f.subs(t=a)
CPU times: user 9 ms, sys: 1 ms, total: 10 ms
Wall time: 9.29 ms
a^-4 + 1 + 5*a + a^4
sage: %time S(f)
CPU times: user 1 ms, sys: 0 ns, total: 1 ms
Wall time: 1.31 ms
a^-4 + 1 + 5*a + a^4
sage: %time S(d)
CPU times: user 1 ms, sys: 0 ns, total: 1 ms
Wall time: 1.02 ms
a^-4 + 1 + 5*a + a^4
sage: %time S(d)
CPU times: user 1 ms, sys: 0 ns, total: 1 ms
Wall time: 293 µs
a^-4 + 1 + 5*a + a^4
sage: d1 = (f+1).dict()
sage: %time S(d1)
CPU times: user 0 ns, sys: 0 ns, total: 0 ns
Wall time: 211 µs
a^-4 + 2 + 5*a + a^4
sage: f1 = f+1   
sage: %time S(f1)
CPU times: user 0 ns, sys: 0 ns, total: 0 ns
Wall time: 147 µs
a^-4 + 2 + 5*a + a^4

```


Definitely .subs is not a good idea. Direct conversion or construction from the underlying dictionary are much faster.

Of course, this might deppend a lot on the rings involved, and the dictionart approach might not work if we talk about fraction fields or multivariate polynomial rings.


---

Comment by mmarco created at 2015-08-14 20:20:32

BTW, even if some complicated conversions need to be done, .subs is still slow compared to direct call:


```
sage: %time f(1/(a+1))
CPU times: user 0 ns, sys: 0 ns, total: 0 ns
Wall time: 450 µs
sage: %time f(a)
CPU times: user 1e+03 µs, sys: 0 ns, total: 1e+03 µs
Wall time: 476 µs
```


Note that the first one gives as result an element of the fraction field of S.


---

Comment by fuglede created at 2015-08-14 21:21:01

Note that there actually aren't any fractions involved a priori here, although it does seem like the code is currently producing silly "fractions" like `-1/A^2` (rather than `-A^-2`) that actually belong to the ring itself.


---

Comment by fuglede created at 2015-08-18 13:27:01

So how's the following: we always cache the first part of the algorithm which is independent of the ring. For the second part, we cache the result if and only if no ring is specified. Also, determining the base ring from the parent of the variable seems like a reasonable idea to me.


---

Comment by mmarco created at 2015-08-18 13:36:30

As a general principle, i think that would be the best choice.

But maybe for soem particular cases it would make sense to cache the final result. That deppends, in this case, in which would be the most usual scenario.

If the usual scenario is: the user computes most Jones polynomial in the same variable, then caching the final result produces no double caching, and we would win speed (since we don't have to convert from the cached value). Besides, if these computations will be usually called a lot of times (i.e. they will be put in a loop), that small speed gain can actually become important.

If, on the other hand, the expected situation is a user computing Jones polynomials in many different rings, then the double caching (with its coinsequent cache misses) will actually become a big problem.

In this case, since it seems that computing the Jones polynomial is much slower than conmverting from a cached value, i think the risks of cache misses outweight the advantages of not needing to convert from the cached value. So i would vote to cache the result in a fixed ring, and then convert to whichever ring the user wants.


---

Comment by git created at 2015-08-25 12:07:10

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2015-08-25 13:34:03

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2015-08-25 13:34:54

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by fuglede created at 2015-08-25 13:42:21

The above commits introduce caching in a number of ways, building on your comments. For the TL representation, the actual TL-part of the algorithm (which is independent of choices of variables) is cached in all cases. The actual (memory heavy) result is stored for the typical case where no variable is specified. The Markov traces and Jones polynomials have been set up so that the combinatorial part of the calculation is done over the general ring; the result of this calculation is cached, and when the user specifies a variable, substitution is carried out on this cached result. I think this strikes the perfect balance.

Also, as suggested by tscrim, the paradigm of supplying the variable as a generator of some polynomial ring, rather than specifying a string and the ring, has been pushed.

One thing that I would still like to fix is the fact that the methods occasionally return elements of fraction fields when they really shouldn't. Fixing this boils down to supplying an answer to [this ask sagemath question](http://ask.sagemath.org/question/29355/inverses-of-matrices-of-laurent-polynomials/).


---

Comment by git created at 2015-08-27 13:21:06

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by fuglede created at 2015-08-27 13:27:00

Fixed the issue in my previous comment with some refactoring to force sage to stay out of the field of fractions of the polynomial ring whenever possible. Even though this appears to require [some silly manipulations](https://github.com/sagemath/sagetrac-mirror/blob/master/src/sage/groups/braid.py?id=1b50612c99d13120a876ee95a4b79fa1008b7d45#n938), this even resulted in a speed gain: the 2961 knots mentioned earlier can now be checked against known data in 38 seconds (down from 69 seconds).

So, what's the process: should I flag as needs review?


---

Comment by tscrim created at 2015-08-27 13:45:31

As soon as you're ready for us to do a formal review, set it to needs_review.

I bet a good chuck of your speedup comes from the fact you're not doing division of a polynomial ring (and, in fact, you could remove one additional polynomial multiplication by being smarter about how you do your q-int). There is also floor division `//`, which does not go to the fraction field. However that is quite an impressive speedup.


---

Comment by fuglede created at 2015-08-27 14:02:37

Thanks for checking it out and for pointing those out. Using `//` provides a significant speed-up for the q-int calculation as well. Also, it's a complete life-saver in `jones_polynomial` where I had to work around what appears to be an [unrelated bug](https://groups.google.com/forum/#!topic/sage-devel/Ioxw4EJt2N4). The benchmark still runs in roughly the same time, but this is a lot more elegant!


---

Comment by git created at 2015-08-27 14:05:39

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by fuglede created at 2015-08-27 14:33:09

Changing status from new to needs_review.


---

Comment by git created at 2015-08-27 15:02:49

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by chapoton created at 2015-08-28 08:09:31

Could you please add an `EXAMPLES::` section to `_TL_action` ?


---

Comment by git created at 2015-08-28 08:19:25

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by tscrim created at 2015-08-30 22:11:29

This is completely baffling to me:

```
sage: R.<x> = QQ[]
sage: p = R.random_element(degree=5000)
sage: %timeit p.subs(x=x^2)
1 loops, best of 3: 1.18 s per loop
sage: %timeit p(x=x^2)
1 loops, best of 3: 1.22 s per loop
sage: %timeit p(x^2)
10 loops, best of 3: 38.6 ms per loop
sage: %timeit p.subs(x^2)
10 loops, best of 3: 38.3 ms per loop
sage: %timeit p(x=x^2)
1 loops, best of 3: 1.23 s per loop
```

So calling `subs` or direct evaluation without parameters with way faster for regular polynomials (and deserves a separate ticket if there isn't one already). However nothing beats direct coercion:

```
sage: S.<x> = LaurentPolynomialRing(QQ)
sage: q = x^-2300 * p
sage: T.<y> = LaurentPolynomialRing(QQ)
sage: %timeit T(q)
The slowest run took 5.28 times longer than the fastest. This could mean that an intermediate result is being cached 
10000 loops, best of 3: 158 µs per loop
```

I will make this change as part of my review (which I am starting now).


---

Comment by tscrim created at 2015-09-02 14:16:52

Okay, I've made my first pass of reviewer changes. There's probably some more documentation stuff that will need to be addressed, but I wanted you to run some speed tests against your previous timings to see what improvements (or regressions) have been made.
----
New commits:


---

Comment by fuglede created at 2015-09-03 11:15:06

Thanks for the detailed review!

Since most of the changes were related to internals in `TL_representation` and `jones_polynomial`, I ran some tests on those methods. Each test was performed three times on a fresh instance of sage (so caching specifics have not been tested), alternating between the old branch and the one that includes your fixes.

*Test 1:* Calculation of a huge `TL_representation` (34 13260x13260 matrices):

My branch:
    {{{
    sage: B = BraidGroup(18)
    sage: %time B.TL_representation(4)
    CPU times: user 1min 23s, sys: 104 ms, total: 1min 23s
    CPU times: user 1min 23s, sys: 104 ms, total: 1min 23s
    CPU times: user 1min 22s, sys: 92 ms, total: 1min 22s
    }}}

Your branch:
    {{{
    sage: B = BraidGroup(18)
    sage: %time B.TL_representation(4)
    CPU times: user 1min 12s, sys: 84 ms, total: 1min 12s
    CPU times: user 1min 12s, sys: 80 ms, total: 1min 12s
    CPU times: user 1min 13s, sys: 116 ms, total: 1min 13s
    }}}

Conclusion: Considerable speed gain.

**Test 2**: Calculation of the Jones polynomials of 2961 knots obtained as closures of braids on at most 7 strands. The test does not use `skein_normalisation` so that in particular, any speed gain obtained through the removal of `subs` should be visible here. The (somewhat ad hoc) test is [available here](https://gist.github.com/fuglede/13016f20c16dd2830756).

My branch:
    {{{
    sage: load("jonesdata.py")
    sage: test_against_dictionary()
    2961 matches and 0 mismatches found in 36.658627 seconds
    2961 matches and 0 mismatches found in 35.956593 seconds
    2961 matches and 0 mismatches found in 36.534720 seconds
    }}}
Your branch:
    {{{
    sage: load("jonesdata.py")
    sage: test_against_dictionary()
    2961 matches and 0 mismatches found in 34.822386 seconds
    2961 matches and 0 mismatches found in 34.758321 seconds
    2961 matches and 0 mismatches found in 36.320710 seconds
    }}}
Conclusion: Speed gain appears to be less significant here.


---

Comment by tscrim created at 2015-09-05 15:42:12

Thank you for running those timings. I'm glad to see that we've squeezed some more speed out of this. I'm going to make another pass over the documentation shortly, but there will likely be minimal changes.


---

Comment by git created at 2015-09-08 21:22:31

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by tscrim created at 2015-09-08 21:23:21

Okay, I'm done making reviewer changes. If you're happy with my latest changes, then you can set a positive review.


---

Comment by fuglede created at 2015-09-10 08:54:50

Changing status from needs_review to positive_review.


---

Comment by fuglede created at 2015-09-10 08:54:50

Looks good to me. I'm setting to positive review after changing just a single variable name.


---

Comment by vbraun created at 2015-09-10 19:46:27

Resolution: fixed
