# Issue 22605: Refactor DocTestDispatcher.parallel_dispatch

Issue created by migration from Trac.

Original creator: embray

Original creation time: 2017-04-20 14:48:44

In the process of working on #22832, I found it somewhat difficult to understand the implementation of `DocTestDispatcher.parallel_dispatch` (this is generally true of my for anything with a code block nested more than 2 levels deep and is more than a page long).

So I carefully reworked it as a class responsible for managing the state of the parallel dispatcher, and broke the main loop into a number of subroutines.  Otherwise there is no difference in functionality, and it incorporates the changes from #22832.  I think this code is (arguably) easier to understand.


---

Comment by jdemeyer created at 2017-04-20 15:11:27

I have been considering for a long time to basically separate this as a independent Python project (minus the doctest-specific parts). It's really just a robust reimplementation of `multiprocessing.Pool`.


---

Comment by jdemeyer created at 2017-04-20 15:16:59

What I'm trying to say is: do you think it's possible to refactor it in such a way that you write very general code to manage a bunch of subprocesses and then have the doctester use that?

There are other parts in Sage which would benefit from this code, the parallel docbuilder for example.


---

Comment by jdemeyer created at 2017-04-20 15:21:45

Minor comment: the calls `signal.signal(signal.SIGCHLD, ...)` could be replaced by the `with changesignal` context from #22695 (analogous to #21206).


---

Comment by embray created at 2017-04-24 13:38:44

Replying to [comment:2 jdemeyer]:
> What I'm trying to say is: do you think it's possible to refactor it in such a way that you write very general code to manage a bunch of subprocesses and then have the doctester use that?
> 
> There are other parts in Sage which would benefit from this code, the parallel docbuilder for example.

Yes, I definitely agree that's a good goal.  I could look into it as an alternative to this.  I wonder if it could also generalize the work-stealing algorithm from [sage.parallel.map_reduce](https://github.com/sagemath/sagetrac-mirror/blob/master/src/sage/parallel/map_reduce.py?id=4d81944c3ba7f6744d1ae7536a4d198bcb02944f) (which could then be reworked on top of the more generic code...?)


---

Comment by embray created at 2017-04-24 13:39:07

Replying to [comment:3 jdemeyer]:
> Minor comment: the calls `signal.signal(signal.SIGCHLD, ...)` could be replaced by the `with changesignal` context from #22695 (analogous to #21206).

Okay.


---

Comment by git created at 2017-04-24 13:49:28

Branch pushed to git repo; I updated commit sha1. This was a forced push. New commits:


---

Comment by embray created at 2017-04-24 14:17:45

Could you maybe summarize something about what this does that `multiprocessing.Pool` doesn't do that makes it more robust?  To me the main benefits seem to be the more intelligent signal handling, and synchronization of messages (for a generic implementation though it might make more sense if the message pipe replaced stdout (and maybe there were a separate pipe to replace stderr as well) on the workers).


---

Comment by jdemeyer created at 2017-04-24 14:44:50

Mainly, robustness in handling error conditions: Python exceptions, crashing subprocesses, interrupts, timeouts. None of this is handled by `multiprocessing.Pool`.


---

Comment by embray created at 2017-04-25 08:34:29

I'm still not entirely sure what you mean.  Don't get me wrong--I fully believe there are good reasons for this implementation which is why I haven't questioned it before.  I just don't know what issues have arisen in the past that led to multiprocessing.Pool being insufficient.

But multiprocessing.Pool _does_ handle exceptions, crashing subprocesses, etc.  But maybe there's some case where its handling is insufficient.  It also handles timeouts in many cases.  It does not handle interrupts very well though--that's the one area I can clearly see a difference.

I ask just because in the process of generalizing this code I want to be able to clearly document why it exists at all.


---

Comment by embray created at 2017-04-25 08:45:42

I think would I would really like to do is re-implement this code in such a way that's API compatible with multiprocessing.Pool, and maybe with optional support for work stealing.


---

Comment by git created at 2017-04-25 08:55:34

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by jdemeyer created at 2017-04-25 09:22:46

Replying to [comment:10 embray]:
> I'm still not entirely sure what you mean.  Don't get me wrong--I fully believe there are good reasons for this implementation which is why I haven't questioned it before.  I just don't know what issues have arisen in the past that led to multiprocessing.Pool being insufficient.
> 
> But multiprocessing.Pool _does_ handle exceptions, crashing subprocesses, etc.

Crashing not, this just hangs:

```
>>> from os import _exit; from multiprocessing import Pool; Pool(1).map(_exit, [0])
```


And exceptions are passed but then you lose the processes which did not raise an exception. It should be possible to continue even when one process raises an exception.


---

Comment by embray created at 2017-04-25 09:57:49

I see--I would consider that a bug but definitely one that needs a workaround.

Another advantage that I hope to generalize is better handling of standard I/O from worker processes.


---

Comment by embray created at 2017-04-25 10:11:42

Another clarification: I wasn't sure what you meant by "timeouts" in this case.  `multiprocessing` has "timeouts" insofar as some blocking operations like getting async results can time out.  But there are not timeouts for workers' tasks as far as I can tell (you could build this into the task of course but that still wouldn't kill stuck workers).


---

Comment by embray created at 2017-04-25 14:34:46

And yet another enhancement, which would be needed for compatibility with #22832, is for an entire computation to be canceled from within a single worker.  In order to re-implement this in a generic way this is something we want to generalize as well (which is easy enough--I've added a special exception which, if raised by a worker, cancels all the other workers' tasks).


---

Comment by embray created at 2017-04-26 12:06:31

This is the Executor interface that Min was talking about--whereas the associated `Future` class is the analogous generalization of the `MapResult` and `AsyncResult` classes of the `multiprocessing` module.

With the work I've already done it should be easy to implement this worker pool implementation on top of that API.
