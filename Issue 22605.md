# Issue 22605: Refactor DocTestDispatcher.parallel_dispatch

archive/issues_022605.json:
```json
{
    "body": "In the process of working on #22832, I found it somewhat difficult to understand the implementation of `DocTestDispatcher.parallel_dispatch` (this is generally true of my for anything with a code block nested more than 2 levels deep and is more than a page long).\n\nSo I carefully reworked it as a class responsible for managing the state of the parallel dispatcher, and broke the main loop into a number of subroutines.  Otherwise there is no difference in functionality, and it incorporates the changes from #22832.  I think this code is (arguably) easier to understand.\n\nIssue created by migration from https://trac.sagemath.org/ticket/22842\n\n",
    "created_at": "2017-04-20T14:48:44Z",
    "labels": [
        "doctest framework",
        "minor",
        "enhancement"
    ],
    "milestone": "https://github.com/sagemath/sagetest/milestones/sage-8.0",
    "title": "Refactor DocTestDispatcher.parallel_dispatch",
    "type": "issue",
    "url": "https://github.com/sagemath/sagetest/issues/22605",
    "user": "embray"
}
```
In the process of working on #22832, I found it somewhat difficult to understand the implementation of `DocTestDispatcher.parallel_dispatch` (this is generally true of my for anything with a code block nested more than 2 levels deep and is more than a page long).

So I carefully reworked it as a class responsible for managing the state of the parallel dispatcher, and broke the main loop into a number of subroutines.  Otherwise there is no difference in functionality, and it incorporates the changes from #22832.  I think this code is (arguably) easier to understand.

Issue created by migration from https://trac.sagemath.org/ticket/22842





---

archive/issue_comments_315415.json:
```json
{
    "body": "I have been considering for a long time to basically separate this as a independent Python project (minus the doctest-specific parts). It's really just a robust reimplementation of `multiprocessing.Pool`.",
    "created_at": "2017-04-20T15:11:27Z",
    "issue": "https://github.com/sagemath/sagetest/issues/22605",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/22605#issuecomment-315415",
    "user": "jdemeyer"
}
```

I have been considering for a long time to basically separate this as a independent Python project (minus the doctest-specific parts). It's really just a robust reimplementation of `multiprocessing.Pool`.



---

archive/issue_comments_315416.json:
```json
{
    "body": "What I'm trying to say is: do you think it's possible to refactor it in such a way that you write very general code to manage a bunch of subprocesses and then have the doctester use that?\n\nThere are other parts in Sage which would benefit from this code, the parallel docbuilder for example.",
    "created_at": "2017-04-20T15:16:59Z",
    "issue": "https://github.com/sagemath/sagetest/issues/22605",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/22605#issuecomment-315416",
    "user": "jdemeyer"
}
```

What I'm trying to say is: do you think it's possible to refactor it in such a way that you write very general code to manage a bunch of subprocesses and then have the doctester use that?

There are other parts in Sage which would benefit from this code, the parallel docbuilder for example.



---

archive/issue_comments_315417.json:
```json
{
    "body": "Minor comment: the calls `signal.signal(signal.SIGCHLD, ...)` could be replaced by the `with changesignal` context from #22695 (analogous to #21206).",
    "created_at": "2017-04-20T15:21:45Z",
    "issue": "https://github.com/sagemath/sagetest/issues/22605",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/22605#issuecomment-315417",
    "user": "jdemeyer"
}
```

Minor comment: the calls `signal.signal(signal.SIGCHLD, ...)` could be replaced by the `with changesignal` context from #22695 (analogous to #21206).



---

archive/issue_comments_315418.json:
```json
{
    "body": "Replying to [comment:2 jdemeyer]:\n> What I'm trying to say is: do you think it's possible to refactor it in such a way that you write very general code to manage a bunch of subprocesses and then have the doctester use that?\n> \n> There are other parts in Sage which would benefit from this code, the parallel docbuilder for example.\n\nYes, I definitely agree that's a good goal.  I could look into it as an alternative to this.  I wonder if it could also generalize the work-stealing algorithm from [sage.parallel.map_reduce](https://github.com/sagemath/sagetrac-mirror/blob/master/src/sage/parallel/map_reduce.py?id=4d81944c3ba7f6744d1ae7536a4d198bcb02944f) (which could then be reworked on top of the more generic code...?)",
    "created_at": "2017-04-24T13:38:44Z",
    "issue": "https://github.com/sagemath/sagetest/issues/22605",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/22605#issuecomment-315418",
    "user": "embray"
}
```

Replying to [comment:2 jdemeyer]:
> What I'm trying to say is: do you think it's possible to refactor it in such a way that you write very general code to manage a bunch of subprocesses and then have the doctester use that?
> 
> There are other parts in Sage which would benefit from this code, the parallel docbuilder for example.

Yes, I definitely agree that's a good goal.  I could look into it as an alternative to this.  I wonder if it could also generalize the work-stealing algorithm from [sage.parallel.map_reduce](https://github.com/sagemath/sagetrac-mirror/blob/master/src/sage/parallel/map_reduce.py?id=4d81944c3ba7f6744d1ae7536a4d198bcb02944f) (which could then be reworked on top of the more generic code...?)



---

archive/issue_comments_315419.json:
```json
{
    "body": "Replying to [comment:3 jdemeyer]:\n> Minor comment: the calls `signal.signal(signal.SIGCHLD, ...)` could be replaced by the `with changesignal` context from #22695 (analogous to #21206).\n\nOkay.",
    "created_at": "2017-04-24T13:39:07Z",
    "issue": "https://github.com/sagemath/sagetest/issues/22605",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/22605#issuecomment-315419",
    "user": "embray"
}
```

Replying to [comment:3 jdemeyer]:
> Minor comment: the calls `signal.signal(signal.SIGCHLD, ...)` could be replaced by the `with changesignal` context from #22695 (analogous to #21206).

Okay.



---

archive/issue_comments_315420.json:
```json
{
    "body": "Branch pushed to git repo; I updated commit sha1. This was a forced push. New commits:",
    "created_at": "2017-04-24T13:49:28Z",
    "issue": "https://github.com/sagemath/sagetest/issues/22605",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/22605#issuecomment-315420",
    "user": "git"
}
```

Branch pushed to git repo; I updated commit sha1. This was a forced push. New commits:



---

archive/issue_comments_315421.json:
```json
{
    "body": "Could you maybe summarize something about what this does that `multiprocessing.Pool` doesn't do that makes it more robust?  To me the main benefits seem to be the more intelligent signal handling, and synchronization of messages (for a generic implementation though it might make more sense if the message pipe replaced stdout (and maybe there were a separate pipe to replace stderr as well) on the workers).",
    "created_at": "2017-04-24T14:17:45Z",
    "issue": "https://github.com/sagemath/sagetest/issues/22605",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/22605#issuecomment-315421",
    "user": "embray"
}
```

Could you maybe summarize something about what this does that `multiprocessing.Pool` doesn't do that makes it more robust?  To me the main benefits seem to be the more intelligent signal handling, and synchronization of messages (for a generic implementation though it might make more sense if the message pipe replaced stdout (and maybe there were a separate pipe to replace stderr as well) on the workers).



---

archive/issue_comments_315422.json:
```json
{
    "body": "Mainly, robustness in handling error conditions: Python exceptions, crashing subprocesses, interrupts, timeouts. None of this is handled by `multiprocessing.Pool`.",
    "created_at": "2017-04-24T14:44:50Z",
    "issue": "https://github.com/sagemath/sagetest/issues/22605",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/22605#issuecomment-315422",
    "user": "jdemeyer"
}
```

Mainly, robustness in handling error conditions: Python exceptions, crashing subprocesses, interrupts, timeouts. None of this is handled by `multiprocessing.Pool`.



---

archive/issue_comments_315423.json:
```json
{
    "body": "I'm still not entirely sure what you mean.  Don't get me wrong--I fully believe there are good reasons for this implementation which is why I haven't questioned it before.  I just don't know what issues have arisen in the past that led to multiprocessing.Pool being insufficient.\n\nBut multiprocessing.Pool *does* handle exceptions, crashing subprocesses, etc.  But maybe there's some case where its handling is insufficient.  It also handles timeouts in many cases.  It does not handle interrupts very well though--that's the one area I can clearly see a difference.\n\nI ask just because in the process of generalizing this code I want to be able to clearly document why it exists at all.",
    "created_at": "2017-04-25T08:34:29Z",
    "issue": "https://github.com/sagemath/sagetest/issues/22605",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/22605#issuecomment-315423",
    "user": "embray"
}
```

I'm still not entirely sure what you mean.  Don't get me wrong--I fully believe there are good reasons for this implementation which is why I haven't questioned it before.  I just don't know what issues have arisen in the past that led to multiprocessing.Pool being insufficient.

But multiprocessing.Pool *does* handle exceptions, crashing subprocesses, etc.  But maybe there's some case where its handling is insufficient.  It also handles timeouts in many cases.  It does not handle interrupts very well though--that's the one area I can clearly see a difference.

I ask just because in the process of generalizing this code I want to be able to clearly document why it exists at all.



---

archive/issue_comments_315424.json:
```json
{
    "body": "I think would I would really like to do is re-implement this code in such a way that's API compatible with multiprocessing.Pool, and maybe with optional support for work stealing.",
    "created_at": "2017-04-25T08:45:42Z",
    "issue": "https://github.com/sagemath/sagetest/issues/22605",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/22605#issuecomment-315424",
    "user": "embray"
}
```

I think would I would really like to do is re-implement this code in such a way that's API compatible with multiprocessing.Pool, and maybe with optional support for work stealing.



---

archive/issue_comments_315425.json:
```json
{
    "body": "Branch pushed to git repo; I updated commit sha1. New commits:",
    "created_at": "2017-04-25T08:55:34Z",
    "issue": "https://github.com/sagemath/sagetest/issues/22605",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/22605#issuecomment-315425",
    "user": "git"
}
```

Branch pushed to git repo; I updated commit sha1. New commits:



---

archive/issue_comments_315426.json:
```json
{
    "body": "Replying to [comment:10 embray]:\n> I'm still not entirely sure what you mean.  Don't get me wrong--I fully believe there are good reasons for this implementation which is why I haven't questioned it before.  I just don't know what issues have arisen in the past that led to multiprocessing.Pool being insufficient.\n> \n> But multiprocessing.Pool *does* handle exceptions, crashing subprocesses, etc.\n\nCrashing not, this just hangs:\n\n```\n>>> from os import _exit; from multiprocessing import Pool; Pool(1).map(_exit, [0])\n```\n\n\nAnd exceptions are passed but then you lose the processes which did not raise an exception. It should be possible to continue even when one process raises an exception.",
    "created_at": "2017-04-25T09:22:46Z",
    "issue": "https://github.com/sagemath/sagetest/issues/22605",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/22605#issuecomment-315426",
    "user": "jdemeyer"
}
```

Replying to [comment:10 embray]:
> I'm still not entirely sure what you mean.  Don't get me wrong--I fully believe there are good reasons for this implementation which is why I haven't questioned it before.  I just don't know what issues have arisen in the past that led to multiprocessing.Pool being insufficient.
> 
> But multiprocessing.Pool *does* handle exceptions, crashing subprocesses, etc.

Crashing not, this just hangs:

```
>>> from os import _exit; from multiprocessing import Pool; Pool(1).map(_exit, [0])
```


And exceptions are passed but then you lose the processes which did not raise an exception. It should be possible to continue even when one process raises an exception.



---

archive/issue_comments_315427.json:
```json
{
    "body": "I see--I would consider that a bug but definitely one that needs a workaround.\n\nAnother advantage that I hope to generalize is better handling of standard I/O from worker processes.",
    "created_at": "2017-04-25T09:57:49Z",
    "issue": "https://github.com/sagemath/sagetest/issues/22605",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/22605#issuecomment-315427",
    "user": "embray"
}
```

I see--I would consider that a bug but definitely one that needs a workaround.

Another advantage that I hope to generalize is better handling of standard I/O from worker processes.



---

archive/issue_comments_315428.json:
```json
{
    "body": "Another clarification: I wasn't sure what you meant by \"timeouts\" in this case.  `multiprocessing` has \"timeouts\" insofar as some blocking operations like getting async results can time out.  But there are not timeouts for workers' tasks as far as I can tell (you could build this into the task of course but that still wouldn't kill stuck workers).",
    "created_at": "2017-04-25T10:11:42Z",
    "issue": "https://github.com/sagemath/sagetest/issues/22605",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/22605#issuecomment-315428",
    "user": "embray"
}
```

Another clarification: I wasn't sure what you meant by "timeouts" in this case.  `multiprocessing` has "timeouts" insofar as some blocking operations like getting async results can time out.  But there are not timeouts for workers' tasks as far as I can tell (you could build this into the task of course but that still wouldn't kill stuck workers).



---

archive/issue_comments_315429.json:
```json
{
    "body": "And yet another enhancement, which would be needed for compatibility with #22832, is for an entire computation to be canceled from within a single worker.  In order to re-implement this in a generic way this is something we want to generalize as well (which is easy enough--I've added a special exception which, if raised by a worker, cancels all the other workers' tasks).",
    "created_at": "2017-04-25T14:34:46Z",
    "issue": "https://github.com/sagemath/sagetest/issues/22605",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/22605#issuecomment-315429",
    "user": "embray"
}
```

And yet another enhancement, which would be needed for compatibility with #22832, is for an entire computation to be canceled from within a single worker.  In order to re-implement this in a generic way this is something we want to generalize as well (which is easy enough--I've added a special exception which, if raised by a worker, cancels all the other workers' tasks).



---

archive/issue_comments_315430.json:
```json
{
    "body": "This is the Executor interface that Min was talking about--whereas the associated `Future` class is the analogous generalization of the `MapResult` and `AsyncResult` classes of the `multiprocessing` module.\n\nWith the work I've already done it should be easy to implement this worker pool implementation on top of that API.",
    "created_at": "2017-04-26T12:06:31Z",
    "issue": "https://github.com/sagemath/sagetest/issues/22605",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/22605#issuecomment-315430",
    "user": "embray"
}
```

This is the Executor interface that Min was talking about--whereas the associated `Future` class is the analogous generalization of the `MapResult` and `AsyncResult` classes of the `multiprocessing` module.

With the work I've already done it should be easy to implement this worker pool implementation on top of that API.
