# Issue 18595: Big Oh terms and equality

archive/issues_018358.json:
```json
{
    "body": "The following should **not** happen:\n\n```\nsage: PSR.<x> = PowerSeriesRing(ZZ)\nsage: x + O(x^2) == x\nTrue\nsage: O(x) == 0\nTrue\n```\n\nAlso, currently it is not easy to check whether a power series contains an O-term (except by comparing representation strings...).\n\nCC:  @dkrenn\n\nKeywords: powerseries, asymptotics\n\nStatus: new\n\nIssue created by migration from https://trac.sagemath.org/ticket/18595\n\n",
    "created_at": "2015-06-02T22:48:50Z",
    "labels": [
        "component: commutative algebra",
        "bug"
    ],
    "milestone": "https://github.com/sagemath/sagetest/milestones/sage-6.8",
    "title": "Big Oh terms and equality",
    "type": "issue",
    "url": "https://github.com/sagemath/sagetest/issues/18595",
    "user": "https://github.com/behackl"
}
```
The following should **not** happen:

```
sage: PSR.<x> = PowerSeriesRing(ZZ)
sage: x + O(x^2) == x
True
sage: O(x) == 0
True
```

Also, currently it is not easy to check whether a power series contains an O-term (except by comparing representation strings...).

CC:  @dkrenn

Keywords: powerseries, asymptotics

Status: new

Issue created by migration from https://trac.sagemath.org/ticket/18595





---

archive/issue_comments_265267.json:
```json
{
    "body": "Changing component from symbolics to commutative algebra.",
    "created_at": "2015-06-07T15:57:16Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18595",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18595#issuecomment-265267",
    "user": "https://github.com/rwst"
}
```

Changing component from symbolics to commutative algebra.



---

archive/issue_comments_265268.json:
```json
{
    "body": "<a id='comment:2'></a>It is not clear to me why the behaviour illustrated in the ticket is not desirable. It is certainly consistent with p-adics and with arithmetic:\n\n```\nsage: PSR.<x> = PowerSeriesRing(ZZ)\nsage: a=x\nsage: b=a+O(x^2)\nsage: (a-b).is_zero()\nTrue\nsage: a==b\nTrue\n```\nso changing the current behaviour would also require that `O(x^2) != 0`.\n\nAlso, checking whether an O-term is present is quite straightforward:\n\n```\nsage: (x+O(x^2)).precision_absolute()\n2\nsage: (x).precision_absolute()\n+Infinity\n```\nI'd think close as Invalid. Please comment if you think otherwise.",
    "created_at": "2015-06-07T22:28:56Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18595",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18595#issuecomment-265268",
    "user": "https://github.com/nbruin"
}
```

<a id='comment:2'></a>It is not clear to me why the behaviour illustrated in the ticket is not desirable. It is certainly consistent with p-adics and with arithmetic:

```
sage: PSR.<x> = PowerSeriesRing(ZZ)
sage: a=x
sage: b=a+O(x^2)
sage: (a-b).is_zero()
True
sage: a==b
True
```
so changing the current behaviour would also require that `O(x^2) != 0`.

Also, checking whether an O-term is present is quite straightforward:

```
sage: (x+O(x^2)).precision_absolute()
2
sage: (x).precision_absolute()
+Infinity
```
I'd think close as Invalid. Please comment if you think otherwise.



---

archive/issue_comments_265269.json:
```json
{
    "body": "<a id='comment:3'></a>I'll probably have to provide some more context. When I'm thinking of O-notation, I have http://en.wikipedia.org/wiki/Big_O_notation#Equals_sign in mind, that is I think of `O(f(x))` as the class of functions `g(x)` such that `|g(x)| <= C |f(x)|` holds for `x -> oo`. By abuse of notation, `g(x) = O(f(x))` then actually means `g(x) \\in O(f(x))` -- and this leads to the problem that I do not agree with\n\n```\nsage: (x + (-x + O(x^2))).is_zero()\nTrue\n```\n\nbecause while `0 = O(x^2)` (mathematically) translates to `0 \\in O(x^2)`, which is true -- the converse, `O(x^2) = 0`, is not.\n\nUnfortunately, I think this \"one-way equality\" cannot be modeled by `==` -- or can it? Or would this even be desireable?\n\nHowever, apart from that, do you think that `is_zero` really shoud evaluate to `True` for `O(x)` and other \"approximate\" terms? Maybe this is not the best comparion, but consider the real interval field:\n\n```\nsage: RIF(0).is_zero()\nTrue\nsage: RIF((-0.1, 0.1)).is_zero()\nFalse\n```\nThis is more like the behavior I would expect from `O(x).is_zero()`. What do you think?\n\n(Also: thanks for pointing me towards `precision_absolute()`, this (more or less) solves my original problem!)",
    "created_at": "2015-06-07T23:12:54Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18595",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18595#issuecomment-265269",
    "user": "https://github.com/behackl"
}
```

<a id='comment:3'></a>I'll probably have to provide some more context. When I'm thinking of O-notation, I have http://en.wikipedia.org/wiki/Big_O_notation#Equals_sign in mind, that is I think of `O(f(x))` as the class of functions `g(x)` such that `|g(x)| <= C |f(x)|` holds for `x -> oo`. By abuse of notation, `g(x) = O(f(x))` then actually means `g(x) \in O(f(x))` -- and this leads to the problem that I do not agree with

```
sage: (x + (-x + O(x^2))).is_zero()
True
```

because while `0 = O(x^2)` (mathematically) translates to `0 \in O(x^2)`, which is true -- the converse, `O(x^2) = 0`, is not.

Unfortunately, I think this "one-way equality" cannot be modeled by `==` -- or can it? Or would this even be desireable?

However, apart from that, do you think that `is_zero` really shoud evaluate to `True` for `O(x)` and other "approximate" terms? Maybe this is not the best comparion, but consider the real interval field:

```
sage: RIF(0).is_zero()
True
sage: RIF((-0.1, 0.1)).is_zero()
False
```
This is more like the behavior I would expect from `O(x).is_zero()`. What do you think?

(Also: thanks for pointing me towards `precision_absolute()`, this (more or less) solves my original problem!)



---

archive/issue_comments_265270.json:
```json
{
    "body": "<a id='comment:4'></a>Replying to [comment:3 behackl]:\n> I'll probably have to provide some more context. When I'm thinking of O-notation, I have http://en.wikipedia.org/wiki/Big_O_notation#Equals_sign in mind, that is I think of `O(f(x))` as the class of functions `g(x)` such that `|g(x)| <= C |f(x)|` holds for `x -> oo`. By abuse of notation, `g(x) = O(f(x))` then actually means `g(x) \\in O(f(x))` -- and this leads to the problem that I do not agree with\n\n\nYes, I don't think that's a very useful way of thinking about the big-oh used for power series approximations, and not the one that comes naturally from their algebra. If anything, the big-oh is with respect to limits for x->0 when applicable, although actual convergence is irrelevant for formal power series arithmetic -- there's no problem taking power series with coefficients over finite fields, for instance. What kind of limit would you be taking?\n\nWith that limit interpretation, we see that O(x<sup>2</sup>) would consist of all those power series (ignoring convergence issues) for which lim_{x->0} f(x)/x<sup>2</sup> is finite. That would include 0.\n\n> {{{\n> sage: RIF(0).is_zero()\n> True\n> sage: RIF((-0.1, 0.1)).is_zero()\n> False\n> }}}\n> This is more like the behavior I would expect from `O(x).is_zero()`. What do you think?\n\n\nThat's a very good parallel and it is exactly the behaviour we have. If you want to do it using calculus-type limits, you should consider lim_{x->0}, though.\n\n**EDIT:** I am sorry, I misread the output from RIF. I have to adjust my answer. That's a pretty good parallel and the choice taken in power series is different. You can indeed think of a power series approximation as an \"interval\". It's quite common that in power series arithmetic (and in p-adic arithmetic) to take two elements \"equal\" if their representing \"intervals\" overlap--conveniently, this implies that one of the intervals is contained in the other.\n\nAlgebraically, you get a much nicer definition. There `ZZ[This is the Trac macro *x* that was inherited from the migration](https://trac.sagemath.org/wiki/WikiMacros#x-macro) = limproj_{n->oo} Z[x]/(x^n)` and O(x<sup>n</sup>) can then be identified with the kernel of the homomorphism `ZZ[This is the Trac macro *x* that was inherited from the migration](https://trac.sagemath.org/wiki/WikiMacros#x-macro)-> Z[x]/(x^n)`. If you're not already familiar with projective limits you might have to do some reading to get familiar with them and if you're not interested in the underlying algebraic theory you might not find it particularly enlightening to do so.",
    "created_at": "2015-06-08T04:30:01Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18595",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18595#issuecomment-265270",
    "user": "https://github.com/nbruin"
}
```

<a id='comment:4'></a>Replying to [comment:3 behackl]:
> I'll probably have to provide some more context. When I'm thinking of O-notation, I have http://en.wikipedia.org/wiki/Big_O_notation#Equals_sign in mind, that is I think of `O(f(x))` as the class of functions `g(x)` such that `|g(x)| <= C |f(x)|` holds for `x -> oo`. By abuse of notation, `g(x) = O(f(x))` then actually means `g(x) \in O(f(x))` -- and this leads to the problem that I do not agree with


Yes, I don't think that's a very useful way of thinking about the big-oh used for power series approximations, and not the one that comes naturally from their algebra. If anything, the big-oh is with respect to limits for x->0 when applicable, although actual convergence is irrelevant for formal power series arithmetic -- there's no problem taking power series with coefficients over finite fields, for instance. What kind of limit would you be taking?

With that limit interpretation, we see that O(x<sup>2</sup>) would consist of all those power series (ignoring convergence issues) for which lim_{x->0} f(x)/x<sup>2</sup> is finite. That would include 0.

> {{{
> sage: RIF(0).is_zero()
> True
> sage: RIF((-0.1, 0.1)).is_zero()
> False
> }}}
> This is more like the behavior I would expect from `O(x).is_zero()`. What do you think?


That's a very good parallel and it is exactly the behaviour we have. If you want to do it using calculus-type limits, you should consider lim_{x->0}, though.

**EDIT:** I am sorry, I misread the output from RIF. I have to adjust my answer. That's a pretty good parallel and the choice taken in power series is different. You can indeed think of a power series approximation as an "interval". It's quite common that in power series arithmetic (and in p-adic arithmetic) to take two elements "equal" if their representing "intervals" overlap--conveniently, this implies that one of the intervals is contained in the other.

Algebraically, you get a much nicer definition. There `ZZ[This is the Trac macro *x* that was inherited from the migration](https://trac.sagemath.org/wiki/WikiMacros#x-macro) = limproj_{n->oo} Z[x]/(x^n)` and O(x<sup>n</sup>) can then be identified with the kernel of the homomorphism `ZZ[This is the Trac macro *x* that was inherited from the migration](https://trac.sagemath.org/wiki/WikiMacros#x-macro)-> Z[x]/(x^n)`. If you're not already familiar with projective limits you might have to do some reading to get familiar with them and if you're not interested in the underlying algebraic theory you might not find it particularly enlightening to do so.



---

archive/issue_comments_265271.json:
```json
{
    "body": "<a id='comment:5'></a>Replying to [comment:4 nbruin]:\n> Replying to [comment:3 behackl]:\n> > I'll probably have to provide some more context. When I'm thinking of O-notation, I have http://en.wikipedia.org/wiki/Big_O_notation#Equals_sign in mind, that is I think of `O(f(x))` as the class of functions `g(x)` such that `|g(x)| <= C |f(x)|` holds for `x -> oo`. By abuse of notation, `g(x) = O(f(x))` then actually means `g(x) \\in O(f(x))` -- and this leads to the problem that I do not agree with\n\n> \n> Yes, I don't think that's a very useful way of thinking about the big-oh used for power series approximations, and not the one that comes naturally from their algebra. If anything, the big-oh is with respect to limits for x->0 when applicable, although actual convergence is irrelevant for formal power series arithmetic -- there's no problem taking power series with coefficients over finite fields, for instance. What kind of limit would you be taking?\n> \n> With that limit interpretation, we see that O(x<sup>2</sup>) would consist of all those power series (ignoring convergence issues) for which lim_{x->0} f(x)/x<sup>2</sup> is finite. That would include 0.\n> \n\n\nWell -- mea culpa. I meant to write `x -> 0`; for `x -> oo` everything is exactly the other way around (e.g. `x + O(x^2)` reduces to `O(x^2)`; there the O term can absorb smaller terms).\n\nSo, the interpretation I have in mind and the limit interpretation coincide. Sorry.\n\nOf course, the limit definition only works when the point of approximation is an inner point; and that also exactly how these O terms that I think of are defined, for example, here: http://algo.inria.fr/flajolet/Publications/AnaCombi/book.pdf (p. 722).\n\n> > {{{\n> > sage: RIF(0).is_zero()\n> > True\n> > sage: RIF((-0.1, 0.1)).is_zero()\n> > False\n> > }}}\n> > This is more like the behavior I would expect from `O(x).is_zero()`. What do you think?\n\n> \n> That's a very good parallel and it is exactly the behaviour we have. If you want to do it using calculus-type limits, you should consider lim_{x->0}, though.\n> \n\n\n```\nsage: R.<x> = PowerSeriesRing(ZZ)\nsage: R(0).is_zero()\nTrue\nsage: O(x).is_zero()\nTrue\n```\n\nFollowing the behavior of RIF, I still would expect `O(x).is_zero()` to return False, because I see `0 + O(x)` like `RIF((-0.1, 0.1))`: an \"approximate\" zero.\n\n> Algebraically, you get a much nicer definition. There `ZZ[This is the Trac macro *x* that was inherited from the migration](https://trac.sagemath.org/wiki/WikiMacros#x-macro) = limproj_{n->oo} Z[x]/(x^n)` and O(x<sup>n</sup>) can then be identified with the kernel of the homomorphism `ZZ[This is the Trac macro *x* that was inherited from the migration](https://trac.sagemath.org/wiki/WikiMacros#x-macro)-> Z[x]/(x^n)`. If you're not already familiar with projective limits you might have to do some reading to get familiar with them and if you're not interested in the underlying algebraic theory you might not find it particularly enlightening to do so.\n\n\nI have to admit that this definition of formal power series is new for me; but I think I understand. I agree that within `ZZ[x]/(x)`, `O(x).is_zero()` should yield `True`. But in `ZZ[This is the Trac macro *x* that was inherited from the migration](https://trac.sagemath.org/wiki/WikiMacros#x-macro)` too?\n\nAnd finally: what about the following:\n\n```\nsage: O(x) == O(x^2)\nTrue\n```\nDoes this equality make sense to you?",
    "created_at": "2015-06-08T06:43:32Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18595",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18595#issuecomment-265271",
    "user": "https://github.com/behackl"
}
```

<a id='comment:5'></a>Replying to [comment:4 nbruin]:
> Replying to [comment:3 behackl]:
> > I'll probably have to provide some more context. When I'm thinking of O-notation, I have http://en.wikipedia.org/wiki/Big_O_notation#Equals_sign in mind, that is I think of `O(f(x))` as the class of functions `g(x)` such that `|g(x)| <= C |f(x)|` holds for `x -> oo`. By abuse of notation, `g(x) = O(f(x))` then actually means `g(x) \in O(f(x))` -- and this leads to the problem that I do not agree with

> 
> Yes, I don't think that's a very useful way of thinking about the big-oh used for power series approximations, and not the one that comes naturally from their algebra. If anything, the big-oh is with respect to limits for x->0 when applicable, although actual convergence is irrelevant for formal power series arithmetic -- there's no problem taking power series with coefficients over finite fields, for instance. What kind of limit would you be taking?
> 
> With that limit interpretation, we see that O(x<sup>2</sup>) would consist of all those power series (ignoring convergence issues) for which lim_{x->0} f(x)/x<sup>2</sup> is finite. That would include 0.
> 


Well -- mea culpa. I meant to write `x -> 0`; for `x -> oo` everything is exactly the other way around (e.g. `x + O(x^2)` reduces to `O(x^2)`; there the O term can absorb smaller terms).

So, the interpretation I have in mind and the limit interpretation coincide. Sorry.

Of course, the limit definition only works when the point of approximation is an inner point; and that also exactly how these O terms that I think of are defined, for example, here: http://algo.inria.fr/flajolet/Publications/AnaCombi/book.pdf (p. 722).

> > {{{
> > sage: RIF(0).is_zero()
> > True
> > sage: RIF((-0.1, 0.1)).is_zero()
> > False
> > }}}
> > This is more like the behavior I would expect from `O(x).is_zero()`. What do you think?

> 
> That's a very good parallel and it is exactly the behaviour we have. If you want to do it using calculus-type limits, you should consider lim_{x->0}, though.
> 


```
sage: R.<x> = PowerSeriesRing(ZZ)
sage: R(0).is_zero()
True
sage: O(x).is_zero()
True
```

Following the behavior of RIF, I still would expect `O(x).is_zero()` to return False, because I see `0 + O(x)` like `RIF((-0.1, 0.1))`: an "approximate" zero.

> Algebraically, you get a much nicer definition. There `ZZ[This is the Trac macro *x* that was inherited from the migration](https://trac.sagemath.org/wiki/WikiMacros#x-macro) = limproj_{n->oo} Z[x]/(x^n)` and O(x<sup>n</sup>) can then be identified with the kernel of the homomorphism `ZZ[This is the Trac macro *x* that was inherited from the migration](https://trac.sagemath.org/wiki/WikiMacros#x-macro)-> Z[x]/(x^n)`. If you're not already familiar with projective limits you might have to do some reading to get familiar with them and if you're not interested in the underlying algebraic theory you might not find it particularly enlightening to do so.


I have to admit that this definition of formal power series is new for me; but I think I understand. I agree that within `ZZ[x]/(x)`, `O(x).is_zero()` should yield `True`. But in `ZZ[This is the Trac macro *x* that was inherited from the migration](https://trac.sagemath.org/wiki/WikiMacros#x-macro)` too?

And finally: what about the following:

```
sage: O(x) == O(x^2)
True
```
Does this equality make sense to you?



---

archive/issue_comments_265272.json:
```json
{
    "body": "<a id='comment:6'></a>Replying to [comment:5 behackl]:\n> And finally: what about the following:\n> \n> ```\n> sage: O(x) == O(x^2)\n> True\n> ```\n> Does this equality make sense to you?\n\n\nYes: the two \"intervals\" (neighbourhoods is perhaps a better term) overlap, so they could be representing the same element.\n\nThe advantage of this lax form of equality is that if you do computations with sufficient precision to tell all distinct elements you'll encounter apart, then you can use the conventional algorithms to arrive at an answer. That means that you can for instance do linear algebra with power series using normal tools, provided you start with enough precision. This works fairly well in practice and you'll usually discover a catastrophic loss of precision by not having any terms left. Of course, for serious applications you do have to use proper numerical methods anyway, but then you won't be using equality tests anyway.",
    "created_at": "2015-06-08T07:07:16Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18595",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18595#issuecomment-265272",
    "user": "https://github.com/nbruin"
}
```

<a id='comment:6'></a>Replying to [comment:5 behackl]:
> And finally: what about the following:
> 
> ```
> sage: O(x) == O(x^2)
> True
> ```
> Does this equality make sense to you?


Yes: the two "intervals" (neighbourhoods is perhaps a better term) overlap, so they could be representing the same element.

The advantage of this lax form of equality is that if you do computations with sufficient precision to tell all distinct elements you'll encounter apart, then you can use the conventional algorithms to arrive at an answer. That means that you can for instance do linear algebra with power series using normal tools, provided you start with enough precision. This works fairly well in practice and you'll usually discover a catastrophic loss of precision by not having any terms left. Of course, for serious applications you do have to use proper numerical methods anyway, but then you won't be using equality tests anyway.
