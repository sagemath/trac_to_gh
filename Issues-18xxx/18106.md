# Issue 18106: QQbar: make sum and product n-ary and remove recursive calls

archive/issues_017869.json:
```json
{
    "body": "In QQbar, there are currently many operations that involve recursive calls. For example, this rather simple example gives an error because the Python stack gets filled:\n\n```\nsage: a = QQbar.zeta(1009)\nsage: p = cyclotomic_polynomial(1009)\nsage: b = p(a)\nsage: b\n0.?e-12 + 0.?e-12*I\nsage: b == 0\nTraceback (most recent call last):\n...\nRuntimeError: maximum recursion depth exceeded\n```\n\nIn this ticket:\n- introduce a new (one variable) polynomial descriptor\n- we make sum and product be n-ary operators instead of binary\n- we remove all recursive call to become depth first search\n\nThe current behavior prevents avoiding lazy fields (RLF and CLF) for number field embeddings (see e.g. #18103).\n\n**CC:**  @gagern\n\n**Keywords:** sd66, qqbar\n\nIssue created by migration from https://trac.sagemath.org/ticket/18106\n\n",
    "created_at": "2015-04-02T09:17:31Z",
    "labels": [
        "component: number fields",
        "bug"
    ],
    "milestone": "https://github.com/sagemath/sagetest/milestones/sage-6.6",
    "title": "QQbar: make sum and product n-ary and remove recursive calls",
    "type": "issue",
    "url": "https://github.com/sagemath/sagetest/issues/18106",
    "user": "https://github.com/videlec"
}
```
In QQbar, there are currently many operations that involve recursive calls. For example, this rather simple example gives an error because the Python stack gets filled:

```
sage: a = QQbar.zeta(1009)
sage: p = cyclotomic_polynomial(1009)
sage: b = p(a)
sage: b
0.?e-12 + 0.?e-12*I
sage: b == 0
Traceback (most recent call last):
...
RuntimeError: maximum recursion depth exceeded
```

In this ticket:
- introduce a new (one variable) polynomial descriptor
- we make sum and product be n-ary operators instead of binary
- we remove all recursive call to become depth first search

The current behavior prevents avoiding lazy fields (RLF and CLF) for number field embeddings (see e.g. #18103).

**CC:**  @gagern

**Keywords:** sd66, qqbar

Issue created by migration from https://trac.sagemath.org/ticket/18106





---

archive/issue_comments_250994.json:
```json
{
    "body": "**Changing keywords** from \"\" to \"sd66\".",
    "created_at": "2015-04-02T09:17:42Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18106",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18106#issuecomment-250994",
    "user": "https://github.com/videlec"
}
```

**Changing keywords** from "" to "sd66".



---

archive/issue_comments_250995.json:
```json
{
    "body": "<a id='comment:2'></a>\nIn `exactify` there is a bit of code which adjusts the recursion limit, increasing it by 10 for every recursive call so it will never be reached. It was introduced in [42b0fb3](https://github.com/sagemath/sagetrac-mirror/commit/42b0fb3d75cf0967592d2ffdc731a8a610659b59) to address #2638. I guess we could use the same for `_interval_fast` as well.\n\nOn the other hand, we could also try addressing the source of this deep recursion. The way I see it, that's because addition is left associative, so that cyclotomic polynomial will be a very deep but thin binary tree. If we had a representation which describes a sum (and perhaps also a product) of an arbitrary number of algebraic numbers using a single descriptor, the data structure would become much more shallow.\n\nAs a third solution, we might set up our own evaluation machinery for these trees, with our own stack instead of Python recursion. I haven't yet worked out all the details, but if this sounds interesting I might write some code to see how this approach feels.\n\nThe way I see it, since the backtrace is about `_interval_fast` and `_more_precision`, all of this is happening before exact computation is triggered, right? Do we have any way to find out that exact computation might in this case be faster than repeated numeric refinement? I fear we have no way to detect this, but if someone has an idea, please share it.",
    "created_at": "2015-04-02T09:39:23Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18106",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18106#issuecomment-250995",
    "user": "https://github.com/gagern"
}
```

<a id='comment:2'></a>
In `exactify` there is a bit of code which adjusts the recursion limit, increasing it by 10 for every recursive call so it will never be reached. It was introduced in [42b0fb3](https://github.com/sagemath/sagetrac-mirror/commit/42b0fb3d75cf0967592d2ffdc731a8a610659b59) to address #2638. I guess we could use the same for `_interval_fast` as well.

On the other hand, we could also try addressing the source of this deep recursion. The way I see it, that's because addition is left associative, so that cyclotomic polynomial will be a very deep but thin binary tree. If we had a representation which describes a sum (and perhaps also a product) of an arbitrary number of algebraic numbers using a single descriptor, the data structure would become much more shallow.

As a third solution, we might set up our own evaluation machinery for these trees, with our own stack instead of Python recursion. I haven't yet worked out all the details, but if this sounds interesting I might write some code to see how this approach feels.

The way I see it, since the backtrace is about `_interval_fast` and `_more_precision`, all of this is happening before exact computation is triggered, right? Do we have any way to find out that exact computation might in this case be faster than repeated numeric refinement? I fear we have no way to detect this, but if someone has an idea, please share it.



---

archive/issue_comments_250996.json:
```json
{
    "body": "<a id='comment:3'></a>\nReplying to [gagern](#comment%3A2): \n> On the other hand, we could also try addressing the source of this deep recursion. The way I see it, that's because addition is left associative, so that cyclotomic polynomial will be a very deep but thin binary tree. If we had a representation which describes a sum (and perhaps also a product) of an arbitrary number of algebraic numbers using a single descriptor, the data structure would become much more shallow.\n\n\nLooks like a good idea to have a polynomial descriptor for one (or several?) algebraic numbers. It might even be used to get faster and more precise interval evaluations.\n\n> As a third solution, we might set up our own evaluation machinery for these trees, with our own stack instead of Python recursion. I haven't yet worked out all the details, but if this sounds interesting I might write some code to see how this approach feels.\n\n\nLooks reasonable to do it without recursion. We might obtain a good speed up.\n\n> The way I see it, since the backtrace is about `_interval_fast` and `_more_precision`, all of this is happening before exact computation is triggered, right?\n\n\nRight!\n\nDo you find reasonable to open two tickets:\n- one for polynomial descriptor in one variable\n- one for evaluation without recursion\n\nVincent",
    "created_at": "2015-04-02T10:11:50Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18106",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18106#issuecomment-250996",
    "user": "https://github.com/videlec"
}
```

<a id='comment:3'></a>
Replying to [gagern](#comment%3A2): 
> On the other hand, we could also try addressing the source of this deep recursion. The way I see it, that's because addition is left associative, so that cyclotomic polynomial will be a very deep but thin binary tree. If we had a representation which describes a sum (and perhaps also a product) of an arbitrary number of algebraic numbers using a single descriptor, the data structure would become much more shallow.


Looks like a good idea to have a polynomial descriptor for one (or several?) algebraic numbers. It might even be used to get faster and more precise interval evaluations.

> As a third solution, we might set up our own evaluation machinery for these trees, with our own stack instead of Python recursion. I haven't yet worked out all the details, but if this sounds interesting I might write some code to see how this approach feels.


Looks reasonable to do it without recursion. We might obtain a good speed up.

> The way I see it, since the backtrace is about `_interval_fast` and `_more_precision`, all of this is happening before exact computation is triggered, right?


Right!

Do you find reasonable to open two tickets:
- one for polynomial descriptor in one variable
- one for evaluation without recursion

Vincent



---

archive/issue_comments_250997.json:
```json
{
    "body": "<a id='comment:4'></a>\nNo, I'd keep it in one ticket, although it certainly makes sense to have multiple branches. But I see these things as complementary: if either one works well, the other *might* become obsolete. And to decide that, we need to compare them, which is easier when we have a single ticket. Once one thing is ready to be merged, *then* we can move the remaining idea to a new ticket.",
    "created_at": "2015-04-02T11:24:58Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18106",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18106#issuecomment-250997",
    "user": "https://github.com/gagern"
}
```

<a id='comment:4'></a>
No, I'd keep it in one ticket, although it certainly makes sense to have multiple branches. But I see these things as complementary: if either one works well, the other *might* become obsolete. And to decide that, we need to compare them, which is easier when we have a single ticket. Once one thing is ready to be merged, *then* we can move the remaining idea to a new ticket.



---

archive/issue_comments_250998.json:
```json
{
    "body": "**Description changed:**\n``````diff\n--- \n+++ \n@@ -1,3 +1,4 @@\n+In QQbar, there are currently many operations that involve recursive calls. For example, this rather simple example gives an error because the Python stack gets filled:\n \n ```\n sage: a = QQbar.zeta(1009)\n@@ -11,4 +12,8 @@\n RuntimeError: maximum recursion depth exceeded\n ```\n \n+In this ticket:\n+- we make sum and product be n-ary operators instead of binary\n+- we remove all recursive call to become depth first search\n+\n Such behavior prevents avoiding lazy fields (RLF and CLF) for number field embeddings (see e.g. #18103).\n``````\n",
    "created_at": "2015-05-16T10:12:34Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18106",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18106#issuecomment-250998",
    "user": "https://github.com/videlec"
}
```

**Description changed:**
``````diff
--- 
+++ 
@@ -1,3 +1,4 @@
+In QQbar, there are currently many operations that involve recursive calls. For example, this rather simple example gives an error because the Python stack gets filled:
 
 ```
 sage: a = QQbar.zeta(1009)
@@ -11,4 +12,8 @@
 RuntimeError: maximum recursion depth exceeded
 ```
 
+In this ticket:
+- we make sum and product be n-ary operators instead of binary
+- we remove all recursive call to become depth first search
+
 Such behavior prevents avoiding lazy fields (RLF and CLF) for number field embeddings (see e.g. #18103).
``````




---

archive/issue_events_165695.json:
```json
{
    "actor": "https://github.com/videlec",
    "created_at": "2015-05-16T10:12:34Z",
    "event": "renamed",
    "issue": "https://github.com/sagemath/sagetest/issues/18106",
    "rename": {
        "from": "Maximum depth recursion in QQbar",
        "to": "QQbar: make sum and product n-ary and remove recursive calls"
    },
    "type": "issue_event",
    "url": "https://github.com/sagemath/sagetest/issues/18106#event-165695"
}
```



---

archive/issue_comments_250999.json:
```json
{
    "body": "**Description changed:**\n``````diff\n--- \n+++ \n@@ -13,7 +13,8 @@\n ```\n \n In this ticket:\n+- introduce a new (one variable) polynomial descriptor\n - we make sum and product be n-ary operators instead of binary\n - we remove all recursive call to become depth first search\n \n-Such behavior prevents avoiding lazy fields (RLF and CLF) for number field embeddings (see e.g. #18103).\n+The current behavior prevents avoiding lazy fields (RLF and CLF) for number field embeddings (see e.g. #18103).\n``````\n",
    "created_at": "2015-05-16T10:14:58Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18106",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18106#issuecomment-250999",
    "user": "https://github.com/videlec"
}
```

**Description changed:**
``````diff
--- 
+++ 
@@ -13,7 +13,8 @@
 ```
 
 In this ticket:
+- introduce a new (one variable) polynomial descriptor
 - we make sum and product be n-ary operators instead of binary
 - we remove all recursive call to become depth first search
 
-Such behavior prevents avoiding lazy fields (RLF and CLF) for number field embeddings (see e.g. #18103).
+The current behavior prevents avoiding lazy fields (RLF and CLF) for number field embeddings (see e.g. #18103).
``````




---

archive/issue_comments_251000.json:
```json
{
    "body": "**Changing keywords** from \"sd66\" to \"sd66, qqbar\".",
    "created_at": "2017-09-22T14:38:01Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18106",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18106#issuecomment-251000",
    "user": "https://github.com/fchapoton"
}
```

**Changing keywords** from "sd66" to "sd66, qqbar".



---

archive/issue_comments_251001.json:
```json
{
    "body": "<a id='comment:8'></a>\nFWIW, in Sage9.1beta3:\n\n```\nsage: a = QQbar.zeta(1009)\nsage: p = cyclotomic_polynomial(1009)\nsage: b = p(a)\nsage: b\n0\nsage: b == 0\nTrue\n```\n\nI arrived on this ticket because of #28599.",
    "created_at": "2020-02-07T17:35:56Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18106",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18106#issuecomment-251001",
    "user": "https://github.com/jplab"
}
```

<a id='comment:8'></a>
FWIW, in Sage9.1beta3:

```
sage: a = QQbar.zeta(1009)
sage: p = cyclotomic_polynomial(1009)
sage: b = p(a)
sage: b
0
sage: b == 0
True
```

I arrived on this ticket because of #28599.



---

archive/issue_comments_251002.json:
```json
{
    "body": "<a id='comment:9'></a>\nOh my, increasing the recursion limit is a *horrible* hack. There's a reason why python doesn't like to do deep recursions: stack management in C means that C generally doesn't like to do it, and CPython implements recursion by doing recursion in C. So along with the Python frame stack, the C call stack is also getting deeper.\n\nBefore you start changing the recursion limit in Python, you really want to make sure you can't accomplish the same thing in another way. In particular, you should make sure that the \"recursion\" really gets used: basically that stack depth will only grow logarithmically with problem size (but a little beyond the default 1000 that is normally set) The patch from #2638 seems to be still in force. If it is at all possible to rewrite that code so that recursion limit increases are not necessary, we'd have a significant improvement in our code base.",
    "created_at": "2020-02-07T21:56:25Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18106",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18106#issuecomment-251002",
    "user": "https://github.com/nbruin"
}
```

<a id='comment:9'></a>
Oh my, increasing the recursion limit is a *horrible* hack. There's a reason why python doesn't like to do deep recursions: stack management in C means that C generally doesn't like to do it, and CPython implements recursion by doing recursion in C. So along with the Python frame stack, the C call stack is also getting deeper.

Before you start changing the recursion limit in Python, you really want to make sure you can't accomplish the same thing in another way. In particular, you should make sure that the "recursion" really gets used: basically that stack depth will only grow logarithmically with problem size (but a little beyond the default 1000 that is normally set) The patch from #2638 seems to be still in force. If it is at all possible to rewrite that code so that recursion limit increases are not necessary, we'd have a significant improvement in our code base.
