# Issue 18055: Improve lookahead in IntegerListsLex

archive/issues_017818.json:
```json
{
    "body": "`IntegerListsLex` uses a depth first search in a prefix tree, with lookahead to prune branches.\nThe purpose of this ticket is to improve the lookahead algorithm in two directions:\n\n- Detect more (all?) branches that can be cut.\n- Better time complexity; this probably will involve identifying important invariants and caching them.\n\nExample:: even just for n=1000 this is taking a long time:\n\n```\n    sage: n = 100\n    sage: IntegerListsLex(binomial(n,2)-1, length=n, min_slope=1).list()\n```\nThe following also take a long time, which should be optimized:\n\n```\n    sage: IntegerListsLex(10^100, max_length=1).list()\n    sage: IntegerListsLex(499499, length=1000, min_slope=1).list()\n```\n\nOne could hope that one could reach an average complexity roughly\nlinear in `O(log(max_n), max_length)` per list generated.\n\nConcrete steps:\n\n- If we want the floor function to satisfy the `max_slope` constraint,\n  we need to do \"reverse smoothing\", and the floor function then\n  depends on the interval `[0,...,k)` over which we want to consider\n  it. The same holds for the ceiling function if we want it to satisfy\n  the `min_slope` constraint. Let thus `f_k` and `c_k` be respectively\n  the floor and ceiling functions for the interval `[0,...k)`\n\n  Let's ignore the constraints on the length and on `n` for now.\n  Then, `f_k` and `c_k` are valid lists. Prove the following remark:\n\n  For any `n` between `sum(f_k)` and `sum(c_k)` there exists a valid\n  list of length `k` and sum `n`.\n\n  Putting back the length and sum constraints, there exists a valid\n  list if and only if the interval `I_k = [sum(f_k), sum(c_k)]`\n  intersects the interval `[min_n, max_n]` for some `k` between\n  `min_length` and `max_length`.\n\n- Extend `Envelope` with a method `.sum(k)` which computes `sum(f_k)`.\n\n  It should have appropriate algorithmic and caching so that the\n  overall time complexity of computing `sum(f_k)` for all `k<=l` is\n  linear in `l`.\n\n  Trick: store, for each `j`, the smallest `i<=j` such that between\n  `i` and `j` the slope is exactly `max_slope`. The point is that\n  computing the sum of the parts of `f_k` between `i` and `j` is\n  constant time. Use that incrementally to derive quickly `sum(f_k)`\n  from `sum(f_j)` for some `j<=k`.\n\n  Suggestion for a faster development cycle: experiment with this by\n  extracting the current code for `Envelope` in a separate file.\n\n- Use the above characterization and the `.sum(k)` methods to\n  implement a method `IntegerListsLex.is_empty` which terminates with\n  guaranteed result on non degenerate cases. This is essentially what\n  the current `lookahead` method does, but starting from `0` and with\n  guaranteed results thanks to the reverse smoothing.\n\n  Determine precisely the degenerate cases where `is_empty` may take\n  an arbitrarily long time (something like: the ceiling can be `0` for\n  an arbitrary long time, without a known `limit=0` and `limit_start`).\n\n  Decide on appropriate metrics to bound tightly the complexity in the\n  other cases (something around `max_length`, `max_n`, `limit_start`).\n\n  As a side product, we probably want to store for later usage the\n  information of which `n` admit a valid list, as a collection of non\n  overlapping intervals. Then, deciding whether there exists a valid\n  list of sum `n` for a given `n` can be achieved efficiently by\n  dichotomy.\n\n- Assuming that `l` is a prefix of a valid list, find out how to\n  determine for which `i` `l+[i]` is still a prefix of a valid list.\n\n  Potential building block: the choice of a prefix imposes more\n  constraints on the floor and ceiling later on (our former `adapt`\n  method), and we want to keep track of that. Given a prefix `l`,\n  write `f_k(l)` be the list obtained by extending `l` to a list of\n  length `k` using the floor `f_k`, with appropriate forward\n  smoothing. Same for `c_k(l)`. Write `I_k(l) = [sum(f_k(l)),\n  sum(c_k(l))]`.\n\n  Now, `l` is a prefix of a valid list if one of the `I_k(l)`\n  intersect `[min_sum, max_sum]`. So, while increasing the length of\n  `l` we want to do something like incrementally adapting the sequence\n  of intervals `I_k(l)` to always make sure we stay within one of\n  them.\n\n- Use this to reimplement `lookahead(self)` implementing the above,\n  with a guaranteed result and good complexity. And if at all possible\n  a constant time complexity when the constraints are simple\n  (e.g. `floor=0`, ...).\n\n  This method should support `_current_list=[]` as well.\n\n- Update `next` accordingly (the logic should be slightly simpler\n  thanks to the handling of the empty prefix).\n\n- If not implemented elsewhere: let the constructor accept a prefix as\n  input, to start the iteration from there. Derive a `next` method as\n  a side effect.\n\n- Remove `integer_list_old` at the final stage.\n\n\nCC:  @bgillesp\n\nStatus: new\n\nDependencies: #18109\n\nIssue created by migration from https://trac.sagemath.org/ticket/18055\n\n",
    "created_at": "2015-03-25T18:25:10Z",
    "labels": [
        "component: combinatorics"
    ],
    "milestone": "https://github.com/sagemath/sagetest/milestones/sage-6.6",
    "title": "Improve lookahead in IntegerListsLex",
    "type": "issue",
    "url": "https://github.com/sagemath/sagetest/issues/18055",
    "user": "https://github.com/nthiery"
}
```
`IntegerListsLex` uses a depth first search in a prefix tree, with lookahead to prune branches.
The purpose of this ticket is to improve the lookahead algorithm in two directions:

- Detect more (all?) branches that can be cut.
- Better time complexity; this probably will involve identifying important invariants and caching them.

Example:: even just for n=1000 this is taking a long time:

```
    sage: n = 100
    sage: IntegerListsLex(binomial(n,2)-1, length=n, min_slope=1).list()
```
The following also take a long time, which should be optimized:

```
    sage: IntegerListsLex(10^100, max_length=1).list()
    sage: IntegerListsLex(499499, length=1000, min_slope=1).list()
```

One could hope that one could reach an average complexity roughly
linear in `O(log(max_n), max_length)` per list generated.

Concrete steps:

- If we want the floor function to satisfy the `max_slope` constraint,
  we need to do "reverse smoothing", and the floor function then
  depends on the interval `[0,...,k)` over which we want to consider
  it. The same holds for the ceiling function if we want it to satisfy
  the `min_slope` constraint. Let thus `f_k` and `c_k` be respectively
  the floor and ceiling functions for the interval `[0,...k)`

  Let's ignore the constraints on the length and on `n` for now.
  Then, `f_k` and `c_k` are valid lists. Prove the following remark:

  For any `n` between `sum(f_k)` and `sum(c_k)` there exists a valid
  list of length `k` and sum `n`.

  Putting back the length and sum constraints, there exists a valid
  list if and only if the interval `I_k = [sum(f_k), sum(c_k)]`
  intersects the interval `[min_n, max_n]` for some `k` between
  `min_length` and `max_length`.

- Extend `Envelope` with a method `.sum(k)` which computes `sum(f_k)`.

  It should have appropriate algorithmic and caching so that the
  overall time complexity of computing `sum(f_k)` for all `k<=l` is
  linear in `l`.

  Trick: store, for each `j`, the smallest `i<=j` such that between
  `i` and `j` the slope is exactly `max_slope`. The point is that
  computing the sum of the parts of `f_k` between `i` and `j` is
  constant time. Use that incrementally to derive quickly `sum(f_k)`
  from `sum(f_j)` for some `j<=k`.

  Suggestion for a faster development cycle: experiment with this by
  extracting the current code for `Envelope` in a separate file.

- Use the above characterization and the `.sum(k)` methods to
  implement a method `IntegerListsLex.is_empty` which terminates with
  guaranteed result on non degenerate cases. This is essentially what
  the current `lookahead` method does, but starting from `0` and with
  guaranteed results thanks to the reverse smoothing.

  Determine precisely the degenerate cases where `is_empty` may take
  an arbitrarily long time (something like: the ceiling can be `0` for
  an arbitrary long time, without a known `limit=0` and `limit_start`).

  Decide on appropriate metrics to bound tightly the complexity in the
  other cases (something around `max_length`, `max_n`, `limit_start`).

  As a side product, we probably want to store for later usage the
  information of which `n` admit a valid list, as a collection of non
  overlapping intervals. Then, deciding whether there exists a valid
  list of sum `n` for a given `n` can be achieved efficiently by
  dichotomy.

- Assuming that `l` is a prefix of a valid list, find out how to
  determine for which `i` `l+[i]` is still a prefix of a valid list.

  Potential building block: the choice of a prefix imposes more
  constraints on the floor and ceiling later on (our former `adapt`
  method), and we want to keep track of that. Given a prefix `l`,
  write `f_k(l)` be the list obtained by extending `l` to a list of
  length `k` using the floor `f_k`, with appropriate forward
  smoothing. Same for `c_k(l)`. Write `I_k(l) = [sum(f_k(l)),
  sum(c_k(l))]`.

  Now, `l` is a prefix of a valid list if one of the `I_k(l)`
  intersect `[min_sum, max_sum]`. So, while increasing the length of
  `l` we want to do something like incrementally adapting the sequence
  of intervals `I_k(l)` to always make sure we stay within one of
  them.

- Use this to reimplement `lookahead(self)` implementing the above,
  with a guaranteed result and good complexity. And if at all possible
  a constant time complexity when the constraints are simple
  (e.g. `floor=0`, ...).

  This method should support `_current_list=[]` as well.

- Update `next` accordingly (the logic should be slightly simpler
  thanks to the handling of the empty prefix).

- If not implemented elsewhere: let the constructor accept a prefix as
  input, to start the iteration from there. Derive a `next` method as
  a side effect.

- Remove `integer_list_old` at the final stage.


CC:  @bgillesp

Status: new

Dependencies: #18109

Issue created by migration from https://trac.sagemath.org/ticket/18055





---

archive/issue_comments_311469.json:
```json
{
    "body": "Description changed:\n``````diff\n--- \n+++ \n@@ -10,6 +10,11 @@\n     sage: n = 100\n     sage: IntegerListsLex(binomial(n,2)-1, length=n, min_slope=1).list()\n ```\n+The following also takes a long time, which should be optimized:\n+\n+```\n+    sage: IntegerListsLex(10^100, max_length=1).list()\n+```\n \n One could hope that, in non degenerate cases, one could reach an\n average complexity roughly linear in `O(log(max_n), max_length)` per\n``````\n",
    "created_at": "2015-03-26T18:20:40Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18055",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18055#issuecomment-311469",
    "user": "https://github.com/anneschilling"
}
```

Description changed:
``````diff
--- 
+++ 
@@ -10,6 +10,11 @@
     sage: n = 100
     sage: IntegerListsLex(binomial(n,2)-1, length=n, min_slope=1).list()
 ```
+The following also takes a long time, which should be optimized:
+
+```
+    sage: IntegerListsLex(10^100, max_length=1).list()
+```
 
 One could hope that, in non degenerate cases, one could reach an
 average complexity roughly linear in `O(log(max_n), max_length)` per
``````




---

archive/issue_comments_311470.json:
```json
{
    "body": "Description changed:\n``````diff\n--- \n+++ \n@@ -10,10 +10,11 @@\n     sage: n = 100\n     sage: IntegerListsLex(binomial(n,2)-1, length=n, min_slope=1).list()\n ```\n-The following also takes a long time, which should be optimized:\n+The following also take a long time, which should be optimized:\n \n ```\n     sage: IntegerListsLex(10^100, max_length=1).list()\n+    sage: IntegerListsLex(499499, length=1000, min_slope=1).list()\n ```\n \n One could hope that, in non degenerate cases, one could reach an\n``````\n",
    "created_at": "2015-03-26T18:23:34Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18055",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18055#issuecomment-311470",
    "user": "https://github.com/anneschilling"
}
```

Description changed:
``````diff
--- 
+++ 
@@ -10,10 +10,11 @@
     sage: n = 100
     sage: IntegerListsLex(binomial(n,2)-1, length=n, min_slope=1).list()
 ```
-The following also takes a long time, which should be optimized:
+The following also take a long time, which should be optimized:
 
 ```
     sage: IntegerListsLex(10^100, max_length=1).list()
+    sage: IntegerListsLex(499499, length=1000, min_slope=1).list()
 ```
 
 One could hope that, in non degenerate cases, one could reach an
``````




---

archive/issue_comments_311471.json:
```json
{
    "body": "Description changed:\n``````diff\n--- \n+++ \n@@ -21,3 +21,40 @@\n average complexity roughly linear in `O(log(max_n), max_length)` per\n list generated.\n \n+Concrete steps:\n+\n+- Extend `Envelope` with a function:\n+  {{{\n+      def area(k):\n+          \"\"\"Return the area under the envelope between `0` and `k`\"\"\"\n+  }}}\n+\n+  This functions should handle the \"reverse smoothing\" from position\n+  `k` (so that the envelope satisfies both `min_slope` and `max_slope`\n+  conditions between `1` and `k`), and have appropriate algorithmic\n+  and caching so that the overall complexity of computing all\n+  `area(k)` for `k<=l` is linear in `l`.\n+\n+- Replace:\n+  {{{\n+      def _possible_m(self, m, ...):\n+  }}}\n+  by:\n+  {{{\n+      def lookahead(self):\n+  }}}\n+\n+  which shall detect whether `_current_list` has a chance to be a\n+  prefix of some valid list. Using the above `area` method of the\n+  envelopes, it should be possible to detect most dead branches.\n+\n+  This method should support `_current_list=[]` as well.\n+\n+  This method should store as much information as relevant to avoid\n+  later recomputation for lower nodes in the tree. A minima, this\n+  could possibly return/store a range for the next value, removing the\n+  need for a separate `_m_interval` method.\n+\n+- Update `next` accordingly (the logic should be slightly simpler\n+  thanks to the handling of the empty prefix).\n+\n``````\n",
    "created_at": "2015-04-03T05:08:43Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18055",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18055#issuecomment-311471",
    "user": "https://github.com/nthiery"
}
```

Description changed:
``````diff
--- 
+++ 
@@ -21,3 +21,40 @@
 average complexity roughly linear in `O(log(max_n), max_length)` per
 list generated.
 
+Concrete steps:
+
+- Extend `Envelope` with a function:
+  {{{
+      def area(k):
+          """Return the area under the envelope between `0` and `k`"""
+  }}}
+
+  This functions should handle the "reverse smoothing" from position
+  `k` (so that the envelope satisfies both `min_slope` and `max_slope`
+  conditions between `1` and `k`), and have appropriate algorithmic
+  and caching so that the overall complexity of computing all
+  `area(k)` for `k<=l` is linear in `l`.
+
+- Replace:
+  {{{
+      def _possible_m(self, m, ...):
+  }}}
+  by:
+  {{{
+      def lookahead(self):
+  }}}
+
+  which shall detect whether `_current_list` has a chance to be a
+  prefix of some valid list. Using the above `area` method of the
+  envelopes, it should be possible to detect most dead branches.
+
+  This method should support `_current_list=[]` as well.
+
+  This method should store as much information as relevant to avoid
+  later recomputation for lower nodes in the tree. A minima, this
+  could possibly return/store a range for the next value, removing the
+  need for a separate `_m_interval` method.
+
+- Update `next` accordingly (the logic should be slightly simpler
+  thanks to the handling of the empty prefix).
+
``````




---

archive/issue_comments_311472.json:
```json
{
    "body": "Description changed:\n``````diff\n--- \n+++ \n@@ -47,6 +47,8 @@\n   which shall detect whether `_current_list` has a chance to be a\n   prefix of some valid list. Using the above `area` method of the\n   envelopes, it should be possible to detect most dead branches.\n+  Using dichotomy on the area / parts, it should be possible to\n+  achieve good complexity in most cases.\n \n   This method should support `_current_list=[]` as well.\n \n``````\n",
    "created_at": "2015-04-03T08:00:47Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18055",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18055#issuecomment-311472",
    "user": "https://github.com/nthiery"
}
```

Description changed:
``````diff
--- 
+++ 
@@ -47,6 +47,8 @@
   which shall detect whether `_current_list` has a chance to be a
   prefix of some valid list. Using the above `area` method of the
   envelopes, it should be possible to detect most dead branches.
+  Using dichotomy on the area / parts, it should be possible to
+  achieve good complexity in most cases.
 
   This method should support `_current_list=[]` as well.
 
``````




---

archive/issue_comments_311473.json:
```json
{
    "body": "<a id='comment:5'></a>\nCan we *please* stop talking about \"degenerate cases\" without specifying what that means?",
    "created_at": "2015-04-11T21:34:49Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18055",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18055#issuecomment-311473",
    "user": "https://github.com/jdemeyer"
}
```

<a id='comment:5'></a>
Can we *please* stop talking about "degenerate cases" without specifying what that means?



---

archive/issue_comments_311474.json:
```json
{
    "body": "Description changed:\n``````diff\n--- \n+++ \n@@ -17,7 +17,7 @@\n     sage: IntegerListsLex(499499, length=1000, min_slope=1).list()\n ```\n \n-One could hope that, in non degenerate cases, one could reach an\n+One could hope that one could reach an\n average complexity roughly linear in `O(log(max_n), max_length)` per\n list generated.\n \n``````\n",
    "created_at": "2015-04-11T21:34:49Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18055",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18055#issuecomment-311474",
    "user": "https://github.com/jdemeyer"
}
```

Description changed:
``````diff
--- 
+++ 
@@ -17,7 +17,7 @@
     sage: IntegerListsLex(499499, length=1000, min_slope=1).list()
 ```
 
-One could hope that, in non degenerate cases, one could reach an
+One could hope that one could reach an
 average complexity roughly linear in `O(log(max_n), max_length)` per
 list generated.
 
``````




---

archive/issue_comments_311475.json:
```json
{
    "body": "<a id='comment:6'></a>\nReplying to [jdemeyer](#comment%3A5):\n> Can we *please* stop talking about \"degenerate cases\" without specifying what that means?\n\n\nThis ticket involves some research, which includes in particular defining precisely what \"degenerate\" is. Until this research is done, we can't do anything but remain vague.",
    "created_at": "2015-04-11T22:59:27Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18055",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18055#issuecomment-311475",
    "user": "https://github.com/nthiery"
}
```

<a id='comment:6'></a>
Replying to [jdemeyer](#comment%3A5):
> Can we *please* stop talking about "degenerate cases" without specifying what that means?


This ticket involves some research, which includes in particular defining precisely what "degenerate" is. Until this research is done, we can't do anything but remain vague.



---

archive/issue_comments_311476.json:
```json
{
    "body": "Description changed:\n``````diff\n--- \n+++ \n@@ -60,3 +60,4 @@\n - Update `next` accordingly (the logic should be slightly simpler\n   thanks to the handling of the empty prefix).\n \n+- Remove `integer_list_old` at the final stage.\n``````\n",
    "created_at": "2015-04-13T11:29:06Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18055",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18055#issuecomment-311476",
    "user": "https://github.com/nthiery"
}
```

Description changed:
``````diff
--- 
+++ 
@@ -60,3 +60,4 @@
 - Update `next` accordingly (the logic should be slightly simpler
   thanks to the handling of the empty prefix).
 
+- Remove `integer_list_old` at the final stage.
``````




---

archive/issue_comments_311477.json:
```json
{
    "body": "Changing dependencies from \"\" to \"#18181\"",
    "created_at": "2015-04-13T18:08:25Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18055",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18055#issuecomment-311477",
    "user": "https://github.com/jdemeyer"
}
```

Changing dependencies from "" to "#18181"



---

archive/issue_comments_311478.json:
```json
{
    "body": "Changing dependencies from \"#18181\" to \"#18109\"",
    "created_at": "2015-04-14T18:12:18Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18055",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18055#issuecomment-311478",
    "user": "https://github.com/jdemeyer"
}
```

Changing dependencies from "#18181" to "#18109"



---

archive/issue_comments_311479.json:
```json
{
    "body": "Description changed:\n``````diff\n--- \n+++ \n@@ -1,7 +1,7 @@\n `IntegerListsLex` uses a depth first search in a prefix tree, with lookahead to prune branches.\n The purpose of this ticket is to improve the lookahead algorithm in two directions:\n \n-- Detect more branches that can be cut.\n+- Detect more (all?) branches that can be cut.\n - Better time complexity; this probably will involve identifying important invariants and caching them.\n \n Example:: even just for n=1000 this is taking a long time:\n@@ -17,47 +17,93 @@\n     sage: IntegerListsLex(499499, length=1000, min_slope=1).list()\n ```\n \n-One could hope that one could reach an\n-average complexity roughly linear in `O(log(max_n), max_length)` per\n-list generated.\n+One could hope that one could reach an average complexity roughly\n+linear in `O(log(max_n), max_length)` per list generated.\n \n Concrete steps:\n \n-- Extend `Envelope` with a function:\n-  {{{\n-      def area(k):\n-          \"\"\"Return the area under the envelope between `0` and `k`\"\"\"\n-  }}}\n+- If we want the floor function to satisfy the `max_slope` constraint,\n+  we need to do \"reverse smoothing\", and the floor function then\n+  depends on the interval `[0,...,k)` over which we want to consider\n+  it. The same holds for the ceiling function if we want it to satisfy\n+  the `min_slope` constraint. Let thus `f_k` and `c_k` be respectively\n+  the floor and ceiling functions for the interval `[0,...k)`\n \n-  This functions should handle the \"reverse smoothing\" from position\n-  `k` (so that the envelope satisfies both `min_slope` and `max_slope`\n-  conditions between `1` and `k`), and have appropriate algorithmic\n-  and caching so that the overall complexity of computing all\n-  `area(k)` for `k<=l` is linear in `l`.\n+  Let's ignore the constraints on the length and on `n` for now.\n+  Then, `f_k` and `c_k` are valid lists. Prove the following remark:\n \n-- Replace:\n-  {{{\n-      def _possible_m(self, m, ...):\n-  }}}\n-  by:\n-  {{{\n-      def lookahead(self):\n-  }}}\n+  For any `n` between `sum(f_k)` and `sum(c_k)` there exists a valid\n+  list of length `k` and sum `n`.\n \n-  which shall detect whether `_current_list` has a chance to be a\n-  prefix of some valid list. Using the above `area` method of the\n-  envelopes, it should be possible to detect most dead branches.\n-  Using dichotomy on the area / parts, it should be possible to\n-  achieve good complexity in most cases.\n+  Putting back the length and sum constraints, there exists a valid\n+  list if and only if the interval `I_k = [sum(f_k), sum(c_k)]`\n+  intersects the interval `[min_n, max_n]` for some `k` between\n+  `min_length` and `max_length`.\n+\n+- Extend `Envelope` with a method `.sum(k)` which computes `sum(f_k)`.\n+\n+  It should have appropriate algorithmic and caching so that the\n+  overall time complexity of computing `sum(f_k)` for all `k<=l` is\n+  linear in `l`.\n+\n+  Trick: store, for each `j`, the smallest `i<=j` such that between\n+  `i` and `j` the slope is exactly `max_slope`. The point is that\n+  computing the sum of the parts of `f_k` between `i` and `j` is\n+  constant time. Use that incrementally to derive quickly `sum(f_k)`\n+  from `sum(f_j)` for some `j<=k`.\n+\n+  Suggestion for a faster development cycle: experiment with this by\n+  extracting the current code for `Envelope` in a separate file.\n+\n+- Use the above characterization and the `.sum(k)` methods to\n+  implement a method `IntegerListsLex.is_empty` which terminates with\n+  guaranteed result on non degenerate cases. This is essentially what\n+  the current `lookahead` method does, but starting from `0` and with\n+  guaranteed results thanks to the reverse smoothing.\n+\n+  Determine precisely the degenerate cases where `is_empty` may take\n+  an arbitrarily long time (something like: the ceiling can be `0` for\n+  an arbitrary long time, without a known `limit=0` and `limit_start`).\n+\n+  Decide on appropriate metrics to bound tightly the complexity in the\n+  other cases (something around `max_length`, `max_n`, `limit_start`).\n+\n+  As a side product, we probably want to store for later usage the\n+  information of which `n` admit a valid list, as a collection of non\n+  overlapping intervals. Then, deciding whether there exists a valid\n+  list of sum `n` for a given `n` can be achieved efficiently by\n+  dichotomy.\n+\n+- Assuming that `l` is a prefix of a valid list, find out how to\n+  determine for which `i` `l+[i]` is still a prefix of a valid list.\n+\n+  Potential building block: the choice of a prefix imposes more\n+  constraints on the floor and ceiling later on (our former `adapt`\n+  method), and we want to keep track of that. Given a prefix `l`,\n+  write `f_k(l)` be the list obtained by extending `l` to a list of\n+  length `k` using the floor `f_k`, with appropriate forward\n+  smoothing. Same for `c_k(l)`. Write `I_k(l) = [sum(f_k(l)),\n+  sum(c_k(l))]`.\n+\n+  Now, `l` is a prefix of a valid list if one of the `I_k(l)`\n+  intersect `[min_sum, max_sum]`. So, while increasing the length of\n+  `l` we want to do something like incrementally adapting the sequence\n+  of intervals `I_k(l)` to always make sure we stay within one of\n+  them.\n+\n+- Use this to reimplement `lookahead(self)` implementing the above,\n+  with a guaranteed result and good complexity. And if at all possible\n+  a constant time complexity when the constraints are simple\n+  (e.g. `floor=0`, ...).\n \n   This method should support `_current_list=[]` as well.\n-\n-  This method should store as much information as relevant to avoid\n-  later recomputation for lower nodes in the tree. A minima, this\n-  could possibly return/store a range for the next value, removing the\n-  need for a separate `_m_interval` method.\n \n - Update `next` accordingly (the logic should be slightly simpler\n   thanks to the handling of the empty prefix).\n \n+- If not implemented elsewhere: let the constructor accept a prefix as\n+  input, to start the iteration from there. Derive a `next` method as\n+  a side effect.\n+\n - Remove `integer_list_old` at the final stage.\n+\n``````\n",
    "created_at": "2015-04-16T02:52:42Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18055",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18055#issuecomment-311479",
    "user": "https://github.com/nthiery"
}
```

Description changed:
``````diff
--- 
+++ 
@@ -1,7 +1,7 @@
 `IntegerListsLex` uses a depth first search in a prefix tree, with lookahead to prune branches.
 The purpose of this ticket is to improve the lookahead algorithm in two directions:
 
-- Detect more branches that can be cut.
+- Detect more (all?) branches that can be cut.
 - Better time complexity; this probably will involve identifying important invariants and caching them.
 
 Example:: even just for n=1000 this is taking a long time:
@@ -17,47 +17,93 @@
     sage: IntegerListsLex(499499, length=1000, min_slope=1).list()
 ```
 
-One could hope that one could reach an
-average complexity roughly linear in `O(log(max_n), max_length)` per
-list generated.
+One could hope that one could reach an average complexity roughly
+linear in `O(log(max_n), max_length)` per list generated.
 
 Concrete steps:
 
-- Extend `Envelope` with a function:
-  {{{
-      def area(k):
-          """Return the area under the envelope between `0` and `k`"""
-  }}}
+- If we want the floor function to satisfy the `max_slope` constraint,
+  we need to do "reverse smoothing", and the floor function then
+  depends on the interval `[0,...,k)` over which we want to consider
+  it. The same holds for the ceiling function if we want it to satisfy
+  the `min_slope` constraint. Let thus `f_k` and `c_k` be respectively
+  the floor and ceiling functions for the interval `[0,...k)`
 
-  This functions should handle the "reverse smoothing" from position
-  `k` (so that the envelope satisfies both `min_slope` and `max_slope`
-  conditions between `1` and `k`), and have appropriate algorithmic
-  and caching so that the overall complexity of computing all
-  `area(k)` for `k<=l` is linear in `l`.
+  Let's ignore the constraints on the length and on `n` for now.
+  Then, `f_k` and `c_k` are valid lists. Prove the following remark:
 
-- Replace:
-  {{{
-      def _possible_m(self, m, ...):
-  }}}
-  by:
-  {{{
-      def lookahead(self):
-  }}}
+  For any `n` between `sum(f_k)` and `sum(c_k)` there exists a valid
+  list of length `k` and sum `n`.
 
-  which shall detect whether `_current_list` has a chance to be a
-  prefix of some valid list. Using the above `area` method of the
-  envelopes, it should be possible to detect most dead branches.
-  Using dichotomy on the area / parts, it should be possible to
-  achieve good complexity in most cases.
+  Putting back the length and sum constraints, there exists a valid
+  list if and only if the interval `I_k = [sum(f_k), sum(c_k)]`
+  intersects the interval `[min_n, max_n]` for some `k` between
+  `min_length` and `max_length`.
+
+- Extend `Envelope` with a method `.sum(k)` which computes `sum(f_k)`.
+
+  It should have appropriate algorithmic and caching so that the
+  overall time complexity of computing `sum(f_k)` for all `k<=l` is
+  linear in `l`.
+
+  Trick: store, for each `j`, the smallest `i<=j` such that between
+  `i` and `j` the slope is exactly `max_slope`. The point is that
+  computing the sum of the parts of `f_k` between `i` and `j` is
+  constant time. Use that incrementally to derive quickly `sum(f_k)`
+  from `sum(f_j)` for some `j<=k`.
+
+  Suggestion for a faster development cycle: experiment with this by
+  extracting the current code for `Envelope` in a separate file.
+
+- Use the above characterization and the `.sum(k)` methods to
+  implement a method `IntegerListsLex.is_empty` which terminates with
+  guaranteed result on non degenerate cases. This is essentially what
+  the current `lookahead` method does, but starting from `0` and with
+  guaranteed results thanks to the reverse smoothing.
+
+  Determine precisely the degenerate cases where `is_empty` may take
+  an arbitrarily long time (something like: the ceiling can be `0` for
+  an arbitrary long time, without a known `limit=0` and `limit_start`).
+
+  Decide on appropriate metrics to bound tightly the complexity in the
+  other cases (something around `max_length`, `max_n`, `limit_start`).
+
+  As a side product, we probably want to store for later usage the
+  information of which `n` admit a valid list, as a collection of non
+  overlapping intervals. Then, deciding whether there exists a valid
+  list of sum `n` for a given `n` can be achieved efficiently by
+  dichotomy.
+
+- Assuming that `l` is a prefix of a valid list, find out how to
+  determine for which `i` `l+[i]` is still a prefix of a valid list.
+
+  Potential building block: the choice of a prefix imposes more
+  constraints on the floor and ceiling later on (our former `adapt`
+  method), and we want to keep track of that. Given a prefix `l`,
+  write `f_k(l)` be the list obtained by extending `l` to a list of
+  length `k` using the floor `f_k`, with appropriate forward
+  smoothing. Same for `c_k(l)`. Write `I_k(l) = [sum(f_k(l)),
+  sum(c_k(l))]`.
+
+  Now, `l` is a prefix of a valid list if one of the `I_k(l)`
+  intersect `[min_sum, max_sum]`. So, while increasing the length of
+  `l` we want to do something like incrementally adapting the sequence
+  of intervals `I_k(l)` to always make sure we stay within one of
+  them.
+
+- Use this to reimplement `lookahead(self)` implementing the above,
+  with a guaranteed result and good complexity. And if at all possible
+  a constant time complexity when the constraints are simple
+  (e.g. `floor=0`, ...).
 
   This method should support `_current_list=[]` as well.
-
-  This method should store as much information as relevant to avoid
-  later recomputation for lower nodes in the tree. A minima, this
-  could possibly return/store a range for the next value, removing the
-  need for a separate `_m_interval` method.
 
 - Update `next` accordingly (the logic should be slightly simpler
   thanks to the handling of the empty prefix).
 
+- If not implemented elsewhere: let the constructor accept a prefix as
+  input, to start the iteration from there. Derive a `next` method as
+  a side effect.
+
 - Remove `integer_list_old` at the final stage.
+
``````

