# Issue 18604: Computing the matching polynomial

archive/issues_018367.json:
```json
{
    "body": "**Disclaimer**: implementing a cache whose keys are (isomorphism type of) graphs and values are some invariant is a *bad* idea. See [comment:1](#comment%3A1) below.\n\nOriginal suggestion:\n\n    At this point I am not in the right state to include this improvement in Sage but I am leaving it here for the future or if someone else is bored.\n\n    Much in the same way as with the chromatic polynomial (as discussed on #14529) one can improve the computation of the matching polynomial with use of caching.\n\n```\nsage: G = graphs.DodecahedralGraph()\nsage: %timeit G.matching_polynomial()\n100 loops, best of 3: 1.97 ms per loop\nsage: %timeit matchpoly(G)\n1 loops, best of 3: 723 \u00b5s per loop\n```\n    The implementation is the usual one though I suppose it makes sense to use this directly in the Cython file.\n\n```\ndef matchpoly(G):\n    \n    global cache \n\n    s = tuple(sorted(G.canonical_label().edges(labels=False)))\n\n    if s in cache:\n        return cache[s]\n    if not G.is_connected():\n        return prod([matchpoly(C) for C in G.connected_components_subgraphs()])\n\n    R = ZZ['x']\n    x = R.gen()\n    \n    if G.size() == 0:\n        return x^G.order()\n\n    u,v = G.edge_iterator(labels=False).next()\n        \n    H = G.copy()\n\n    H.delete_edge(u,v)\n    p = matchpoly(H)\n\n    H.delete_vertices([u,v])\n\n    ret = p - matchpoly(H)\n    \n    cache[s] = ret \n\n    return ret \n```\n\n**CC:**  @nathanncohen @videlec\n\n**Reviewer:** Vincent Delecroix\n\nIssue created by migration from https://trac.sagemath.org/ticket/18604\n\n",
    "closed_at": "2015-07-17T20:08:54Z",
    "created_at": "2015-06-04T07:40:56Z",
    "labels": [
        "component: graph theory",
        "enhancement",
        "duplicate"
    ],
    "title": "Computing the matching polynomial",
    "type": "issue",
    "url": "https://github.com/sagemath/sage/issues/18604",
    "user": "https://trac.sagemath.org/admin/accounts/users/azi"
}
```
**Disclaimer**: implementing a cache whose keys are (isomorphism type of) graphs and values are some invariant is a *bad* idea. See [comment:1](#comment%3A1) below.

Original suggestion:

    At this point I am not in the right state to include this improvement in Sage but I am leaving it here for the future or if someone else is bored.

    Much in the same way as with the chromatic polynomial (as discussed on #14529) one can improve the computation of the matching polynomial with use of caching.

```
sage: G = graphs.DodecahedralGraph()
sage: %timeit G.matching_polynomial()
100 loops, best of 3: 1.97 ms per loop
sage: %timeit matchpoly(G)
1 loops, best of 3: 723 µs per loop
```
    The implementation is the usual one though I suppose it makes sense to use this directly in the Cython file.

```
def matchpoly(G):
    
    global cache 

    s = tuple(sorted(G.canonical_label().edges(labels=False)))

    if s in cache:
        return cache[s]
    if not G.is_connected():
        return prod([matchpoly(C) for C in G.connected_components_subgraphs()])

    R = ZZ['x']
    x = R.gen()
    
    if G.size() == 0:
        return x^G.order()

    u,v = G.edge_iterator(labels=False).next()
        
    H = G.copy()

    H.delete_edge(u,v)
    p = matchpoly(H)

    H.delete_vertices([u,v])

    ret = p - matchpoly(H)
    
    cache[s] = ret 

    return ret 
```

**CC:**  @nathanncohen @videlec

**Reviewer:** Vincent Delecroix

Issue created by migration from https://trac.sagemath.org/ticket/18604





---

archive/issue_comments_261190.json:
```json
{
    "body": "<a id='comment:1'></a>\nHi,\n\nYour proposition is far from being a computational improvement. Caching the values of all possible graphs results in using a lot of memory. Moreover, for most graphs your proposition would be slower (because you call for canonical labels).\n\nFor very symmetric graph of a reasonable size your function is already slower\n\n```\nsage: G = graphs.GridGraph((5,7))\nsage: %time p = G.matching_polynomial()\nCPU times: user 15.5 s, sys: 0 ns, total: 15.5 s\nsage: %time p = matchpoly(G)\nCPU times: user 18.6 s, sys: 4 ms, total: 18.6 s\nWall time: 18.6 s\n```\nAnd it is **infinitely** slower on random graphs\n\n```\nsage: G = graphs.RandomGNP(28, 5/28)\nsage: %time p = G.matching_polynomial()\nCPU times: user 3.36 s, sys: 0 ns, total: 3.36 s\nWall time: 3.36 s\nsage: %runfile test.py\nsage: %time p = matchpoly(G)\nCPU times: user 2min 14s, sys: 224 ms, total: 2min 14s\nWall time: 2min 14s\n```\nOf course the next call would be faster but I do not know anybody who will call twice an expensive function.\n\nI propose to just close this ticket as a won't fix and emphasize in the description that caching is of no help here! If you care about the computation of matching polynomial you can have a look at #17921.\n\nVincent",
    "created_at": "2015-06-08T08:12:50Z",
    "issue": "https://github.com/sagemath/sage/issues/18604",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/18604#issuecomment-261190",
    "user": "https://github.com/videlec"
}
```

<a id='comment:1'></a>
Hi,

Your proposition is far from being a computational improvement. Caching the values of all possible graphs results in using a lot of memory. Moreover, for most graphs your proposition would be slower (because you call for canonical labels).

For very symmetric graph of a reasonable size your function is already slower

```
sage: G = graphs.GridGraph((5,7))
sage: %time p = G.matching_polynomial()
CPU times: user 15.5 s, sys: 0 ns, total: 15.5 s
sage: %time p = matchpoly(G)
CPU times: user 18.6 s, sys: 4 ms, total: 18.6 s
Wall time: 18.6 s
```
And it is **infinitely** slower on random graphs

```
sage: G = graphs.RandomGNP(28, 5/28)
sage: %time p = G.matching_polynomial()
CPU times: user 3.36 s, sys: 0 ns, total: 3.36 s
Wall time: 3.36 s
sage: %runfile test.py
sage: %time p = matchpoly(G)
CPU times: user 2min 14s, sys: 224 ms, total: 2min 14s
Wall time: 2min 14s
```
Of course the next call would be faster but I do not know anybody who will call twice an expensive function.

I propose to just close this ticket as a won't fix and emphasize in the description that caching is of no help here! If you care about the computation of matching polynomial you can have a look at #17921.

Vincent



---

archive/issue_comments_261191.json:
```json
{
    "body": "<a id='comment:2'></a>\nHey there,\n\nthanks for having a look! I am really surprised about this outcome. The same idea is used for the Tutte polynomial and is a solid improvement. As tested on the Dodecahderal graph  it seemed like it makes sense. I guess cache efficiency comes from edge contractions not vertex deletions?\n\nThat said I suggest we close this down (can't find the option on my side?)\n\nJernej",
    "created_at": "2015-06-08T16:01:33Z",
    "issue": "https://github.com/sagemath/sage/issues/18604",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/18604#issuecomment-261191",
    "user": "https://trac.sagemath.org/admin/accounts/users/azi"
}
```

<a id='comment:2'></a>
Hey there,

thanks for having a look! I am really surprised about this outcome. The same idea is used for the Tutte polynomial and is a solid improvement. As tested on the Dodecahderal graph  it seemed like it makes sense. I guess cache efficiency comes from edge contractions not vertex deletions?

That said I suggest we close this down (can't find the option on my side?)

Jernej



---

archive/issue_comments_261192.json:
```json
{
    "body": "**Reviewer:** Vincent Delecroix",
    "created_at": "2015-06-08T16:14:21Z",
    "issue": "https://github.com/sagemath/sage/issues/18604",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/18604#issuecomment-261192",
    "user": "https://github.com/videlec"
}
```

**Reviewer:** Vincent Delecroix



---

archive/issue_events_167315.json:
```json
{
    "actor": "https://github.com/videlec",
    "created_at": "2015-06-08T16:14:21Z",
    "event": "labeled",
    "issue": "https://github.com/sagemath/sage/issues/18604",
    "label": "needs review",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sage/issues/18604#event-167315"
}
```



---

archive/issue_comments_261193.json:
```json
{
    "body": "**Description changed:**\n``````diff\n--- \n+++ \n@@ -1,8 +1,10 @@\n-Hey there!\n+**Disclaimer**: implementing a cache whose keys are (isomorphism type of) graphs and values are some invariant is a *bad* idea. See [comment:1](#comment%3A1) below.\n \n-At this point I am not in the right state to include this improvement in Sage but I am leaving it here for the future or if someone else is bored.\n+Original suggestion:\n \n-Much in the same way as with the chromatic polynomial (as discussed on #14529) one can improve the computation of the matching polynomial with use of caching.\n+    At this point I am not in the right state to include this improvement in Sage but I am leaving it here for the future or if someone else is bored.\n+\n+    Much in the same way as with the chromatic polynomial (as discussed on #14529) one can improve the computation of the matching polynomial with use of caching.\n \n ```\n sage: G = graphs.DodecahedralGraph()\n@@ -11,8 +13,7 @@\n sage: %timeit matchpoly(G)\n 1 loops, best of 3: 723 \u00b5s per loop\n ```\n-\n-The implementation is the usual one though I suppose it makes sense to use this directly in the Cython file.\n+    The implementation is the usual one though I suppose it makes sense to use this directly in the Cython file.\n \n ```\n def matchpoly(G):\n@@ -47,5 +48,3 @@\n \n     return ret \n ```\n-\n-\n``````\n",
    "created_at": "2015-06-08T16:14:21Z",
    "issue": "https://github.com/sagemath/sage/issues/18604",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/18604#issuecomment-261193",
    "user": "https://github.com/videlec"
}
```

**Description changed:**
``````diff
--- 
+++ 
@@ -1,8 +1,10 @@
-Hey there!
+**Disclaimer**: implementing a cache whose keys are (isomorphism type of) graphs and values are some invariant is a *bad* idea. See [comment:1](#comment%3A1) below.
 
-At this point I am not in the right state to include this improvement in Sage but I am leaving it here for the future or if someone else is bored.
+Original suggestion:
 
-Much in the same way as with the chromatic polynomial (as discussed on #14529) one can improve the computation of the matching polynomial with use of caching.
+    At this point I am not in the right state to include this improvement in Sage but I am leaving it here for the future or if someone else is bored.
+
+    Much in the same way as with the chromatic polynomial (as discussed on #14529) one can improve the computation of the matching polynomial with use of caching.
 
 ```
 sage: G = graphs.DodecahedralGraph()
@@ -11,8 +13,7 @@
 sage: %timeit matchpoly(G)
 1 loops, best of 3: 723 µs per loop
 ```
-
-The implementation is the usual one though I suppose it makes sense to use this directly in the Cython file.
+    The implementation is the usual one though I suppose it makes sense to use this directly in the Cython file.
 
 ```
 def matchpoly(G):
@@ -47,5 +48,3 @@
 
     return ret 
 ```
-
-
``````




---

archive/issue_events_167316.json:
```json
{
    "actor": "https://github.com/videlec",
    "created_at": "2015-06-08T16:14:21Z",
    "event": "demilestoned",
    "issue": "https://github.com/sagemath/sage/issues/18604",
    "milestone": "sage-6.8",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sage/issues/18604#event-167316"
}
```



---

archive/issue_comments_261194.json:
```json
{
    "body": "<a id='comment:3'></a>\nHello,\n\nReplying to [azi](#comment%3A2):\n> thanks for having a look! I am really surprised about this outcome. The same idea is used for the Tutte polynomial and is a solid improvement. As tested on the Dodecahderal graph  it seemed like it makes sense. I guess cache efficiency comes from edge contractions not vertex deletions?\n\nWhat do you mean by \"solid improvement\"? Are you sure it is faster to use caching there? Did you do serious benchmarking with and without? I am very curious about that.\n\n> That said I suggest we close this down (can't find the option on my side?)\n\nAll right.\n\nVincent",
    "created_at": "2015-06-08T16:14:21Z",
    "issue": "https://github.com/sagemath/sage/issues/18604",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/18604#issuecomment-261194",
    "user": "https://github.com/videlec"
}
```

<a id='comment:3'></a>
Hello,

Replying to [azi](#comment%3A2):
> thanks for having a look! I am really surprised about this outcome. The same idea is used for the Tutte polynomial and is a solid improvement. As tested on the Dodecahderal graph  it seemed like it makes sense. I guess cache efficiency comes from edge contractions not vertex deletions?

What do you mean by "solid improvement"? Are you sure it is faster to use caching there? Did you do serious benchmarking with and without? I am very curious about that.

> That said I suggest we close this down (can't find the option on my side?)

All right.

Vincent



---

archive/issue_comments_261195.json:
```json
{
    "body": "<a id='comment:4'></a>\nMore precisely this is what I get (with caching):\n\n```\nsage: %time p = G.tutte_polynomial()\nCPU times: user 184 ms, sys: 8 ms, total: 192 ms\nWall time: 186 ms\nsage: G = graphs.RandomGNP(14, 0.2)\nsage: %time p = G.tutte_polynomial()\nCPU times: user 16 ms, sys: 0 ns, total: 16 ms\nWall time: 16 ms\nsage: G = graphs.RandomGNP(14, 0.2)\nsage: %time p = G.tutte_polynomial()\nCPU times: user 80 ms, sys: 4 ms, total: 84 ms\nWall time: 76.7 ms\nsage: G = graphs.RandomGNP(14, 0.2)\nsage: %time p = G.tutte_polynomial()\nCPU times: user 84 ms, sys: 8 ms, total: 92 ms\nWall time: 83.8 ms\nsage: G = graphs.RandomGNP(14, 0.2)\nsage: %time p = G.tutte_polynomial()\nCPU times: user 656 ms, sys: 4 ms, total: 660 ms\nWall time: 652 ms\nsage: %time p = G.tutte_polynomial()\nCPU times: user 740 ms, sys: 0 ns, total: 740 ms\nWall time: 734 ms\n```\n\nwithout caching (i.e. redefining `def _cached(func)` as `return func`):\n\n```\nsage: G = graphs.RandomGNP(14, 0.2)\nsage: %time p = G.tutte_polynomial()\nCPU times: user 180 ms, sys: 24 ms, total: 204 ms\nWall time: 194 ms\nsage: G = graphs.RandomGNP(14, 0.2)\nsage: %time p = G.tutte_polynomial()\nCPU times: user 12 ms, sys: 0 ns, total: 12 ms\nWall time: 13.5 ms\nsage: G = graphs.RandomGNP(14, 0.2)\nsage: %time p = G.tutte_polynomial()\nCPU times: user 16 ms, sys: 4 ms, total: 20 ms\nWall time: 19.5 ms\nsage: G = graphs.RandomGNP(14, 0.2)\nsage: %time p = G.tutte_polynomial()\nCPU times: user 28 ms, sys: 0 ns, total: 28 ms\nWall time: 27.1 ms\nsage: G = graphs.RandomGNP(14, 0.2)\nsage: %time p = G.tutte_polynomial()\nCPU times: user 80 ms, sys: 4 ms, total: 84 ms\nWall time: 75.8 ms\nsage: G = graphs.RandomGNP(14, 0.2)\nsage: %time p = G.tutte_polynomial()\nCPU times: user 8 ms, sys: 0 ns, total: 8 ms\nWall time: 7.01 ms\nsage: G = graphs.RandomGNP(14, 0.2)\nsage: %time p = G.tutte_polynomial()\nCPU times: user 44 ms, sys: 0 ns, total: 44 ms\nWall time: 39.1 ms\n```\n\nSo I wonder where is your \"solid improvement\"!?\n\nVincent",
    "created_at": "2015-06-08T16:20:25Z",
    "issue": "https://github.com/sagemath/sage/issues/18604",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/18604#issuecomment-261195",
    "user": "https://github.com/videlec"
}
```

<a id='comment:4'></a>
More precisely this is what I get (with caching):

```
sage: %time p = G.tutte_polynomial()
CPU times: user 184 ms, sys: 8 ms, total: 192 ms
Wall time: 186 ms
sage: G = graphs.RandomGNP(14, 0.2)
sage: %time p = G.tutte_polynomial()
CPU times: user 16 ms, sys: 0 ns, total: 16 ms
Wall time: 16 ms
sage: G = graphs.RandomGNP(14, 0.2)
sage: %time p = G.tutte_polynomial()
CPU times: user 80 ms, sys: 4 ms, total: 84 ms
Wall time: 76.7 ms
sage: G = graphs.RandomGNP(14, 0.2)
sage: %time p = G.tutte_polynomial()
CPU times: user 84 ms, sys: 8 ms, total: 92 ms
Wall time: 83.8 ms
sage: G = graphs.RandomGNP(14, 0.2)
sage: %time p = G.tutte_polynomial()
CPU times: user 656 ms, sys: 4 ms, total: 660 ms
Wall time: 652 ms
sage: %time p = G.tutte_polynomial()
CPU times: user 740 ms, sys: 0 ns, total: 740 ms
Wall time: 734 ms
```

without caching (i.e. redefining `def _cached(func)` as `return func`):

```
sage: G = graphs.RandomGNP(14, 0.2)
sage: %time p = G.tutte_polynomial()
CPU times: user 180 ms, sys: 24 ms, total: 204 ms
Wall time: 194 ms
sage: G = graphs.RandomGNP(14, 0.2)
sage: %time p = G.tutte_polynomial()
CPU times: user 12 ms, sys: 0 ns, total: 12 ms
Wall time: 13.5 ms
sage: G = graphs.RandomGNP(14, 0.2)
sage: %time p = G.tutte_polynomial()
CPU times: user 16 ms, sys: 4 ms, total: 20 ms
Wall time: 19.5 ms
sage: G = graphs.RandomGNP(14, 0.2)
sage: %time p = G.tutte_polynomial()
CPU times: user 28 ms, sys: 0 ns, total: 28 ms
Wall time: 27.1 ms
sage: G = graphs.RandomGNP(14, 0.2)
sage: %time p = G.tutte_polynomial()
CPU times: user 80 ms, sys: 4 ms, total: 84 ms
Wall time: 75.8 ms
sage: G = graphs.RandomGNP(14, 0.2)
sage: %time p = G.tutte_polynomial()
CPU times: user 8 ms, sys: 0 ns, total: 8 ms
Wall time: 7.01 ms
sage: G = graphs.RandomGNP(14, 0.2)
sage: %time p = G.tutte_polynomial()
CPU times: user 44 ms, sys: 0 ns, total: 44 ms
Wall time: 39.1 ms
```

So I wonder where is your "solid improvement"!?

Vincent



---

archive/issue_comments_261196.json:
```json
{
    "body": "<a id='comment:5'></a>\nReplying to [@videlec](#comment%3A3):\n> Hello,\n> \n> Replying to [azi](#comment%3A2):\n> > thanks for having a look! I am really surprised about this outcome. The same idea is used for the Tutte polynomial and is a solid improvement. As tested on the Dodecahderal graph  it seemed like it makes sense. I guess cache efficiency comes from edge contractions not vertex deletions?\n\n> \n> What do you mean by \"solid improvement\"? Are you sure it is faster to use caching there? Did you do serious benchmarking with and without? I am very curious about that.\n\nYep the improvement in such cases is well know. There is actually even a paper that describes this idea. See the paper cited  here http://homepages.ecs.vuw.ac.nz/~djp/tutte/\n> \n> > That said I suggest we close this down (can't find the option on my side?)\n\n> \n> All right.\n> \n> Vincent",
    "created_at": "2015-06-08T16:22:45Z",
    "issue": "https://github.com/sagemath/sage/issues/18604",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/18604#issuecomment-261196",
    "user": "https://trac.sagemath.org/admin/accounts/users/azi"
}
```

<a id='comment:5'></a>
Replying to [@videlec](#comment%3A3):
> Hello,
> 
> Replying to [azi](#comment%3A2):
> > thanks for having a look! I am really surprised about this outcome. The same idea is used for the Tutte polynomial and is a solid improvement. As tested on the Dodecahderal graph  it seemed like it makes sense. I guess cache efficiency comes from edge contractions not vertex deletions?

> 
> What do you mean by "solid improvement"? Are you sure it is faster to use caching there? Did you do serious benchmarking with and without? I am very curious about that.

Yep the improvement in such cases is well know. There is actually even a paper that describes this idea. See the paper cited  here http://homepages.ecs.vuw.ac.nz/~djp/tutte/
> 
> > That said I suggest we close this down (can't find the option on my side?)

> 
> All right.
> 
> Vincent



---

archive/issue_comments_261197.json:
```json
{
    "body": "<a id='comment:6'></a>\nI see... Thanks for the link. Apparently, Sage is not smart enough to make a difference here ;-)\n\nVincent",
    "created_at": "2015-06-08T16:26:03Z",
    "issue": "https://github.com/sagemath/sage/issues/18604",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/18604#issuecomment-261197",
    "user": "https://github.com/videlec"
}
```

<a id='comment:6'></a>
I see... Thanks for the link. Apparently, Sage is not smart enough to make a difference here ;-)

Vincent



---

archive/issue_comments_261198.json:
```json
{
    "body": "<a id='comment:7'></a>\nYep. Perhaps one of the bottlenecks is that canonical forms in Sage is (currently) written in Python and the algorithm itself is not the most efficient (as far as I've compared with say nauty)",
    "created_at": "2015-06-08T16:53:53Z",
    "issue": "https://github.com/sagemath/sage/issues/18604",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/18604#issuecomment-261198",
    "user": "https://trac.sagemath.org/admin/accounts/users/azi"
}
```

<a id='comment:7'></a>
Yep. Perhaps one of the bottlenecks is that canonical forms in Sage is (currently) written in Python and the algorithm itself is not the most efficient (as far as I've compared with say nauty)



---

archive/issue_comments_261199.json:
```json
{
    "body": "<a id='comment:8'></a>\nSo perhaps this ticket would still makes sense?",
    "created_at": "2015-06-09T05:05:33Z",
    "issue": "https://github.com/sagemath/sage/issues/18604",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/18604#issuecomment-261199",
    "user": "https://github.com/videlec"
}
```

<a id='comment:8'></a>
So perhaps this ticket would still makes sense?



---

archive/issue_comments_261200.json:
```json
{
    "body": "<a id='comment:9'></a>\nIn some sense it does but one would really have to be careful in designing this properly. \n\nYou argued that on random graphs on 14 vertices is less efficient and if we take that as our base benchmark then it may not be worth it.\n\nIn general I think it can be made in a worthwhile improvement especially for larger graphs and provided that we use bliss or nauty.",
    "created_at": "2015-06-09T19:34:00Z",
    "issue": "https://github.com/sagemath/sage/issues/18604",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/18604#issuecomment-261200",
    "user": "https://trac.sagemath.org/admin/accounts/users/azi"
}
```

<a id='comment:9'></a>
In some sense it does but one would really have to be careful in designing this properly. 

You argued that on random graphs on 14 vertices is less efficient and if we take that as our base benchmark then it may not be worth it.

In general I think it can be made in a worthwhile improvement especially for larger graphs and provided that we use bliss or nauty.



---

archive/issue_comments_261201.json:
```json
{
    "body": "<a id='comment:10'></a>\nDoes this ticket still needs a review? #17921 also claims to make this routine faster.",
    "created_at": "2015-06-28T19:07:22Z",
    "issue": "https://github.com/sagemath/sage/issues/18604",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/18604#issuecomment-261201",
    "user": "https://github.com/nathanncohen"
}
```

<a id='comment:10'></a>
Does this ticket still needs a review? #17921 also claims to make this routine faster.



---

archive/issue_events_167317.json:
```json
{
    "actor": "https://github.com/rwst",
    "created_at": "2015-06-29T15:09:14Z",
    "event": "unlabeled",
    "issue": "https://github.com/sagemath/sage/issues/18604",
    "label": "needs review",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sage/issues/18604#event-167317"
}
```



---

archive/issue_events_167318.json:
```json
{
    "actor": "https://github.com/rwst",
    "created_at": "2015-06-29T15:09:14Z",
    "event": "labeled",
    "issue": "https://github.com/sagemath/sage/issues/18604",
    "label": "positive review",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sage/issues/18604#event-167318"
}
```



---

archive/issue_comments_261202.json:
```json
{
    "body": "<a id='comment:11'></a>\nThe algorithm in #17921 has a speed factor of >1000x for the bigger examples given here, so this is a complete different game. There is the original Sage algorithm if one needs a check.",
    "created_at": "2015-06-29T15:09:14Z",
    "issue": "https://github.com/sagemath/sage/issues/18604",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/18604#issuecomment-261202",
    "user": "https://github.com/rwst"
}
```

<a id='comment:11'></a>
The algorithm in #17921 has a speed factor of >1000x for the bigger examples given here, so this is a complete different game. There is the original Sage algorithm if one needs a check.



---

archive/issue_events_167319.json:
```json
{
    "actor": "https://github.com/vbraun",
    "created_at": "2015-07-17T20:08:54Z",
    "event": "unlabeled",
    "issue": "https://github.com/sagemath/sage/issues/18604",
    "label": "positive review",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sage/issues/18604#event-167319"
}
```



---

archive/issue_events_167320.json:
```json
{
    "actor": "https://github.com/vbraun",
    "created_at": "2015-07-17T20:08:54Z",
    "event": "closed",
    "issue": "https://github.com/sagemath/sage/issues/18604",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sage/issues/18604#event-167320"
}
```



---

archive/issue_events_167321.json:
```json
{
    "actor": "https://github.com/vbraun",
    "created_at": "2015-07-17T20:08:54Z",
    "event": "labeled",
    "issue": "https://github.com/sagemath/sage/issues/18604",
    "label": "duplicate",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sage/issues/18604#event-167321"
}
```
