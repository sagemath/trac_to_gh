# Issue 27906: Minimal kernel bases

archive/issues_027906.json:
```json
{
    "body": "CC:  @romainlebreton @johanrosenkilde @ke456 @vneiger\n\nKeywords: polynomial matrix; kernel basis; approximant basis\n\nNew functionalities:\n\n    computation of shifted minimal kernel bases (e.g. via approximant bases at large order and/or via Zhou-Labahn-Storjohann 2012),\n    verification that a matrix is a shifted minimal approximant basis. \n\nThis should be done in a general context:\n\n    accepting non-uniform orders and non-uniform shifts,\n    allowing to work row-wise or column-wise,\n    offering the possibility of obtaining the canonical basis (that is, the one in shifted Popov form).\n\nIssue created by migration from https://trac.sagemath.org/ticket/28143\n\n",
    "created_at": "2019-07-09T12:39:17Z",
    "labels": [
        "algebra",
        "major",
        "enhancement"
    ],
    "milestone": "https://github.com/sagemath/sagetest/milestones/sage-9.3",
    "title": "Minimal kernel bases",
    "type": "issue",
    "url": "https://github.com/sagemath/sagetest/issues/27906",
    "user": "@vneiger"
}
```
CC:  @romainlebreton @johanrosenkilde @ke456 @vneiger

Keywords: polynomial matrix; kernel basis; approximant basis

New functionalities:

    computation of shifted minimal kernel bases (e.g. via approximant bases at large order and/or via Zhou-Labahn-Storjohann 2012),
    verification that a matrix is a shifted minimal approximant basis. 

This should be done in a general context:

    accepting non-uniform orders and non-uniform shifts,
    allowing to work row-wise or column-wise,
    offering the possibility of obtaining the canonical basis (that is, the one in shifted Popov form).

Issue created by migration from https://trac.sagemath.org/ticket/28143





---

archive/issue_comments_394054.json:
```json
{
    "body": "Great that you're picking this up! Some initial comments:\n\n* There is already `left_kernel` and `right_kernel` which move into the fraction field and return a module. Perhaps the function here should be called `left_kernel_basis`, without the explicit \"minimal\". This is under the assumption that whenever a user asks for (a basis of) the (left/right) kernel of an `F[x]` matrix, he should/would invariably prefer a reduced basis of the kernel, represented over `F[x]` again. Note similarly that when you ask for a `left_kernel().basis_matrix()` of a `Q`-matrix, you get one in rref form.\n\n* Row-wise/Column-wise: Handled by optional arguments like in `weak_popov_form()` and friends, I presume?\n\n* We don't yet have `M.approximant_basis()` or some such. If following the first suggested approach for implementing this ticket's functionality, then we should add that as a stand-alone method.\n\n* Note that we don't yet have a `M.popov_form()` method. If we already had that, then the ticket's last suggested functionality really becomes a question of optimisation rather than added functionality.\n\n* \"verification that a matrix is a shifted minimal kernel basis.\" I'm not sure I understand what this means. Is it a method on a matrix `M` to ask whether another given matrix `K` is a left/right kernel basis (minimality is just row/col reduced, right?). Doesn't this boil down to `M * K == 0 and K.is_column_reduced() and K.is_saturated()`? We don't have `is_saturated()` right now, of course.",
    "created_at": "2019-07-30T09:45:00Z",
    "issue": "https://github.com/sagemath/sagetest/issues/27906",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/27906#issuecomment-394054",
    "user": "@johanrosenkilde"
}
```

Great that you're picking this up! Some initial comments:

* There is already `left_kernel` and `right_kernel` which move into the fraction field and return a module. Perhaps the function here should be called `left_kernel_basis`, without the explicit "minimal". This is under the assumption that whenever a user asks for (a basis of) the (left/right) kernel of an `F[x]` matrix, he should/would invariably prefer a reduced basis of the kernel, represented over `F[x]` again. Note similarly that when you ask for a `left_kernel().basis_matrix()` of a `Q`-matrix, you get one in rref form.

* Row-wise/Column-wise: Handled by optional arguments like in `weak_popov_form()` and friends, I presume?

* We don't yet have `M.approximant_basis()` or some such. If following the first suggested approach for implementing this ticket's functionality, then we should add that as a stand-alone method.

* Note that we don't yet have a `M.popov_form()` method. If we already had that, then the ticket's last suggested functionality really becomes a question of optimisation rather than added functionality.

* "verification that a matrix is a shifted minimal kernel basis." I'm not sure I understand what this means. Is it a method on a matrix `M` to ask whether another given matrix `K` is a left/right kernel basis (minimality is just row/col reduced, right?). Doesn't this boil down to `M * K == 0 and K.is_column_reduced() and K.is_saturated()`? We don't have `is_saturated()` right now, of course.



---

archive/issue_comments_394055.json:
```json
{
    "body": "Ticket retargeted after milestone closed",
    "created_at": "2019-12-30T14:48:17Z",
    "issue": "https://github.com/sagemath/sagetest/issues/27906",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/27906#issuecomment-394055",
    "user": "@embray"
}
```

Ticket retargeted after milestone closed



---

archive/issue_comments_394056.json:
```json
{
    "body": "Branch pushed to git repo; I updated commit sha1. New commits:",
    "created_at": "2020-04-03T11:54:14Z",
    "issue": "https://github.com/sagemath/sagetest/issues/27906",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/27906#issuecomment-394056",
    "user": "git"
}
```

Branch pushed to git repo; I updated commit sha1. New commits:



---

archive/issue_comments_394057.json:
```json
{
    "body": "Hi,\n\nThanks Johan for your input.\n\nThe ticket functionalities are now written. Can you please check if you see any issue?\n\nSince `minimal_approximant_basis` now already exists (answering your third point) I chose to follow the same naming, i.e. `minimal_kernel_basis` (answering your first point). Still, these names can be discussed and we could get rid of `minimal_` in both.\n\nYour second and fourth points: yes, this is right. Also, since the implemented `minimal_approximant_basis` algorithm already allows to return the Popov form (with small overhead compared to weak Popov), and since the chosen kernel basis algorithm is essentially a call to that algorithm at sufficiently high order, it made sense to do it this way rather computing a weak Popov kernel basis and then calling another normalization procedure (which indeed is not yet written, this is clearly a missing basic feature).\n\nFor your last point: yes, this is right. I implemented this with plain multiplication for `M*K==0` (no Freivalds or such), and for the saturation I compute a HNF basis of the column space: this is the identity matrix iff the (full rank) matrix is row-saturated. Here as well, a Popov form algorithm would also work (instead of HNF) and would probably be somewhat faster.",
    "created_at": "2020-04-03T12:06:11Z",
    "issue": "https://github.com/sagemath/sagetest/issues/27906",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/27906#issuecomment-394057",
    "user": "@vneiger"
}
```

Hi,

Thanks Johan for your input.

The ticket functionalities are now written. Can you please check if you see any issue?

Since `minimal_approximant_basis` now already exists (answering your third point) I chose to follow the same naming, i.e. `minimal_kernel_basis` (answering your first point). Still, these names can be discussed and we could get rid of `minimal_` in both.

Your second and fourth points: yes, this is right. Also, since the implemented `minimal_approximant_basis` algorithm already allows to return the Popov form (with small overhead compared to weak Popov), and since the chosen kernel basis algorithm is essentially a call to that algorithm at sufficiently high order, it made sense to do it this way rather computing a weak Popov kernel basis and then calling another normalization procedure (which indeed is not yet written, this is clearly a missing basic feature).

For your last point: yes, this is right. I implemented this with plain multiplication for `M*K==0` (no Freivalds or such), and for the saturation I compute a HNF basis of the column space: this is the identity matrix iff the (full rank) matrix is row-saturated. Here as well, a Popov form algorithm would also work (instead of HNF) and would probably be somewhat faster.



---

archive/issue_comments_394058.json:
```json
{
    "body": "Set assignee to @vneiger.",
    "created_at": "2020-04-03T12:07:58Z",
    "issue": "https://github.com/sagemath/sagetest/issues/27906",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/27906#issuecomment-394058",
    "user": "@vneiger"
}
```

Set assignee to @vneiger.



---

archive/issue_comments_394059.json:
```json
{
    "body": "Changing status from new to needs_review.",
    "created_at": "2020-04-03T12:08:09Z",
    "issue": "https://github.com/sagemath/sagetest/issues/27906",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/27906#issuecomment-394059",
    "user": "@vneiger"
}
```

Changing status from new to needs_review.



---

archive/issue_comments_394060.json:
```json
{
    "body": "Batch modifying tickets that will likely not be ready for 9.1, based on a review of the ticket title, branch/review status, and last modification date.",
    "created_at": "2020-04-14T19:41:51Z",
    "issue": "https://github.com/sagemath/sagetest/issues/27906",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/27906#issuecomment-394060",
    "user": "@mkoeppe"
}
```

Batch modifying tickets that will likely not be ready for 9.1, based on a review of the ticket title, branch/review status, and last modification date.



---

archive/issue_comments_394061.json:
```json
{
    "body": "Replying to [comment:4 jsrn]:\n> Great that you're picking this up! Some initial comments:\n> \n> * There is already `left_kernel` and `right_kernel` which move into the fraction field and return a module. Perhaps the function here should be called `left_kernel_basis`, without the explicit \"minimal\". This is under the assumption that whenever a user asks for (a basis of) the (left/right) kernel of an `F[x]` matrix, he should/would invariably prefer a reduced basis of the kernel, represented over `F[x]` again. Note similarly that when you ask for a `left_kernel().basis_matrix()` of a `Q`-matrix, you get one in rref form.\nI guess we could make use of the new function to implement the core of `left_kernel` (just need to make a module from the computed basis matrix, if I follow correctly). One advantage is that we have freedom of the shift here: we could take it as the one yielding best performance, i.e. the row degrees of the input matrix.\n\n> * Row-wise/Column-wise: Handled by optional arguments like in `weak_popov_form()` and friends, I presume?\nYes, this is how it is done.\n\n> * We don't yet have `M.approximant_basis()` or some such. If following the first suggested approach for implementing this ticket's functionality, then we should add that as a stand-alone method.\nWe do have `minimal_approximant_basis` , indeed the first approach directly builds upon this. The second approach was not incorporated in the end since it did not provide sufficient gains (we would need faster polynomial matrix multiplication for it to make sense).\n\n> * Note that we don't yet have a `M.popov_form()` method. If we already had that, then the ticket's last suggested functionality really becomes a question of optimisation rather than added functionality.\nIndeed. By the way, writing a Popov form algorithm should be done; it is not much to do since there is already a weak Popov form algorithm.\n> \n> * \"verification that a matrix is a shifted minimal kernel basis.\" I'm not sure I understand what this means. Is it a method on a matrix `M` to ask whether another given matrix `K` is a left/right kernel basis (minimality is just row/col reduced, right?). Doesn't this boil down to `M * K == 0 and K.is_column_reduced() and K.is_saturated()`? We don't have `is_saturated()` right now, of course.\n\nYes indeed. It boils down to this, but I think it is convenient to have a method to check. This was implemented using the characterization of being saturated as having unimodular column bases; this is checked by verifying that the column Hermite form is the identity matrix (ideally, once the Popov form algorithm exists, we should use a column Popov form for likely better performance in usual cases).",
    "created_at": "2020-05-05T16:25:36Z",
    "issue": "https://github.com/sagemath/sagetest/issues/27906",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/27906#issuecomment-394061",
    "user": "@vneiger"
}
```

Replying to [comment:4 jsrn]:
> Great that you're picking this up! Some initial comments:
> 
> * There is already `left_kernel` and `right_kernel` which move into the fraction field and return a module. Perhaps the function here should be called `left_kernel_basis`, without the explicit "minimal". This is under the assumption that whenever a user asks for (a basis of) the (left/right) kernel of an `F[x]` matrix, he should/would invariably prefer a reduced basis of the kernel, represented over `F[x]` again. Note similarly that when you ask for a `left_kernel().basis_matrix()` of a `Q`-matrix, you get one in rref form.
I guess we could make use of the new function to implement the core of `left_kernel` (just need to make a module from the computed basis matrix, if I follow correctly). One advantage is that we have freedom of the shift here: we could take it as the one yielding best performance, i.e. the row degrees of the input matrix.

> * Row-wise/Column-wise: Handled by optional arguments like in `weak_popov_form()` and friends, I presume?
Yes, this is how it is done.

> * We don't yet have `M.approximant_basis()` or some such. If following the first suggested approach for implementing this ticket's functionality, then we should add that as a stand-alone method.
We do have `minimal_approximant_basis` , indeed the first approach directly builds upon this. The second approach was not incorporated in the end since it did not provide sufficient gains (we would need faster polynomial matrix multiplication for it to make sense).

> * Note that we don't yet have a `M.popov_form()` method. If we already had that, then the ticket's last suggested functionality really becomes a question of optimisation rather than added functionality.
Indeed. By the way, writing a Popov form algorithm should be done; it is not much to do since there is already a weak Popov form algorithm.
> 
> * "verification that a matrix is a shifted minimal kernel basis." I'm not sure I understand what this means. Is it a method on a matrix `M` to ask whether another given matrix `K` is a left/right kernel basis (minimality is just row/col reduced, right?). Doesn't this boil down to `M * K == 0 and K.is_column_reduced() and K.is_saturated()`? We don't have `is_saturated()` right now, of course.

Yes indeed. It boils down to this, but I think it is convenient to have a method to check. This was implemented using the characterization of being saturated as having unimodular column bases; this is checked by verifying that the column Hermite form is the identity matrix (ideally, once the Popov form algorithm exists, we should use a column Popov form for likely better performance in usual cases).



---

archive/issue_comments_394062.json:
```json
{
    "body": "Adding gh accounts in cc.",
    "created_at": "2021-02-18T20:43:20Z",
    "issue": "https://github.com/sagemath/sagetest/issues/27906",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/27906#issuecomment-394062",
    "user": "@vneiger"
}
```

Adding gh accounts in cc.



---

archive/issue_comments_394063.json:
```json
{
    "body": "Changing status from needs_review to positive_review.",
    "created_at": "2021-02-19T21:49:33Z",
    "issue": "https://github.com/sagemath/sagetest/issues/27906",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/27906#issuecomment-394063",
    "user": "@ke456"
}
```

Changing status from needs_review to positive_review.



---

archive/issue_comments_394064.json:
```json
{
    "body": "New commits:",
    "created_at": "2021-02-19T21:49:33Z",
    "issue": "https://github.com/sagemath/sagetest/issues/27906",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/27906#issuecomment-394064",
    "user": "@ke456"
}
```

New commits:



---

archive/issue_comments_394065.json:
```json
{
    "body": "The current implementation computes minimal kernel bases via approximant bases at large order, not the algorithm of Zhou-Labahn-Storjohann. It accepts non-uniform shifts, works row-wise or column-wise, and can optionally return the output in shifted Popov form.",
    "created_at": "2021-02-19T21:55:11Z",
    "issue": "https://github.com/sagemath/sagetest/issues/27906",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/27906#issuecomment-394065",
    "user": "@ke456"
}
```

The current implementation computes minimal kernel bases via approximant bases at large order, not the algorithm of Zhou-Labahn-Storjohann. It accepts non-uniform shifts, works row-wise or column-wise, and can optionally return the output in shifted Popov form.



---

archive/issue_comments_394066.json:
```json
{
    "body": "Resolution: fixed",
    "created_at": "2021-03-01T00:20:59Z",
    "issue": "https://github.com/sagemath/sagetest/issues/27906",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/27906#issuecomment-394066",
    "user": "@vbraun"
}
```

Resolution: fixed
