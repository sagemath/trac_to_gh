# Issue 32130: Replace Lazy Power Series in species directory with the new Lazy Taylor Series

Issue created by migration from https://trac.sagemath.org/ticket/32367

Original creator: @tejasvicsr1

Original creation time: 2021-08-11 16:14:19

CC:  mantepse tscrim paul zimmermann tmonteil

Keywords: LazyPowerSeries, FormalSeries, GSoC21

Replace the functionalities and add combinatorial meaning for the coefficients in the series


---

Comment by git created at 2021-08-11 20:00:08

Branch pushed to git repo; I updated commit sha1. Last 10 new commits:


---

Comment by tscrim created at 2021-08-12 00:50:19

Changing keywords from "LazyPowerSeries, FormalSeries, GSoC21" to "LazyPowerSeries, FormalSeries, gsoc2021".


---

Comment by git created at 2021-08-13 18:13:59

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2021-08-16 19:34:48

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2021-08-17 20:44:00

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2021-08-18 09:30:59

Branch pushed to git repo; I updated commit sha1. Last 10 new commits:


---

Comment by git created at 2021-08-18 09:34:20

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2021-08-24 20:18:06

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2021-08-25 18:47:36

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2022-08-11 18:36:20

Branch pushed to git repo; I updated commit sha1. Last 10 new commits:


---

Comment by git created at 2022-08-12 08:06:24

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2022-08-16 12:41:51

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by tscrim created at 2022-08-22 07:57:39

Is this ready for review?


---

Comment by mantepse created at 2022-08-22 07:59:32

No, not at all, I am working on it.

I am having slight difficulties with plethysm, but I think that I have mostly resolved these by now.


---

Comment by git created at 2022-08-24 21:11:28

Branch pushed to git repo; I updated commit sha1. Last 10 new commits:


---

Comment by git created at 2022-09-02 21:01:36

Branch pushed to git repo; I updated commit sha1. Last 10 new commits:


---

Comment by git created at 2022-09-02 21:15:50

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by mantepse created at 2022-09-02 21:17:17

Changing status from new to needs_review.


---

Comment by mantepse created at 2022-09-02 21:17:17

A small step but a giant leap!


---

Comment by tscrim created at 2022-09-02 23:16:11

From a first quick look, it seems like there are just a few small things to address:

These need at least one doctest each:

```
    def __init__(self, base_ring):
        super().__init__(base_ring, names="z")
```


This can be simplified:

```diff
-    return CIS(lambda n: _cl_term(n))
+    return CIS(_cl_term)
```


We can also use (the cached)

```diff
-base_ring(1)
+base_ring.one()
```


We no longer have a `coefficients()` method (a difference between the implementations), right? We should introduce a deprecation message for this method or add it to the lazy series. I am leaning towards adding it to the lazy series as a redirect of `self[:n]`.


---

Comment by git created at 2022-09-03 08:49:12

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by mantepse created at 2022-09-03 09:03:42

There are several failing doctests and a few hidden bugs elsewhere (found using grep LazyPowerSeries).  Trying to fix.


---

Comment by mantepse created at 2022-09-03 09:20:36

There is at least one place, where we feed the LazyPowerSeriesRing with an infinite iterator, see below.

While this is surely easy to change, shouldn't we support this, too?  Actually, I thought we did, but I cannot find it right now.

```
                # If we're here, we may not be a finite crystal.
                # In fact, we're probably infinite.
                from sage.rings.lazy_series_ring import LazyTaylorSeriesRing
                if q is None:
                    P = LazyTaylorSeriesRing(ZZ, names='q')
                else:
                    P = q.parent()
                if not isinstance(P, LazyTaylorSeriesRing):
                    raise TypeError("the parent of q must be a lazy power series ring")
                ret = P(iter_by_deg(mg))
                return ret
```



---

Comment by mantepse created at 2022-09-03 09:30:53

There is one doctest from a book which we cannot sensibly support anymore, see below.

In short:

```
  sage: L.<z> = LazyPowerSeriesRing(QQ)
  sage: C = L()
  sage: C._name = 'C'
  sage: C.define( z + C * C )
```

must become

```
  sage: L.<z> = LazyPowerSeriesRing(QQ)
  sage: C = L.undefined(valuation=1)
  sage: C.define( z + C * C )
```

Can I simply change this?  (Note that we do not support this recursive definition with valuation=0 anymore.)


```
Sage example in ./combinat.tex, line 654::

  sage: L.<z> = LazyPowerSeriesRing(QQ)

Sage example in ./combinat.tex, line 661::

  sage: C = L()
  sage: C._name = 'C'
  sage: C.define( z + C * C )

Sage example in ./combinat.tex, line 666::

  sage: [C.coefficient(i) for i in range(11)]
  [0, 1, 1, 2, 5, 14, 42, 132, 429, 1430, 4862]
```



---

Comment by mantepse created at 2022-09-03 09:37:26

Similarly, also in `src/sage/tests/books/computational-mathematics-with-sagemath/`, but `polynomes.tex`.

I think we can make `exponential` an alias, but `compute_coefficients` does not really make sense anymore.


```
  sage: L.<x> = LazyPowerSeriesRing(QQ)
  sage: lazy_exp = x.exponential(); lazy_exp
  O(1)

Sage example in ./polynomes.tex, line 2039::

  sage: lazy_exp[5]
  1/120
  sage: lazy_exp
  1 + x + 1/2*x^2 + 1/6*x^3 + 1/24*x^4 + 1/120*x^5 + O(x^6)

Sage example in ./polynomes.tex, line 2062::

  sage: f = L(1)  # the constant lazy series 1
  sage: for i in range(5):
  ....:     f = (x*f).exponential()
  ....:     f.compute_coefficients(5) # forces the computation
  ....:     print(f)                  # of the first coefficients
  1 + x + 1/2*x^2 + 1/6*x^3 + 1/24*x^4 + 1/120*x^5 + O(x^6)
  1 + x + 3/2*x^2 + 5/3*x^3 + 41/24*x^4 + 49/30*x^5 + O(x^6)
  1 + x + 3/2*x^2 + 8/3*x^3 + 101/24*x^4 + 63/10*x^5 + O(x^6)
  1 + x + 3/2*x^2 + 8/3*x^3 + 125/24*x^4 + 49/5*x^5 + O(x^6)
  1 + x + 3/2*x^2 + 8/3*x^3 + 125/24*x^4 + 54/5*x^5 + O(x^6)
```

Finally:

```
Sage example in ./polynomes.tex, line 2105::

  sage: from sage.combinat.species.series import LazyPowerSeries
  sage: f = LazyPowerSeries(L, name='f')
  sage: f.define((x*f).exponential())
  sage: f.coefficients(8)
  [1, 1, 3/2, 8/3, 125/24, 54/5, 16807/720, 16384/315]
```

(`L` is the lazy power series ring here)


---

Comment by mantepse created at 2022-09-03 09:42:05

Changing status from needs_review to needs_info.


---

Comment by tscrim created at 2022-09-03 11:15:20

I thought we also supported iterators too, but it is possible that we don’t. I don’t quite have any explicit memory of what we did other than have a discussion about how to handle them. It might have fallen through the cracks.

We can make these changes. The standard thing to do is to cc the book author(s) to let them know.

I guess we don’t have a good mechanism for finding out what is the smallest valuation for a `define()` series should make sense. I remember us talking about this for Laurent series and not knowing there is a unique solution, much less knowing what lower bound might work. The issue for the power series was we had to try and catch an infinite recursion error (which would be very bad practice because it would hide bugs). I don’t think we talked too much about other solutions. When we have one unknown function, we could take its `_approximate_order` to be a variable, e.g., `n` and take the ceiling of the smallest positive real root of `f(n) - n`, where `f` is the function that we get from the `define()` input `_approximate_order`.

Well, if we don’t want to try anything like this beforehand (or it becomes too much work), then we can simply change the test (and I would say it is better for the user to supply anyways). (That is also a very evil test. `:p`)

I think `exponential()` is a good alias to have. I would add a deprecation for `compute_coefficients()` and remove the line in the above doctest.


---

Comment by mantepse created at 2022-09-04 08:32:23

Important and somewhat urgent question:

Support for passing generators turns out to be easy, but there is a question of semantics.  If the valuation is specified, should it refer to the first term yielded by the generator, or the first non-zero term yielded by the generator.

Both is easy to achieve.

By way of example: do we want

```
sage: L.<x> = LazyLaurentSeriesRing(QQ); L(iter(NN), valuation=-3)
x^-3 + 2*x^-2 + 3*x^-1 + 4 + 5*x + 6*x^2 + O(x^3)
```

or

```
sage: L.<x> = LazyLaurentSeriesRing(QQ); L(iter(NN), valuation=-3)
x^-2 + 2*x^-1 + 3 + 4*x + 5*x^2 + 6*x^3 + O(x^4)
```


Compare with our current decisions:

```
sage: L.<x> = LazyLaurentSeriesRing(QQ); L(range(5), valuation=-3)
x^-3 + 2*x^-2 + 3*x^-1 + 4
sage: L.<x> = LazyLaurentSeriesRing(QQ); L(lambda n: n+3, valuation=-3)
x^-2 + 2*x^-1 + 3 + 4*x + 5*x^2 + 6*x^3 + O(x^4)
```



---

Comment by tscrim created at 2022-09-04 09:25:09

The first nonzero term following our statement that passing the `valuation` means the series exactly has that valuation.

We might want to do something as a safety guard of running forever (say 1000 trials) if someone does something crazy like pass

```
def zero():
    while True: yield 0
```

(This might arise more naturally if someone passes something that is not known to be exactly `0` but ends up being `0` and doing some iteration over that.)


---

Comment by git created at 2022-09-07 20:37:05

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by mantepse created at 2022-09-08 15:34:00

There are a few further minor issues.

I think that for `LazyTaylorSeries`, `LazyDirichletSeries`, `LazySymmetricFunction`, etc. we really don't want

```
sage: L.<x> = LazyTaylorSeriesRing(QQ)
sage: (x^2/(1-x)^3)[:5]
[1, 3, 6]
sage: L(lambda n: n*(n-1)/2)[:5]
[0, 0, 1, 3, 6]
```

Instead, I think that for these classes we always want to start from degree 0.
The current behaviour also breaks some doctests in the species directory.

I am also hesitant to encode a `coefficients` method with behaviour quite different from the other methods with the same name.  In particular, we have

```
    def coefficients(self):
        """
        Return the nonzero coefficients of this polynomial in a list.
        The returned list is decreasingly ordered by the term ordering
        of ``self.parent()``, i.e. the list of coefficients matches the list
        of monomials returned by
        :meth:`sage.rings.polynomial.multi_polynomial_libsingular.MPolynomial_libsingular.monomials`.

        EXAMPLES::

            sage: R.<x,y,z> = PolynomialRing(QQ,3,order='degrevlex')
            sage: f=23*x^6*y^7 + x^3*y+6*x^7*z
            sage: f.coefficients()
            [23, 6, 1]
            sage: R.<x,y,z> = PolynomialRing(QQ,3,order='lex')
            sage: f=23*x^6*y^7 + x^3*y+6*x^7*z
            sage: f.coefficients()
            [6, 23, 1]

        Test the same stuff with base ring `\ZZ` -- different implementation::

            sage: R.<x,y,z> = PolynomialRing(ZZ,3,order='degrevlex')
            sage: f=23*x^6*y^7 + x^3*y+6*x^7*z
            sage: f.coefficients()
            [23, 6, 1]
            sage: R.<x,y,z> = PolynomialRing(ZZ,3,order='lex')
            sage: f=23*x^6*y^7 + x^3*y+6*x^7*z
            sage: f.coefficients()
            [6, 23, 1]
```

As far as I can see, there is a single exception to the behaviour indicated by the doctests above, which is the definition in `multi_power_series_ring_elemnt.py`.

I could imagine returning a `lazy_list` and a list, if the support is known to be finite.  Unfortunately, for the code in species, the default behaviour is `sparse=False`, whereas in all other cases, it is `sparse=True`.

Another minor issue: for `L.<x> = LazyPowerSeriesRing(QQ)` we had `L([1,2,3])` what would now be `L([1,2], constant = 3)`.  However, I really do not want to replicate this behaviour.


---

Comment by git created at 2022-09-08 20:09:56

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2022-09-08 20:21:33

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by mantepse created at 2022-09-08 20:22:58

This last push could be moved into a separate ticket if absolutely necessary.

Apart from that, the only thing missing is a decision about the semantics of the `coefficients` function.


---

Comment by tscrim created at 2022-09-08 23:52:17

Replying to [comment:39 Martin Rubey]:
> I think that for `LazyTaylorSeries`, `LazyDirichletSeries`, `LazySymmetricFunction`, etc. we really don't want
> {{{
> sage: L.<x> = LazyTaylorSeriesRing(QQ)
> sage: (x<sup>2/(1-x)</sup>3)[:5]
> [1, 3, 6]
> sage: L(lambda n: n*(n-1)/2)[:5]
> [0, 0, 1, 3, 6]
> }}}
> Instead, I think that for these classes we always want to start from degree 0.
> The current behaviour also breaks some doctests in the species directory.

I would say that is a bug and should be fixed (which I think is what you’re saying as well).

> I am also hesitant to encode a `coefficients` method with behaviour quite different from the other methods with the same name.  In particular, we have
> {{{
>     def coefficients(self):
>         """
>         Return the nonzero coefficients of this polynomial in a list.
>         The returned list is decreasingly ordered by the term ordering
>         of ``self.parent()``, i.e. the list of coefficients matches the list
>         of monomials returned by
>         :meth:`sage.rings.polynomial.multi_polynomial_libsingular.MPolynomial_libsingular.monomials`.
> }}}
> As far as I can see, there is a single exception to the behaviour indicated by the doctests above, which is the definition in `multi_power_series_ring_elemnt.py`.

I agree with you. It’s not a bug, so we are not justified in simply changing the behavior. Although I feel a general deprecation message every time this is call would be obtrusive (and bad). I am leaning towards just making the backwards incompatible change, documenting how to get the previous behavior `[f[i] for i in range(n)]`, and dealing with the consequences, but it was used all over the examples. I can’t think of a good way out of this other than something convoluted with an extra argument. Thus, we probably just have to make the change and take our medicine.

> I could imagine returning a `lazy_list` and a list, if the support is known to be finite.  Unfortunately, for the code in species, the default behaviour is `sparse=False`, whereas in all other cases, it is `sparse=True`.

I don’t think it is so important whether the backend is sparse or dense. I think you’re intuition is correct in returning a `lazy_list` unless the series is known to be finite.
 
> Another minor issue: for `L.<x> = LazyPowerSeriesRing(QQ)` we had `L([1,2,3])` what would now be `L([1,2], constant = 3)`.  However, I really do not want to replicate this behaviour.

Eek, that is highly unexpected. Did we think that should be the behavior at some point? I (now?) think we should have list input be the corresponding finite to match what polynomials do.


---

Comment by mantepse created at 2022-09-09 06:50:38

Replying to [comment:44 Travis Scrimshaw]:
> Replying to [comment:39 Martin Rubey]:
> > I think that for `LazyTaylorSeries`, `LazyDirichletSeries`, `LazySymmetricFunction`, etc. we really don't want
> > {{{
> > sage: L.<x> = LazyTaylorSeriesRing(QQ)
> > sage: (x<sup>2/(1-x)</sup>3)[:5]
> > [1, 3, 6]
> > sage: L(lambda n: n*(n-1)/2)[:5]
> > [0, 0, 1, 3, 6]
> > }}}
> > Instead, I think that for these classes we always want to start from degree 0.
> 
> I would say that is a bug and should be fixed (which I think is what you’re saying as well).

Yes, that's done already in the commit in comment:41.

> > I am also hesitant to encode a `coefficients` method with behaviour quite different from the other methods with the same name.  In particular, we have

[in `multi_polynomia.pyx`]

> > {{{
> >     def coefficients(self):
> >         """
> >         Return the nonzero coefficients of this polynomial in a list.

> > As far as I can see, there is a single exception to the behaviour indicated by the doctests above, which is the definition in `multi_power_series_ring_elemnt.py`.
> 
> I agree with you. It’s not a bug, so we are not justified in simply changing the behavior. Although I feel a general deprecation message every time this is call would be obtrusive (and bad). I am leaning towards just making the backwards incompatible change, documenting how to get the previous behavior `[f[i] for i in range(n)]`, and dealing with the consequences, but it was used all over the examples. I can’t think of a good way out of this other than something convoluted with an extra argument. Thus, we probably just have to make the change and take our medicine.

Just to be clear: making the definition as

```
def coefficients(self, n=None, sparse=False):
```

i.e., with default behaviour as it is now, but with an option that makes it in line with the other coefficient methods in sage is *not* what we should do?

I must say, if we make the default `sparse=True`, i.e., introduce a backwards incompatible change, then I think we really should provide a deprecation warning.  One might not notice immediately that zeros are missing all of a sudden.

Possibly, to make this decision slightly less important, I could put the definition into the generating functions module only, or, alternatively, only into `LazyPowerSeries`, and raise a `NotImplementedError` for multivariate series.

> > Another minor issue: for `L.<x> = LazyPowerSeriesRing(QQ)` we had `L([1,2,3])` what would now be `L([1,2], constant = 3)`.  However, I really do not want to replicate this behaviour.
> 
> Eek, that is highly unexpected.

As far as I remember we discussed this issue and decided that we cannot do anything sensible about it.  I think I'll put a

```
.. WARNING::

    The behaviour of ``LazyPowerSeries(l)`` for a list ``l`` with non-zero last element `e` changed with :trac:`32367`.  To obtain the old behaviour, use ``LazyPowerSeries(l, constant=e)``.
```

into the docstring of the (new) LazyPowerSeries.


---

Comment by git created at 2022-09-09 10:46:16

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by mantepse created at 2022-09-09 10:47:58

I added a warning for the new behaviour concerning the specification of the constant.


---

Comment by git created at 2022-09-09 18:27:08

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by tscrim created at 2022-09-09 23:23:05

Replying to [comment:45 Martin Rubey]:
> Replying to [comment:44 Travis Scrimshaw]:
> > Replying to [comment:39 Martin Rubey]:
> > > I am also hesitant to encode a `coefficients` method with behaviour quite different from the other methods with the same name. 
> > >
> > > [snip]
> > > 
> > > As far as I can see, there is a single exception to the behaviour indicated by the doctests above, which is the definition in `multi_power_series_ring_elemnt.py`.
> > 
> > I agree with you. It’s not a bug, so we are not justified in simply changing the behavior. Although I feel a general deprecation message every time this is call would be obtrusive (and bad). I am leaning towards just making the backwards incompatible change, documenting how to get the previous behavior `[f[i] for i in range(n)]`, and dealing with the consequences, but it was used all over the examples. I can’t think of a good way out of this other than something convoluted with an extra argument. Thus, we probably just have to make the change and take our medicine.
> 
> Just to be clear: making the definition as
> {{{
> def coefficients(self, n=None, sparse=False):
> }}}
> i.e., with default behaviour as it is now, but with an option that makes it in line with the other coefficient methods in sage is *not* what we should do?

No, I agree with you that it is what we should do. The problem is how to do this with an effective and unobtrusive deprecation.

> I must say, if we make the default `sparse=True`, i.e., introduce a backwards incompatible change, then I think we really should provide a deprecation warning.  One might not notice immediately that zeros are missing all of a sudden.

Then we are introducing a new argument that we then have to add to code, which we will also want to deprecate later. This becomes a hassle on both the developer and user side.

Actually, maybe we can just issue a deprecation on the `n` parameter, where we also say this now will return only nonzero coefficients? If people are passing `n`, then they are expecting the old behavior.

Given the other backwards-incompatible change we are making (the one below), it isn’t much more painful to do a second one at the same time either.
 
> Possibly, to make this decision slightly less important, I could put the definition into the generating functions module only, or, alternatively, only into `LazyPowerSeries`, and raise a `NotImplementedError` for multivariate series.

I think it is better to be consistent about this.

> > > Another minor issue: for `L.<x> = LazyPowerSeriesRing(QQ)` we had `L([1,2,3])` what would now be `L([1,2], constant = 3)`.  However, I really do not want to replicate this behaviour.
> > 
> > Eek, that is highly unexpected.
> 
> As far as I remember we discussed this issue and decided that we cannot do anything sensible about it.  I think I'll put a
> {{{
> .. WARNING::
> 
>     The behaviour of ``LazyPowerSeries(l)`` for a list ``l`` with non-zero last element `e` changed with :trac:`32367`.  To obtain the old behaviour, use ``LazyPowerSeries(l, constant=e)``.
> }}}
> into the docstring of the (new) `LazyPowerSeries`.

Ah, I misread it initially. This was the behavior of the old `LazyPowerSeries`. Just two little things with this:

- Use `L` instead of `l` since it has a chance to be read as `I` depending on the font (like the one I am using to type this comment in fact).
- Make sure there is an easy to see example of the new constant behavior is clearly visible (in the class-level ring doc, its `_element_constructor_`, the element class’s class-level doc; the module-level doc if there are examples there).


---

Comment by mantepse created at 2022-09-10 06:19:47

Replying to [comment:49 Travis Scrimshaw]:

> - Use `L` instead of `l` since it has a chance to be read as `I` depending on the font (like the one I am using to type this comment in fact).

OK, I am using `c` now, for 'coefficients', since `L` is used for the parent usually.

> - Make sure there is an easy to see example of the new constant behavior is clearly visible (in the class-level ring doc, its `_element_constructor_`, the element class’s class-level doc; the module-level doc if there are examples there).

There are several such examples, eg. line 1344 and beyond.  Note that this change is not so bad as it may look: almost always, the old input was a list ending with 0, because this is the constant you usually want.


---

Comment by git created at 2022-09-10 06:20:29

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by chapoton created at 2022-09-10 06:23:28

Hello, we are supposed to be in maintenance mode today, as announced on sage-devel and trac main page. I think everything is now in order, but please try clicking around..


---

Comment by tscrim created at 2022-09-10 06:45:19

Changing status from needs_info to needs_review.


---

Comment by tscrim created at 2022-09-10 06:45:19

Everything seems to be okay.


---

Comment by git created at 2022-09-10 06:47:02

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by tscrim created at 2022-09-10 06:47:42

Replying to [comment:50 Martin Rubey]:
> Replying to [comment:49 Travis Scrimshaw]:
> 
> > - Use `L` instead of `l` since it has a chance to be read as `I` depending on the font (like the one I am using to type this comment in fact).
> 
> OK, I am using `c` now, for 'coefficients', since `L` is used for the parent usually.

Thank you.

> > - Make sure there is an easy to see example of the new constant behavior is clearly visible (in the class-level ring doc, its `_element_constructor_`, the element class’s class-level doc; the module-level doc if there are examples there).
> 
> There are several such examples, eg. line 1344 and beyond.  Note that this change is not so bad as it may look: almost always, the old input was a list ending with 0, because this is the constant you usually want.

Thank you. I didn't have time to check when I posted that.

Given your comments, I think this is now at needs review, correct? Feel free to revert if more is still needed.

Actually, I think I am mostly ready to turn this to a positive review if the patchbot comes back green.


---

Comment by tscrim created at 2022-09-10 06:50:08

I take that back slightly. I think we should have uniformity with the get item and that `f[:5]` should work for all series because they all have an approximate valuation.


---

Comment by mantepse created at 2022-09-10 06:51:32

I am now (i.e., within the hour) implementing `coefficients`.  Other than that, it is ready!

(to be honest: !!!!!!!!! with just as many smileys!)

Explanation for the last push: we actually change _aproximate_valuation already in a place, and I think we will want to do that more often, and I certainly do not want that the result of __getitem__ depends on that.


---

Comment by mantepse created at 2022-09-10 07:00:15

Actually, I just discovered something quite disturbing:

```
sage: L.<x> = PowerSeriesRing(QQ)
sage: f = x^-5/(1-2*x)
sage: f[:10]
<ipython-input-11-f66b5b8a9c22>:1: DeprecationWarning: polynomial slicing with a start index is deprecated, use list() and slice the resulting list instead
See http://trac.sagemath.org/18940 for details.
  f[:Integer(10)]
32 + 64*x + 128*x^2 + 256*x^3 + 512*x^4 + 1024*x^5 + 2048*x^6 + 4096*x^7 + 8192*x^8 + 16384*x^9 + O(x^15)
```


I find this rather hard to believe.


---

Comment by tscrim created at 2022-09-10 07:40:38

Replying to [comment:57 Martin Rubey]:
> Explanation for the last push: we actually change _aproximate_valuation already in a place, and I think we will want to do that more often, and I certainly do not want that the result of `__getitem__` depends on that.

I was misremembering what we implemented as I thought it did strip the leading zeros, but this is not the case:

```
sage: L.<x> = LazyLaurentSeriesRing(QQ)
sage: f = L(lambda n: 1, valuation=0)
sage: fp = (f - 1)
sage: fp[:5]
[0, 1, 1, 1, 1]
```


I would say we should start from the approximate order up to the stop and then strip leading zeros (with updating the valuation accordingly). I find the `f[:5]` syntax really nice. It also means we promise you have all nonzero coefficients up to the stop without having to compute the valuation (in particular, this would work for zero series).

This could be made consistent with `f[a:b]` that does return the leading `0`'s because the input is clearly different (and we would not update the approximate valuation because we are not using it).

The major point with updating the current behavior is there is no other way to guarantee that we have computed enough using `f[a:b]` to guarantee all coefficients of degree less than `a` are zero because we have not made the approximate valuation part of the API. Otherwise I would want a way to get that so I can guarantee my computations. (Of course, I can but don't want to keep track of this by hand.)


---

Comment by tscrim created at 2022-09-10 07:47:33

Replying to [comment:58 Martin Rubey]:
> Actually, I just discovered something quite disturbing:
> {{{
> sage: L.<x> = PowerSeriesRing(QQ)
> sage: f = x^-5/(1-2*x)
> sage: f[:10]
> <ipython-input-11-f66b5b8a9c22>:1: DeprecationWarning: polynomial slicing with a start index is deprecated, use list() and slice the resulting list instead
> See http://trac.sagemath.org/18940 for details.
>   f[:Integer(10)]
> 32 + 64*x + 128*x^2 + 256*x^3 + 512*x^4 + 1024*x^5 + 2048*x^6 + 4096*x^7 + 8192*x^8 + 16384*x^9 + O(x^15)
> }}}
>
> I find this rather hard to believe.

That is disturbing on many different levels for FPS. For polynomials, it probably would be better for them to be done as lists rather than polynomials, but it was somewhat natural there to return a polynomial as we often want to lop off terms. For FPS, I think slicing makes less sense to return a FPS because we are actually interested in a certain range of coefficients. We aren't really manipulating parts of the polynomial.

Since this is deprecated and could be removed now, we are free to implement our own version of slicing.


---

Comment by mantepse created at 2022-09-10 07:48:13

I am absolutely against starting with `_approximate_order`, since this is not well-defined.

ANd I absolutely want a method (I do not care which name it has) which gives me the list or lazy list of all coefficients, beginning with a specified degree.  This is one of the most important use cases for me, for example, I feed this list to oeis, or to the guessing packages, or I plot it.


---

Comment by mantepse created at 2022-09-10 07:53:06

(Let me stress again that _approximate_order may change after certain operations, and may depend on the way we construct the series.)


---

Comment by tscrim created at 2022-09-10 07:55:57

Replying to [comment:61 Martin Rubey]:
> I am absolutely against starting with `_approximate_order`, since this is not well-defined.

With slicing returning leading zeros, I completely agree that we should not do this. My proposal would be to strip the leading zeros and start at the actual valuation (or return an empty list if the valuation is at least as large as `stop`).

> ANd I absolutely want a method (I do not care which name it has) which gives me the list or lazy list of all coefficients, beginning with a specified degree.  This is one of the most important use cases for me, for example, I feed this list to oeis, or to the guessing packages, or I plot it.

Big +1 as well. I am not proposing a change to the slicing `f[start:stop]`, which would still return a list.

Basically, what I would have is a lazy series `f` with:

- approximate valuation `a`
- actual valuation `v`

behave as follows:

1. For `f[:stop]`, then get the list of coefficients from `f[a]` to `f[stop-1]` and strip the leading zeros and update the approximate valuation as appropriate.
2. For `f[start:start]`, return `[f[i] for i in range(start, stop)]`.

As a concrete example, suppose we have `g` with approximate valuation `-3` but actual valuation `2`. Then doing the following (with a freshly created `g`):

1. `g[:5]` returns `[2, 3, 4]` and sets the approximate valuation to `2`.
2. `g[-1:5]` returns `[0, 0, 0, 2, 3, 4]`.
3. `g[:1]` returns `[]` and sets the approximate valuation to `1`.

Does that clarify what I am proposing? How do you feel about that? I can implement this if you want too.


---

Comment by mantepse created at 2022-09-10 08:03:19

Yes, I think that distinguishing between `start=None` and `start=d` in this way is a good idea.

I'd also propose to propagate this change to all polynomial-like `__getitem__` methods (in a later ticket).

I have roughly half an hour left, which I will invest into the coefficient method.  The tricky part is to get multivariate and graded series right, to be consistent with

```
sage: P.<x,y> = QQ[]
sage: f = (x+2*y^3 +3*x*y + 5)
sage: f.coefficients()
[2, 3, 1, 5]
```



---

Comment by tscrim created at 2022-09-10 08:25:01

Hmm...that is a bit tricky. Can you just concatenate the `coefficients()` of each of the components by degree?


---

Comment by mantepse created at 2022-09-10 08:27:31

I'm almost there :-)


---

Comment by git created at 2022-09-10 09:03:23

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2022-09-10 14:08:04

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2022-09-11 17:49:29

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by mantepse created at 2022-09-11 17:51:00

Ready!


---

Comment by git created at 2022-09-11 19:09:26

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by tscrim created at 2022-09-12 12:51:56

The using you should use the approximate order instead of the actual order is that you do not need to compute it exactly. It should be “up to the (necessarily specified) `stop`” so it will still work for series that do not know they are zero (nor compute more than they need to).

I also think the result of `coefficients()` should all lie in the base ring.

I have a number of other small changes that I will do tomorrow, along with the above two if you don’t disagree.


---

Comment by mantepse created at 2022-09-12 13:14:35

Re stop: Oh, yes, I agree!  I overlooked that!

Re base ring: indeed.  (I thought they did.)


---

Comment by mantepse created at 2022-09-12 20:34:55

There is a bug in `LazyModuleElement.map_coefficients`: it applies the map to the coefficients of the stream, rather than the coefficients of the series.  It is unfortunate that we call the elements of the stream coefficients, we should call them graded pieces or something like that.


---

Comment by git created at 2022-09-12 21:33:35

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2022-09-12 21:43:16

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2022-09-12 22:06:47

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by tscrim created at 2022-09-13 00:19:15

Replying to [comment:74 Martin Rubey]:
> There is a bug in `LazyModuleElement.map_coefficients`: it applies the map to the coefficients of the stream, rather than the coefficients of the series.  It is unfortunate that we call the elements of the stream coefficients, we should call them graded pieces or something like that.

Good catch. The fix seems good, although it seems a bit brittle. I will see if I can come up with a better test, but this can work if I can’t.


---

Comment by git created at 2022-09-13 10:10:02

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by mantepse created at 2022-09-13 12:36:58

Given ticket:34470#comment:19, possibly we should do

```diff
diff --git a/src/sage/rings/lazy_series_ring.py b/src/sage/rings/lazy_series_ring.py
index 98e40a41c8f..5164e19dd2e 100644
--- a/src/sage/rings/lazy_series_ring.py
+++ b/src/sage/rings/lazy_series_ring.py
@@ -1578,7 +1578,7 @@ class LazyCompletionGradedAlgebra(LazySeriesRing):
         if basis in Algebras.TensorProducts:
             self._arity = len(basis._sets)
         else:
-            if basis not in Algebras.Graded:
+            if basis not in GradedAlgebrasWithBasis
                 raise ValueError("basis should be a graded algebra")
             self._arity = 1
         category = Algebras(base_ring.category())

```



---

Comment by tscrim created at 2022-09-13 12:42:11

Indeed, we should do that. I didn’t realize I did it like this at the time.


---

Comment by git created at 2022-09-13 12:58:16

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by mantepse created at 2022-09-13 13:01:04

Do you think we are ready? The part of comment:72, concerning coefficients being in the base ring might still be open.

I am guessing that this will not make it into the upcoming release, right?


---

Comment by tscrim created at 2022-09-13 14:57:55

Indeed, I think this is ready.

My last commit makes sure the coefficients are in the correct ring, which was not the case before for the test I added.

I did a few other small touch ups that I saw (mainly breaking very long doctest output lines) and marking one test as long.

If my changes are good, then positive review.

Indeed, this will definitely not be in 9.7 since we are in the rc stages. However, that is probably better so it can get lots of testing during the beta releases.
----
New commits:


---

Comment by mantepse created at 2022-09-13 15:15:30

I'm afraid, there is something we did not want:

```
sage: L.<x> = LazyPowerSeriesRing(GF(2))
sage: f=L(lambda n: n)
sage: f._coeff_stream._cache
{}
sage: f
x + x^3 + x^5 + O(x^7)
sage: f._coeff_stream._cache
{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6}
```


I am quite sure we wanted that the cache contains the coefficients in the correct ring, no?


---

Comment by mantepse created at 2022-09-13 15:29:03

I think I forgot to adapt the `_element_constructor_` of all rings except for the `LazyTaylorSeriesRing` in https://git.sagemath.org/sage.git/commit/?h=3bd9f8c26726786ff40db79486a1cb0b3cd58b00&id=60103619caa275cb7087e425d25afacdba48af9b

I am guessing that your change to coefficients is masking that.

I have to leave now, I'll try to fix it in the evening.


---

Comment by mantepse created at 2022-09-13 19:57:46

Done!  I'm happy for the moment.  Can't wait to see this in sage develop!

I'll wait with the other tickets until it is, so that I can see the diff better.
----
New commits:


---

Comment by tscrim created at 2022-09-14 03:00:39

I lean towards not having the cached coefficients to be in the base ring as much as possible so intermediate computations could succeed. I saw I could do the change you did and explicitly did not do this because of potential intermediate computations. Although it would make the behavior independent of the arity, which is good. I don't hold a strong opinion here (right now). So your change is fine with me, and you can also remove the extra mappings to the base ring.

Also, I forgot to mention I did find a test for checking how the coefficients behave that I think is more robust (at least, with the current implementation):

```diff
-        if self.base_ring() == self.parent()._internal_poly_ring.base_ring():
+        if P._internal_poly_ring.base_ring() is not P._laurent_poly_ring:
```

What I am worried about is you might possibly get a false equality in the first test. I am not 100% certain this could happen (maybe with Dirichlet series and `SR`), but with the changed test, those in the new test are identical if and only if we are using the internal polynomial ring to encode the degree.


---

Comment by mantepse created at 2022-09-14 06:43:31

In all other rings we have in `lazy_series_ring.py` we put the coefficients into the base ring using the element constructor.  This change was done in #34473, where I overlooked the case of power series.  It should also be consistent with the other ways to construct an element, intentionwise.

There are two reasons I think that this is a good idea:

* the conversion into the base ring may be computationally expensive, especially in the case of symmetric functions.

* if a coefficient happens to be zero in the base ring, but not in the given ring, `Stream_map_coefficients` will apply the function in one case, but not the other.  I think that this could lead to rather obscure bugs.

I believe I removed the extra mappings in my last commit, and I also saw your new test, which is fine with me.


---

Comment by git created at 2022-09-14 06:58:06

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by mantepse created at 2022-09-14 06:58:49

Sorry, I had to fix another thing.

But now - ready, set, go!


---

Comment by tscrim created at 2022-09-14 06:59:13

Replying to [comment:90 Martin Rubey]:
> In all other rings we have in `lazy_series_ring.py` we put the coefficients into the base ring using the element constructor.  This change was done in #34473, where I overlooked the case of power series.  It should also be consistent with the other ways to construct an element, intentionwise.

I missed this change on my review of #34473. I would have raised it then, but now it might be too late.

> There are two reasons I think that this is a good idea:
> 
> * the conversion into the base ring may be computationally expensive, especially in the case of symmetric functions.

This seems to be a reason to not do it until the very end.

> * if a coefficient happens to be zero in the base ring, but not in the given ring, `Stream_map_coefficients` will apply the function in one case, but not the other.  I think that this could lead to rather obscure bugs.

A good point, but are we guaranteed to not get the same behavior with other streams? I think so, but it is not clear. I am wondering if we want to actually go back to including the ring for `Stream_map_coefficients` to really make sure we have the correct inputs. IIRC, we removed that to uniformly have no stream take a ring as input, but this one appears to be really special.

> I believe I removed the extra mappings in my last commit, and I also saw your new test, which is fine with me.

Thank you.


---

Comment by mantepse created at 2022-09-14 07:29:47

> > * the conversion into the base ring may be computationally expensive, especially in the case of symmetric functions.
> 
> This seems to be a reason to not do it until the very end.

I should have been more precise: if we do the conversion before putting things into the cache, we only do it once, and use it for subsequent computations.  Otherwise, we may do it many times.

Of course, if computations in one base ring turn out to be more efficient than in another one, then it may make sense to do a `change_ring` at the very end.

> A good point, but are we guaranteed to not get the same behavior with other streams? I think so, but it is not clear. I am wondering if we want to actually go back to including the ring for Stream_map_coefficients to really make sure we have the correct inputs. IIRC, we removed that to uniformly have no stream take a ring as input, but this one appears to be really special. 

In principle, I like the current setup, but I agree that the burden on developers is quite big. However, I think I'd prefer to do this in a different ticket, after this one is in develop.  I find it already quite hard to see the modifications we make.

Once this is positive review, I would write a short summary describing what we did for the mailing list.  I think we have done something really awesome!


---

Comment by tscrim created at 2022-09-14 07:56:19

Replying to [comment:94 Martin Rubey]:
> > > * the conversion into the base ring may be computationally expensive, especially in the case of symmetric functions.
> > 
> > This seems to be a reason to not do it until the very end.
> 
> I should have been more precise: if we do the conversion before putting things into the cache, we only do it once, and use it for subsequent computations.  Otherwise, we may do it many times.
> 
> Of course, if computations in one base ring turn out to be more efficient than in another one, then it may make sense to do a `change_ring` at the very end.

Indeed, this is hard to say. I would prefer to leave it as much as possible in the hands of the user to decide, but this is a fairly technical thing to document.

> > A good point, but are we guaranteed to not get the same behavior with other streams? I think so, but it is not clear. I am wondering if we want to actually go back to including the ring for Stream_map_coefficients to really make sure we have the correct inputs. IIRC, we removed that to uniformly have no stream take a ring as input, but this one appears to be really special. 
> 
> In principle, I like the current setup, but I agree that the burden on developers is quite big.

A bit of a side effect of being packed with awesomeness. The current setup is sufficient for me. I am just wondering while we wait if it can be made better easily.

> However, I think I'd prefer to do this in a different ticket, after this one is in develop.  I find it already quite hard to see the modifications we make.

Easiest way would be to run `git diff` locally between this branch and the dependency.

> Once this is positive review, I would write a short summary describing what we did for the mailing list.  I think we have done something really awesome!

+1 I have already put this code to good use with a problem I have been working on.

There are still a few things to be improved upon, but this seems to be quite fast and very powerful.


---

Comment by mantepse created at 2022-09-14 09:22:41

So, are you happy for the moment?


---

Comment by tscrim created at 2022-09-14 09:35:40

Indeed I am.


---

Comment by git created at 2022-09-14 12:53:17

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2022-09-15 07:36:08

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2022-09-15 08:53:26

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2022-09-15 11:56:02

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by mantepse created at 2022-09-15 12:00:05

I start to hate doctests.

Let's try again.


---

Comment by mantepse created at 2022-09-15 14:43:01

YES!


---

Comment by tscrim created at 2022-09-16 02:26:47

From the patchbot, I caught a few errors. I have mostly fixed them as they are trivial, but there is one that requires discussion.

In particular, changing the base ring to `QQ` leads to not implemented methods because of the change in category. Some of these are noted on #34470.  My proposal is we first add in these methods (possibly on a separate ticket) and the uncontroversial changes from #34470. (I already have a branch that does this. I can handle the merge with the current branch here and my other changes.)

Now we could just sweep this under the rug by skipping the `_test_not_implemented`, but I think it is easier and better to just fix them first.

What do you think?


---

Comment by mantepse created at 2022-09-16 07:19:09

I don't quite understand: I see three patchbot runs (one from github and two at https://patchbot.sagemath.org/ticket/32367/), but all three of them say "all tests passed".  Also, the pyflakes doesn't mention any non-expected errors.  Where can I find the report you mention?

Apart from that: of course, please go ahead!

Apart from that: is any of the changes in the branch attached to #34470 controversial?  Here is a diff.  An implementation of `residue_field` is still missing.  More generally, I did not find out how to activate the `_test_not_implemented` gadget.

```diff
diff --git a/src/sage/rings/lazy_series.py b/src/sage/rings/lazy_series.py
index 4e2f35f2c3b..23992898376 100644
--- a/src/sage/rings/lazy_series.py
+++ b/src/sage/rings/lazy_series.py
@@ -2934,6 +2934,32 @@ class LazyLaurentSeries(LazyCauchyProductSeries):
         sage: f = 1 / (1 - z - z^2)
         sage: TestSuite(f).run()
     """
+    def _im_gens_(self, codomain, im_gens, base_map=None):
+        """
+        Returns the image of ``self`` under the map that sends the
+        generators of the parent of ``self`` to the elements of the
+        tuple ``im_gens``.
+
+        EXAMPLES::
+
+            sage: Z.<x> = ZZ[]
+            sage: K.<i> = NumberField(x^2 + 1)
+            sage: R.<t> = LazyLaurentSeriesRing(K)
+            sage: f = R(lambda n: i^n, valuation=-2)
+            sage: f
+            -t^-2 - i*t^-1 + 1 + i*t - t^2 - i*t^3 + t^4 + O(t^5)
+            sage: f._im_gens_(R, [t + t^2])
+            -t^-2 + (-i + 2)*t^-1 + (i - 2) + 4*t + (2*i - 6)*t^2 + (-2*i + 4)*t^3 + (-2*i - 7)*t^4 + O(t^5)
+
+            sage: cc = K.hom([-i])
+            sage: f._im_gens_(R, [t + t^2], base_map=cc)
+            -t^-2 + (i + 2)*t^-1 + (-i - 2) + 4*t + (-2*i - 6)*t^2 + (2*i + 4)*t^3 + (2*i - 7)*t^4 + O(t^5)
+
+        """
+        if base_map is None:
+            return codomain(self(im_gens[0]))
+
+        return codomain(self.map_coefficients(base_map)(im_gens[0]))
 
     def __call__(self, g, *, check=True):
         r"""
@@ -3844,6 +3870,33 @@ class LazyPowerSeries(LazyCauchyProductSeries):
         deprecation(32367, "the method compute_coefficients obsolete and has no effect.")
         return
 
+    def _im_gens_(self, codomain, im_gens, base_map=None):
+        """
+        Returns the image of ``self`` under the map that sends the
+        generators of the parent of ``self`` to the elements of the
+        tuple ``im_gens``.
+
+        EXAMPLES::
+
+            sage: Z.<x> = QQ[]
+            sage: R.<q, t> = LazyPowerSeriesRing(Z)
+            sage: f = 1/(1-q-t)
+            sage: f
+            1 + (q+t) + (q^2+2*q*t+t^2) + (q^3+3*q^2*t+3*q*t^2+t^3) + (q^4+4*q^3*t+6*q^2*t^2+4*q*t^3+t^4) + (q^5+5*q^4*t+10*q^3*t^2+10*q^2*t^3+5*q*t^4+t^5) + (q^6+6*q^5*t+15*q^4*t^2+20*q^3*t^3+15*q^2*t^4+6*q*t^5+t^6) + O(q,t)^7
+            sage: S.<s> = LazyPowerSeriesRing(Z)
+            sage: f._im_gens_(S, [s, x*s])
+            1 + ((x+1)*s) + ((x^2+2*x+1)*s^2) + ((x^3+3*x^2+3*x+1)*s^3) + ((x^4+4*x^3+6*x^2+4*x+1)*s^4) + ((x^5+5*x^4+10*x^3+10*x^2+5*x+1)*s^5) + ((x^6+6*x^5+15*x^4+20*x^3+15*x^2+6*x+1)*s^6) + O(s^7)
+
+            sage: cc = Z.hom([-x])
+            sage: f = 1/(1+x*q-t)
+            sage: f._im_gens_(S, [s, x*s], base_map=cc)
+            1 + 2*x*s + 4*x^2*s^2 + 8*x^3*s^3 + 16*x^4*s^4 + 32*x^5*s^5 + 64*x^6*s^6 + O(s^7)
+        """
+        if base_map is None:
+            return codomain(self(*im_gens))
+
+        return codomain(self.map_coefficients(base_map)(*im_gens))
+
     def __call__(self, *g, check=True):
         r"""
         Return the composition of ``self`` with ``g``.
diff --git a/src/sage/rings/lazy_series_ring.py b/src/sage/rings/lazy_series_ring.py
index acaef041566..7b8a001ca1d 100644
--- a/src/sage/rings/lazy_series_ring.py
+++ b/src/sage/rings/lazy_series_ring.py
@@ -1201,6 +1201,27 @@ class LazyPowerSeriesRing(LazySeriesRing):
 
             sage: L = LazyPowerSeriesRing(ZZ, 't')
             sage: TestSuite(L).run(skip=['_test_elements', '_test_associativity', '_test_distributivity', '_test_zero'])
+
+            sage: L = LazyPowerSeriesRing(ZZ, 's, t')
+            sage: TestSuite(L).run(skip=['_test_elements', '_test_associativity', '_test_distributivity', '_test_zero'])
+
+        Check that :trac:`34470` is fixed::
+
+            sage: L.<t> = LazyPowerSeriesRing(QQ)
+            sage: L in CompleteDiscreteValuationRings
+            True
+            sage: L.uniformizer()
+            t
+            sage: lcm(1/(1 - t^2) - 1, t)
+            t^2
+
+            sage: L.<t> = LazyPowerSeriesRing(ZZ)
+            sage: L in PrincipalIdealDomains
+            False
+
+            sage: L = LazyPowerSeriesRing(QQ, 's, t')
+            sage: L in PrincipalIdealDomains
+            False
         """
         from sage.structure.category_object import normalize_names
         names = normalize_names(-1, names)
@@ -1213,8 +1234,9 @@ class LazyPowerSeriesRing(LazySeriesRing):
         else:
             self._internal_poly_ring = PolynomialRing(self._laurent_poly_ring, "DUMMY_VARIABLE")
         category = Algebras(base_ring.category())
-        if base_ring in Fields():
+        if base_ring in Fields() and self._arity == 1:
             category &= CompleteDiscreteValuationRings()
+            self.uniformizer = lambda: self.gen()
         elif base_ring in IntegralDomains():
             category &= IntegralDomains()
         elif base_ring in Rings().Commutative():
@@ -1610,6 +1632,13 @@ class LazyCompletionGradedAlgebra(LazySeriesRing):
             sage: L = LazySymmetricFunctions(s)
             sage: TestSuite(L).run(skip=['_test_elements', '_test_associativity', '_test_distributivity', '_test_zero'])
 
+        Check that :trac:`34470` is fixed::
+
+            sage: s = SymmetricFunctions(QQ).s()
+            sage: L = LazySymmetricFunctions(s)
+            sage: L in PrincipalIdealDomains
+            False
+
         Check that a basis which is not graded is not enough::
 
             sage: ht = SymmetricFunctions(ZZ).ht()
@@ -1627,9 +1656,7 @@ class LazyCompletionGradedAlgebra(LazySeriesRing):
                 raise ValueError("basis should be in GradedAlgebrasWithBasis")
             self._arity = 1
         category = Algebras(base_ring.category())
-        if base_ring in Fields():
-            category &= CompleteDiscreteValuationRings()
-        elif base_ring in IntegralDomains():
+        if base_ring in IntegralDomains():
             category &= IntegralDomains()
         elif base_ring in Rings().Commutative():
             category = category.Commutative()
```



---

Comment by tscrim created at 2022-09-16 13:11:01

Replying to [comment:106 Martin Rubey]:
> I don't quite understand: I see three patchbot runs (one from github and two at https://patchbot.sagemath.org/ticket/32367/), but all three of them say "all tests passed".  Also, the pyflakes doesn't mention any non-expected errors.  Where can I find the report you mention?

If you look at the coverage, you see that there are missing doctests. `self:` is not `sage:`, so those tests are not getting run. So I changed them to run the `TestSuite` on the corresponding classes, which lead to failures of the form:

```
sage: L.<z> = LazyLaurentSeriesRing(QQ)
sage: L._test_not_implemented_methods()
```

which we were not previously testing in our old code.

> Apart from that: of course, please go ahead!

I will merge it into this ticket and push shortly.

> Apart from that: is any of the changes in the branch attached to #34470 controversial?

As I mentioned on #34470, not currently, but there remains the question of putting things in UFD or not. As well as if we want them to be graded (by default) or not.

> Here is a diff.  An implementation of `residue_field` is still missing.  More generally, I did not find out how to activate the `_test_not_implemented` gadget.

Thank you for the diff.

The biggest change I made is that `uniformizer` and `residue_field` are always included as public methods on the ring. I want to avoid the monkey patching (which should generally be avoided), which not only hides documentation, there is a a technical difference as well:

```
sage: class Foo:
....:     def __init__(self):
....:         self.bar = lambda: 5
....:     def baz(self):
....:         return -5
....:         
sage: F = Foo()
sage: F.bar()
5
sage: F.baz()
-5
sage: F.bar
<function Foo.__init__.<locals>.<lambda> at 0x7f9d6bea1630>
sage: F.baz
<bound method Foo.baz of <__main__.Foo object at 0x7f9d728a2530>>
```

While I doubt this is important in practice, it is generally considered bad practice to monkey patch. If you really don't want these methods there, I can implement the appropriate subclasses with the appropriate dispatching using the standard `__classcall_private__` mechanism (like, e.g., `Partitions`).


---

Comment by tscrim created at 2022-09-16 13:19:15

New commits:


---

Comment by mantepse created at 2022-09-16 13:22:10

Oh wow, thank you!  I love self:!


---

Comment by tscrim created at 2022-09-16 13:23:06

But too much `self:` love is bad. `:P`


---

Comment by mantepse created at 2022-09-16 19:31:02


```
sage: L.<t> = LazyPowerSeriesRing(QQ)
sage: t/L(1)
t^2
```



---

Comment by mantepse created at 2022-09-16 20:24:15

The bug above was easy to fix (I'll do it in #34470, because that's where I noticed it), but the following garbage-in-garbage-out is really hard to detect:

```
sage: L.<t> = LazyPowerSeriesRing(QQ)
sage: t*((1+t)/(t-t^2))
1 + t + t^2 + O(t^3)
sage: t*(1+t)/(t-t^2)
1 + 2*t + 2*t^2 + 2*t^3 + O(t^4)
```



---

Comment by tscrim created at 2022-09-16 23:45:52

Did we want to error out when doing the division by a positive valuation series? I don’t remember. Although these are integral domains, right (of course, assuming the base ring is)? So we could (and probably should) follow many other things in Sage and go to the formal fraction field and do the computation there, although that possibly needs the `gcd` to be implemented. I am not sure what the best way forward with division. In any case, we should end up with the second answer (and likely consistently in the fraction field).


---

Comment by mantepse created at 2022-09-17 06:00:12

Fraction field sounds great.

The problem i see with error: we can only check once a coefficient is requested. If we check already in div itself, implicit definitions might not work anymore.


---

Comment by tscrim created at 2022-09-17 10:58:19

Yea, I don’t see an easy way out of something that has an uninitialized series. Although I was thinking of erroring out whenever the approximate valuation was positive.

With fraction fields, we run into the problem of if we want to always return something in the fraction field or not. If we do, then we need to teach using more `//` instead of `/`. If we don’t, then we need to check somehow when to give something in the fraction field, which is basically the same problem.

Maybe we could get around this with using the same implementation for the fraction field with just a different parent. This might help with making things work more seamlessly.

For the short-term, I propose we raise an `NotImplementedError` whenever the denominator is known to have a positive valuation.


---

Comment by mantepse created at 2022-09-17 11:54:49

OK, any way you like.  I admit that I like the idea of  `//`.  I remember that in FriCAS it was sometimes buggy to go from the fraction field to the ring, if mathematically possible.


---

Comment by tscrim created at 2022-09-17 15:02:03

A fraction field shouldn't be too hard to implement, but it shouldn't be something we should hold up this ticket for. I have a good idea for how to do it now. Well, for right now, it is GIGO, so we can leave it be other than explicitly telling the user when giving a positive valuation series (and promising we will implement it via the `NotImplementedError`, as we know those cases are bad). What do you think?


---

Comment by mantepse created at 2022-09-17 15:32:08

I keep saying to myself: let me just do this tiny thing, and then I'll stop and continue with my research (one week to go until term starts).

Now it's saturday evening, and I haven't even started what I promised to do...

It is fun, though.


---

Comment by mantepse created at 2022-09-17 21:17:27

It wasn't as easy as I thought to raise an error and be lazy at the same time, but its done.

Again, I pushed this to #34470.

I used the `TestSuite.run()` a lot to discover bugs, and I found many.  Whenever I thought I finally did it right, the `TestSuite.run()` taught me otherwise.  We should absolutely put more effort into these.


---

Comment by tscrim created at 2022-09-17 22:48:01

From a quick look and what I was thinking, it seems like an overly complicated solution. I was just thinking of putting `if self._stream._approximate_order > 0:` in the inverse/division methods, then in the division/inverse streams, adding a `check` attribute and, e.g., `if check and not self.right[0]:`. I will take a closer look today.

Indeed, that is the idea behind the `TestSuite`, and one of the reasons why I make sure to add it somewhere, typically for the `__init__` doctests.


---

Comment by mantepse created at 2022-09-17 23:07:26

Well, part of the problem was that we were not lazy enough for certain recursive definitions.  For example

```
            sage: P.<x> = LazyPowerSeriesRing(QQ)
            sage: f = P.undefined()
            sage: f.define(1 - ~f*x)
            sage: f
            1 - x - x^2 - 2*x^3 - 5*x^4 - 14*x^5 - 42*x^6 + O(x^7)

            sage: D = LazyDirichletSeriesRing(QQ, "s")
            sage: g = D([0, 1])
            sage: f = D.undefined()
            sage: f.define(1 + ~f*g)
            sage: f
            1 + 1/(2^s) - 1/(4^s) + O(1/(8^s))
```

did not work previously.

Also, equality testing should be clearer now.  I don't know why we decided to check terms in the range

```
n = min(self._coeff_stream._approximate_order, other._coeff_stream._approximate_order)
m = max(self._coeff_stream._approximate_order, other._coeff_stream._approximate_order)
```

previously - it seems to me that this computes coefficients for no good reason.  (it won't hurt, but it won't help either).

Other than that, the diff is not really large.

I believe that giving a name to the true order, if it is known, might be helpful for further improvements, but I did not check.

I also did not check whether we should update `_approximate_order` in `Stream_inexact.__getitem__`.  I would like to first implement more `_test_XXX` methods (in particular for composition and reversion), to get a better picture of performance.


---

Comment by git created at 2022-09-18 11:42:41

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by tscrim created at 2022-09-18 11:48:32

Well, for now, let's bring this to a positive review and move onto the next ticket (assuming we get a green bot this time because I didn't do anything stupid). I will do stuff there starting from your changes.

I did a few little things from what I saw from the last patchbot report (the other failure seems unrelated). I made species library lazily imported to decrease the startup modules number.


---

Comment by mantepse created at 2022-09-19 21:41:34

The `Returns` in the doctring noticed by the patchbot is fixed in the follow-up ticket #34470.

The pyflakes warnings about imported but unused modules in `species/library.py`, are, as far as I know, unavoidable.

The ellipsis in the doctest in `sfa.py` is misinterpreted by the patchbot as a doctest continuation, but is correct, as far as I know.

I am therefore setting this to positive review.


---

Comment by mantepse created at 2022-09-19 21:41:51

Changing status from needs_review to positive_review.


---

Comment by git created at 2022-09-26 10:27:15

Changing status from positive_review to needs_review.


---

Comment by git created at 2022-09-26 10:27:15

Branch pushed to git repo; I updated commit sha1 and set ticket back to needs_review. Last 10 new commits:


---

Comment by mantepse created at 2022-09-26 10:27:34

trivial (autopmatic) merge, necessary to make the patchbots happy.


---

Comment by mantepse created at 2022-09-26 10:27:34

Changing status from needs_review to positive_review.


---

Comment by git created at 2022-09-30 13:08:51

Branch pushed to git repo; I updated commit sha1 and set ticket back to needs_review. New commits:


---

Comment by git created at 2022-09-30 13:08:51

Changing status from positive_review to needs_review.


---

Comment by mantepse created at 2022-09-30 13:09:45

Changing status from needs_review to positive_review.


---

Comment by mantepse created at 2022-09-30 13:09:45

trivial fixes to make patchbot happy.


---

Comment by vbraun created at 2022-10-11 09:14:50

Resolution: fixed
