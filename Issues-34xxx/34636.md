# Issue 34636: make sparsity a decision of the user

archive/issues_034399.json:
```json
{
    "body": "The decision whether a Stream_XXX class uses a dense or a sparse cache should not depend on the input streams.\n\nFor example, for `Stream_add` it is actually irrelevant whether the input streams left and right are dense or sparse.\n\nFor `Stream_zero` and `Stream_exact`, a separate cache never makes sense.\n\nThis also makes the need to implement a conversion between sparse and dense less important.\n\nCC:  @tscrim @fchapoton\n\nKeywords: LazyPowerSeries\n\nBranch/Commit: de424bd78aab5b7e151316644ad460b39261734f\n\nReviewer: Travis Scrimshaw\n\nAuthor: Martin Rubey\n\nDependencies: #34552, #34653\n\nResolution: fixed\n\nIssue created by migration from https://trac.sagemath.org/ticket/34636\n\n",
    "closed_at": "2022-11-07T20:26:18Z",
    "created_at": "2022-10-07T16:24:34Z",
    "labels": [
        "component: combinatorics"
    ],
    "milestone": "https://github.com/sagemath/sagetest/milestones/sage-9.8",
    "title": "make sparsity a decision of the user",
    "type": "issue",
    "url": "https://github.com/sagemath/sagetest/issues/34636",
    "user": "https://github.com/mantepse"
}
```
The decision whether a Stream_XXX class uses a dense or a sparse cache should not depend on the input streams.

For example, for `Stream_add` it is actually irrelevant whether the input streams left and right are dense or sparse.

For `Stream_zero` and `Stream_exact`, a separate cache never makes sense.

This also makes the need to implement a conversion between sparse and dense less important.

CC:  @tscrim @fchapoton

Keywords: LazyPowerSeries

Branch/Commit: de424bd78aab5b7e151316644ad460b39261734f

Reviewer: Travis Scrimshaw

Author: Martin Rubey

Dependencies: #34552, #34653

Resolution: fixed

Issue created by migration from https://trac.sagemath.org/ticket/34636





---

archive/issue_comments_520750.json:
```json
{
    "body": "Changing component from PLEASE CHANGE to combinatorics.",
    "created_at": "2022-10-07T16:35:47Z",
    "issue": "https://github.com/sagemath/sagetest/issues/34636",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/34636#issuecomment-520750",
    "user": "https://github.com/mantepse"
}
```

Changing component from PLEASE CHANGE to combinatorics.



---

archive/issue_comments_520751.json:
```json
{
    "body": "Changing keywords from \"\" to \"LazyPowerSeries\".",
    "created_at": "2022-10-07T16:35:47Z",
    "issue": "https://github.com/sagemath/sagetest/issues/34636",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/34636#issuecomment-520751",
    "user": "https://github.com/mantepse"
}
```

Changing keywords from "" to "LazyPowerSeries".



---

archive/issue_comments_520752.json:
```json
{
    "body": "Description changed:\n``````diff\n--- \n+++ \n@@ -1,4 +1,10 @@\n+The decision whether a Stream_XXX class uses a dense or a sparse cache should not depend on the input streams.\n \n+For example, for `Stream_add` it is actually irrelevant whether the input streams left and right are dense or sparse.\n+\n+For `Stream_zero` and `Stream_exact`, a separate cache never makes sense.\n+\n+This also makes the need to implement a conversion between sparse and dense less important.\n \n Comment: 1\n \n``````\n",
    "created_at": "2022-10-07T16:35:47Z",
    "issue": "https://github.com/sagemath/sagetest/issues/34636",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/34636#issuecomment-520752",
    "user": "https://github.com/mantepse"
}
```

Description changed:
``````diff
--- 
+++ 
@@ -1,4 +1,10 @@
+The decision whether a Stream_XXX class uses a dense or a sparse cache should not depend on the input streams.
 
+For example, for `Stream_add` it is actually irrelevant whether the input streams left and right are dense or sparse.
+
+For `Stream_zero` and `Stream_exact`, a separate cache never makes sense.
+
+This also makes the need to implement a conversion between sparse and dense less important.
 
 Comment: 1
 
``````




---

archive/issue_comments_520753.json:
```json
{
    "body": "Changing type from PLEASE CHANGE to enhancement.",
    "created_at": "2022-10-07T16:35:47Z",
    "issue": "https://github.com/sagemath/sagetest/issues/34636",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/34636#issuecomment-520753",
    "user": "https://github.com/mantepse"
}
```

Changing type from PLEASE CHANGE to enhancement.



---

archive/issue_comments_520754.json:
```json
{
    "body": "<a id='comment:2'></a>Last 10 new commits:",
    "created_at": "2022-10-07T16:35:47Z",
    "issue": "https://github.com/sagemath/sagetest/issues/34636",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/34636#issuecomment-520754",
    "user": "https://github.com/mantepse"
}
```

<a id='comment:2'></a>Last 10 new commits:



---

archive/issue_comments_520755.json:
```json
{
    "body": "<a id='comment:4'></a>A sparse representation does not make sense also for `Cauchy_invert`: `get_coefficient` accesses all previously computed values.",
    "created_at": "2022-10-11T08:54:44Z",
    "issue": "https://github.com/sagemath/sagetest/issues/34636",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/34636#issuecomment-520755",
    "user": "https://github.com/mantepse"
}
```

<a id='comment:4'></a>A sparse representation does not make sense also for `Cauchy_invert`: `get_coefficient` accesses all previously computed values.



---

archive/issue_comments_520756.json:
```json
{
    "body": "<a id='comment:5'></a>Branch pushed to git repo; I updated commit sha1. New commits:",
    "created_at": "2022-10-11T10:11:37Z",
    "issue": "https://github.com/sagemath/sagetest/issues/34636",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/34636#issuecomment-520756",
    "user": "https://trac.sagemath.org/admin/accounts/users/git"
}
```

<a id='comment:5'></a>Branch pushed to git repo; I updated commit sha1. New commits:



---

archive/issue_comments_520757.json:
```json
{
    "body": "<a id='comment:6'></a>Branch pushed to git repo; I updated commit sha1. New commits:",
    "created_at": "2022-10-11T13:57:09Z",
    "issue": "https://github.com/sagemath/sagetest/issues/34636",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/34636#issuecomment-520757",
    "user": "https://trac.sagemath.org/admin/accounts/users/git"
}
```

<a id='comment:6'></a>Branch pushed to git repo; I updated commit sha1. New commits:



---

archive/issue_comments_520758.json:
```json
{
    "body": "Changing status from new to needs_review.",
    "created_at": "2022-10-11T13:59:35Z",
    "issue": "https://github.com/sagemath/sagetest/issues/34636",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/34636#issuecomment-520758",
    "user": "https://github.com/mantepse"
}
```

Changing status from new to needs_review.



---

archive/issue_comments_520759.json:
```json
{
    "body": "<a id='comment:8'></a>From #34611: it may make sense to make `Stream_uninitialized` always dense, and doctest that the following then works:\n\n```\nsage: L.<z> = LazyPowerSeriesRing(ZZ); C = L.undefined(); C.define(1 + z*C^2)\nsage: C[500]\n```\n\nAnother question: it may make sense to make `Stream_XXX` always sparse, if the computation of `s[n]` *obviously* does not benefit from the values of `s[n-1], s[n-2], ...`.  This is the case, for example, with `Stream_add`.\n\nThe benefit of a dense representation of `Stream_add` may be in storage and access: if we have a sparse representation and have to compute most values, the list representation uses (much) less memory, and access will be faster. For example, storing the first 600 values of a stream of integers as a list uses no more memory than storing 200 values in a dict.  Lookup in a list of about 1000 elements seems to take about 60%-70% of the time lookup in a dictionary takes.\n\nIn cases when we apply a very simple function to each coefficient, as in `Stream_neg`, we may not want to create a separate cache at all.  For `Stream_map_coefficients`, we currently only apply very costly functions.",
    "created_at": "2022-10-12T06:51:23Z",
    "issue": "https://github.com/sagemath/sagetest/issues/34636",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/34636#issuecomment-520759",
    "user": "https://github.com/mantepse"
}
```

<a id='comment:8'></a>From #34611: it may make sense to make `Stream_uninitialized` always dense, and doctest that the following then works:

```
sage: L.<z> = LazyPowerSeriesRing(ZZ); C = L.undefined(); C.define(1 + z*C^2)
sage: C[500]
```

Another question: it may make sense to make `Stream_XXX` always sparse, if the computation of `s[n]` *obviously* does not benefit from the values of `s[n-1], s[n-2], ...`.  This is the case, for example, with `Stream_add`.

The benefit of a dense representation of `Stream_add` may be in storage and access: if we have a sparse representation and have to compute most values, the list representation uses (much) less memory, and access will be faster. For example, storing the first 600 values of a stream of integers as a list uses no more memory than storing 200 values in a dict.  Lookup in a list of about 1000 elements seems to take about 60%-70% of the time lookup in a dictionary takes.

In cases when we apply a very simple function to each coefficient, as in `Stream_neg`, we may not want to create a separate cache at all.  For `Stream_map_coefficients`, we currently only apply very costly functions.



---

archive/issue_comments_520760.json:
```json
{
    "body": "<a id='comment:9'></a>I am wondering how much we even want the sparsity in the streams. We want it for the exact series in some cases (sparse versus dense for the (Laurent) polynomial ring), but it seems more like extra weight we are carrying around for the streams, which should instead simply be as dense or sparse as is most effective for them. Or maybe just for multiplication, which might be the only one that could matter? Do you remember if in any place we take advantage of the dense or sparse implementation currently?",
    "created_at": "2022-10-12T08:53:13Z",
    "issue": "https://github.com/sagemath/sagetest/issues/34636",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/34636#issuecomment-520760",
    "user": "https://github.com/tscrim"
}
```

<a id='comment:9'></a>I am wondering how much we even want the sparsity in the streams. We want it for the exact series in some cases (sparse versus dense for the (Laurent) polynomial ring), but it seems more like extra weight we are carrying around for the streams, which should instead simply be as dense or sparse as is most effective for them. Or maybe just for multiplication, which might be the only one that could matter? Do you remember if in any place we take advantage of the dense or sparse implementation currently?



---

archive/issue_comments_520761.json:
```json
{
    "body": "<a id='comment:10'></a>I don't think we can decide for the user.  For multiplication it makes a big difference, whether you are only interested in `(f*g)[10000]` or in `(f*g)[:10000]`.  The former may be relevant, if you want to compute a few random coefficients, e.g., to quickly see how much they grow.  But I admit that I do not know any serious application.\n\nExact series are neither sparse nor dense in the sense of `Stream`, they implement their own (mixed) cache: an index and a list for the initial coefficients, and an index and a constant for the rest.\n\nI am not completely sure whether I understand your question.  I think that `Stream_mul`, `Stream_cauchy_compose` and the like should have sparse and dense versions. `Stream_uninitialized` probably only a dense version, `Stream_add`, `Stream_sub`, etc. possibly only a sparse version.\n\nThe only two reasons for `Stream_add` etc. to have a dense version is, if the speedup in access and the memory overhead matter.  There is no additional code.  So I guess it is better to keep the option.  We currently only use subtraction, implicitly in `LazySymmetricFunction.revert`:\n\n```\n        g = P.undefined(valuation=1)\n        g.define(b_inv * (X - (self - b * X)(g)))\n```\nI am guessing (but I am not sure) that it makes sense to use either only the sparse versions or only the dense versions of the operations here.",
    "created_at": "2022-10-12T09:29:39Z",
    "issue": "https://github.com/sagemath/sagetest/issues/34636",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/34636#issuecomment-520761",
    "user": "https://github.com/mantepse"
}
```

<a id='comment:10'></a>I don't think we can decide for the user.  For multiplication it makes a big difference, whether you are only interested in `(f*g)[10000]` or in `(f*g)[:10000]`.  The former may be relevant, if you want to compute a few random coefficients, e.g., to quickly see how much they grow.  But I admit that I do not know any serious application.

Exact series are neither sparse nor dense in the sense of `Stream`, they implement their own (mixed) cache: an index and a list for the initial coefficients, and an index and a constant for the rest.

I am not completely sure whether I understand your question.  I think that `Stream_mul`, `Stream_cauchy_compose` and the like should have sparse and dense versions. `Stream_uninitialized` probably only a dense version, `Stream_add`, `Stream_sub`, etc. possibly only a sparse version.

The only two reasons for `Stream_add` etc. to have a dense version is, if the speedup in access and the memory overhead matter.  There is no additional code.  So I guess it is better to keep the option.  We currently only use subtraction, implicitly in `LazySymmetricFunction.revert`:

```
        g = P.undefined(valuation=1)
        g.define(b_inv * (X - (self - b * X)(g)))
```
I am guessing (but I am not sure) that it makes sense to use either only the sparse versions or only the dense versions of the operations here.



---

archive/issue_comments_520762.json:
```json
{
    "body": "<a id='comment:11'></a>You\u2019re right; for multiplication, we should have both a sparse and dense version.\n\nAh, right, we don\u2019t store the polynomials themselves in the `Stream_exact`, although there can be uses for passing the sparsity to that. I don\u2019t remember if we implement both types of exact storage. Perhaps we should, in case someone wants to create x<sup>10000</sup>.\n\nI am mostly wondering how much we should drop within the streams to carry around the `_sparse` parameter altogether. The multiplication will likely be split into 2 classes (with not being too lazy with the dense multiplication); the rest, except possibly the exact, are all naturally either dense (e.g., inverse) or sparse (e.g., addition).\n\nI will have to look at the code we currently have more closely I think to get a more clear picture. I don\u2019t remember some of the details regarding this. Perhaps you already have a clear picture about this though.",
    "created_at": "2022-10-12T14:04:59Z",
    "issue": "https://github.com/sagemath/sagetest/issues/34636",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/34636#issuecomment-520762",
    "user": "https://github.com/tscrim"
}
```

<a id='comment:11'></a>You’re right; for multiplication, we should have both a sparse and dense version.

Ah, right, we don’t store the polynomials themselves in the `Stream_exact`, although there can be uses for passing the sparsity to that. I don’t remember if we implement both types of exact storage. Perhaps we should, in case someone wants to create x<sup>10000</sup>.

I am mostly wondering how much we should drop within the streams to carry around the `_sparse` parameter altogether. The multiplication will likely be split into 2 classes (with not being too lazy with the dense multiplication); the rest, except possibly the exact, are all naturally either dense (e.g., inverse) or sparse (e.g., addition).

I will have to look at the code we currently have more closely I think to get a more clear picture. I don’t remember some of the details regarding this. Perhaps you already have a clear picture about this though.



---

archive/issue_comments_520763.json:
```json
{
    "body": "<a id='comment:12'></a>Creating z<sup>10000</sup> is not a problem:\n\n```\nsage: L.<z> = LazyPowerSeriesRing(ZZ)\nsage: f = z^100000\nsage: f._coeff_stream.__dict__\n{'_constant': 0,\n '_degree': 100001,\n '_initial_coefficients': (1,),\n '_true_order': True,\n '_approximate_order': 100000}\n```\nhowever, z<sup>100000</sup>-1 is:\n\n```\nsage: f = z^10 - 1\nsage: f._coeff_stream.__dict__\n{'_constant': 0,\n '_degree': 11,\n '_initial_coefficients': (-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1),\n '_true_order': True,\n '_approximate_order': 0}\n```\n\nCuriously, it takes a very long time to create, all of which is spent in the polynomial exponentiation - this is, because the underlying polynomial ring, for some reason is always dense:\n\n```python\nclass LazyLaurentSeriesRing(LazySeriesRing):\n    def __init__(self, base_ring, names, sparse=True, category=None):\n        self._sparse = sparse\n        # We always use the dense because our CS_exact is implemented densely\n        self._laurent_poly_ring = LaurentPolynomialRing(base_ring, names)\n        self._internal_poly_ring = self._laurent_poly_ring\n```\n\nThere are actually two easy improvements:\n\n* a sparse version, so we can create 1 + x<sup>100000000</sup>\n* I think that the polynomial ring should be dense or sparse depending on our input\n\nand, orthogonal to this,\n\n* a lazy version of `Stream_exact`, with coefficients provided by a function, might also help with the problem of computing large powers or large compositions of exact series.\n\nI can imagine that having only sparse addition is bad.  I can try to create an example if you want.\n\nWhat I'd be interested in is some help with van der Hoeven's algorithm in #34616.",
    "created_at": "2022-10-12T14:36:44Z",
    "issue": "https://github.com/sagemath/sagetest/issues/34636",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/34636#issuecomment-520763",
    "user": "https://github.com/mantepse"
}
```

<a id='comment:12'></a>Creating z<sup>10000</sup> is not a problem:

```
sage: L.<z> = LazyPowerSeriesRing(ZZ)
sage: f = z^100000
sage: f._coeff_stream.__dict__
{'_constant': 0,
 '_degree': 100001,
 '_initial_coefficients': (1,),
 '_true_order': True,
 '_approximate_order': 100000}
```
however, z<sup>100000</sup>-1 is:

```
sage: f = z^10 - 1
sage: f._coeff_stream.__dict__
{'_constant': 0,
 '_degree': 11,
 '_initial_coefficients': (-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1),
 '_true_order': True,
 '_approximate_order': 0}
```

Curiously, it takes a very long time to create, all of which is spent in the polynomial exponentiation - this is, because the underlying polynomial ring, for some reason is always dense:

```python
class LazyLaurentSeriesRing(LazySeriesRing):
    def __init__(self, base_ring, names, sparse=True, category=None):
        self._sparse = sparse
        # We always use the dense because our CS_exact is implemented densely
        self._laurent_poly_ring = LaurentPolynomialRing(base_ring, names)
        self._internal_poly_ring = self._laurent_poly_ring
```

There are actually two easy improvements:

* a sparse version, so we can create 1 + x<sup>100000000</sup>
* I think that the polynomial ring should be dense or sparse depending on our input

and, orthogonal to this,

* a lazy version of `Stream_exact`, with coefficients provided by a function, might also help with the problem of computing large powers or large compositions of exact series.

I can imagine that having only sparse addition is bad.  I can try to create an example if you want.

What I'd be interested in is some help with van der Hoeven's algorithm in #34616.



---

archive/issue_comments_520764.json:
```json
{
    "body": "<a id='comment:13'></a>Branch pushed to git repo; I updated commit sha1. New commits:",
    "created_at": "2022-10-12T14:43:08Z",
    "issue": "https://github.com/sagemath/sagetest/issues/34636",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/34636#issuecomment-520764",
    "user": "https://trac.sagemath.org/admin/accounts/users/git"
}
```

<a id='comment:13'></a>Branch pushed to git repo; I updated commit sha1. New commits:



---

archive/issue_comments_520765.json:
```json
{
    "body": "<a id='comment:14'></a>Branch pushed to git repo; I updated commit sha1. New commits:",
    "created_at": "2022-10-13T06:50:51Z",
    "issue": "https://github.com/sagemath/sagetest/issues/34636",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/34636#issuecomment-520765",
    "user": "https://trac.sagemath.org/admin/accounts/users/git"
}
```

<a id='comment:14'></a>Branch pushed to git repo; I updated commit sha1. New commits:



---

archive/issue_comments_520766.json:
```json
{
    "body": "<a id='comment:15'></a>I made the internal polynomial rings sparse or dense according to the lazy series ring, although this really is of very little consequence.\n\nEssentially, creating z<sup>100000</sup> is now fast in the sparse case, and some computations for exact series (powers, compositions) are now carried out with sparse polynomials.  I did not check, however, whether this makes sense.  We actually do not use the polynomial rings so much, not even for multiplication.\n\nA completely sparse version of `Stream_exact` should be easy, I think - in the non-lazy setting we would simply have a dictionary of non-zero coefficients.",
    "created_at": "2022-10-13T07:04:02Z",
    "issue": "https://github.com/sagemath/sagetest/issues/34636",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/34636#issuecomment-520766",
    "user": "https://github.com/mantepse"
}
```

<a id='comment:15'></a>I made the internal polynomial rings sparse or dense according to the lazy series ring, although this really is of very little consequence.

Essentially, creating z<sup>100000</sup> is now fast in the sparse case, and some computations for exact series (powers, compositions) are now carried out with sparse polynomials.  I did not check, however, whether this makes sense.  We actually do not use the polynomial rings so much, not even for multiplication.

A completely sparse version of `Stream_exact` should be easy, I think - in the non-lazy setting we would simply have a dictionary of non-zero coefficients.



---

archive/issue_comments_520767.json:
```json
{
    "body": "<a id='comment:16'></a>Although having a sparse version of `Stream_exact` should be easy, taking advantage of it may be much more work, because currently we always compute a *list* of initial coefficients in `lazy_ring.py`.\n\nI very much doubt that it is worth the effort right now.",
    "created_at": "2022-10-13T07:08:07Z",
    "issue": "https://github.com/sagemath/sagetest/issues/34636",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/34636#issuecomment-520767",
    "user": "https://github.com/mantepse"
}
```

<a id='comment:16'></a>Although having a sparse version of `Stream_exact` should be easy, taking advantage of it may be much more work, because currently we always compute a *list* of initial coefficients in `lazy_ring.py`.

I very much doubt that it is worth the effort right now.



---

archive/issue_comments_520768.json:
```json
{
    "body": "<a id='comment:17'></a>The dense Laurent polynomials might be a bit better at creating z<sup>10000</sup> than the usual polynomials as they factor out the valuation portion.\n\nIt might not be so prudent to spend time implementing a sparse version of `Stream_exact` right now actually. There will be some additional changes needed throughout the code (this might indicate that we need to refactor so the stream can handle more things in its construction method). There are plenty of other things that we can do to improve the speed and efficiency that are likely to be more useful to people.",
    "created_at": "2022-10-14T01:38:11Z",
    "issue": "https://github.com/sagemath/sagetest/issues/34636",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/34636#issuecomment-520768",
    "user": "https://github.com/tscrim"
}
```

<a id='comment:17'></a>The dense Laurent polynomials might be a bit better at creating z<sup>10000</sup> than the usual polynomials as they factor out the valuation portion.

It might not be so prudent to spend time implementing a sparse version of `Stream_exact` right now actually. There will be some additional changes needed throughout the code (this might indicate that we need to refactor so the stream can handle more things in its construction method). There are plenty of other things that we can do to improve the speed and efficiency that are likely to be more useful to people.



---

archive/issue_comments_520769.json:
```json
{
    "body": "<a id='comment:19'></a>Let us move along. This is definitely an improvement, and we can do further work on subsequent tickets.",
    "created_at": "2022-10-28T07:13:52Z",
    "issue": "https://github.com/sagemath/sagetest/issues/34636",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/34636#issuecomment-520769",
    "user": "https://github.com/tscrim"
}
```

<a id='comment:19'></a>Let us move along. This is definitely an improvement, and we can do further work on subsequent tickets.



---

archive/issue_comments_520770.json:
```json
{
    "body": "Changing status from needs_review to positive_review.",
    "created_at": "2022-10-28T07:13:52Z",
    "issue": "https://github.com/sagemath/sagetest/issues/34636",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/34636#issuecomment-520770",
    "user": "https://github.com/tscrim"
}
```

Changing status from needs_review to positive_review.



---

archive/issue_events_089699.json:
```json
{
    "actor": "https://github.com/vbraun",
    "created_at": "2022-11-07T20:26:18Z",
    "event": "closed",
    "issue": "https://github.com/sagemath/sagetest/issues/34636",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sagetest/issues/34636#event-89699"
}
```



---

archive/issue_comments_520771.json:
```json
{
    "body": "Resolution: fixed",
    "created_at": "2022-11-07T20:26:18Z",
    "issue": "https://github.com/sagemath/sagetest/issues/34636",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/34636#issuecomment-520771",
    "user": "https://github.com/vbraun"
}
```

Resolution: fixed
