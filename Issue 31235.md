# Issue 31235: Truncated inverse and system solution for polynomial matrices

archive/issues_031235.json:
```json
{
    "body": "CC:  @ke456\n\nKeywords: polynomial matrix; truncated inverse expansion\n\nTwo functions can be added:\n* `inverse_series_trunc`, similarly to what exists for polynomials: it returns a polynomial approximation at the given precision of the inverse series of this polynomial matrix (algorithm: Newton iteration; requirement: constant coefficient is a unit)\n* truncated expansion of linear system solution.\nFor the latter, it should be decided whereas to support only the case where the constant coefficient is a unit (easier to handle), or more generally any nonsingular input matrix.\n\nIssue created by migration from https://trac.sagemath.org/ticket/31472\n\n",
    "created_at": "2021-03-08T10:21:00Z",
    "labels": [
        "linear algebra",
        "major",
        "enhancement"
    ],
    "milestone": "https://github.com/sagemath/sagetest/milestones/sage-9.5",
    "title": "Truncated inverse and system solution for polynomial matrices",
    "type": "issue",
    "url": "https://github.com/sagemath/sagetest/issues/31235",
    "user": "@vneiger"
}
```
CC:  @ke456

Keywords: polynomial matrix; truncated inverse expansion

Two functions can be added:
* `inverse_series_trunc`, similarly to what exists for polynomials: it returns a polynomial approximation at the given precision of the inverse series of this polynomial matrix (algorithm: Newton iteration; requirement: constant coefficient is a unit)
* truncated expansion of linear system solution.
For the latter, it should be decided whereas to support only the case where the constant coefficient is a unit (easier to handle), or more generally any nonsingular input matrix.

Issue created by migration from https://trac.sagemath.org/ticket/31472





---

archive/issue_comments_446461.json:
```json
{
    "body": "Sage development has entered the release candidate phase for 9.3. Setting a new milestone for this ticket based on a cursory review of ticket status, priority, and last modification date.",
    "created_at": "2021-03-24T02:04:25Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31235",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31235#issuecomment-446461",
    "user": "mkoeppe"
}
```

Sage development has entered the release candidate phase for 9.3. Setting a new milestone for this ticket based on a cursory review of ticket status, priority, and last modification date.



---

archive/issue_comments_446462.json:
```json
{
    "body": "Branch pushed to git repo; I updated commit sha1. New commits:",
    "created_at": "2021-07-31T11:31:51Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31235",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31235#issuecomment-446462",
    "user": "git"
}
```

Branch pushed to git repo; I updated commit sha1. New commits:



---

archive/issue_comments_446463.json:
```json
{
    "body": "The truncated inverse method is complete (code, doc, tests) and ready for review. I add here that in the current state of sage and without considering the time for format conversions:\n* this method is much faster than the same operation done via polynomials with matrix coefficients when the degrees are \"large\" and matrix dimensions are \"small\";\n* this method is much slower than the same operation done via polynomials with matrix coefficients when the degrees are \"small\" and matrix dimensions are \"large\".\n\nThis is simply explained: with the current implementations, the \"matrix of polynomials\" format benefits from fast polynomial multiplication but relies on naive matrix multiplication, whereas the \"polynomial with matrix coefficients\" format benefits from fast linear algebra but relies on naive polynomial multiplication. **In short, sage currently lacks a fast polynomial matrix multiplication combining fast polynomial multiplication and fast matrix multiplication**, at least when working over fields where such things are not too tricky to do. But the best approach should be to incorporate this from [LinBox](https://github.com/linbox-team/linbox), [NTL/PML](https://github.com/vneiger/pml), or other efficient libraries which already implement this.\n\n**Examples:**\n\n\n```\nsage: mpR.<X> = MatrixSpace(GF(9001),3,3)[]\nsage: C = mpR.random_element(degree=1000)\nsage: %time inv_trunc = C.inverse_series_trunc(1001)\nWall time: 1.39 s\nsage: %time inv_trunc = C.inverse_series_trunc(10000)\nWall time: 31.4 s\n\nsage: pR.<x> = GF(9001)[]\nsage: M = Matrix.random(pR,3,3,degree=1000)\nsage: %time inv_trunc = M.inverse_series_trunc(1001)\nWall time: 8.21 ms\nsage: %time inv_trunc = M.inverse_series_trunc(1000000)\nCPU times: user 5.9 s, sys: 80 ms, total: 5.98 s\nWall time: 5.98 s\n\nsage: mpR.<X> = MatrixSpace(GF(9001),200,200)[]\nsage: C = mpR.random_element(degree=10)\nsage: %time inv_trunc = C.inverse_series_trunc(11)\nWall time: 271 ms\nsage: M = Matrix.random(pR,200,200,degree=10)\nsage: %time inv_trunc = M.inverse_series_trunc(11)\nWall time: 30.3 s\n```\n",
    "created_at": "2021-07-31T12:00:39Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31235",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31235#issuecomment-446463",
    "user": "@vneiger"
}
```

The truncated inverse method is complete (code, doc, tests) and ready for review. I add here that in the current state of sage and without considering the time for format conversions:
* this method is much faster than the same operation done via polynomials with matrix coefficients when the degrees are "large" and matrix dimensions are "small";
* this method is much slower than the same operation done via polynomials with matrix coefficients when the degrees are "small" and matrix dimensions are "large".

This is simply explained: with the current implementations, the "matrix of polynomials" format benefits from fast polynomial multiplication but relies on naive matrix multiplication, whereas the "polynomial with matrix coefficients" format benefits from fast linear algebra but relies on naive polynomial multiplication. **In short, sage currently lacks a fast polynomial matrix multiplication combining fast polynomial multiplication and fast matrix multiplication**, at least when working over fields where such things are not too tricky to do. But the best approach should be to incorporate this from [LinBox](https://github.com/linbox-team/linbox), [NTL/PML](https://github.com/vneiger/pml), or other efficient libraries which already implement this.

**Examples:**


```
sage: mpR.<X> = MatrixSpace(GF(9001),3,3)[]
sage: C = mpR.random_element(degree=1000)
sage: %time inv_trunc = C.inverse_series_trunc(1001)
Wall time: 1.39 s
sage: %time inv_trunc = C.inverse_series_trunc(10000)
Wall time: 31.4 s

sage: pR.<x> = GF(9001)[]
sage: M = Matrix.random(pR,3,3,degree=1000)
sage: %time inv_trunc = M.inverse_series_trunc(1001)
Wall time: 8.21 ms
sage: %time inv_trunc = M.inverse_series_trunc(1000000)
CPU times: user 5.9 s, sys: 80 ms, total: 5.98 s
Wall time: 5.98 s

sage: mpR.<X> = MatrixSpace(GF(9001),200,200)[]
sage: C = mpR.random_element(degree=10)
sage: %time inv_trunc = C.inverse_series_trunc(11)
Wall time: 271 ms
sage: M = Matrix.random(pR,200,200,degree=10)
sage: %time inv_trunc = M.inverse_series_trunc(11)
Wall time: 30.3 s
```




---

archive/issue_comments_446464.json:
```json
{
    "body": "Branch pushed to git repo; I updated commit sha1. New commits:",
    "created_at": "2021-07-31T12:10:21Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31235",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31235#issuecomment-446464",
    "user": "git"
}
```

Branch pushed to git repo; I updated commit sha1. New commits:



---

archive/issue_comments_446465.json:
```json
{
    "body": "Branch pushed to git repo; I updated commit sha1. New commits:",
    "created_at": "2021-07-31T16:31:48Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31235",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31235#issuecomment-446465",
    "user": "git"
}
```

Branch pushed to git repo; I updated commit sha1. New commits:



---

archive/issue_comments_446466.json:
```json
{
    "body": "The second item is now handled (truncated expansion of linear system solution). It is done in full generality, supporting any matrix as input, and will either give a solution or reports that none exists. When the input matrix is square with invertible constant matrix (thus in particular ensuring the existence of a unique solution), it directly relies on Newton iteration and a Dixon-like solver; otherwise for the general case it goes through an approximant basis computation.",
    "created_at": "2021-07-31T16:35:08Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31235",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31235#issuecomment-446466",
    "user": "@vneiger"
}
```

The second item is now handled (truncated expansion of linear system solution). It is done in full generality, supporting any matrix as input, and will either give a solution or reports that none exists. When the input matrix is square with invertible constant matrix (thus in particular ensuring the existence of a unique solution), it directly relies on Newton iteration and a Dixon-like solver; otherwise for the general case it goes through an approximant basis computation.



---

archive/issue_comments_446467.json:
```json
{
    "body": "Changing status from new to needs_review.",
    "created_at": "2021-07-31T16:35:40Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31235",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31235#issuecomment-446467",
    "user": "@vneiger"
}
```

Changing status from new to needs_review.



---

archive/issue_comments_446468.json:
```json
{
    "body": "Set assignee to @ke456.",
    "created_at": "2021-07-31T16:36:10Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31235",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31235#issuecomment-446468",
    "user": "@vneiger"
}
```

Set assignee to @ke456.



---

archive/issue_comments_446469.json:
```json
{
    "body": "Great start, but a few comments:\n\n1) Can this be used for solving (solve_left and solve_right) at full precision? Even if we don't do anything clever, we should give a function that computes the correct precision and calls the truncated algorithm.\n\n2) If we are sticking with Sage's functionality for solve_left and solve_right, then we should provide support for nonsingular and non-square matrices.\n\n3) Can the truncated inverse be used to compute the inverse at full precision?",
    "created_at": "2021-08-01T04:14:01Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31235",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31235#issuecomment-446469",
    "user": "@ke456"
}
```

Great start, but a few comments:

1) Can this be used for solving (solve_left and solve_right) at full precision? Even if we don't do anything clever, we should give a function that computes the correct precision and calls the truncated algorithm.

2) If we are sticking with Sage's functionality for solve_left and solve_right, then we should provide support for nonsingular and non-square matrices.

3) Can the truncated inverse be used to compute the inverse at full precision?



---

archive/issue_comments_446470.json:
```json
{
    "body": "Thank you for the comments. For 2), it was indeed the properties of Sage's `solve_left` which pushed me to handle the general case. I will now look into 1) and 3) to see whether it is interesting to have these full precision procedures (interesting meaning somehow more efficient than the existing `solve_left` and `inverse` which already exist but use generic algorithms), and whether it is straightforward to add or should be part of another ticket.",
    "created_at": "2021-08-01T12:51:05Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31235",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31235#issuecomment-446470",
    "user": "@vneiger"
}
```

Thank you for the comments. For 2), it was indeed the properties of Sage's `solve_left` which pushed me to handle the general case. I will now look into 1) and 3) to see whether it is interesting to have these full precision procedures (interesting meaning somehow more efficient than the existing `solve_left` and `inverse` which already exist but use generic algorithms), and whether it is straightforward to add or should be part of another ticket.



---

archive/issue_comments_446471.json:
```json
{
    "body": "First experiments: `solve_left`, in the case of a **square nonsingular matrix**.\n\nIn that case, the standard approach to do `solve_left` is to do the `solve_left_series_trunc` version at precision twice the degree times the dimension (`2*m*d` in the code below), and then reconstruct the fractions via fast GCD. This seems to be **substantially faster than the existing `solve_left`** for all parameters I tried (note that below I am not timing the GCD step, but that must be negligible compared to the matrix operations).\n\n\n```\nsage: pR.<x> = GF(9001)[]\n\nsage: m = 4\nsage: d = 64\nsage: A = Matrix.random(pR, m, m, degree=d-1)\nsage: B = Matrix.random(pR, 1, m, degree=d-1)\nsage: %timeit XX = A.solve_left(B)\n10.9 ms \u00b1 16.5 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\nsage: %timeit X = A.solve_left_series_trunc(B, 2*m*d)\n2.5 ms \u00b1 2.2 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\n\nsage: m = 16\nsage: A = Matrix.random(pR, m, m, degree=d-1)\nsage: B = Matrix.random(pR, 1, m, degree=d-1)\nsage: %timeit XX = A.solve_left(B)\n5.27 s \u00b1 15.2 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\nsage: %timeit X = A.solve_left_series_trunc(B, 2*m*d)\n76.6 ms \u00b1 168 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each)\n\nsage: m = 4\nsage: d = 512\nsage: A = Matrix.random(pR, m, m, degree=d-1)\nsage: B = Matrix.random(pR, 1, m, degree=d-1)\nsage: %timeit XX = A.solve_left(B)\n228 ms \u00b1 295 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\nsage: %timeit X = A.solve_left_series_trunc(B, 2*m*d)\n15.8 ms \u00b1 11.4 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\n\nsage: B = Matrix.random(pR, 1, m, degree=m*d-1)\nsage: %timeit XX = A.solve_left(B)\n247 ms \u00b1 332 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\nsage: %timeit X = A.solve_left_series_trunc(B, 2*m*d)\n18.2 ms \u00b1 5.47 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\n```\n",
    "created_at": "2021-08-01T13:32:59Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31235",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31235#issuecomment-446471",
    "user": "@vneiger"
}
```

First experiments: `solve_left`, in the case of a **square nonsingular matrix**.

In that case, the standard approach to do `solve_left` is to do the `solve_left_series_trunc` version at precision twice the degree times the dimension (`2*m*d` in the code below), and then reconstruct the fractions via fast GCD. This seems to be **substantially faster than the existing `solve_left`** for all parameters I tried (note that below I am not timing the GCD step, but that must be negligible compared to the matrix operations).


```
sage: pR.<x> = GF(9001)[]

sage: m = 4
sage: d = 64
sage: A = Matrix.random(pR, m, m, degree=d-1)
sage: B = Matrix.random(pR, 1, m, degree=d-1)
sage: %timeit XX = A.solve_left(B)
10.9 ms ± 16.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)
sage: %timeit X = A.solve_left_series_trunc(B, 2*m*d)
2.5 ms ± 2.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)

sage: m = 16
sage: A = Matrix.random(pR, m, m, degree=d-1)
sage: B = Matrix.random(pR, 1, m, degree=d-1)
sage: %timeit XX = A.solve_left(B)
5.27 s ± 15.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
sage: %timeit X = A.solve_left_series_trunc(B, 2*m*d)
76.6 ms ± 168 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)

sage: m = 4
sage: d = 512
sage: A = Matrix.random(pR, m, m, degree=d-1)
sage: B = Matrix.random(pR, 1, m, degree=d-1)
sage: %timeit XX = A.solve_left(B)
228 ms ± 295 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)
sage: %timeit X = A.solve_left_series_trunc(B, 2*m*d)
15.8 ms ± 11.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)

sage: B = Matrix.random(pR, 1, m, degree=m*d-1)
sage: %timeit XX = A.solve_left(B)
247 ms ± 332 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)
sage: %timeit X = A.solve_left_series_trunc(B, 2*m*d)
18.2 ms ± 5.47 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)
```




---

archive/issue_comments_446472.json:
```json
{
    "body": "Now some timings for `inverse`, in the case of a **square matrix with invertible constant term**.\n\nAgain, compared against the existing `inverse`, there is a **clear advantage of using the new `inverse_series_trunc`** (Newton iteration) at precision twice the dimension times the degree, and then reconstructing the inverse entries by fast GCD.\n\n\n```\npR.<x> = GF(9001)[]\nsage: m = 4\nsage: d = 64\nsage: A = Matrix.random(pR, m, m, degree=d)\nsage: %timeit C = A.inverse()\n13.7 ms \u00b1 3.15 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\nsage: %timeit B = A.inverse_series_trunc(2*m*d)\n2.78 ms \u00b1 9.35 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\n\nsage: m = 16\nsage: A = Matrix.random(pR, m, m, degree=d)\nsage: %timeit C = A.inverse()\n8.18 s \u00b1 5.35 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\nsage: %timeit B = A.inverse_series_trunc(2*m*d)\n447 ms \u00b1 268 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n\nsage: m = 4\nsage: d = 512\nsage: A = Matrix.random(pR, m, m, degree=d)\nsage: %timeit C = A.inverse()\n263 ms \u00b1 548 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\nsage: %timeit B = A.inverse_series_trunc(2*m*d)\n25.5 ms \u00b1 15.8 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each)\n```\n",
    "created_at": "2021-08-01T13:45:55Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31235",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31235#issuecomment-446472",
    "user": "@vneiger"
}
```

Now some timings for `inverse`, in the case of a **square matrix with invertible constant term**.

Again, compared against the existing `inverse`, there is a **clear advantage of using the new `inverse_series_trunc`** (Newton iteration) at precision twice the dimension times the degree, and then reconstructing the inverse entries by fast GCD.


```
pR.<x> = GF(9001)[]
sage: m = 4
sage: d = 64
sage: A = Matrix.random(pR, m, m, degree=d)
sage: %timeit C = A.inverse()
13.7 ms ± 3.15 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)
sage: %timeit B = A.inverse_series_trunc(2*m*d)
2.78 ms ± 9.35 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)

sage: m = 16
sage: A = Matrix.random(pR, m, m, degree=d)
sage: %timeit C = A.inverse()
8.18 s ± 5.35 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
sage: %timeit B = A.inverse_series_trunc(2*m*d)
447 ms ± 268 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)

sage: m = 4
sage: d = 512
sage: A = Matrix.random(pR, m, m, degree=d)
sage: %timeit C = A.inverse()
263 ms ± 548 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)
sage: %timeit B = A.inverse_series_trunc(2*m*d)
25.5 ms ± 15.8 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)
```




---

archive/issue_comments_446473.json:
```json
{
    "body": "Now, to conclude, **my suggestion is to open two new tickets for improving system solve and inversion using these new functionalities**.\n\nIndeed the above experiments show good potential, but this is only tested on a small set of parameters, and in the favorable case of square matrices with invertible constant term.\n- System solve (i.e. `solve_left` and `solve_right`) can be applied much more generally, such as to rank-deficient and rectangular matrices. It should be investigated whether the approximant basis approach used in `solve_left_series_trunc` for these general cases is still interesting versus the existing `solve_left`. Another (directly related) approach for the general case, to be investigated as well, is to apply the minimal kernel basis method.\n- Inversion (i.e. `inverse`) can be applied to nonsingular matrices that do not have invertible constant term, which `inverse_series_trunc` cannot do. Also, we should investigate more general inversion methods such as those based on a partial diagonalization procedure (Zhou & Labahn & Storjohann 2015).\n- In all cases, more extensive benchmarking should be made to make sure that there is no loss of performance for some families of parameters.\n\nThis is too much work and changes not directly in the scope of this ticket.\n\nPlease let me know if you have comments about these comments (before I create these tickets), and also about potential other things to improve on the core of this ticket.",
    "created_at": "2021-08-01T13:53:57Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31235",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31235#issuecomment-446473",
    "user": "@vneiger"
}
```

Now, to conclude, **my suggestion is to open two new tickets for improving system solve and inversion using these new functionalities**.

Indeed the above experiments show good potential, but this is only tested on a small set of parameters, and in the favorable case of square matrices with invertible constant term.
- System solve (i.e. `solve_left` and `solve_right`) can be applied much more generally, such as to rank-deficient and rectangular matrices. It should be investigated whether the approximant basis approach used in `solve_left_series_trunc` for these general cases is still interesting versus the existing `solve_left`. Another (directly related) approach for the general case, to be investigated as well, is to apply the minimal kernel basis method.
- Inversion (i.e. `inverse`) can be applied to nonsingular matrices that do not have invertible constant term, which `inverse_series_trunc` cannot do. Also, we should investigate more general inversion methods such as those based on a partial diagonalization procedure (Zhou & Labahn & Storjohann 2015).
- In all cases, more extensive benchmarking should be made to make sure that there is no loss of performance for some families of parameters.

This is too much work and changes not directly in the scope of this ticket.

Please let me know if you have comments about these comments (before I create these tickets), and also about potential other things to improve on the core of this ticket.



---

archive/issue_comments_446474.json:
```json
{
    "body": "Since this seems close to finished, I suppose we can safely revert to milestone 9.4.",
    "created_at": "2021-08-02T08:47:44Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31235",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31235#issuecomment-446474",
    "user": "@vneiger"
}
```

Since this seems close to finished, I suppose we can safely revert to milestone 9.4.



---

archive/issue_comments_446475.json:
```json
{
    "body": "Yes, these tasks seem to be too broad in scope for this ticket alone. I believe the goal that was set for this ticket has been met.",
    "created_at": "2021-08-02T15:11:22Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31235",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31235#issuecomment-446475",
    "user": "@ke456"
}
```

Yes, these tasks seem to be too broad in scope for this ticket alone. I believe the goal that was set for this ticket has been met.



---

archive/issue_comments_446476.json:
```json
{
    "body": "Changing status from needs_review to positive_review.",
    "created_at": "2021-08-02T15:11:22Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31235",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31235#issuecomment-446476",
    "user": "@ke456"
}
```

Changing status from needs_review to positive_review.



---

archive/issue_comments_446477.json:
```json
{
    "body": "Resolution: fixed",
    "created_at": "2021-09-26T01:48:17Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31235",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31235#issuecomment-446477",
    "user": "mkoeppe"
}
```

Resolution: fixed



---

archive/issue_comments_446478.json:
```json
{
    "body": "It looks like this was merged as part of #31465.",
    "created_at": "2021-09-26T01:48:17Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31235",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31235#issuecomment-446478",
    "user": "mkoeppe"
}
```

It looks like this was merged as part of #31465.
