# Issue 17957: Speedup of calculation of Macdonald H and Ht bases

Issue created by migration from Trac.

Original creator: zabrocki

Original creation time: 2015-04-14 19:47:31

CC:  sage-combinat darij tscrim aschilling

Keywords: Macdonald symmetric functions

A formula of F. Bergeron, A. Garsia and M. Haiman gives a Pieri rule for `h_r^\perp {\tilde H}_\mu` and this formula can be used to compute the `H` and `Ht` bases much quicker than previous implementations.  The current implementation computes the `H` and `Ht` basis through the `J` basis and this basis is implemented through creation operators.

For instance a command that takes a relatively long time to compute is

```
sage: %time H([3,2]).nabla(q=H.q,t=1/H.t)
CPU times: user 2.75 s, sys: 86.6 ms, total: 2.83 s
Wall time: 2.95 s
q^4/t^2*McdH[3, 2]
```

and with the new implementation the same command has the timing

```
CPU times: user 184 ms, sys: 18.7 ms, total: 203 ms
Wall time: 196 ms
```


One reason that some of the computations in the `H` and `Ht` bases take a long time is that the entire basis a given degree is cached and so subsequent computations will be faster.  However it seems that the new implementation is cached more efficiently and is faster.


---

Comment by zabrocki created at 2015-04-14 19:55:37

Changing keywords from "Macdonald symmetric functions" to "sf, days67, sage-combinat".


---

Comment by git created at 2015-04-14 21:15:35

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2015-04-14 21:32:53

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by zabrocki created at 2015-04-14 21:34:43

Changing type from PLEASE CHANGE to enhancement.


---

Comment by zabrocki created at 2015-04-14 21:34:43

Changing status from new to needs_review.


---

Comment by zabrocki created at 2015-04-14 21:52:26

Time tests (former implementation)

```
sage: %time qt_kostka([3,3,2],[4,2,2])
CPU times: user 1min 49s, sys: 418 ms, total: 1min 50s
Wall time: 1min 49s
```

(new implementation):

```
sage: %time qt_kostka([3,3,2],[4,2,2])
CPU times: user 3.69 s, sys: 238 ms, total: 3.93 s
Wall time: 3.77 s
```


###

(former implementation):

```
sage: %time s[1,1,1,1,1,1].nabla()
CPU times: user 6.33 s, sys: 125 ms, total: 6.45 s
Wall time: 6.39 s
```

(new implementation):

```
sage: %time s[1,1,1,1,1,1].nabla()
CPU times: user 1.15 s, sys: 69 ms, total: 1.22 s
Wall time: 1.17 s
```



---

Comment by git created at 2015-04-14 22:02:00

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2015-04-19 17:14:52

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by chapoton created at 2015-04-20 06:52:07

two failing doctests, see patchbot report


---

Comment by chapoton created at 2015-04-20 06:52:07

Changing status from needs_review to needs_work.


---

Comment by tscrim created at 2015-04-20 06:55:04

I did some cleanup of the docstrings and imports. However there are some doctest failures:

```
----------------------------------------------------------------------
sage -t ../../tests/book_schilling_zabrocki_kschur_primer.py  # 1 doctest failed
sage -t ../../structure/parent.pyx  # 1 doctest failed
----------------------------------------------------------------------
```

The second one is slightly worrysome in that the coercion path has gotten longer, but it is not so bad. The first one is much more serious as I (and the patchbot) get a division by zero error on this test:

```
sage: Sym = SymmetricFunctions(FractionField(QQ['q']))
sage: Mac = Sym.macdonald(t=0)
sage: H = Mac.H()
sage: s = Sym.schur()
sage: for la in Partitions(3):
....:    print "H",la, "=", s(H(la))
```

I suspect your computational assumptions are not always being met and lead to this error.
----
New commits:


---

Comment by zabrocki created at 2015-04-20 10:48:47

I had not tested `t=0` or `q=0` and should have.  The reason it is failing is because there were a few places where I calculated "f[X(t-1)]" using `f.theta_qt(1/t,0)`.  There are ways around this because I can also use `f.omega_qt(t,0)`


---

Comment by git created at 2015-04-20 14:05:48

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by zabrocki created at 2015-04-20 14:23:07

The fact that there is a change in the coercion path from `J` to `H` is to be expected because the new implementation takes `H` and `Ht` to and from the monomial basis while `J`, `P` and `Q` must pass through the Schur basis.  However, I do not know why the path it finds from Schur to monomial passes through homogeneous and the power basis.

```
sage: copy(H._internal_coerce_map_from(J))
Composite map:
  From: Symmetric Functions over Fraction Field of Multivariate Polynomial Ring in q, t over Rational Field in the Macdonald J basis
  To:   Symmetric Functions over Fraction Field of Multivariate Polynomial Ring in q, t over Rational Field in the Macdonald H basis
  Defn:   Generic morphism:
          From: Symmetric Functions over Fraction Field of Multivariate Polynomial Ring in q, t over Rational Field in the Macdonald J basis
          To:   Symmetric Functions over Fraction Field of Multivariate Polynomial Ring in q, t over Rational Field in the Schur basis
        then
          Generic morphism:
          From: Symmetric Functions over Fraction Field of Multivariate Polynomial Ring in q, t over Rational Field in the Schur basis
          To:   Symmetric Functions over Fraction Field of Multivariate Polynomial Ring in q, t over Rational Field in the homogeneous basis
        then
          Generic morphism:
          From: Symmetric Functions over Fraction Field of Multivariate Polynomial Ring in q, t over Rational Field in the homogeneous basis
          To:   Symmetric Functions over Fraction Field of Multivariate Polynomial Ring in q, t over Rational Field in the powersum basis
        then
          Generic morphism:
          From: Symmetric Functions over Fraction Field of Multivariate Polynomial Ring in q, t over Rational Field in the powersum basis
          To:   Symmetric Functions over Fraction Field of Multivariate Polynomial Ring in q, t over Rational Field in the monomial basis
        then
          Generic morphism:
          From: Symmetric Functions over Fraction Field of Multivariate Polynomial Ring in q, t over Rational Field in the monomial basis
          To:   Symmetric Functions over Fraction Field of Multivariate Polynomial Ring in q, t over Rational Field in the Macdonald H basis
```


What is the technique for ensuring that Sage finds the shortest coercion path?


---

Comment by tscrim created at 2015-04-20 15:42:01

Unfortunately I don't think there is a way to do so unless you explicitly specify the coercion. IIRC, there are known issues with finding efficient paths. Often times it comes from finding some path depending upon prior object creation (i.e., the monomial basis was perhaps [not] created this time whereas previously it was not?). It might lead to some slowdown, but it may not be a significant part of the computation.


---

Comment by zabrocki created at 2015-04-20 16:00:25

I'm willing to leave that as the coercion path because one would not normally convert from `Q`, `P` or `J` bases to `Ht` or `H` bases.  Where there might see a slowdown is between the `Qp` and `H` or `Ht` because `copy(H._internal_coerce_map_from(Qp))` has the extra two steps (although the reverse direction does not) and for mathematical reasons one *might* want to convert between these bases.

I could write the `_self_to_s` and `_s_to_self` functions and add those as coercions, but mathematically they are equivalent to converting between the Schur and monomial basis.


---

Comment by tscrim created at 2015-04-20 17:16:52

You could just explicitly compose the respective coercions and set that composition as the coercion map as well (this is what the coercion framework essentially does).


---

Comment by git created at 2015-04-21 01:17:54

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by zabrocki created at 2015-04-21 01:38:02

Changing status from needs_work to needs_review.


---

Comment by zabrocki created at 2015-04-21 01:38:02

I added the `_self_to_s` and `_s_to_self` methods.  This restores old coercion paths because I registered these coercions before the ones to and from the `m` basis (if I did it in a different order the coercion paths were different).


---

Comment by zabrocki created at 2015-04-21 13:23:14

Changing status from needs_review to needs_work.


---

Comment by zabrocki created at 2015-04-21 13:23:14

I have no good explanation yet, but the commits that I made in comment 14 added a full second (roughly 3.7 -> 4.7) on the computation of the `qt_kostka` computation that I listed the timing above.

```
sage: qt_kostka = sage.combinat.sf.macdonald.qt_kostka
sage: %time qt_kostka([3,3,2],[4,2,2])
CPU times: user 4.68 s, sys: 85.8 ms, total: 4.77 s
Wall time: 4.72 s
```

I am also having issues with the docstring viewer.  Is this a problem with 6.7.beta1?


---

Comment by tscrim created at 2015-04-21 16:11:09

I'm doing some profiling now (`%prun`). How are the docstrings behaving?


---

Comment by tscrim created at 2015-04-21 16:22:05

Here's at 9196d33:

```
         1354375 function calls (1342455 primitive calls) in 18.690 seconds

   Ordered by: internal time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      484    8.666    0.018   10.441    0.022 {method 'subs' of 'sage.structure.element.Element' objects}
    19061    1.364    0.000    1.460    0.000 fraction_field.py:293(<lambda>)
6231/2951    1.089    0.000   15.034    0.005 {sum}
    25/23    0.832    0.033    2.594    0.113 {sage.combinat.dict_addition.dict_linear_combination}
     1289    0.475    0.000    1.076    0.001 macdonald.py:722(<genexpr>)
1859/1005    0.393    0.000    1.577    0.002 macdonald.py:1388(<genexpr>)
     4664    0.294    0.000    0.323    0.000 free_module.py:2028(<genexpr>)
    14485    0.270    0.000    0.702    0.000 partition.py:608(__init__)
    62071    0.245    0.000    0.357    0.000 combinat.py:1069(__hash__)
     1958    0.229    0.000   14.979    0.008 macdonald.py:1245(<genexpr>)
      484    0.225    0.000    1.215    0.003 {sage.libs.symmetrica.symmetrica.t_MONOMIAL_SCHUR_symmetrica}
    82819    0.210    0.000    0.210    0.000 non_negative_integers.py:94(__contains__)
  840/701    0.188    0.000    2.481    0.004 macdonald.py:1391(<genexpr>)
      642    0.177    0.000    0.179    0.000 dynamic_class.py:324(dynamic_class_internal)
    14620    0.173    0.000    0.469    0.000 partition.py:5049(__contains__)
    47261    0.172    0.000    0.258    0.000 partition.py:632(<genexpr>)
     8878    0.162    0.000    1.227    0.000 partition.py:552(__classcall_private__)
   183978    0.160    0.000    0.160    0.000 rational_field.py:825(is_finite)
   102278    0.158    0.000    0.158    0.000 {isinstance}
   194018    0.133    0.000    0.133    0.000 rational_field.py:814(is_field)
    10814    0.123    0.000    1.104    0.000 partition.py:5030(_element_constructor_)
    35558    0.123    0.000    0.184    0.000 partition.py:5081(<genexpr>)
  835/356    0.123    0.000    1.987    0.006 macdonald.py:677(cmunu)
     1474    0.121    0.000    0.136    0.000 free_module.py:670(support)
     1487    0.105    0.000    0.109    0.000 macdonald.py:636(<genexpr>)
       22    0.104    0.005   15.518    0.705 macdonald.py:1244(<dictcomp>)
      290    0.092    0.000    0.164    0.001 macdonald.py:669(<genexpr>)
      290    0.082    0.000    0.144    0.000 macdonald.py:672(<genexpr>)
22609/20887    0.080    0.000    0.112    0.000 combinat.py:951(__eq__)
     3497    0.077    0.000    0.440    0.000 free_module.py:1976(_from_dict)
    15893    0.076    0.000    0.076    0.000 combinat.py:821(__init__)
    24936    0.071    0.000    0.583    0.000 {all}
      968    0.066    0.000    0.085    0.000 free_module.py:519(_coefficient_fast)
    73371    0.066    0.000    0.095    0.000 {len}
    67171    0.066    0.000    0.066    0.000 fraction_field.py:463(ring)
 2331/484    0.058    0.000    4.225    0.009 macdonald.py:1338(_Lmunu)
```

With the current branch:

```
         1666331 function calls (1654153 primitive calls) in 24.257 seconds

   Ordered by: internal time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      968   12.717    0.013   16.142    0.017 {method 'subs' of 'sage.structure.element.Element' objects}
    37990    2.681    0.000    2.871    0.000 fraction_field.py:293(<lambda>)
6231/2951    1.070    0.000   20.717    0.007 {sum}
    25/23    0.833    0.033    2.509    0.109 {sage.combinat.dict_addition.dict_linear_combination}
     1289    0.476    0.000    1.074    0.001 macdonald.py:722(<genexpr>)
1859/1005    0.397    0.000    1.578    0.002 macdonald.py:1453(<genexpr>)
     4664    0.294    0.000    0.322    0.000 free_module.py:2028(<genexpr>)
    14485    0.275    0.000    0.711    0.000 partition.py:608(__init__)
   281963    0.253    0.000    0.253    0.000 rational_field.py:825(is_finite)
    62071    0.245    0.000    0.360    0.000 combinat.py:1069(__hash__)
     1958    0.232    0.000   20.663    0.011 macdonald.py:1304(<genexpr>)
    82819    0.218    0.000    0.218    0.000 non_negative_integers.py:94(__contains__)
   291562    0.195    0.000    0.195    0.000 rational_field.py:814(is_field)
  840/701    0.189    0.000    2.463    0.004 macdonald.py:1456(<genexpr>)
      642    0.172    0.000    0.174    0.000 dynamic_class.py:324(dynamic_class_internal)
    47261    0.172    0.000    0.261    0.000 partition.py:632(<genexpr>)
     8878    0.161    0.000    1.196    0.000 partition.py:552(__classcall_private__)
   104289    0.159    0.000    0.159    0.000 {isinstance}
    14620    0.144    0.000    0.434    0.000 partition.py:5049(__contains__)
      484    0.140    0.000    1.127    0.002 {sage.libs.symmetrica.symmetrica.t_MONOMIAL_SCHUR_symmetrica}
    35558    0.126    0.000    0.190    0.000 partition.py:5081(<genexpr>)
    10814    0.124    0.000    1.076    0.000 partition.py:5030(_element_constructor_)
     1474    0.122    0.000    0.137    0.000 free_module.py:670(support)
  835/356    0.122    0.000    1.966    0.006 macdonald.py:677(cmunu)
     1487    0.107    0.000    0.111    0.000 macdonald.py:636(<genexpr>)
       22    0.106    0.005   21.207    0.964 macdonald.py:1303(<dictcomp>)
   105995    0.103    0.000    0.103    0.000 fraction_field.py:463(ring)
     3445    0.083    0.000    0.112    0.000 {method 'sub' of '_sre.SRE_Pattern' objects}
22609/20887    0.082    0.000    0.114    0.000 combinat.py:951(__eq__)
    15893    0.076    0.000    0.076    0.000 combinat.py:821(__init__)
      290    0.075    0.000    0.146    0.001 macdonald.py:669(<genexpr>)
     3497    0.074    0.000    0.440    0.000 free_module.py:1976(_from_dict)
    24936    0.072    0.000    0.592    0.000 {all}
      290    0.071    0.000    0.135    0.000 macdonald.py:672(<genexpr>)
      968    0.067    0.000    0.085    0.000 free_module.py:519(_coefficient_fast)
    73394    0.066    0.000    0.095    0.000 {len}
     1968    0.065    0.000    0.067    0.000 fraction_field.py:412(_repr_)
```

So the issue is doing the 2 substitutions, which are quite expensive, instead of 1. (Although it's quite worrisome the sheer number of calls to certain things, like `is_finite`, but they are minor in terms of speed).


---

Comment by zabrocki created at 2015-04-21 16:22:39

The command `from sphinx.ext import doctest` raises the error `AttributeError: 'module' object has no attribute 'DocTestParser'` (but this is triggered by typing ?? after anything).  Is this a problem with this branch or I need to build from scratch?  This is clearly not related to changes to sf.


---

Comment by zabrocki created at 2015-04-21 16:47:28

We need the two subs though for this to work properly because if `t=0` then you can't substitute `t->1/t` (as one would need to in order to compute the `H` values from the `Ht` values), it needs to be done symbolically and then substitute the value for `t` afterwards.  
If the main culprit is are the subs then one workaround is that I can figure out the formulas for the functions `cmunu` which work for the `H` basis and create a separate cache for the `H` functions.  This is not ideal because then it memorizes the values for `H` and `Ht` bases separately.  On current branch it computes `Ht` values first and them computes `H` values with `t->1/t`.


---

Comment by tscrim created at 2015-04-21 17:50:29

Are you running Sage from `$SAGE_ROOT/src/sage`? This has been known to cause problems.

Perhaps what we should do is special case the `t=0` cases when we end up doing a `t -> 1/t` substitution?


---

Comment by zabrocki created at 2015-04-21 18:05:01

Thanks, the `$SAGE_ROOT/src/sage` was exactly the problem.

At t=0, `H(mu).subs(t=0) == Qp(mu.conjugate()).subs(t=q).omega()`

That doesn't quite cut it for the `Ht` basis, but then maybe we never have to invert `t`.  I'll see if I can cover all cases this way.


---

Comment by git created at 2015-04-22 01:08:16

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2015-04-22 01:22:10

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by zabrocki created at 2015-04-22 01:29:25

This version seems to have the faster timings.  I did as you suggested and handled the `t==0` case separately and this only needs to happen in the `H` basis (the `Ht` basis doesn't invert `t` so does not need to be handled separately).  To handle the `t==0` case separately I use the Hall-Littlewood `Qp` basis.  That corner case will probably run even faster than before but I didn't test it beyond ensuring that it works.


---

Comment by zabrocki created at 2015-04-22 01:29:25

Changing status from needs_work to needs_review.


---

Comment by darij created at 2015-04-22 01:39:07

This is way over my head -- sorry, Mike...

But there is one thing I can suggest: correcting "rational polynomial" to "rational functional". Even if the former would have been a better notion, were it not also a synonym for a polynomial over `QQ`...


---

Comment by git created at 2015-04-22 01:48:58

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by zabrocki created at 2015-04-22 01:50:19

It took me while to figure out precisely what you were referring to.  I changed to fraction field of polynomials in q and t.


---

Comment by zabrocki created at 2015-04-22 14:33:48

Some timing tests.  On branch ​54336b9


```
sage: H = SymmetricFunctions(QQ['q','t'].fraction_field()).macdonald(t=0).H()
sage: s = H.symmetric_function_ring().s()
sage: %time H(s[4,3,2,1])
CPU times: user 14.6 s, sys: 113 ms, total: 14.7 s
Wall time: 14.7 s
```


on current branch

```
sage: %time H(s[4,3,2,1])
CPU times: user 667 ms, sys: 66.2 ms, total: 734 ms
Wall time: 719 ms
```


This is a huge improvement for this corner case.  For arbitrary `t` case on branch 54336b9

```
sage: H = SymmetricFunctions(QQ['q','t'].fraction_field()).macdonald().H()
sage: s = H.symmetric_function_ring().s()
sage: %time H(s[4,3,2,1])
CPU times: user 1min 8s, sys: 213 ms, total: 1min 8s
Wall time: 1min 8s
```


While on the current branch

```
sage: %time H(s[4,3,2,1])
CPU times: user 59.5 s, sys: 172 ms, total: 59.7 s
Wall time: 59.6 s
```


This is a small but healthy improvement.  Timings for the `Ht` basis and applications of `nabla` seem to be similar on both of these branches.  These computations would not run in a reasonable amount of time without this ticket.


---

Comment by tscrim created at 2015-04-22 18:56:11

That's quite a huge speedup. Do you want me to go through the code en masse and do some old-fashion profiling and tuning or just merge this in as-is?


---

Comment by zabrocki created at 2015-04-23 01:52:51

The major speed enhancement here is mathematical (the formula for computing the Macdonald symmetric functions).  If you want to tune it up I can see we might get a few seconds here and there.  Here are the places I can see algorithmic improvements:

* `cmunu`, `cmunu1` and `Bmu` are a cached functions.  Are there improvements to be gained from using a global dictionary cache rather than a ``@`cached_function`?
* carefully look at `_self_to_m`.  That would be my main concern where efficiency gains are to be had.  This function uses `_Lmunu` and this is the coefficient of the monomial symmetric function in a Macdonald symmetric function.


---

Comment by git created at 2015-04-23 03:42:37

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2015-04-23 03:52:05

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by tscrim created at 2015-04-23 04:03:21

Okay, so I've managed to gain another 5~10% it seems but doing some mild code duplication with specialization. I've also had to fix this doctest in `sfa.py`:

```
sage: all( GR_def2(lam) == h.gessel_reutenauer(lam)
....:      for n in range(5) for lam in Partitions(n) )
```

by explicitly casting the left-hand side to `h` as it now seems to ignore the equality check by coercion. However this worked for me on a smaller example, so something subtle seems to have changed with 5ff5d5a... I will look into this tomorrow for sure, but I will try tonight (after dinner).


---

Comment by git created at 2015-04-23 04:19:44

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by tscrim created at 2015-04-23 04:23:39

A combination of "it's bugging me" and some clever testing made me realize that `to_symmetric_function` is returning compositions instead of partitions! Now why this is just being realized with my recent set of changes, I have no idea. Anyways, it's fixed and I'm okay with the state of things. At least, I couldn't figure out a way to twist out some more speed without doing some moderate cythonization and changing fraction field elements. There might be some gain from doing some of the arithmetic on the polynomial ring and then converting the numerator and denominator to the fraction field, but I'm too hungry and don't know if there will be a sizable enough gain to warrant such an experiment (at this point).


---

Comment by zabrocki created at 2015-04-23 11:24:35

Well I see some clever ways that you have added a bit of efficiency, but unfortunately I am not seeing a speedup on at least one computation.  On 59394c6

```
sage: s = SymmetricFunctions(QQ['q','t'].fraction_field()).s()
sage: %time s[3,3,3,3].nabla()
CPU times: user 4min 8s, sys: 512 ms, total: 4min 8s
Wall time: 4min 8s
```

on current branch

```
sage: %time s[3,3,3,3].nabla()
CPU times: user 4min 29s, sys: 454 ms, total: 4min 29s
Wall time: 4min 29s
```

This computation uses only the `Ht` basis (it does a conversion to the `Ht`, multiply by eigenvalue, then from `Ht` to `s`).


---

Comment by git created at 2015-04-23 15:18:23

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2015-04-23 16:23:48

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by tscrim created at 2015-04-23 16:26:57

So in small scale, just calling the element directly is faster, but at this scale, doing `subs` is actually faster because of some preprocessing it seems to do. *shrugs* I also did some other things which should be faster.

The testing I did previously was on `H(s[3,2,2,1])`, and looking at the profile, the coercions between bases are faster, but some other parts of the computation seems to be slower (for reasons currently unknown to me).


---

Comment by git created at 2015-04-23 18:24:10

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by zabrocki created at 2015-04-23 18:26:30

I know that your sum looks faster (by changing `mu in x.support...` to `c, mu in x`), but this seems to cut off 20 seconds in my test computation.


```
sage: %time s[3,3,3,3].nabla()
CPU times: user 4min 5s, sys: 389 ms, total: 4min 6s
Wall time: 4min 6s
```



---

Comment by tscrim created at 2015-04-23 18:42:05

Really? O_o I really don't believe that is faster because `homogeneous component` is:

```python
degree_on_basis = self.parent().degree_on_basis
return self.parent().sum_of_terms((i, c)
                                  for (i, c) in self
                                  if degree_on_basis(i) == n)
```

Plus there is a `sorted` being called in `support`, not to mention the intermediate element created. I don't see how we'd be doing fewer terms in the sum.

Ahhh...here's a thought, it's the call to `sorted` that results in the speedup because the smaller elements result in fewer terms that have to be resolved until the end. I'm going to experiment, but if that's true, then that's one subtle issue.

Although that call to `QQqt` is superfluous as `_Lmunu` returns an element of `QQqt`.


---

Comment by git created at 2015-04-23 18:56:29

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2015-04-23 18:57:58

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by darij created at 2015-04-23 19:10:30

A couple comments on the cmunu1(mu, nu) function:

The comments on lines 640-641 of macdonald.py are obsolete, right?

You use prod(...) and QQqt(prod(...)). I have not done any profiling, but wouldn't QQqt.prod(...) be the "right" way in both situations?

On line 936, what is \mu'? The conjugate?


---

Comment by tscrim created at 2015-04-23 19:10:51

Yes, it is the call to `sorted` that causes the slowdown, which does make sense because the coefficients we obtain have fewer terms (at least, that's my assumption). Quite a subtle issue IMO (perhaps this is more expected to you?). This version is faster than your version in my testing with `s[3,2,2].nabla()` and `H(s[3,2,2,1])`. If this is faster, then I think we can set this to positive review. (BTW, we are wanting to remove the call to `sorted` in `support`)


---

Comment by zabrocki created at 2015-04-23 19:23:40

Strangely, this is not faster.


```
sage: %time s[3,3,3,3].nabla()
CPU times: user 4min 11s, sys: 555 ms, total: 4min 12s
Wall time: 4min 12s
```



---

Comment by tscrim created at 2015-04-23 20:15:12

*bangs head into the nearest wall* I'll have to test and profile on a larger example then...


---

Comment by tscrim created at 2015-04-23 20:48:42

For the record, this is what I get.
Current version:

```
sage: %time s[3,2,2].nabla()
CPU times: user 7.61 s, sys: 73.2 ms, total: 7.68 s
Wall time: 7.6 s
```

Your commit:

```
sage: %time s[3,2,2].nabla()
CPU times: user 7.7 s, sys: 25.1 ms, total: 7.72 s
Wall time: 7.68 s
```

Current:

```
sage: %time s[3,2,2,1].nabla()
CPU times: user 27.4 s, sys: 74.8 ms, total: 27.5 s
Wall time: 27.5 s
```

Yours:

```
sage: %time s[3,2,2,1].nabla()
CPU times: user 27.5 s, sys: 42.3 ms, total: 27.5 s
Wall time: 27.5 s
```

From profiling, the current branch of the above example has fewer function calls by ~5%, and at the very least, this should not increase the time when they do the same functionality (except for checking for coefficients of 0). For smaller partitions, the recent commit seems to be faster, but the larger ones it slows down. I don't understand and am missing something. Perhaps we should just revert back to `da67e9a` and go with that.


---

Comment by zabrocki created at 2015-04-23 23:06:36

I am no longer convinced `da67e9a` is faster.  I ran about 15-20 timings of `s[3,3,3,3].nabla()` and sometimes it was faster, sometimes it wasn't.  They seem about the same, but if you say there are ~5% less function calls with current, lets go with that.


---

Comment by zabrocki created at 2015-04-24 12:29:53

I closed all other applications and windows, dimmed the lights, very quietly breathed through my nose and ran some more timing tests.  Current: 3.55, 3.53 and 3.55 and on branch `da67e9a`: 3.55, 3.54 and 3.56.  My conclusion: close enough.


---

Comment by chapoton created at 2015-04-24 19:27:56

One typo in the doctests, see patchbot reports


---

Comment by git created at 2015-04-25 06:14:56

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2015-04-25 06:22:46

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by tscrim created at 2015-04-25 06:26:20

I'd ask if you put on some mood music, but that would've disrupted the timings. :P I also addressed [comment:52 Darij's questions].

Darij, I found that running `prod` is faster than `QQqt.prod` on this scale because the C/cython implementation of the `prod` function plus the one coercion beats the python implementation of the `prod` method without a coercion.

So I think we're at positive review?


---

Comment by darij created at 2015-04-25 06:28:10

Ouch, this speaks badly of our OOP. Thanks for timing!


---

Comment by tscrim created at 2015-04-25 06:38:16

It's not OOP per say, it's just Python vs. Cython. Usually performing the coercion is the slow step. However, in this case because the multiplication is slow and frequent. The little python difference adds up.


---

Comment by darij created at 2015-04-25 06:41:09

What I mean is that the implementation in Sage makes the OOP-friendly methods slower than the hacky ducktyped ones. It's not a good state to be in... Is there a way to implement `M.sum` and `R.prod` in Cython without refactoring the whole classes?


---

Comment by tscrim created at 2015-04-25 06:48:27

That's not quite being fair to Sage as: the built-in python version is just as ducktyped, it is a shortcoming of support in Cython to not be able to handle multiple inheritance, and `M.sum` and `M.prod` don't guarantee the result is in `M`. If you want the builtin/cython speed, then call `prod(args, M.one())` (the coercion really is non-existent in terms of time here).


---

Comment by darij created at 2015-04-25 06:50:26

Ah, nice trick with `M.one()`.


---

Comment by zabrocki created at 2015-04-25 13:04:55

I am pleased.  I think it is ready for positive review.  Thanks for all the effort put into it.


---

Comment by tscrim created at 2015-04-25 16:05:18

Thanks for all your testing and timings too.


---

Comment by tscrim created at 2015-04-25 16:05:18

Changing status from needs_review to positive_review.


---

Comment by vbraun created at 2015-04-26 02:21:40

Resolution: fixed
