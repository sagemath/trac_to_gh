# Issue 32080: Remove overhead from `annihilator_basis`

Issue created by migration from https://trac.sagemath.org/ticket/32317

Original creator: tkarn

Original creation time: 2021-07-31 03:27:44

CC:  tscrim tkarn

Keywords: gsoc2021 optimization annihilator

There are a few unnecessary matrices created in the `FiniteDimensionalModulesWithBasis.annihilator_basis()` method. This streamlines them leading to a significant improvement in performance.


---

Comment by tkarn created at 2021-07-31 03:29:06

With the original code:


```
sage: F = FiniteDimensionalAlgebrasWithBasis(QQ).example();                                                                                                                           
sage: x,y,a,b = F.basis()                                                                                                                                                             
sage: %time F.annihilator_basis([x])                                                                                                                                                  
CPU times: user 164 ms, sys: 66.2 ms, total: 230 ms
Wall time: 564 ms
(y, a, b)
```


With the updated code:


```
sage: sage: F = FiniteDimensionalAlgebrasWithBasis(QQ).example();                                                                                                                     
sage: x,y,a,b = F.basis()                                                                                                                                                             
sage: %time F.annihilator_basis([x])                                                                                                                                                  
CPU times: user 1.6 ms, sys: 471 µs, total: 2.07 ms
Wall time: 2.13 ms
(y, a, b)
```



---

Comment by tkarn created at 2021-07-31 03:30:18

Changing status from new to needs_review.


---

Comment by tkarn created at 2021-07-31 03:30:18

New commits:


---

Comment by tscrim created at 2021-07-31 07:59:05

Doctests are failing because you have changed how the matrix augmentation works:

```
sage -t --long --random-seed=0 src/sage/categories/finite_dimensional_lie_algebras_with_basis.py  # 1 doctest failed
sage -t --long --random-seed=0 src/sage/categories/finite_dimensional_algebras_with_basis.py  # 4 doctests failed
sage -t --long --random-seed=0 src/sage/categories/finite_dimensional_modules_with_basis.py  # 12 doctests failed
```


```
sage: matrix([[1,2],[3,4]]).augment(matrix([vector([5,6]), vector([7,8])]))
[1 2 5 6]
[3 4 7 8]
sage: matrix([[1,2],[3,4]]).augment(vector([5,6])).augment(vector([7,8]))
[1 2 5 7]
[3 4 6 8]
```

Actually, each time you augment with a vector, it is actually creating a matrix:

```
sage: vector([1,2]).column()  # called in augment
[1]
[2]
sage: type(_)
<class 'sage.matrix.matrix_integer_dense.Matrix_integer_dense'>
```

It also creates a lot more transient objects. So this really should not be faster (although I don't think you can get around the bug. I also cannot reproduce your timings. Your branch:

```
sage: F = FiniteDimensionalAlgebrasWithBasis(QQ).example()                                                                         
sage: x,y,a,b = F.basis()                                                                                                          
sage: %time F.annihilator_basis([x])                                                                                               
CPU times: user 56.2 ms, sys: 4.28 ms, total: 60.5 ms
Wall time: 59.8 ms
(y, a, b)
```

Previous code:

```
CPU times: user 23.2 ms, sys: 0 ns, total: 23.2 ms
Wall time: 33.2 ms
(y, a, b)
```

Although I get quite a bit of variation in these timings, so it isn't so definitive. Yet it nothing on the order of magnitude difference in comment:1.

Potentially a way to improve the speed is just create one big matrix in one go, and maybe also get rid of the extra function calls with `side='right'`...


---

Comment by tscrim created at 2021-07-31 07:59:05

Changing status from needs_review to needs_work.


---

Comment by tkarn created at 2021-07-31 13:03:39

I think the speedup I was seeing was because I was being sloppy about clearing the cache. If I call annihilator basis twice consecutively, I see the performance gains I thought I was getting from the code.


```
sage: F = FiniteDimensionalAlgebrasWithBasis(QQ).example()                                                                            
sage: x,y,a,b = F.basis()                                                                                                             
sage: %time F.annihilator_basis([x])                                                                                                  
CPU times: user 155 ms, sys: 55.9 ms, total: 211 ms
Wall time: 545 ms
(y, a, b)
sage: %time F.annihilator_basis([x])                                                                                                  
CPU times: user 2.1 ms, sys: 572 µs, total: 2.68 ms
Wall time: 2.74 ms
(y, a, b)
```



---

Comment by git created at 2021-08-02 02:57:35

Branch pushed to git repo; I updated commit sha1. This was a forced push. New commits:


---

Comment by tkarn created at 2021-08-02 02:58:36

I tried to create one big matrix in one go and it seems to have slowed things down just a tiny bit. Code is pushed just for completeness.
----
New commits:


---

Comment by git created at 2021-08-03 20:54:04

Branch pushed to git repo; I updated commit sha1. This was a forced push. New commits:


---

Attachment

Timing comparison of changes of commit 5b1d2


---

Comment by tkarn created at 2021-08-03 20:58:51

I noticed that in the call of `.left_kernel()` there is a call of `.transpose().right_kernel()` so I thought maybe we could build the matrix in a way that the right kernel is really what we want. To get the dimensions right I had to add some overhead. When I did the comparison the new changes may have been _slightly_ faster, but I'm unconvinced that this change should be made.


---

Comment by tscrim created at 2021-08-03 21:21:15

Don't we know that the number of entries in the output vector is going to be `d` the dimension?


---

Comment by tscrim created at 2021-08-03 21:21:43

What I mean is that isn't `block_dim == d`?


---

Comment by tkarn created at 2021-08-04 03:11:13

I originally made that assumption as well, but it causes the test which is the computation of the orthogonal complement as the kernel of a scalar product to fail, because the module is `d`-dimensional, but the scalar product is 1-dimensional.


---

Comment by tscrim created at 2021-08-04 04:18:16

Ah, right, it doesn't require the codomain to be the same as the domain.
