# Issue 18694: Boost shortest paths

archive/issues_018694.json:
```json
{
    "body": "CC:  ncohen dcoudert\n\n\n\nIssue created by migration from https://trac.sagemath.org/ticket/18931\n\n",
    "created_at": "2015-07-21T05:52:22Z",
    "labels": [
        "PLEASE CHANGE",
        "major",
        "PLEASE CHANGE"
    ],
    "title": "Boost shortest paths",
    "type": "issue",
    "url": "https://github.com/sagemath/sagetest/issues/18694",
    "user": "borassi"
}
```
CC:  ncohen dcoudert



Issue created by migration from https://trac.sagemath.org/ticket/18931





---

archive/issue_comments_254845.json:
```json
{
    "body": "Changing component from PLEASE CHANGE to graph theory.",
    "created_at": "2015-07-21T05:57:17Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18694",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18694#issuecomment-254845",
    "user": "borassi"
}
```

Changing component from PLEASE CHANGE to graph theory.



---

archive/issue_comments_254846.json:
```json
{
    "body": "Changing type from PLEASE CHANGE to enhancement.",
    "created_at": "2015-07-21T05:57:17Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18694",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18694#issuecomment-254846",
    "user": "borassi"
}
```

Changing type from PLEASE CHANGE to enhancement.



---

archive/issue_comments_254847.json:
```json
{
    "body": "Changing keywords from \"\" to \"Boost, shortest paths, Bellman-Ford, Johnson\".",
    "created_at": "2015-07-21T05:57:17Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18694",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18694#issuecomment-254847",
    "user": "borassi"
}
```

Changing keywords from "" to "Boost, shortest paths, Bellman-Ford, Johnson".



---

archive/issue_comments_254848.json:
```json
{
    "body": "Hello!\n\nThis is my first attempt to include Boost shortest paths. Some benchmark:\n\n\n```\nsage: def random_weighted_graph(n, m, lower_weight = 1, upper_weight = 100):\n\u00a0\u00a0\u00a0 import random\n\u00a0\u00a0\u00a0 g = graphs.RandomGNM(n,m)\n\u00a0\u00a0\u00a0 weights = [random.randint(lower_weight, upper_weight) for r in xrange(m)]\n\u00a0\u00a0\u00a0 uw_edges = g.edges()\n\u00a0\u00a0\u00a0 w_edges = [(uw_edges[i][0], uw_edges[i][1], weights[i]) for i in xrange(m)]\n\u00a0\u00a0\u00a0 return Graph(w_edges, weighted = True)\n....: \nsage: g = random_weighted_graph(30000,120000)\nsage: %timeit g.shortest_paths(0, by_weight=True, algorithm='Dijkstra_Boost', check_weight=False)\n1 loops, best of 3: 304 ms per loop\nsage: %timeit g.shortest_paths(0, by_weight=True, algorithm='Dijkstra_NetworkX', check_weight=False)\n1 loops, best of 3: 792 ms per loop\nsage: g = random_weighted_graph(10000,300000)\nsage: %timeit g.shortest_paths(0, by_weight=True, algorithm='Dijkstra_Boost', check_weight=False)\n1 loops, best of 3: 333 ms per loop\nsage: %timeit g.shortest_paths(0, by_weight=True, algorithm='Dijkstra_NetworkX', check_weight=False)\n1 loops, best of 3: 1.36 s per loop\nsage: %timeit g.shortest_path_all_pairs(by_weight=True, algorithm='Johnson_Boost')\n10 loops, best of 3: 21.6 ms per loop\nsage: %timeit g.shortest_path_all_pairs(by_weight=True, algorithm='Floyd-Warshall-Python')\n1 loops, best of 3: 5.46 s per loop\n```\n\nWe have a slight improvement with Dijkstra (2-3x), and we have an enormous improvement in computing the all-pairs-shortest-path.\n\nLet me know if you like it!\n\nThank you very much,\n\nMichele",
    "created_at": "2015-08-06T15:12:27Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18694",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18694#issuecomment-254848",
    "user": "borassi"
}
```

Hello!

This is my first attempt to include Boost shortest paths. Some benchmark:


```
sage: def random_weighted_graph(n, m, lower_weight = 1, upper_weight = 100):
    import random
    g = graphs.RandomGNM(n,m)
    weights = [random.randint(lower_weight, upper_weight) for r in xrange(m)]
    uw_edges = g.edges()
    w_edges = [(uw_edges[i][0], uw_edges[i][1], weights[i]) for i in xrange(m)]
    return Graph(w_edges, weighted = True)
....: 
sage: g = random_weighted_graph(30000,120000)
sage: %timeit g.shortest_paths(0, by_weight=True, algorithm='Dijkstra_Boost', check_weight=False)
1 loops, best of 3: 304 ms per loop
sage: %timeit g.shortest_paths(0, by_weight=True, algorithm='Dijkstra_NetworkX', check_weight=False)
1 loops, best of 3: 792 ms per loop
sage: g = random_weighted_graph(10000,300000)
sage: %timeit g.shortest_paths(0, by_weight=True, algorithm='Dijkstra_Boost', check_weight=False)
1 loops, best of 3: 333 ms per loop
sage: %timeit g.shortest_paths(0, by_weight=True, algorithm='Dijkstra_NetworkX', check_weight=False)
1 loops, best of 3: 1.36 s per loop
sage: %timeit g.shortest_path_all_pairs(by_weight=True, algorithm='Johnson_Boost')
10 loops, best of 3: 21.6 ms per loop
sage: %timeit g.shortest_path_all_pairs(by_weight=True, algorithm='Floyd-Warshall-Python')
1 loops, best of 3: 5.46 s per loop
```

We have a slight improvement with Dijkstra (2-3x), and we have an enormous improvement in computing the all-pairs-shortest-path.

Let me know if you like it!

Thank you very much,

Michele



---

archive/issue_comments_254849.json:
```json
{
    "body": "Changing status from new to needs_review.",
    "created_at": "2015-08-06T15:12:27Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18694",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18694#issuecomment-254849",
    "user": "borassi"
}
```

Changing status from new to needs_review.



---

archive/issue_comments_254850.json:
```json
{
    "body": "Hello,\n\nthe output of the method is correct and already faster than networkx on small graphs. Excellent!\n\n```\nsage: G = graphs.PetersenGraph()\nsage: for u,v,_ in G.edges():\n    G.set_edge_label(u,v,1)\n....:     \nsage: G.weighted(True)\nsage: G.add_vertex(10)\nsage: G.shortest_paths(0, by_weight=True, algorithm='Dijkstra_Boost', check_weight=False)\n{0: [0],\n 1: [0, 1],\n 2: [0, 1, 2],\n 3: [0, 4, 3],\n 4: [0, 4],\n 5: [0, 5],\n 6: [0, 1, 6],\n 7: [0, 5, 7],\n 8: [0, 5, 8],\n 9: [0, 4, 9]}\nsage: %timeit G.shortest_paths(0, by_weight=True, algorithm='Dijkstra_Boost', check_weight=False)\n10000 loops, best of 3: 74 \u00b5s per loop\nsage: %timeit G.shortest_paths(0, by_weight=True, algorithm='Dijkstra_NetworkX', check_weight=False)\nThe slowest run took 1387.62 times longer than the fastest. This could mean that an intermediate result is being cached \n1 loops, best of 3: 146 \u00b5s per loop\nsage: %timeit G.shortest_paths(0, by_weight=True, algorithm='Dijkstra_NetworkX', check_weight=False)\n10000 loops, best of 3: 86.7 \u00b5s per loop\n```\n\n\ndo you also plan to add `G.shortest_path()` ?\n\n\nFor all pairs shortest paths:\n- we don't have predecessors with `Johnson_Boost`\n- distance to unreacheable vertices should be set to +Infinity to be consistent with other methods.\n\n\n```\nsage: dist,pred = G.shortest_path_all_pairs(by_weight=True, algorithm='Johnson_Boost')\nsage: print dist\n{0: {0: 0, 1: 1, 2: 2, 3: 2, 4: 1, 5: 1, 6: 2, 7: 2, 8: 2, 9: 2}, 1: {0: 1, 1: 0, 2: 1, 3: 2, 4: 2, 5: 2, 6: 1, 7: 2, 8: 2, 9: 2}, 2: {0: 2, 1: 1, 2: 0, 3: 1, 4: 2, 5: 2, 6: 2, 7: 1, 8: 2, 9: 2}, 3: {0: 2, 1: 2, 2: 1, 3: 0, 4: 1, 5: 2, 6: 2, 7: 2, 8: 1, 9: 2}, 4: {0: 1, 1: 2, 2: 2, 3: 1, 4: 0, 5: 2, 6: 2, 7: 2, 8: 2, 9: 1}, 5: {0: 1, 1: 2, 2: 2, 3: 2, 4: 2, 5: 0, 6: 2, 7: 1, 8: 1, 9: 2}, 6: {0: 2, 1: 1, 2: 2, 3: 2, 4: 2, 5: 2, 6: 0, 7: 2, 8: 1, 9: 1}, 7: {0: 2, 1: 2, 2: 1, 3: 2, 4: 2, 5: 1, 6: 2, 7: 0, 8: 2, 9: 1}, 8: {0: 2, 1: 2, 2: 2, 3: 1, 4: 2, 5: 1, 6: 1, 7: 2, 8: 0, 9: 2}, 9: {0: 2, 1: 2, 2: 2, 3: 2, 4: 1, 5: 2, 6: 1, 7: 1, 8: 2, 9: 0}, 10: {10: 0}}\nsage: print pred\nNone\nsage: dist,pred = G.shortest_path_all_pairs(by_weight=True, algorithm='Floyd-Warshall-Python')\nsage: print dist\n{0: {0: 0, 1: 1, 2: 2, 3: 2, 4: 1, 5: 1, 6: 2, 7: 2, 8: 2, 9: 2, 10: +Infinity}, 1: {0: 1, 1: 0, 2: 1, 3: 2, 4: 2, 5: 2, 6: 1, 7: 2, 8: 2, 9: 2, 10: +Infinity}, 2: {0: 2, 1: 1, 2: 0, 3: 1, 4: 2, 5: 2, 6: 2, 7: 1, 8: 2, 9: 2, 10: +Infinity}, 3: {0: 2, 1: 2, 2: 1, 3: 0, 4: 1, 5: 2, 6: 2, 7: 2, 8: 1, 9: 2, 10: +Infinity}, 4: {0: 1, 1: 2, 2: 2, 3: 1, 4: 0, 5: 2, 6: 2, 7: 2, 8: 2, 9: 1, 10: +Infinity}, 5: {0: 1, 1: 2, 2: 2, 3: 2, 4: 2, 5: 0, 6: 2, 7: 1, 8: 1, 9: 2, 10: +Infinity}, 6: {0: 2, 1: 1, 2: 2, 3: 2, 4: 2, 5: 2, 6: 0, 7: 2, 8: 1, 9: 1, 10: +Infinity}, 7: {0: 2, 1: 2, 2: 1, 3: 2, 4: 2, 5: 1, 6: 2, 7: 0, 8: 2, 9: 1, 10: +Infinity}, 8: {0: 2, 1: 2, 2: 2, 3: 1, 4: 2, 5: 1, 6: 1, 7: 2, 8: 0, 9: 2, 10: +Infinity}, 9: {0: 2, 1: 2, 2: 2, 3: 2, 4: 1, 5: 2, 6: 1, 7: 1, 8: 2, 9: 0, 10: +Infinity}, 10: {0: +Infinity, 1: +Infinity, 2: +Infinity, 3: +Infinity, 4: +Infinity, 5: +Infinity, 6: +Infinity, 7: +Infinity, 8: +Infinity, 9: +Infinity, 10: 0}}\nsage: print pred\n{0: {0: None, 1: 0, 2: 1, 3: 4, 4: 0, 5: 0, 6: 1, 7: 5, 8: 5, 9: 4, 10: None}, 1: {0: 1, 1: None, 2: 1, 3: 2, 4: 0, 5: 0, 6: 1, 7: 2, 8: 6, 9: 6, 10: None}, 2: {0: 1, 1: 2, 2: None, 3: 2, 4: 3, 5: 7, 6: 1, 7: 2, 8: 3, 9: 7, 10: None}, 3: {0: 4, 1: 2, 2: 3, 3: None, 4: 3, 5: 8, 6: 8, 7: 2, 8: 3, 9: 4, 10: None}, 4: {0: 4, 1: 0, 2: 3, 3: 4, 4: None, 5: 0, 6: 9, 7: 9, 8: 3, 9: 4, 10: None}, 5: {0: 5, 1: 0, 2: 7, 3: 8, 4: 0, 5: None, 6: 8, 7: 5, 8: 5, 9: 7, 10: None}, 6: {0: 1, 1: 6, 2: 1, 3: 8, 4: 9, 5: 8, 6: None, 7: 9, 8: 6, 9: 6, 10: None}, 7: {0: 5, 1: 2, 2: 7, 3: 2, 4: 9, 5: 7, 6: 9, 7: None, 8: 5, 9: 7, 10: None}, 8: {0: 5, 1: 6, 2: 3, 3: 8, 4: 3, 5: 8, 6: 8, 7: 5, 8: None, 9: 6, 10: None}, 9: {0: 4, 1: 6, 2: 7, 3: 4, 4: 9, 5: 7, 6: 9, 7: 9, 8: 6, 9: None, 10: None}, 10: {0: None, 1: None, 2: None, 3: None, 4: None, 5: None, 6: None, 7: None, 8: None, 9: None, 10: None}}\nsage: dist,pred = G.shortest_path_all_pairs()\nsage: print dist\n{0: {0: 0, 1: 1, 2: 2, 3: 2, 4: 1, 5: 1, 6: 2, 7: 2, 8: 2, 9: 2, 10: +Infinity}, 1: {0: 1, 1: 0, 2: 1, 3: 2, 4: 2, 5: 2, 6: 1, 7: 2, 8: 2, 9: 2, 10: +Infinity}, 2: {0: 2, 1: 1, 2: 0, 3: 1, 4: 2, 5: 2, 6: 2, 7: 1, 8: 2, 9: 2, 10: +Infinity}, 3: {0: 2, 1: 2, 2: 1, 3: 0, 4: 1, 5: 2, 6: 2, 7: 2, 8: 1, 9: 2, 10: +Infinity}, 4: {0: 1, 1: 2, 2: 2, 3: 1, 4: 0, 5: 2, 6: 2, 7: 2, 8: 2, 9: 1, 10: +Infinity}, 5: {0: 1, 1: 2, 2: 2, 3: 2, 4: 2, 5: 0, 6: 2, 7: 1, 8: 1, 9: 2, 10: +Infinity}, 6: {0: 2, 1: 1, 2: 2, 3: 2, 4: 2, 5: 2, 6: 0, 7: 2, 8: 1, 9: 1, 10: +Infinity}, 7: {0: 2, 1: 2, 2: 1, 3: 2, 4: 2, 5: 1, 6: 2, 7: 0, 8: 2, 9: 1, 10: +Infinity}, 8: {0: 2, 1: 2, 2: 2, 3: 1, 4: 2, 5: 1, 6: 1, 7: 2, 8: 0, 9: 2, 10: +Infinity}, 9: {0: 2, 1: 2, 2: 2, 3: 2, 4: 1, 5: 2, 6: 1, 7: 1, 8: 2, 9: 0, 10: +Infinity}, 10: {0: +Infinity, 1: +Infinity, 2: +Infinity, 3: +Infinity, 4: +Infinity, 5: +Infinity, 6: +Infinity, 7: +Infinity, 8: +Infinity, 9: +Infinity, 10: 0}}\nsage: print pred\n{0: {0: None, 1: 0, 2: 1, 3: 4, 4: 0, 5: 0, 6: 1, 7: 5, 8: 5, 9: 4, 10: None}, 1: {0: 1, 1: None, 2: 1, 3: 2, 4: 0, 5: 0, 6: 1, 7: 2, 8: 6, 9: 6, 10: None}, 2: {0: 1, 1: 2, 2: None, 3: 2, 4: 3, 5: 7, 6: 1, 7: 2, 8: 3, 9: 7, 10: None}, 3: {0: 4, 1: 2, 2: 3, 3: None, 4: 3, 5: 8, 6: 8, 7: 2, 8: 3, 9: 4, 10: None}, 4: {0: 4, 1: 0, 2: 3, 3: 4, 4: None, 5: 0, 6: 9, 7: 9, 8: 3, 9: 4, 10: None}, 5: {0: 5, 1: 0, 2: 7, 3: 8, 4: 0, 5: None, 6: 8, 7: 5, 8: 5, 9: 7, 10: None}, 6: {0: 1, 1: 6, 2: 1, 3: 8, 4: 9, 5: 8, 6: None, 7: 9, 8: 6, 9: 6, 10: None}, 7: {0: 5, 1: 2, 2: 7, 3: 2, 4: 9, 5: 7, 6: 9, 7: None, 8: 5, 9: 7, 10: None}, 8: {0: 5, 1: 6, 2: 3, 3: 8, 4: 3, 5: 8, 6: 8, 7: 5, 8: None, 9: 6, 10: None}, 9: {0: 4, 1: 6, 2: 7, 3: 4, 4: 9, 5: 7, 6: 9, 7: 9, 8: 6, 9: None, 10: None}, 10: {0: None, 1: None, 2: None, 3: None, 4: None, 5: None, 6: None, 7: None, 8: None, 9: None, 10: None}}\n```\n\n\nBest,\nDavid.",
    "created_at": "2015-08-07T10:36:05Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18694",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18694#issuecomment-254850",
    "user": "dcoudert"
}
```

Hello,

the output of the method is correct and already faster than networkx on small graphs. Excellent!

```
sage: G = graphs.PetersenGraph()
sage: for u,v,_ in G.edges():
    G.set_edge_label(u,v,1)
....:     
sage: G.weighted(True)
sage: G.add_vertex(10)
sage: G.shortest_paths(0, by_weight=True, algorithm='Dijkstra_Boost', check_weight=False)
{0: [0],
 1: [0, 1],
 2: [0, 1, 2],
 3: [0, 4, 3],
 4: [0, 4],
 5: [0, 5],
 6: [0, 1, 6],
 7: [0, 5, 7],
 8: [0, 5, 8],
 9: [0, 4, 9]}
sage: %timeit G.shortest_paths(0, by_weight=True, algorithm='Dijkstra_Boost', check_weight=False)
10000 loops, best of 3: 74 µs per loop
sage: %timeit G.shortest_paths(0, by_weight=True, algorithm='Dijkstra_NetworkX', check_weight=False)
The slowest run took 1387.62 times longer than the fastest. This could mean that an intermediate result is being cached 
1 loops, best of 3: 146 µs per loop
sage: %timeit G.shortest_paths(0, by_weight=True, algorithm='Dijkstra_NetworkX', check_weight=False)
10000 loops, best of 3: 86.7 µs per loop
```


do you also plan to add `G.shortest_path()` ?


For all pairs shortest paths:
- we don't have predecessors with `Johnson_Boost`
- distance to unreacheable vertices should be set to +Infinity to be consistent with other methods.


```
sage: dist,pred = G.shortest_path_all_pairs(by_weight=True, algorithm='Johnson_Boost')
sage: print dist
{0: {0: 0, 1: 1, 2: 2, 3: 2, 4: 1, 5: 1, 6: 2, 7: 2, 8: 2, 9: 2}, 1: {0: 1, 1: 0, 2: 1, 3: 2, 4: 2, 5: 2, 6: 1, 7: 2, 8: 2, 9: 2}, 2: {0: 2, 1: 1, 2: 0, 3: 1, 4: 2, 5: 2, 6: 2, 7: 1, 8: 2, 9: 2}, 3: {0: 2, 1: 2, 2: 1, 3: 0, 4: 1, 5: 2, 6: 2, 7: 2, 8: 1, 9: 2}, 4: {0: 1, 1: 2, 2: 2, 3: 1, 4: 0, 5: 2, 6: 2, 7: 2, 8: 2, 9: 1}, 5: {0: 1, 1: 2, 2: 2, 3: 2, 4: 2, 5: 0, 6: 2, 7: 1, 8: 1, 9: 2}, 6: {0: 2, 1: 1, 2: 2, 3: 2, 4: 2, 5: 2, 6: 0, 7: 2, 8: 1, 9: 1}, 7: {0: 2, 1: 2, 2: 1, 3: 2, 4: 2, 5: 1, 6: 2, 7: 0, 8: 2, 9: 1}, 8: {0: 2, 1: 2, 2: 2, 3: 1, 4: 2, 5: 1, 6: 1, 7: 2, 8: 0, 9: 2}, 9: {0: 2, 1: 2, 2: 2, 3: 2, 4: 1, 5: 2, 6: 1, 7: 1, 8: 2, 9: 0}, 10: {10: 0}}
sage: print pred
None
sage: dist,pred = G.shortest_path_all_pairs(by_weight=True, algorithm='Floyd-Warshall-Python')
sage: print dist
{0: {0: 0, 1: 1, 2: 2, 3: 2, 4: 1, 5: 1, 6: 2, 7: 2, 8: 2, 9: 2, 10: +Infinity}, 1: {0: 1, 1: 0, 2: 1, 3: 2, 4: 2, 5: 2, 6: 1, 7: 2, 8: 2, 9: 2, 10: +Infinity}, 2: {0: 2, 1: 1, 2: 0, 3: 1, 4: 2, 5: 2, 6: 2, 7: 1, 8: 2, 9: 2, 10: +Infinity}, 3: {0: 2, 1: 2, 2: 1, 3: 0, 4: 1, 5: 2, 6: 2, 7: 2, 8: 1, 9: 2, 10: +Infinity}, 4: {0: 1, 1: 2, 2: 2, 3: 1, 4: 0, 5: 2, 6: 2, 7: 2, 8: 2, 9: 1, 10: +Infinity}, 5: {0: 1, 1: 2, 2: 2, 3: 2, 4: 2, 5: 0, 6: 2, 7: 1, 8: 1, 9: 2, 10: +Infinity}, 6: {0: 2, 1: 1, 2: 2, 3: 2, 4: 2, 5: 2, 6: 0, 7: 2, 8: 1, 9: 1, 10: +Infinity}, 7: {0: 2, 1: 2, 2: 1, 3: 2, 4: 2, 5: 1, 6: 2, 7: 0, 8: 2, 9: 1, 10: +Infinity}, 8: {0: 2, 1: 2, 2: 2, 3: 1, 4: 2, 5: 1, 6: 1, 7: 2, 8: 0, 9: 2, 10: +Infinity}, 9: {0: 2, 1: 2, 2: 2, 3: 2, 4: 1, 5: 2, 6: 1, 7: 1, 8: 2, 9: 0, 10: +Infinity}, 10: {0: +Infinity, 1: +Infinity, 2: +Infinity, 3: +Infinity, 4: +Infinity, 5: +Infinity, 6: +Infinity, 7: +Infinity, 8: +Infinity, 9: +Infinity, 10: 0}}
sage: print pred
{0: {0: None, 1: 0, 2: 1, 3: 4, 4: 0, 5: 0, 6: 1, 7: 5, 8: 5, 9: 4, 10: None}, 1: {0: 1, 1: None, 2: 1, 3: 2, 4: 0, 5: 0, 6: 1, 7: 2, 8: 6, 9: 6, 10: None}, 2: {0: 1, 1: 2, 2: None, 3: 2, 4: 3, 5: 7, 6: 1, 7: 2, 8: 3, 9: 7, 10: None}, 3: {0: 4, 1: 2, 2: 3, 3: None, 4: 3, 5: 8, 6: 8, 7: 2, 8: 3, 9: 4, 10: None}, 4: {0: 4, 1: 0, 2: 3, 3: 4, 4: None, 5: 0, 6: 9, 7: 9, 8: 3, 9: 4, 10: None}, 5: {0: 5, 1: 0, 2: 7, 3: 8, 4: 0, 5: None, 6: 8, 7: 5, 8: 5, 9: 7, 10: None}, 6: {0: 1, 1: 6, 2: 1, 3: 8, 4: 9, 5: 8, 6: None, 7: 9, 8: 6, 9: 6, 10: None}, 7: {0: 5, 1: 2, 2: 7, 3: 2, 4: 9, 5: 7, 6: 9, 7: None, 8: 5, 9: 7, 10: None}, 8: {0: 5, 1: 6, 2: 3, 3: 8, 4: 3, 5: 8, 6: 8, 7: 5, 8: None, 9: 6, 10: None}, 9: {0: 4, 1: 6, 2: 7, 3: 4, 4: 9, 5: 7, 6: 9, 7: 9, 8: 6, 9: None, 10: None}, 10: {0: None, 1: None, 2: None, 3: None, 4: None, 5: None, 6: None, 7: None, 8: None, 9: None, 10: None}}
sage: dist,pred = G.shortest_path_all_pairs()
sage: print dist
{0: {0: 0, 1: 1, 2: 2, 3: 2, 4: 1, 5: 1, 6: 2, 7: 2, 8: 2, 9: 2, 10: +Infinity}, 1: {0: 1, 1: 0, 2: 1, 3: 2, 4: 2, 5: 2, 6: 1, 7: 2, 8: 2, 9: 2, 10: +Infinity}, 2: {0: 2, 1: 1, 2: 0, 3: 1, 4: 2, 5: 2, 6: 2, 7: 1, 8: 2, 9: 2, 10: +Infinity}, 3: {0: 2, 1: 2, 2: 1, 3: 0, 4: 1, 5: 2, 6: 2, 7: 2, 8: 1, 9: 2, 10: +Infinity}, 4: {0: 1, 1: 2, 2: 2, 3: 1, 4: 0, 5: 2, 6: 2, 7: 2, 8: 2, 9: 1, 10: +Infinity}, 5: {0: 1, 1: 2, 2: 2, 3: 2, 4: 2, 5: 0, 6: 2, 7: 1, 8: 1, 9: 2, 10: +Infinity}, 6: {0: 2, 1: 1, 2: 2, 3: 2, 4: 2, 5: 2, 6: 0, 7: 2, 8: 1, 9: 1, 10: +Infinity}, 7: {0: 2, 1: 2, 2: 1, 3: 2, 4: 2, 5: 1, 6: 2, 7: 0, 8: 2, 9: 1, 10: +Infinity}, 8: {0: 2, 1: 2, 2: 2, 3: 1, 4: 2, 5: 1, 6: 1, 7: 2, 8: 0, 9: 2, 10: +Infinity}, 9: {0: 2, 1: 2, 2: 2, 3: 2, 4: 1, 5: 2, 6: 1, 7: 1, 8: 2, 9: 0, 10: +Infinity}, 10: {0: +Infinity, 1: +Infinity, 2: +Infinity, 3: +Infinity, 4: +Infinity, 5: +Infinity, 6: +Infinity, 7: +Infinity, 8: +Infinity, 9: +Infinity, 10: 0}}
sage: print pred
{0: {0: None, 1: 0, 2: 1, 3: 4, 4: 0, 5: 0, 6: 1, 7: 5, 8: 5, 9: 4, 10: None}, 1: {0: 1, 1: None, 2: 1, 3: 2, 4: 0, 5: 0, 6: 1, 7: 2, 8: 6, 9: 6, 10: None}, 2: {0: 1, 1: 2, 2: None, 3: 2, 4: 3, 5: 7, 6: 1, 7: 2, 8: 3, 9: 7, 10: None}, 3: {0: 4, 1: 2, 2: 3, 3: None, 4: 3, 5: 8, 6: 8, 7: 2, 8: 3, 9: 4, 10: None}, 4: {0: 4, 1: 0, 2: 3, 3: 4, 4: None, 5: 0, 6: 9, 7: 9, 8: 3, 9: 4, 10: None}, 5: {0: 5, 1: 0, 2: 7, 3: 8, 4: 0, 5: None, 6: 8, 7: 5, 8: 5, 9: 7, 10: None}, 6: {0: 1, 1: 6, 2: 1, 3: 8, 4: 9, 5: 8, 6: None, 7: 9, 8: 6, 9: 6, 10: None}, 7: {0: 5, 1: 2, 2: 7, 3: 2, 4: 9, 5: 7, 6: 9, 7: None, 8: 5, 9: 7, 10: None}, 8: {0: 5, 1: 6, 2: 3, 3: 8, 4: 3, 5: 8, 6: 8, 7: 5, 8: None, 9: 6, 10: None}, 9: {0: 4, 1: 6, 2: 7, 3: 4, 4: 9, 5: 7, 6: 9, 7: 9, 8: 6, 9: None, 10: None}, 10: {0: None, 1: None, 2: None, 3: None, 4: None, 5: None, 6: None, 7: None, 8: None, 9: None, 10: None}}
```


Best,
David.



---

archive/issue_comments_254851.json:
```json
{
    "body": "Changing status from needs_review to needs_work.",
    "created_at": "2015-08-07T10:36:05Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18694",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18694#issuecomment-254851",
    "user": "dcoudert"
}
```

Changing status from needs_review to needs_work.



---

archive/issue_comments_254852.json:
```json
{
    "body": "Hello!\n\nThank you very much for your comments. I think we should discuss some issues, and I would like to hear also Nathann's opinion, because I think shortest paths are very important.\n\nIn the following, I tried to support the choices I made in the version of the code that will soon be uploaded: feel free to disagree!\n\nBest,\n\nMichele\n\nReplying to [comment:5 dcoudert]:\n\n> Hello,\n> \n> the output of the method is correct and already faster than networkx on small graphs. Excellent!\n\n:)\n\n> do you also plan to add `G.shortest_path()` ?\n\nUps, you are right. I am quite sure that the bidirectional Dijkstra that is already implemented is better than Boost Dijkstra algorithm (hence, I did not include it), but I did not think that we may add an algorithm that works with negative weights.\n\nNow I have done it! However, I still have doubts on what happens if we run Dijkstra with negative weights. Before this patch, the result was completely unreliable:\n\n\n```\nsage: G = DiGraph([(0,1,1),(1,2,1),(0,3,1000),(3,4,-3000), (4,2,1000)])\nsage: G.shortest_path_length(0, 2, by_weight=True, algorithm='Bellman-Ford_Boost')\n-1000\nsage: G.shortest_path_length(0, 2, by_weight=True)\n2\n```\n\nHowever, reading all edges to check if there are negative weights may increase drastically the running-time, since the algorithm is sublinear. Hence, I just added a note and two examples to show the issue. Moreover, now, if Dijkstra algorithm finds an edge with negative weight, an error is raised (however, if the error is not raised, it doesn't mean that the path is correct, as shown by the previous example). Do you think it is a good solution?\n\n> For all pairs shortest paths:\n> - we don't have predecessors with `Johnson_Boost`\n\nYes, it is documented in the OUTPUT section of the documentation. Unfortunately Boost does not have this feature, and recomputing predecessors from distances is too time-consuming. For this reason, I still use Floyd-Warshall algorithm as default, and I use the faster Johnson algorithm only if paths are not needed (for instance, when computing eccentricities).\n\n> - distance to unreacheable vertices should be set to +Infinity to be consistent with other methods.\n\nI think we should discuss a bit more this point. My proposal is to do the converse, that is, to remove from dictionaries all unreachable vertices: this is what I have done in this commit. I have some reasons to support this solution: please, let me know if you think they are sufficient!\n\nFirst of all, this task is memory-consuming, and saving memory for graphs which are not connected might be a good choice. Also the running-time is decreased, and the code is simplified. Furthermore, before, the predecessor of the starting vertex (None) was the same as the predecessor of unreachable vertices. This might be unwanted, if the user writes something like:\n\n\n```\ndistance_v_w = 0\nwhile pred[w] is not None:\n\u00a0\u00a0\u00a0 distance_v_w = distance_v_w + 1\n\u00a0\u00a0\u00a0 w = pred[w]\n\n```\n\nWith this code, the distance from an unreachable vertex is 0 (while I think we should distinguish between \"I have already reached the starting vertex\" and \"I cannot reach the starting vertex\").\n\nMoreover, the `shortest_paths` and `shortest_path_lengths` routines already follow this policy: adapting the `shortest_path_all_pairs` routine is good for consistency, to simplify the code and to reduce the running-time when `shortest_path_all_pairs` calls `shortest_paths`. Finally, one might easily imitate the other behavior by writing `d[v].get(w,Infinity)` instead of `d[v][w]`.",
    "created_at": "2015-08-07T13:59:14Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18694",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18694#issuecomment-254852",
    "user": "borassi"
}
```

Hello!

Thank you very much for your comments. I think we should discuss some issues, and I would like to hear also Nathann's opinion, because I think shortest paths are very important.

In the following, I tried to support the choices I made in the version of the code that will soon be uploaded: feel free to disagree!

Best,

Michele

Replying to [comment:5 dcoudert]:

> Hello,
> 
> the output of the method is correct and already faster than networkx on small graphs. Excellent!

:)

> do you also plan to add `G.shortest_path()` ?

Ups, you are right. I am quite sure that the bidirectional Dijkstra that is already implemented is better than Boost Dijkstra algorithm (hence, I did not include it), but I did not think that we may add an algorithm that works with negative weights.

Now I have done it! However, I still have doubts on what happens if we run Dijkstra with negative weights. Before this patch, the result was completely unreliable:


```
sage: G = DiGraph([(0,1,1),(1,2,1),(0,3,1000),(3,4,-3000), (4,2,1000)])
sage: G.shortest_path_length(0, 2, by_weight=True, algorithm='Bellman-Ford_Boost')
-1000
sage: G.shortest_path_length(0, 2, by_weight=True)
2
```

However, reading all edges to check if there are negative weights may increase drastically the running-time, since the algorithm is sublinear. Hence, I just added a note and two examples to show the issue. Moreover, now, if Dijkstra algorithm finds an edge with negative weight, an error is raised (however, if the error is not raised, it doesn't mean that the path is correct, as shown by the previous example). Do you think it is a good solution?

> For all pairs shortest paths:
> - we don't have predecessors with `Johnson_Boost`

Yes, it is documented in the OUTPUT section of the documentation. Unfortunately Boost does not have this feature, and recomputing predecessors from distances is too time-consuming. For this reason, I still use Floyd-Warshall algorithm as default, and I use the faster Johnson algorithm only if paths are not needed (for instance, when computing eccentricities).

> - distance to unreacheable vertices should be set to +Infinity to be consistent with other methods.

I think we should discuss a bit more this point. My proposal is to do the converse, that is, to remove from dictionaries all unreachable vertices: this is what I have done in this commit. I have some reasons to support this solution: please, let me know if you think they are sufficient!

First of all, this task is memory-consuming, and saving memory for graphs which are not connected might be a good choice. Also the running-time is decreased, and the code is simplified. Furthermore, before, the predecessor of the starting vertex (None) was the same as the predecessor of unreachable vertices. This might be unwanted, if the user writes something like:


```
distance_v_w = 0
while pred[w] is not None:
    distance_v_w = distance_v_w + 1
    w = pred[w]

```

With this code, the distance from an unreachable vertex is 0 (while I think we should distinguish between "I have already reached the starting vertex" and "I cannot reach the starting vertex").

Moreover, the `shortest_paths` and `shortest_path_lengths` routines already follow this policy: adapting the `shortest_path_all_pairs` routine is good for consistency, to simplify the code and to reduce the running-time when `shortest_path_all_pairs` calls `shortest_paths`. Finally, one might easily imitate the other behavior by writing `d[v].get(w,Infinity)` instead of `d[v][w]`.



---

archive/issue_comments_254853.json:
```json
{
    "body": "Branch pushed to git repo; I updated commit sha1. New commits:",
    "created_at": "2015-08-07T13:59:43Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18694",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18694#issuecomment-254853",
    "user": "git"
}
```

Branch pushed to git repo; I updated commit sha1. New commits:



---

archive/issue_comments_254854.json:
```json
{
    "body": "Hello,\n\nsorry for the late reply. Not always easy to find time when you are on vacation ;)\n\n> Now I have done it! However, I still have doubts on what happens if we run Dijkstra with negative weights. Before this patch, the result was completely unreliable:\n> \n> {{{\n> sage: G = DiGraph([(0,1,1),(1,2,1),(0,3,1000),(3,4,-3000), (4,2,1000)])\n> sage: G.shortest_path_length(0, 2, by_weight=True, algorithm='Bellman-Ford_Boost')\n> -1000\n> sage: G.shortest_path_length(0, 2, by_weight=True)\n> 2\n> }}}\n> However, reading all edges to check if there are negative weights may increase drastically the running-time, since the algorithm is sublinear. Hence, I just added a note and two examples to show the issue. Moreover, now, if Dijkstra algorithm finds an edge with negative weight, an error is raised (however, if the error is not raised, it doesn't mean that the path is correct, as shown by the previous example). Do you think it is a good solution?\n\nThis is embarrassing. If the graph has a negative cycle, the `Bellman-Ford` method should detect it!\nIf you check at the method I proposed in ticket #8714 (not finalized yet, but I can do it before or after this patch if it is interesting), which is a much more efficient way to implement Bellman Ford, the trick is to check that the algorithm may perform more than `n` iterations (i.e., a negative cost cycle allows for further reducing the costs). I don't know how the `Bellman-Ford_Boost` method is working, but if it cannot detect negative cost cycle, this is not good at all.\n\nWe must find a way to have reliable results.\n\nIs the `Bellman-Ford_Boost` method fast? In fact, if it is not faster than #8714, we can get ride of it and finalize #8714 instead. Let me know.\n \n> > For all pairs shortest paths:\n> > - we don't have predecessors with `Johnson_Boost`\n> \n> Yes, it is documented in the OUTPUT section of the documentation. Unfortunately Boost does not have this feature, and recomputing predecessors from distances is too time-consuming. For this reason, I still use Floyd-Warshall algorithm as default, and I use the faster Johnson algorithm only if paths are not needed (for instance, when computing eccentricities).\nOK\n \n> > - distance to unreacheable vertices should be set to +Infinity to be consistent with other methods.\n> \n> I think we should discuss a bit more this point. My proposal is to do the converse, that is, to remove from dictionaries all unreachable vertices: this is what I have done in this commit. I have some reasons to support this solution: please, let me know if you think they are sufficient!\n> \n> First of all, this task is memory-consuming, and saving memory for graphs which are not connected might be a good choice. Also the running-time is decreased, and the code is simplified. Furthermore, before, the predecessor of the starting vertex (None) was the same as the predecessor of unreachable vertices. This might be unwanted, if the user writes something like:\n> \n> {{{\n> distance_v_w = 0\n> while pred[w] is not None:\n> \u00a0\u00a0\u00a0 distance_v_w = distance_v_w + 1\n> \u00a0\u00a0\u00a0 w = pred[w]\n> \n> }}}\n> With this code, the distance from an unreachable vertex is 0 (while I think we should distinguish between \"I have already reached the starting vertex\" and \"I cannot reach the starting vertex\").\n> \n> Moreover, the `shortest_paths` and `shortest_path_lengths` routines already follow this policy: adapting the `shortest_path_all_pairs` routine is good for consistency, to simplify the code and to reduce the running-time when `shortest_path_all_pairs` calls `shortest_paths`. Finally, one might easily imitate the other behavior by writing `d[v].get(w,Infinity)` instead of `d[v][w]`.\n\nThat's correct and I buy your arguments.\nYou could eventually add a simple example like:\n\n```\nG = 2*graphs.PathGraph(2)\nd,_ = G.shortest_path_all_pairs()\nimport itertools\nfor u,v in itertools.combinations(G.vertices(),2):\n    print \"dist({}, {}) = {}\".format(u,v, d[u].get(v,+Infinity))\n```\n\nSo that non Python-expert can guess the `d[u].get(v,+Infinity)` trick.\n\n\nNathann, do you have other comments/suggestions?",
    "created_at": "2015-08-12T11:45:15Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18694",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18694#issuecomment-254854",
    "user": "dcoudert"
}
```

Hello,

sorry for the late reply. Not always easy to find time when you are on vacation ;)

> Now I have done it! However, I still have doubts on what happens if we run Dijkstra with negative weights. Before this patch, the result was completely unreliable:
> 
> {{{
> sage: G = DiGraph([(0,1,1),(1,2,1),(0,3,1000),(3,4,-3000), (4,2,1000)])
> sage: G.shortest_path_length(0, 2, by_weight=True, algorithm='Bellman-Ford_Boost')
> -1000
> sage: G.shortest_path_length(0, 2, by_weight=True)
> 2
> }}}
> However, reading all edges to check if there are negative weights may increase drastically the running-time, since the algorithm is sublinear. Hence, I just added a note and two examples to show the issue. Moreover, now, if Dijkstra algorithm finds an edge with negative weight, an error is raised (however, if the error is not raised, it doesn't mean that the path is correct, as shown by the previous example). Do you think it is a good solution?

This is embarrassing. If the graph has a negative cycle, the `Bellman-Ford` method should detect it!
If you check at the method I proposed in ticket #8714 (not finalized yet, but I can do it before or after this patch if it is interesting), which is a much more efficient way to implement Bellman Ford, the trick is to check that the algorithm may perform more than `n` iterations (i.e., a negative cost cycle allows for further reducing the costs). I don't know how the `Bellman-Ford_Boost` method is working, but if it cannot detect negative cost cycle, this is not good at all.

We must find a way to have reliable results.

Is the `Bellman-Ford_Boost` method fast? In fact, if it is not faster than #8714, we can get ride of it and finalize #8714 instead. Let me know.
 
> > For all pairs shortest paths:
> > - we don't have predecessors with `Johnson_Boost`
> 
> Yes, it is documented in the OUTPUT section of the documentation. Unfortunately Boost does not have this feature, and recomputing predecessors from distances is too time-consuming. For this reason, I still use Floyd-Warshall algorithm as default, and I use the faster Johnson algorithm only if paths are not needed (for instance, when computing eccentricities).
OK
 
> > - distance to unreacheable vertices should be set to +Infinity to be consistent with other methods.
> 
> I think we should discuss a bit more this point. My proposal is to do the converse, that is, to remove from dictionaries all unreachable vertices: this is what I have done in this commit. I have some reasons to support this solution: please, let me know if you think they are sufficient!
> 
> First of all, this task is memory-consuming, and saving memory for graphs which are not connected might be a good choice. Also the running-time is decreased, and the code is simplified. Furthermore, before, the predecessor of the starting vertex (None) was the same as the predecessor of unreachable vertices. This might be unwanted, if the user writes something like:
> 
> {{{
> distance_v_w = 0
> while pred[w] is not None:
>     distance_v_w = distance_v_w + 1
>     w = pred[w]
> 
> }}}
> With this code, the distance from an unreachable vertex is 0 (while I think we should distinguish between "I have already reached the starting vertex" and "I cannot reach the starting vertex").
> 
> Moreover, the `shortest_paths` and `shortest_path_lengths` routines already follow this policy: adapting the `shortest_path_all_pairs` routine is good for consistency, to simplify the code and to reduce the running-time when `shortest_path_all_pairs` calls `shortest_paths`. Finally, one might easily imitate the other behavior by writing `d[v].get(w,Infinity)` instead of `d[v][w]`.

That's correct and I buy your arguments.
You could eventually add a simple example like:

```
G = 2*graphs.PathGraph(2)
d,_ = G.shortest_path_all_pairs()
import itertools
for u,v in itertools.combinations(G.vertices(),2):
    print "dist({}, {}) = {}".format(u,v, d[u].get(v,+Infinity))
```

So that non Python-expert can guess the `d[u].get(v,+Infinity)` trick.


Nathann, do you have other comments/suggestions?



---

archive/issue_comments_254855.json:
```json
{
    "body": "Branch pushed to git repo; I updated commit sha1. New commits:",
    "created_at": "2015-08-12T13:27:42Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18694",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18694#issuecomment-254855",
    "user": "git"
}
```

Branch pushed to git repo; I updated commit sha1. New commits:



---

archive/issue_comments_254856.json:
```json
{
    "body": "Branch pushed to git repo; I updated commit sha1. New commits:",
    "created_at": "2015-08-12T13:37:47Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18694",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18694#issuecomment-254856",
    "user": "git"
}
```

Branch pushed to git repo; I updated commit sha1. New commits:



---

archive/issue_comments_254857.json:
```json
{
    "body": "Branch pushed to git repo; I updated commit sha1. New commits:",
    "created_at": "2015-08-12T14:38:22Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18694",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18694#issuecomment-254857",
    "user": "git"
}
```

Branch pushed to git repo; I updated commit sha1. New commits:



---

archive/issue_comments_254858.json:
```json
{
    "body": "Hello!\n\nDon't worry: thank you very much for having some time for me even if you are on holidays!\n\nSee you,\n\nMichele\n\nReplying to [comment:8 dcoudert]:\n\n\n> Hello,\n> \n> sorry for the late reply. Not always easy to find time when you are on vacation ;)\n> \n> \n> > Now  I have done it! However, I still have doubts on what happens if we run  Dijkstra with negative weights. Before this patch, the result was  completely unreliable:\n> > \n> > {{{\n> > sage: G = DiGraph([(0,1,1),(1,2,1),(0,3,1000),(3,4,-3000), (4,2,1000)])\n> > sage: G.shortest_path_length(0, 2, by_weight=True, algorithm='Bellman-Ford_Boost')\n> > -1000\n> > sage: G.shortest_path_length(0, 2, by_weight=True)\n> > 2\n> > }}}\n> > However,  reading all edges to check if there are negative weights may increase  drastically the running-time, since the algorithm is sublinear. Hence, I  just added a note and two examples to show the issue. Moreover, now, if  Dijkstra algorithm finds an edge with negative weight, an error is  raised (however, if the error is not raised, it doesn't mean that the  path is correct, as shown by the previous example). Do you think it is a  good solution?\n> > \n> \n> This is embarrassing. If the graph has a negative cycle, the `Bellman-Ford` method should detect it!\n> If you check at the method I proposed in ticket #8714  (not finalized yet, but I can do it before or after this patch if it is  interesting), which is a much more efficient way to implement Bellman  Ford, the trick is to check that the algorithm may perform more than `n` iterations (i.e., a negative cost cycle allows for further reducing the costs). I don't know how the `Bellman-Ford_Boost` method is working, but if it cannot detect negative cost cycle, this is not good at all.\n> \n> We must find a way to have reliable results.\n> \n> Is the `Bellman-Ford_Boost` method fast? In fact, if it is not faster than #8714, we can get ride of it and finalize #8714 instead. Let me know.\n\nMaybe  I was not clear enough when trying to explain the problem. In  particular, it comes out with *Dijkstra*, not with Bellman-Ford.  The `Bellman-Ford_Boost` algorithm is quite efficient (maybe you can  improve it with #8714,  but only by constant factors), and it outputs an error if there is a  negative cycle. This error is collected by my code, and an exception is  raised, saying `ValueError: The graph contains a negative cycle.`. So far, so good, I think.\n\nAlso Dijkstra is okay, if it is not bidirectional, as shown by the examples of function `shortest_paths`.\n\nThe problem occurs with bidirectional Dijkstra, in routine `shortest_path`:  bidirectional algorithms are designed to cut visits as soon as  possible, so that the total running-time is sublinear. However, these  cuts are based on the fact that all unvisited edges have positive  weights. Hence, the only possibility is to hope that the user does not  ask for bidirectional algorithms with negative weights, I think. Is it  clear now? \n\n> You could eventually add a simple example like:\n> {{{\n> G = 2*graphs.[This is the Trac macro *PathGraph* that was inherited from the migration](https://trac.sagemath.org/wiki/WikiMacros#PathGraph-macro)(2)\n> d,_ = G.shortest_path_all_pairs()\n> import itertools\n> for u,v in itertools.combinations(G.vertices(),2):\n> print \"dist({}, {}) = {}\".format(u,v, d[u].get(v,+Infinity))\n> }}}\n> So that non Python-expert can guess the `d[u].get(v,+Infinity)` trick.\n\nDone!",
    "created_at": "2015-08-12T14:39:49Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18694",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18694#issuecomment-254858",
    "user": "borassi"
}
```

Hello!

Don't worry: thank you very much for having some time for me even if you are on holidays!

See you,

Michele

Replying to [comment:8 dcoudert]:


> Hello,
> 
> sorry for the late reply. Not always easy to find time when you are on vacation ;)
> 
> 
> > Now  I have done it! However, I still have doubts on what happens if we run  Dijkstra with negative weights. Before this patch, the result was  completely unreliable:
> > 
> > {{{
> > sage: G = DiGraph([(0,1,1),(1,2,1),(0,3,1000),(3,4,-3000), (4,2,1000)])
> > sage: G.shortest_path_length(0, 2, by_weight=True, algorithm='Bellman-Ford_Boost')
> > -1000
> > sage: G.shortest_path_length(0, 2, by_weight=True)
> > 2
> > }}}
> > However,  reading all edges to check if there are negative weights may increase  drastically the running-time, since the algorithm is sublinear. Hence, I  just added a note and two examples to show the issue. Moreover, now, if  Dijkstra algorithm finds an edge with negative weight, an error is  raised (however, if the error is not raised, it doesn't mean that the  path is correct, as shown by the previous example). Do you think it is a  good solution?
> > 
> 
> This is embarrassing. If the graph has a negative cycle, the `Bellman-Ford` method should detect it!
> If you check at the method I proposed in ticket #8714  (not finalized yet, but I can do it before or after this patch if it is  interesting), which is a much more efficient way to implement Bellman  Ford, the trick is to check that the algorithm may perform more than `n` iterations (i.e., a negative cost cycle allows for further reducing the costs). I don't know how the `Bellman-Ford_Boost` method is working, but if it cannot detect negative cost cycle, this is not good at all.
> 
> We must find a way to have reliable results.
> 
> Is the `Bellman-Ford_Boost` method fast? In fact, if it is not faster than #8714, we can get ride of it and finalize #8714 instead. Let me know.

Maybe  I was not clear enough when trying to explain the problem. In  particular, it comes out with *Dijkstra*, not with Bellman-Ford.  The `Bellman-Ford_Boost` algorithm is quite efficient (maybe you can  improve it with #8714,  but only by constant factors), and it outputs an error if there is a  negative cycle. This error is collected by my code, and an exception is  raised, saying `ValueError: The graph contains a negative cycle.`. So far, so good, I think.

Also Dijkstra is okay, if it is not bidirectional, as shown by the examples of function `shortest_paths`.

The problem occurs with bidirectional Dijkstra, in routine `shortest_path`:  bidirectional algorithms are designed to cut visits as soon as  possible, so that the total running-time is sublinear. However, these  cuts are based on the fact that all unvisited edges have positive  weights. Hence, the only possibility is to hope that the user does not  ask for bidirectional algorithms with negative weights, I think. Is it  clear now? 

> You could eventually add a simple example like:
> {{{
> G = 2*graphs.[This is the Trac macro *PathGraph* that was inherited from the migration](https://trac.sagemath.org/wiki/WikiMacros#PathGraph-macro)(2)
> d,_ = G.shortest_path_all_pairs()
> import itertools
> for u,v in itertools.combinations(G.vertices(),2):
> print "dist({}, {}) = {}".format(u,v, d[u].get(v,+Infinity))
> }}}
> So that non Python-expert can guess the `d[u].get(v,+Infinity)` trick.

Done!



---

archive/issue_comments_254859.json:
```json
{
    "body": "Changing status from needs_work to needs_review.",
    "created_at": "2015-08-12T14:40:03Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18694",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18694#issuecomment-254859",
    "user": "borassi"
}
```

Changing status from needs_work to needs_review.



---

archive/issue_comments_254860.json:
```json
{
    "body": "Branch pushed to git repo; I updated commit sha1. New commits:",
    "created_at": "2015-08-13T16:33:05Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18694",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18694#issuecomment-254860",
    "user": "git"
}
```

Branch pushed to git repo; I updated commit sha1. New commits:



---

archive/issue_comments_254861.json:
```json
{
    "body": "Changing status from needs_review to positive_review.",
    "created_at": "2015-08-13T17:11:46Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18694",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18694#issuecomment-254861",
    "user": "dcoudert"
}
```

Changing status from needs_review to positive_review.



---

archive/issue_comments_254862.json:
```json
{
    "body": "Hello,\n\nI don't know how is implemented the `Bellman-Ford_Boost`, but the implementation I proposed in #8714 is quite smart since the running time is in between `O(n+m)` and `O(n^2)`, depending on the weights. Anyway, now that you have improved and cleaned many parts, I will be able to compare #8714 and see if it is interesting to finalize it or not.\n\nThis is really big patch. It passes all tests and the doc builds properly and looks good.\nI don't have comments anymore and so Iset the ticket to positive review.\n\nBest,\nDavid.",
    "created_at": "2015-08-13T17:11:46Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18694",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18694#issuecomment-254862",
    "user": "dcoudert"
}
```

Hello,

I don't know how is implemented the `Bellman-Ford_Boost`, but the implementation I proposed in #8714 is quite smart since the running time is in between `O(n+m)` and `O(n^2)`, depending on the weights. Anyway, now that you have improved and cleaned many parts, I will be able to compare #8714 and see if it is interesting to finalize it or not.

This is really big patch. It passes all tests and the doc builds properly and looks good.
I don't have comments anymore and so Iset the ticket to positive review.

Best,
David.



---

archive/issue_comments_254863.json:
```json
{
    "body": "Resolution: fixed",
    "created_at": "2015-08-13T20:21:13Z",
    "issue": "https://github.com/sagemath/sagetest/issues/18694",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/18694#issuecomment-254863",
    "user": "vbraun"
}
```

Resolution: fixed
