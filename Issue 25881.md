# Issue 25881: sage -tp times out on a 160 core machine

Issue created by migration from https://trac.sagemath.org/ticket/26118

Original creator: saraedum

Original creation time: 2018-08-24 02:32:11

CC:  slelievre roed

Strangely `SAGE_NUM_THREADS=160 sage -tp --long --all` produces lots of timeouts on a 160 core machine.

It turns out that only a few cores are actually used (three or four most of the time) which seems to be related to the set CPU affinity. I've read some reports online that numpy sets that affinity.

This ugly workaround fixes it:
```
--- a/src/sage/doctest/forker.py
+++ b/src/sage/doctest/forker.py
`@``@` -1696,6 +1696,9 `@``@` class DocTestDispatcher(SageObject):
         # Logger
         log = self.controller.log
 
+        import os
+        os.system("taskset -p 0xffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffff %d 2>/dev/null >/dev/null" % os.getpid())
+
         from cysignals.pselect import PSelecter
         try:
             # Block SIGCHLD and SIGINT except during the pselect() call
```


---

Comment by saraedum created at 2018-08-24 02:32:59

roed: As you are often working on k8s. Does this also happen there?


---

Comment by saraedum created at 2018-08-24 02:48:48

With an initial workaround, that set the CPU affinity before forking:

Btw., with that workaround often the following part of the "A tour of Sage" in all languages hangs:

```
Trying (line 99):    m = random_matrix(RDF,500)
Expecting nothing
ok [0.09 s]
Trying (line 108):    e = m.eigenvalues()  # ungefähr 2 Sekunden
Expecting nothing
```


So maybe this has something to do with some BLAS?


---

Comment by saraedum created at 2018-08-24 03:01:26

The hangs do not happen anymore with `OPENBLAS_NUM_THREADS=1` and `sage -tp --all` finishes in 2:29 minutes (which is the time it takes to run the tests in `sage.manifolds.differentiable.tensorfield`).


---

Comment by embray created at 2018-08-24 12:57:37

What I want to know is, where is this 160 core machine and can I use it to build sage?


---

Comment by roed created at 2018-08-24 12:59:38

I haven't seen this on k8s, though I haven't been using it much recently.


---

Comment by saraedum created at 2018-08-24 13:02:07

Replying to [comment:5 embray]:
> What I want to know is, where is this 160 core machine and can I use it to build sage?
I spawned it with the google cloud credits from slelievre. I think they still work for today if you want to play with it.


---

Comment by saraedum created at 2018-08-24 14:32:59

Replying to [comment:6 roed]:
> I haven't seen this on k8s, though I haven't been using it much recently.
This seems to be a new issue caused by #24669.


---

Comment by saraedum created at 2018-08-24 14:42:11

See #21323 for some background on `OPENBLAS_NUM_THREADS`.


---

Comment by saraedum created at 2018-08-24 14:53:12

Setting `export OPENBLAS_MAIN_FREE=1` causes hangs in the "a tour of Sage", same as in comment 3.


---

Comment by saraedum created at 2018-08-24 15:21:28

Changing status from new to needs_review.


---

Comment by saraedum created at 2018-08-24 15:21:28

New commits:


---

Comment by saraedum created at 2018-08-24 15:42:40

`SAGE_NUM_THREADS=160 sage -tp --long --all` btw crashes with segfaults in `gentourng`; that's probably unrelated.

`SAGE_NUM_THREADS=1 SAGE_NUM_THREADS_PARALLEL=160 sage -tp --long --all` works however, and finishes after 4 minutes (which is the time that sage.schemes.elliptic_curves.ell_number_field takes…)

Note that the latter setting would not work without the changes introduced in this ticket (all 160 workers are scheduled on the same core.)


---

Comment by @timokau created at 2018-08-24 15:42:54

If we decide to set `OPENBLAS_NUM_THREADS=1`, would it be possible to set it within python instead of in `sage-env`? That way it would also work when using `from sage import ...`.


---

Comment by embray created at 2018-08-24 16:41:05

Changing status from needs_review to needs_work.


---

Comment by embray created at 2018-08-24 16:41:05

Let us not set this is for all cases; in normal usage it is not a problem, only in the doctests.  And only, it seems, in extreme cases.  I would prefer to find out exactly what the limits are here and limit functionality only near those limits (and to maybe investigate what exactly is going on at those limits and maybe fix the underlying issue).


---

Comment by @timokau created at 2018-08-24 16:43:43

What makes you think this is only a doctest problem?


---

Comment by saraedum created at 2018-08-24 18:22:49

Yes, please look at my benchmarks above. This is a performance and a stability problem in normal usage.


---

Comment by vbraun created at 2018-08-24 22:49:32

Changing status from needs_work to positive_review.


---

Comment by vbraun created at 2018-08-24 22:49:32

I've also noted the wrong cpu affinity on the buildbot, it is a major nuisance.


---

Comment by vbraun created at 2018-08-25 11:01:27

Resolution: fixed


---

Comment by embray created at 2018-08-29 13:41:03

I don't see why you would want to set this for all use cases.  It seems, rather, libraries that use their own multithreading and would conflict with openblas's should explicitly set `openblas_set_num_threads` as in #21323#comment:7

This just looks like a brute-force workaround for a specific case.


---

Comment by embray created at 2018-08-29 13:52:46

I there some reliable way to reproduce this problem?  I'm having trouble even doing that, though I'm sure it's possible.


---

Comment by vbraun created at 2018-08-29 22:36:52

It was quite reproducible. But afair the cpu affinity is only set in the course of running the tests, not immediately. Wait until make ptestlong is mostly done and then check the taskset output.


---

Comment by embray created at 2018-09-03 10:21:21

I'm not sure what I'm looking for here.  Julian suggested that it's a problem that occurs in "normal usage".  Is there a way to reproduce this problem without having to run `make ptestlong`?

In any case it sounds like a bug that should be fixed in openblas, not hackishly worked around.  The reason I'm confused is that in the doctests we fork for every test, so I don't see why there would be a problem with thread CPU affinity since from test to test it's not even going to be reusing the same threads.

Perhaps I need to study more carefully what exactly this option is doing in openblas.


---

Comment by saraedum created at 2018-09-03 10:25:20

Replying to [comment:26 embray]:
> I'm not sure what I'm looking for here.  Julian suggested that it's a problem that occurs in "normal usage".  Is there a way to reproduce this problem without having to run `make ptestlong`?

Yes, see ticket description.


---

Comment by embray created at 2018-09-03 10:33:02

I see; it's nothing to do with thread CPU affinity at all, but process CPU affinity.  The mention of `OPENBLAS_NUM_THREADS=1` had me thinking this was something about threads.  That makes more sense.

What's weird is that `gotoblas_affinity_init()` still sets up a new CPU affinity mask and installs it with `sched_setaffinity()`--does some stuff I don't understand--and _then_ if `OPENBLAS_MAIN_FREE=1` and only if, calls `sched_setaffinity()` again to set it back to the original mask.


---

Comment by embray created at 2018-09-03 10:41:25

Replying to [comment:27 saraedum]:
> Replying to [comment:26 embray]:
> > I'm not sure what I'm looking for here.  Julian suggested that it's a problem that occurs in "normal usage".  Is there a way to reproduce this problem without having to run `make ptestlong`?
> 
> Yes, see ticket description.

I tried that, but there was only one time I was able to get a kind of slow result, and I think I deleted that matrix.  Now, no matter how many times I try to create a random matrix, I seem to be getting ones whose eigenvalues are solved very quickly and I barely see any problem.  Perhaps I need some specific matrix that exhibits the problem.

Anyways, now that I've looked at the openblas code I have no problem with this workaround.  I want to understand the code in openblas a bit better, but I agree that for the purposes of Sage we don't have any reason for openblas to mess with CPU affinity.  Perhaps we should even build Sage's openblas with `NO_AFFINITY=1` (but keep the environment variable set for non-Sage builds of openblas).


---

Comment by embray created at 2018-09-03 10:51:42

I'm surprised `OPENBLAS_NUM_THREADS=1` didn't work for you:


```c
#ifdef USE_OPENMP
  numprocs = 0;
#else
  numprocs = readenv_atoi("OPENBLAS_NUM_THREADS");
  if (numprocs == 0) numprocs = readenv_atoi("GOTO_NUM_THREADS");
#endif

  if (numprocs == 0) numprocs = readenv_atoi("OMP_NUM_THREADS");

  numnodes = 1;

  if (numprocs == 1) {
    disable_mapping = 1;
    return;
  }
```



---

Comment by saraedum created at 2018-09-03 10:55:39

Sorry, I don't understand what you mean with "didn't work for you".


---

Comment by embray created at 2018-09-03 11:03:24

Nevermind, apparently it did: #26118#comment:4
I misread something else.
