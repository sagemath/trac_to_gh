# Issue 31530: Enhanced checks for sign() with qqbar elements with addition and subtraction

archive/issues_031530.json:
```json
{
    "body": "CC:  @videlec @mezzarobba @mwageringel @fredrik-johansson @saraedum @slel\n\nKeywords: qqbar\n\nThe following are painfully slow:\n\n```\nsage: x1 = AA(2^(1/100))\nsage: x2 = AA(2^(1/100))\nsage: y = x1 - x2\nsage: z = x1 - x2\nsage: y == y\nsage: y == 0\nsage: y == z\n```\nNote that for testing, you need to recreate `y` before each comparison as otherwise it has been made exact.\n\nWe avoid computing the minimum polynomial (as it calls `exactify()`) in the rich comparison until we need to. We also avoid calling `exactify()` for a binary operation in `sign()` until we absolutely need to. Additionally, the identity test is not done before reaching `_richcmp_`.\n\nIssue created by migration from https://trac.sagemath.org/ticket/31767\n\n",
    "created_at": "2021-05-03T01:37:39Z",
    "labels": [
        "component: performance"
    ],
    "milestone": "https://github.com/sagemath/sagetest/milestones/sage-9.4",
    "title": "Enhanced checks for sign() with qqbar elements with addition and subtraction",
    "type": "issue",
    "url": "https://github.com/sagemath/sagetest/issues/31530",
    "user": "https://github.com/tscrim"
}
```
CC:  @videlec @mezzarobba @mwageringel @fredrik-johansson @saraedum @slel

Keywords: qqbar

The following are painfully slow:

```
sage: x1 = AA(2^(1/100))
sage: x2 = AA(2^(1/100))
sage: y = x1 - x2
sage: z = x1 - x2
sage: y == y
sage: y == 0
sage: y == z
```
Note that for testing, you need to recreate `y` before each comparison as otherwise it has been made exact.

We avoid computing the minimum polynomial (as it calls `exactify()`) in the rich comparison until we need to. We also avoid calling `exactify()` for a binary operation in `sign()` until we absolutely need to. Additionally, the identity test is not done before reaching `_richcmp_`.

Issue created by migration from https://trac.sagemath.org/ticket/31767





---

archive/issue_comments_450172.json:
```json
{
    "body": "I have not run any timings on this, but things to check for speed regressions would be low degree minimal polynomials. Suggestions for good timing tests would be useful.\n\nI don't completely understand why I need to update some of the test for the eigenvalues, but the real precision seems to have significantly improved. So there might be some other doctests that need fixing; waiting for the patchbot.\n\nI also took the change to mark a test as `# long time` that was taking nearly 2 seconds on my computer.\n\n---\nNew commits:",
    "created_at": "2021-05-03T01:59:14Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31530",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31530#issuecomment-450172",
    "user": "https://github.com/tscrim"
}
```

I have not run any timings on this, but things to check for speed regressions would be low degree minimal polynomials. Suggestions for good timing tests would be useful.

I don't completely understand why I need to update some of the test for the eigenvalues, but the real precision seems to have significantly improved. So there might be some other doctests that need fixing; waiting for the patchbot.

I also took the change to mark a test as `# long time` that was taking nearly 2 seconds on my computer.

---
New commits:



---

archive/issue_comments_450173.json:
```json
{
    "body": "Changing status from new to needs_review.",
    "created_at": "2021-05-03T01:59:14Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31530",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31530#issuecomment-450173",
    "user": "https://github.com/tscrim"
}
```

Changing status from new to needs_review.



---

archive/issue_comments_450174.json:
```json
{
    "body": "See also #31768 for a followup subclassing `ANUnaryExpr` for some finer control and trivial simplifications.",
    "created_at": "2021-05-03T03:37:36Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31530",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31530#issuecomment-450174",
    "user": "https://github.com/tscrim"
}
```

See also #31768 for a followup subclassing `ANUnaryExpr` for some finer control and trivial simplifications.



---

archive/issue_comments_450175.json:
```json
{
    "body": "This proposal looks good to me but\n\n```\n+            # Rationals\n+            if type(sd._left._descr) is ANRational and type(sd._right._descr) is ANRational:\n+                ret = sd._op(sd._left._descr._value, sd._right._descr._value)\n+                if ret == 0:\n+                    self._set_descr(ANRational(QQ.zero()))\n+                    return 0\n+                return ret.sign()\n```\nDo you have an instance where the above code path is used? When both operands are rationals the descriptor should be automatically updated. We don't want to repeat this block in all possible places `cmp`, `sign`, `_add_`, ...\n\nReplying to [comment:1 tscrim]:\n> I have not run any timings on this, but things to check for speed regressions would be low degree minimal polynomials. Suggestions for good timing tests would be useful.\n> \n> I don't completely understand why I need to update some of the test for the eigenvalues, but the real precision seems to have significantly improved. So there might be some other doctests that need fixing; waiting for the patchbot.\n\n\nWhen precision increases it is typically that more enclosure refinement occurred. With the new code it looks to me that we should have less refinement. If my diagnostic is correct, this is bad. Would be nice to check what are the diameters of the intervals before and after the change.",
    "created_at": "2021-05-03T06:34:29Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31530",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31530#issuecomment-450175",
    "user": "https://github.com/videlec"
}
```

This proposal looks good to me but

```
+            # Rationals
+            if type(sd._left._descr) is ANRational and type(sd._right._descr) is ANRational:
+                ret = sd._op(sd._left._descr._value, sd._right._descr._value)
+                if ret == 0:
+                    self._set_descr(ANRational(QQ.zero()))
+                    return 0
+                return ret.sign()
```
Do you have an instance where the above code path is used? When both operands are rationals the descriptor should be automatically updated. We don't want to repeat this block in all possible places `cmp`, `sign`, `_add_`, ...

Replying to [comment:1 tscrim]:
> I have not run any timings on this, but things to check for speed regressions would be low degree minimal polynomials. Suggestions for good timing tests would be useful.
> 
> I don't completely understand why I need to update some of the test for the eigenvalues, but the real precision seems to have significantly improved. So there might be some other doctests that need fixing; waiting for the patchbot.


When precision increases it is typically that more enclosure refinement occurred. With the new code it looks to me that we should have less refinement. If my diagnostic is correct, this is bad. Would be nice to check what are the diameters of the intervals before and after the change.



---

archive/issue_comments_450176.json:
```json
{
    "body": "Replying to [comment:3 vdelecroix]:\n> This proposal looks good to me but\n> \n> ```\n> +            # Rationals\n> +            if type(sd._left._descr) is ANRational and type(sd._right._descr) is ANRational:\n> +                ret = sd._op(sd._left._descr._value, sd._right._descr._value)\n> +                if ret == 0:\n> +                    self._set_descr(ANRational(QQ.zero()))\n> +                    return 0\n> +                return ret.sign()\n> ```\n> Do you have an instance where the above code path is used? When both operands are rationals the descriptor should be automatically updated. We don't want to repeat this block in all possible places `cmp`, `sign`, `_add_`, ...\n\n\nThis is occurring after a call to `exactify()`. Thus, we could have something that ends up being a rational that didn't know it before. For example, `b = a - (a + 1)` for some irrational `a`, then taking `b + 1 == 0`). Adding a `print(\"rat check\")` just after the `if` statement gives:\n\n```sage\nsage: a = AA(sqrt(2))\nsage: b = a - (a + 1)\nsage: (b + 1).sign()\nrat check\n0\n```\nI will add this as a test and push. I also need to figure out why the test in `src/sage/geometry/polyhedron/backend_field.py` is failing too...\n\n> Replying to [comment:1 tscrim]:\n> > I have not run any timings on this, but things to check for speed regressions would be low degree minimal polynomials. Suggestions for good timing tests would be useful.\n> > \n> > I don't completely understand why I need to update some of the test for the eigenvalues, but the real precision seems to have significantly improved. So there might be some other doctests that need fixing; waiting for the patchbot.\n\n> \n> When precision increases it is typically that more enclosure refinement occurred. With the new code it looks to me that we should have less refinement. If my diagnostic is correct, this is bad. Would be nice to check what are the diameters of the intervals before and after the change.\n\n\nHere is what is happening. Because we are sorting the (complex) roots, we compare things lex on the `(real, imag)` pair. Eventually it has to check that the real parts of the two numbers are not equal (see `case 3:`). This calls the real `_richcmp_` method. In here, before it computed the `minpoly()` (which called `exactify()` of the treal parts), whereas now only gets the minpoly if they are known, so it first tries the refinement before ultimately ended up calling `exactify()` (as both are supposed to actually be 0). This gets called when comparing these roots with a root that is explicitly known with a real part of 0.\n\nI don't think this is a bad thing as I believe the refinement is a relatively fast operation, especially if we ultimately compute `exactify()` on most elements. Also, getting rid of calls to `exactify()` in cases when it is not needed is a larger benefit IMO. However, some more actual use-cases could be useful here for testing timings.",
    "created_at": "2021-05-04T03:03:47Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31530",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31530#issuecomment-450176",
    "user": "https://github.com/tscrim"
}
```

Replying to [comment:3 vdelecroix]:
> This proposal looks good to me but
> 
> ```
> +            # Rationals
> +            if type(sd._left._descr) is ANRational and type(sd._right._descr) is ANRational:
> +                ret = sd._op(sd._left._descr._value, sd._right._descr._value)
> +                if ret == 0:
> +                    self._set_descr(ANRational(QQ.zero()))
> +                    return 0
> +                return ret.sign()
> ```
> Do you have an instance where the above code path is used? When both operands are rationals the descriptor should be automatically updated. We don't want to repeat this block in all possible places `cmp`, `sign`, `_add_`, ...


This is occurring after a call to `exactify()`. Thus, we could have something that ends up being a rational that didn't know it before. For example, `b = a - (a + 1)` for some irrational `a`, then taking `b + 1 == 0`). Adding a `print("rat check")` just after the `if` statement gives:

```sage
sage: a = AA(sqrt(2))
sage: b = a - (a + 1)
sage: (b + 1).sign()
rat check
0
```
I will add this as a test and push. I also need to figure out why the test in `src/sage/geometry/polyhedron/backend_field.py` is failing too...

> Replying to [comment:1 tscrim]:
> > I have not run any timings on this, but things to check for speed regressions would be low degree minimal polynomials. Suggestions for good timing tests would be useful.
> > 
> > I don't completely understand why I need to update some of the test for the eigenvalues, but the real precision seems to have significantly improved. So there might be some other doctests that need fixing; waiting for the patchbot.

> 
> When precision increases it is typically that more enclosure refinement occurred. With the new code it looks to me that we should have less refinement. If my diagnostic is correct, this is bad. Would be nice to check what are the diameters of the intervals before and after the change.


Here is what is happening. Because we are sorting the (complex) roots, we compare things lex on the `(real, imag)` pair. Eventually it has to check that the real parts of the two numbers are not equal (see `case 3:`). This calls the real `_richcmp_` method. In here, before it computed the `minpoly()` (which called `exactify()` of the treal parts), whereas now only gets the minpoly if they are known, so it first tries the refinement before ultimately ended up calling `exactify()` (as both are supposed to actually be 0). This gets called when comparing these roots with a root that is explicitly known with a real part of 0.

I don't think this is a bad thing as I believe the refinement is a relatively fast operation, especially if we ultimately compute `exactify()` on most elements. Also, getting rid of calls to `exactify()` in cases when it is not needed is a larger benefit IMO. However, some more actual use-cases could be useful here for testing timings.



---

archive/issue_comments_450177.json:
```json
{
    "body": "Branch pushed to git repo; I updated commit sha1. New commits:",
    "created_at": "2021-05-04T05:37:11Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31530",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31530#issuecomment-450177",
    "user": "https://trac.sagemath.org/admin/accounts/users/git"
}
```

Branch pushed to git repo; I updated commit sha1. New commits:



---

archive/issue_comments_450178.json:
```json
{
    "body": "Branch pushed to git repo; I updated commit sha1. New commits:",
    "created_at": "2021-05-04T06:01:36Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31530",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31530#issuecomment-450178",
    "user": "https://trac.sagemath.org/admin/accounts/users/git"
}
```

Branch pushed to git repo; I updated commit sha1. New commits:



---

archive/issue_comments_450179.json:
```json
{
    "body": "Branch pushed to git repo; I updated commit sha1. New commits:",
    "created_at": "2021-05-04T06:06:38Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31530",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31530#issuecomment-450179",
    "user": "https://trac.sagemath.org/admin/accounts/users/git"
}
```

Branch pushed to git repo; I updated commit sha1. New commits:



---

archive/issue_comments_450180.json:
```json
{
    "body": "I have fixed a bug with addition `x + (-x)` giving the wrong sign. This was the issue with `backend_field.py`. I added in a few other doctests and removed some redundant checks.\n\nI just don't know how much this will affect timings refining the precision instead of calling the `exactify()` via the `minpoly()`. Something else that might be useful is adding a way to compute the `minpoly` without computing `exactify()` for elements that have an idea about what their `minpoly` is. Mainly here I am thinking elements using `ANRoot`. We could also fashion something that passes around the `minpoly` when we do operations that preserve it, such as conjugation. This can be done on a separate ticket. What do you think?",
    "created_at": "2021-05-04T06:11:52Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31530",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31530#issuecomment-450180",
    "user": "https://github.com/tscrim"
}
```

I have fixed a bug with addition `x + (-x)` giving the wrong sign. This was the issue with `backend_field.py`. I added in a few other doctests and removed some redundant checks.

I just don't know how much this will affect timings refining the precision instead of calling the `exactify()` via the `minpoly()`. Something else that might be useful is adding a way to compute the `minpoly` without computing `exactify()` for elements that have an idea about what their `minpoly` is. Mainly here I am thinking elements using `ANRoot`. We could also fashion something that passes around the `minpoly` when we do operations that preserve it, such as conjugation. This can be done on a separate ticket. What do you think?



---

archive/issue_comments_450181.json:
```json
{
    "body": "Replying to [comment:8 tscrim]:\n> I have fixed a bug with addition `x + (-x)` giving the wrong sign. This was the issue with `backend_field.py`. I added in a few other doctests and removed some redundant checks.\n\n>\n> I just don't know how much this will affect timings refining the precision instead of calling the `exactify()` via the `minpoly()`. Something else that might be useful is adding a way to compute the `minpoly` without computing `exactify()` for elements that have an idea about what their `minpoly` is. Mainly here I am thinking elements using `ANRoot`. We could also fashion something that passes around the `minpoly` when we do operations that preserve it, such as conjugation. This can be done on a separate ticket. What do you think?\n\n\nComputing minpoly is doable and desirable for all descriptors without exactification. This is the reason why was introduced the function `composed_op` on polynomials\n\n```\nsage: x = polygen(QQ)\nsage: p = x^3 + 2*x - 1\nsage: q = x^3 - x + 3\nsage: a = p.roots(QQbar, multiplicities=False)[0]\nsage: b = q.roots(QQbar, multiplicities=False)[0]\nsage: r = p.composed_op(q, operator.add)\nsage: r(a + b)  # not necessary minpoly, but at least a multiple\n0.?e-15\n```\n\nMore generally, I think that QQbar elements beyond degree 8 (let say) should not try to find a reasonable representation of the number field they represent (what is exactify currently doing via `polred` which is costly). They should just be considered as the root of some irreducible polynomial. Computing minpoly of `a + b`, `abs(a)`, etc is doable.\n\nThough, all this logic is now in [Fredrik's calcium](https://fredrikj.net/calcium/) and I am not sure how much it is desirable to improve the version in Sage compared to having a calcium version of `AA`/`QQbar`.",
    "created_at": "2021-05-04T07:20:39Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31530",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31530#issuecomment-450181",
    "user": "https://github.com/videlec"
}
```

Replying to [comment:8 tscrim]:
> I have fixed a bug with addition `x + (-x)` giving the wrong sign. This was the issue with `backend_field.py`. I added in a few other doctests and removed some redundant checks.

>
> I just don't know how much this will affect timings refining the precision instead of calling the `exactify()` via the `minpoly()`. Something else that might be useful is adding a way to compute the `minpoly` without computing `exactify()` for elements that have an idea about what their `minpoly` is. Mainly here I am thinking elements using `ANRoot`. We could also fashion something that passes around the `minpoly` when we do operations that preserve it, such as conjugation. This can be done on a separate ticket. What do you think?


Computing minpoly is doable and desirable for all descriptors without exactification. This is the reason why was introduced the function `composed_op` on polynomials

```
sage: x = polygen(QQ)
sage: p = x^3 + 2*x - 1
sage: q = x^3 - x + 3
sage: a = p.roots(QQbar, multiplicities=False)[0]
sage: b = q.roots(QQbar, multiplicities=False)[0]
sage: r = p.composed_op(q, operator.add)
sage: r(a + b)  # not necessary minpoly, but at least a multiple
0.?e-15
```

More generally, I think that QQbar elements beyond degree 8 (let say) should not try to find a reasonable representation of the number field they represent (what is exactify currently doing via `polred` which is costly). They should just be considered as the root of some irreducible polynomial. Computing minpoly of `a + b`, `abs(a)`, etc is doable.

Though, all this logic is now in [Fredrik's calcium](https://fredrikj.net/calcium/) and I am not sure how much it is desirable to improve the version in Sage compared to having a calcium version of `AA`/`QQbar`.



---

archive/issue_comments_450182.json:
```json
{
    "body": "Replying to [comment:1 tscrim]:\n> New commits:\n> |                                                                                                                                          |                                                            |\n> |------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------|\n> |[fc64ba2](https://git.sagemath.org/sage.git/commit?id=fc64ba2ec7d3337e2799fc57f78dcbb30dfa0fe7)|`Improvements to sign() and comparisons for qqbar elements.`|\n\n\nWhy not use (good enough refinements of) approximate values to compute the sign of x-y when x and y are known to have different minimal polynomials? (cf. https://groups.google.com/g/sage-devel/c/OaUlf5VHBbc/m/doZC1KpMBAAJ )",
    "created_at": "2021-05-04T12:06:32Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31530",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31530#issuecomment-450182",
    "user": "https://github.com/Ilia-Smilga"
}
```

Replying to [comment:1 tscrim]:
> New commits:
> |                                                                                                                                          |                                                            |
> |------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------|
> |[fc64ba2](https://git.sagemath.org/sage.git/commit?id=fc64ba2ec7d3337e2799fc57f78dcbb30dfa0fe7)|`Improvements to sign() and comparisons for qqbar elements.`|


Why not use (good enough refinements of) approximate values to compute the sign of x-y when x and y are known to have different minimal polynomials? (cf. https://groups.google.com/g/sage-devel/c/OaUlf5VHBbc/m/doZC1KpMBAAJ )



---

archive/issue_comments_450183.json:
```json
{
    "body": "comment:9: I agree that it is better to not invest a lot of time in improving `AA`/`QQbar` since it will almost certainly be replaced by Calcium. However, I think we can do a few improvements around the current code, and some of these changes might still be applicable once we switch the backend over (unlike, say, #31768). Perhaps we can include the current patch, maybe I will do a followup to try and lessen the impact of the changes.\n\nFredrik, do you have any comments about this?\n\ncomment:10: Once you have different minimal polynomials, then I believe you essentially have everything. Perhaps I have misunderstood something?\n\nGreen patchbot (the pyflakes warning existed before this ticket).",
    "created_at": "2021-05-05T01:55:54Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31530",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31530#issuecomment-450183",
    "user": "https://github.com/tscrim"
}
```

comment:9: I agree that it is better to not invest a lot of time in improving `AA`/`QQbar` since it will almost certainly be replaced by Calcium. However, I think we can do a few improvements around the current code, and some of these changes might still be applicable once we switch the backend over (unlike, say, #31768). Perhaps we can include the current patch, maybe I will do a followup to try and lessen the impact of the changes.

Fredrik, do you have any comments about this?

comment:10: Once you have different minimal polynomials, then I believe you essentially have everything. Perhaps I have misunderstood something?

Green patchbot (the pyflakes warning existed before this ticket).



---

archive/issue_comments_450184.json:
```json
{
    "body": "Actually, to construct a better refinement of `a + b` knowing the minimal polynomials `m_a(x)` and `m_b(x)` there are at least two strategies\n- compute `m_{a+b}(x)` (eg via `composed_op`) and do refinement with it\n- compute better refinement of `a` and `b` and add them\nDepending on `deg(m_a)`, `deg(m_b)`, `deg(m_{a+b})` it might be better to use the second option.",
    "created_at": "2021-05-05T06:39:22Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31530",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31530#issuecomment-450184",
    "user": "https://github.com/videlec"
}
```

Actually, to construct a better refinement of `a + b` knowing the minimal polynomials `m_a(x)` and `m_b(x)` there are at least two strategies
- compute `m_{a+b}(x)` (eg via `composed_op`) and do refinement with it
- compute better refinement of `a` and `b` and add them
Depending on `deg(m_a)`, `deg(m_b)`, `deg(m_{a+b})` it might be better to use the second option.



---

archive/issue_comments_450185.json:
```json
{
    "body": "To compare (the real parts of) two qqbars in Calcium, I just compare enclosures at a couple of different levels of precision, otherwise do an exact subtraction and check the sign of the difference. Most of the work will then be in the subtraction (which factors the resultant polynomial and then refines the precision of the inputs if needed to get the right root). This is not really optimized, but so far it has not been a bottleneck that I needed to fix. In fact, this issue reminds me that I did not even optimize for both inputs being real, in which case it will suffice to increase the precision until convergence...\n\nMore generally, it's an interesting problem to optimize computing sign(a1+a2+...+an) or proving a1+a2+...+an == 0 without computing the entire sum explicitly.",
    "created_at": "2021-05-05T08:31:28Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31530",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31530#issuecomment-450185",
    "user": "https://github.com/fredrik-johansson"
}
```

To compare (the real parts of) two qqbars in Calcium, I just compare enclosures at a couple of different levels of precision, otherwise do an exact subtraction and check the sign of the difference. Most of the work will then be in the subtraction (which factors the resultant polynomial and then refines the precision of the inputs if needed to get the right root). This is not really optimized, but so far it has not been a bottleneck that I needed to fix. In fact, this issue reminds me that I did not even optimize for both inputs being real, in which case it will suffice to increase the precision until convergence...

More generally, it's an interesting problem to optimize computing sign(a1+a2+...+an) or proving a1+a2+...+an == 0 without computing the entire sum explicitly.



---

archive/issue_comments_450186.json:
```json
{
    "body": "Replying to [comment:11 tscrim]:\n> comment:10: Once you have different minimal polynomials, then I believe you essentially have everything. Perhaps I have misunderstood something?\n\n\nConsider the following computation:\n\n```\nx = AA(1+100*2^(-1000))^(1/100)\ny = AA(1+101*2^(-1000))^(1/101)\nx < y\n```\n(which calls `sign(y-x)` internally). With your patch (if I read it correctly; I did not actually run it), Sage will notice that the minimal polynomials are different, but will not take advantage of that information. It will still trigger exact computation of `y-x` (which takes forever). \n\nI suggest adding for this case (different minimal polynomials) the code\n\n```\nwhile self._value.contains_zero():\n    self._more_precision()\nreturn self._value.unique_sign()\n```\nIs there any reason not to do so? (For the record: in this particular example, this loop takes 82ms on my machine.)",
    "created_at": "2021-05-05T10:22:32Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31530",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31530#issuecomment-450186",
    "user": "https://github.com/Ilia-Smilga"
}
```

Replying to [comment:11 tscrim]:
> comment:10: Once you have different minimal polynomials, then I believe you essentially have everything. Perhaps I have misunderstood something?


Consider the following computation:

```
x = AA(1+100*2^(-1000))^(1/100)
y = AA(1+101*2^(-1000))^(1/101)
x < y
```
(which calls `sign(y-x)` internally). With your patch (if I read it correctly; I did not actually run it), Sage will notice that the minimal polynomials are different, but will not take advantage of that information. It will still trigger exact computation of `y-x` (which takes forever). 

I suggest adding for this case (different minimal polynomials) the code

```
while self._value.contains_zero():
    self._more_precision()
return self._value.unique_sign()
```
Is there any reason not to do so? (For the record: in this particular example, this loop takes 82ms on my machine.)



---

archive/issue_comments_450187.json:
```json
{
    "body": "Replying to [comment:14 gh-Ilia-Smilga]:\n> I suggest adding for this case (different minimal polynomials) the code\n> \n> ```\n> while self._value.contains_zero():\n>     self._more_precision()\n> return self._value.unique_sign()\n> ```\n> Is there any reason not to do so? (For the record: in this particular example, this loop takes 82ms on my machine.)\n\n\nI see what you're saying, but that is a more invasive change. It probably is better to just do that here. However, I don't quite understand Dima's suggestion on the sage-devel thread. It probably is something simple, and I am just too tired to see it right now.",
    "created_at": "2021-05-05T12:52:42Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31530",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31530#issuecomment-450187",
    "user": "https://github.com/tscrim"
}
```

Replying to [comment:14 gh-Ilia-Smilga]:
> I suggest adding for this case (different minimal polynomials) the code
> 
> ```
> while self._value.contains_zero():
>     self._more_precision()
> return self._value.unique_sign()
> ```
> Is there any reason not to do so? (For the record: in this particular example, this loop takes 82ms on my machine.)


I see what you're saying, but that is a more invasive change. It probably is better to just do that here. However, I don't quite understand Dima's suggestion on the sage-devel thread. It probably is something simple, and I am just too tired to see it right now.



---

archive/issue_comments_450188.json:
```json
{
    "body": "In this part of the new code\n\n```\n        if sd._left.minpoly() == sd._right.minpoly():\n            # Negating the element does not change the minpoly\n            right = sd._right if sd._op is operator.sub else -sd._right\n            c = cmp_elements_with_same_minpoly(sd._left, right, sd._left.minpoly())\n            if c == 0:\n                self._set_descr(ANRational(QQ.zero()))\n                return 0\n            elif c is not None:\n                return c\n```\nyou seemed to ignore that the operator could be `mul` or `truediv`.",
    "created_at": "2021-05-30T08:16:28Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31530",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31530#issuecomment-450188",
    "user": "https://github.com/videlec"
}
```

In this part of the new code

```
        if sd._left.minpoly() == sd._right.minpoly():
            # Negating the element does not change the minpoly
            right = sd._right if sd._op is operator.sub else -sd._right
            c = cmp_elements_with_same_minpoly(sd._left, right, sd._left.minpoly())
            if c == 0:
                self._set_descr(ANRational(QQ.zero()))
                return 0
            elif c is not None:
                return c
```
you seemed to ignore that the operator could be `mul` or `truediv`.



---

archive/issue_comments_450189.json:
```json
{
    "body": "I wonder if we can improve *exactification* instead of avoiding it. At the moment any two instances of `AlgebraicGenerator` are recognized to be different, even if they describe the *same root* of the same polynomial. Is there a special reason for this? What is the idea behind the attribute `_index`?\n\nHowsoever, I did the following attempt modifying the method  `_richcmp_` of this class  and changed `self is other` in `union` to `self == other` and accordingly `super is self` to `super == self` in `super_poly` (`diff` shown with respect to stable 9.3):\n\n```diff\ndiff --git a/src/sage/rings/qqbar.py b/src/sage/rings/qqbar.py\nindex 81e333b..b94bea7 100644\n--- a/src/sage/rings/qqbar.py\n+++ b/src/sage/rings/qqbar.py\n@@ -2911,6 +2911,19 @@ class AlgebraicGenerator(SageObject):\n             sage: gen > qq_generator\n             True\n         \"\"\"\n+        sf = self._field\n+        of = other._field\n+        if type(sf) != type(of):\n+           return rich_to_bool(op, 1)\n+        if sf != of:\n+           return richcmp_not_equal(sf, of, op)\n+        sa = self.root_as_algebraic()\n+        oa = other.root_as_algebraic()\n+        if sa in QQ and oa in QQ:\n+            return richcmp(QQ(sa), QQ(oa), op)\n+        c = cmp_elements_with_same_minpoly(sa, oa, sf.polynomial())\n+        if c is not None:\n+            return rich_to_bool(op, c)\n         return richcmp(self._index, other._index, op)\n\n     def is_complex(self):\n@@ -3108,7 +3121,7 @@ class AlgebraicGenerator(SageObject):\n             return other\n         if other._trivial:\n             return self\n-        if self is other:\n+        if self == other:\n             return self\n         if other in self._unions:\n             return self._unions[other].parent\n@@ -3207,7 +3220,7 @@ class AlgebraicGenerator(SageObject):\n         if checked is None:\n             checked = {}\n         checked[self] = True\n-        if super is self:\n+        if super == self:\n             return self._field.gen()\n         for u in self._unions.values():\n             if u.parent in checked:\n```\n\nThis change passes through all doctests (including `--long`) and makes *exactification* possible for the testcase of the ticket description:\n\n```sage\nsage: x1 = AA(2^(1/100))\n....: x2 = AA(2^(1/100))\n....: y = x1 - x2\n....: z = x1 - x2\nsage: %time y._exact_field()\nCPU times: user 160 ms, sys: 16 ms, total: 176 ms\nWall time: 174 ms\nTrivial generator\nsage: %time y == z\nCPU times: user 260 ms, sys: 0 ns, total: 260 ms\nWall time: 259 ms\nTrue\n```\n\nOf course this does not solve the testcase of [comment:14](https://trac.sagemath.org/ticket/31767#comment:14). Concerning this it seems, that the function `composed_op` could do a good job here:\n\n\n\n```sage\nsage: x = AA(1+2*2^(-1000))^(1/2); y = AA(1+3*2^(-1000))^(1/3)\nsage: p = x.minpoly()\nsage: q = y.minpoly()\nsage: %time r = p.composed_op(q, operator.sub)\nCPU times: user 4 ms, sys: 0 ns, total: 4 ms\nWall time: 5.53 ms\nsage: %time F = r.factor()\nCPU times: user 0 ns, sys: 0 ns, total: 0 ns\nWall time: 2.65 ms\n```\n\nI would prefer such a solution since it would not just fix this issue, but also improve exactification in general. On the other hand I agree with Vincent that this only makes sense (in view of the upcoming Calcium), if it will be easy to realize.\n\nBut note, that this issue is different from the former one in not just hanging in Pari's `nffactor` but already one step before in the construction of the Pari number field (of degree two!):\n\n```sage\nsage: AG = x._exact_field()\nsage: AG.pari_field()\n^C---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\n<ipython-input-8-2b02365498e1> in <module>\n----> 1 AG.pari_field()\n\n~/devel/sage/local/lib/python3.9/site-packages/sage/rings/qqbar.py in pari_field(self)\n   3025         if self._pari_field is None:\n   3026             pari_pol = self._field.pari_polynomial(\"y\")\n-> 3027             self._pari_field = pari_pol.nfinit(1)\n   3028         return self._pari_field\n   3029\n\ncypari2/auto_gen.pxi in cypari2.gen.Gen_base.nfinit()\n\nKeyboardInterrupt:\n```\n\n\nThus, I would take this for bug in Pari, isn't it?",
    "created_at": "2021-05-30T09:10:08Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31530",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31530#issuecomment-450189",
    "user": "https://github.com/soehms"
}
```

I wonder if we can improve *exactification* instead of avoiding it. At the moment any two instances of `AlgebraicGenerator` are recognized to be different, even if they describe the *same root* of the same polynomial. Is there a special reason for this? What is the idea behind the attribute `_index`?

Howsoever, I did the following attempt modifying the method  `_richcmp_` of this class  and changed `self is other` in `union` to `self == other` and accordingly `super is self` to `super == self` in `super_poly` (`diff` shown with respect to stable 9.3):

```diff
diff --git a/src/sage/rings/qqbar.py b/src/sage/rings/qqbar.py
index 81e333b..b94bea7 100644
--- a/src/sage/rings/qqbar.py
+++ b/src/sage/rings/qqbar.py
@@ -2911,6 +2911,19 @@ class AlgebraicGenerator(SageObject):
             sage: gen > qq_generator
             True
         """
+        sf = self._field
+        of = other._field
+        if type(sf) != type(of):
+           return rich_to_bool(op, 1)
+        if sf != of:
+           return richcmp_not_equal(sf, of, op)
+        sa = self.root_as_algebraic()
+        oa = other.root_as_algebraic()
+        if sa in QQ and oa in QQ:
+            return richcmp(QQ(sa), QQ(oa), op)
+        c = cmp_elements_with_same_minpoly(sa, oa, sf.polynomial())
+        if c is not None:
+            return rich_to_bool(op, c)
         return richcmp(self._index, other._index, op)

     def is_complex(self):
@@ -3108,7 +3121,7 @@ class AlgebraicGenerator(SageObject):
             return other
         if other._trivial:
             return self
-        if self is other:
+        if self == other:
             return self
         if other in self._unions:
             return self._unions[other].parent
@@ -3207,7 +3220,7 @@ class AlgebraicGenerator(SageObject):
         if checked is None:
             checked = {}
         checked[self] = True
-        if super is self:
+        if super == self:
             return self._field.gen()
         for u in self._unions.values():
             if u.parent in checked:
```

This change passes through all doctests (including `--long`) and makes *exactification* possible for the testcase of the ticket description:

```sage
sage: x1 = AA(2^(1/100))
....: x2 = AA(2^(1/100))
....: y = x1 - x2
....: z = x1 - x2
sage: %time y._exact_field()
CPU times: user 160 ms, sys: 16 ms, total: 176 ms
Wall time: 174 ms
Trivial generator
sage: %time y == z
CPU times: user 260 ms, sys: 0 ns, total: 260 ms
Wall time: 259 ms
True
```

Of course this does not solve the testcase of [comment:14](https://trac.sagemath.org/ticket/31767#comment:14). Concerning this it seems, that the function `composed_op` could do a good job here:



```sage
sage: x = AA(1+2*2^(-1000))^(1/2); y = AA(1+3*2^(-1000))^(1/3)
sage: p = x.minpoly()
sage: q = y.minpoly()
sage: %time r = p.composed_op(q, operator.sub)
CPU times: user 4 ms, sys: 0 ns, total: 4 ms
Wall time: 5.53 ms
sage: %time F = r.factor()
CPU times: user 0 ns, sys: 0 ns, total: 0 ns
Wall time: 2.65 ms
```

I would prefer such a solution since it would not just fix this issue, but also improve exactification in general. On the other hand I agree with Vincent that this only makes sense (in view of the upcoming Calcium), if it will be easy to realize.

But note, that this issue is different from the former one in not just hanging in Pari's `nffactor` but already one step before in the construction of the Pari number field (of degree two!):

```sage
sage: AG = x._exact_field()
sage: AG.pari_field()
^C---------------------------------------------------------------------------
KeyboardInterrupt                         Traceback (most recent call last)
<ipython-input-8-2b02365498e1> in <module>
----> 1 AG.pari_field()

~/devel/sage/local/lib/python3.9/site-packages/sage/rings/qqbar.py in pari_field(self)
   3025         if self._pari_field is None:
   3026             pari_pol = self._field.pari_polynomial("y")
-> 3027             self._pari_field = pari_pol.nfinit(1)
   3028         return self._pari_field
   3029

cypari2/auto_gen.pxi in cypari2.gen.Gen_base.nfinit()

KeyboardInterrupt:
```


Thus, I would take this for bug in Pari, isn't it?



---

archive/issue_comments_450190.json:
```json
{
    "body": "Replying to [comment:16 vdelecroix]:\n> In this part of the new code\n> \n> ```\n>         if sd._left.minpoly() == sd._right.minpoly():\n>             # Negating the element does not change the minpoly\n>             right = sd._right if sd._op is operator.sub else -sd._right\n>             c = cmp_elements_with_same_minpoly(sd._left, right, sd._left.minpoly())\n>             if c == 0:\n>                 self._set_descr(ANRational(QQ.zero()))\n>                 return 0\n>             elif c is not None:\n>                 return c\n> ```\n> you seemed to ignore that the operator could be `mul` or `truediv`.\n\n\nThose cases already would have been picked up earlier in this block:\n\n```diff\n         elif type(sd) is ANBinaryExpr:\n             ls = sd._left.sign()\n             rs = sd._right.sign()\n             if sd._op is operator.mul or sd._op is operator.truediv:\n-                return sd._left.sign() * sd._right.sign()\n+                return ls * rs\n```",
    "created_at": "2021-06-01T01:04:24Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31530",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31530#issuecomment-450190",
    "user": "https://github.com/tscrim"
}
```

Replying to [comment:16 vdelecroix]:
> In this part of the new code
> 
> ```
>         if sd._left.minpoly() == sd._right.minpoly():
>             # Negating the element does not change the minpoly
>             right = sd._right if sd._op is operator.sub else -sd._right
>             c = cmp_elements_with_same_minpoly(sd._left, right, sd._left.minpoly())
>             if c == 0:
>                 self._set_descr(ANRational(QQ.zero()))
>                 return 0
>             elif c is not None:
>                 return c
> ```
> you seemed to ignore that the operator could be `mul` or `truediv`.


Those cases already would have been picked up earlier in this block:

```diff
         elif type(sd) is ANBinaryExpr:
             ls = sd._left.sign()
             rs = sd._right.sign()
             if sd._op is operator.mul or sd._op is operator.truediv:
-                return sd._left.sign() * sd._right.sign()
+                return ls * rs
```



---

archive/issue_comments_450191.json:
```json
{
    "body": "`@`soehms That seems like a good idea. However, we now have to come up with a better hash. My guess behind the  `_index` idea is that they wanted very fast comparison checks and hashing that is consistent with equality. This line actually dates back to the initial implementation of algebraic reals (commit `07704df513`). So there is room for improvement here.",
    "created_at": "2021-06-01T01:53:30Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31530",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31530#issuecomment-450191",
    "user": "https://github.com/tscrim"
}
```

`@`soehms That seems like a good idea. However, we now have to come up with a better hash. My guess behind the  `_index` idea is that they wanted very fast comparison checks and hashing that is consistent with equality. This line actually dates back to the initial implementation of algebraic reals (commit `07704df513`). So there is room for improvement here.



---

archive/issue_comments_450192.json:
```json
{
    "body": "What about postponing further improvements to other tickets? This one is ready and I think it is worth setting to positive review.",
    "created_at": "2021-06-01T07:01:51Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31530",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31530#issuecomment-450192",
    "user": "https://github.com/videlec"
}
```

What about postponing further improvements to other tickets? This one is ready and I think it is worth setting to positive review.



---

archive/issue_comments_450193.json:
```json
{
    "body": "Replying to [comment:14 gh-Ilia-Smilga]:\n> Replying to [comment:11 tscrim]:\n> > comment:10: Once you have different minimal polynomials, then I believe you essentially have everything. Perhaps I have misunderstood something?\n\n> \n> Consider the following computation:\n> \n> ```\n> x = AA(1+100*2^(-1000))^(1/100)\n> y = AA(1+101*2^(-1000))^(1/101)\n> x < y\n> ```\n\n\nI agree that for a single `+` operation on two elements for which you know the minimal polynomial, infinite refinement is a way to go.\n\nHowever, you need someting to compute minimal polynomials in order to handle\n\n```\nsage: a = AA(1 + 2^(-1000))\nsage: x = a^(1/100) + a^(1/104) - a^(1/102) - a^(1/103)\n```\nI opened #31889 for that purpose.",
    "created_at": "2021-06-01T07:18:01Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31530",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31530#issuecomment-450193",
    "user": "https://github.com/videlec"
}
```

Replying to [comment:14 gh-Ilia-Smilga]:
> Replying to [comment:11 tscrim]:
> > comment:10: Once you have different minimal polynomials, then I believe you essentially have everything. Perhaps I have misunderstood something?

> 
> Consider the following computation:
> 
> ```
> x = AA(1+100*2^(-1000))^(1/100)
> y = AA(1+101*2^(-1000))^(1/101)
> x < y
> ```


I agree that for a single `+` operation on two elements for which you know the minimal polynomial, infinite refinement is a way to go.

However, you need someting to compute minimal polynomials in order to handle

```
sage: a = AA(1 + 2^(-1000))
sage: x = a^(1/100) + a^(1/104) - a^(1/102) - a^(1/103)
```
I opened #31889 for that purpose.



---

archive/issue_comments_450194.json:
```json
{
    "body": "Replying to [comment:20 vdelecroix]:\n> What about postponing further improvements to other tickets? This one is ready and I think it is worth setting to positive review.\n\nAgreed!",
    "created_at": "2021-06-01T21:42:41Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31530",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31530#issuecomment-450194",
    "user": "https://github.com/soehms"
}
```

Replying to [comment:20 vdelecroix]:
> What about postponing further improvements to other tickets? This one is ready and I think it is worth setting to positive review.

Agreed!



---

archive/issue_comments_450195.json:
```json
{
    "body": "Branch pushed to git repo; I updated commit sha1. New commits:",
    "created_at": "2021-06-02T01:35:47Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31530",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31530#issuecomment-450195",
    "user": "https://trac.sagemath.org/admin/accounts/users/git"
}
```

Branch pushed to git repo; I updated commit sha1. New commits:



---

archive/issue_comments_450196.json:
```json
{
    "body": "The bot was green modulo one pyflakes before I pushed. The last change just removes an unused import. Tests still pass for me.",
    "created_at": "2021-06-02T01:37:05Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31530",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31530#issuecomment-450196",
    "user": "https://github.com/tscrim"
}
```

The bot was green modulo one pyflakes before I pushed. The last change just removes an unused import. Tests still pass for me.



---

archive/issue_comments_450197.json:
```json
{
    "body": "Changing status from needs_review to positive_review.",
    "created_at": "2021-06-02T14:29:40Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31530",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31530#issuecomment-450197",
    "user": "https://github.com/soehms"
}
```

Changing status from needs_review to positive_review.



---

archive/issue_comments_450198.json:
```json
{
    "body": "Thank you.",
    "created_at": "2021-06-02T21:25:51Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31530",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31530#issuecomment-450198",
    "user": "https://github.com/tscrim"
}
```

Thank you.



---

archive/issue_comments_450199.json:
```json
{
    "body": "Resolution: fixed",
    "created_at": "2021-06-19T20:57:50Z",
    "issue": "https://github.com/sagemath/sagetest/issues/31530",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/31530#issuecomment-450199",
    "user": "https://github.com/vbraun"
}
```

Resolution: fixed



---

archive/issue_events_083850.json:
```json
{
    "actor": "https://github.com/vbraun",
    "created_at": "2021-06-19T20:57:50Z",
    "event": "closed",
    "issue": "https://github.com/sagemath/sagetest/issues/31530",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sagetest/issues/31530#event-83850"
}
```
