# Issue 14324: Additional doctests for the graph module

Issue created by migration from https://trac.sagemath.org/ticket/14528

Original creator: azi

Original creation time: 2013-05-04 08:47:59

Assignee: tbd

CC:  ncohen stefan slani

Hello!

This patch introduces new tests and documentation for the graph.py file. The previous version of the tests took 10 seconds to finish, the new one takes ~3 minutes.

Please consider suggesting new tests as well and telling which one should be marked with #long time (if any)

Best,

Jernej


---

Comment by azi created at 2013-05-04 08:50:36

Changing status from new to needs_review.


---

Comment by ncohen created at 2013-05-04 09:04:19

HMmm... This, on the other hand, is probably a bad idea... You make some tests very long to check and we are supposed to run tests very often (I got yelled at recently for not doing it). 

Most of the tests you added are good, but you increased several constants a lot : `trees(6)` bbecomes `trees(15)`, and you test twice that a bipartite graph with more than 1000 vertices is bipartite `:-P`

And computer the chromatic number of Kneser graphs is very slow if I remember correctly `O_o`

Plus I'm not very sure that Jeroen would like that ... `:-P`

Nathann


---

Comment by azi created at 2013-05-04 09:09:00

Yes I was told by Harald this could happen :-) He also told me that the #long time directive should help with that!

My motivation for doing such tests is that then you have a quick indicator if something went wrong somewhere.. If the tests run 10s and after a change they go to 20s you don't notice this as you would notice if it goes from 5mins to 10mins. 

I agree that is not practical for day to day testings but isn't #long time supposed to fix that?


---

Comment by ncohen created at 2013-05-04 09:39:42

> Yes I was told by Harald this could happen :-) He also told me that the #long time directive should help with that!

If a test takes more than 5 seconds I guess you should put a # long time somewhere. Perhaps it is even written somewhere in the developper's manual.

> My motivation for doing such tests is that then you have a quick indicator if something went wrong somewhere.. If the tests run 10s and after a change they go to 20s you don't notice this as you would notice if it goes from 5mins to 10mins. 

Agreed. But then what we need is a way to record past performances, not make tests longer. I an quite unaware of the time Sage takes to compile because it is usually so long that I run it before leaving my office. So compiling Sage "takes one night", whatever is added to it `:-P`

> I agree that is not practical for day to day testings but isn't #long time supposed to fix that?

Hmmm... What we need is a way to record performances I guess. That's an interesting problem though `O_O`

But I really think that you are going too far with these tests `:-/`

Nathann


---

Comment by azi created at 2013-05-04 10:25:03

Replying to [comment:4 ncohen]:
> > Yes I was told by Harald this could happen :-) He also told me that the #long time directive should help with that!
> 
> If a test takes more than 5 seconds I guess you should put a # long time somewhere. Perhaps it is even written somewhere in the developper's manual.
> 
> > My motivation for doing such tests is that then you have a quick indicator if something went wrong somewhere.. If the tests run 10s and after a change they go to 20s you don't notice this as you would notice if it goes from 5mins to 10mins. 
> 
> Agreed. But then what we need is a way to record past performances, not make tests longer. I an quite unaware of the time Sage takes to compile because it is usually so long that I run it before leaving my office. So compiling Sage "takes one night", whatever is added to it `:-P`

Yes! Also considering the fact that your hardware setup may change drastically over the years...

BTW do you use the make flag that makes use of parallelization when building sage?

> 
> > I agree that is not practical for day to day testings but isn't #long time supposed to fix that?
> 
> Hmmm... What we need is a way to record performances I guess. That's an interesting problem though `O_O`
> 
> But I really think that you are going too far with these tests `:-/`
Yes! As mentioned in the other trac ticket I agree with you. Though I still think the current tests are way way to small (testing just a few documentation examples). 

We need a better framework for extensive tests. Something that you can run over the night, as is I don't feel relieved when the tests pass with success. 

> 
> Nathann


---

Comment by ncohen created at 2013-05-04 10:51:48

Helloooooooooo !!

> Yes! Also considering the fact that your hardware setup may change drastically over the years...

But if you just want to avoid severe regressions, it is enough to check that Sage X+1 is not much slower that Sage X ?... Though it would be nice to know how our performances evolve...

> BTW do you use the make flag that makes use of parallelization when building sage?

From time to time. Actually, I run all tests on my lab's computer, not on my laptop. This parallel tests do make a difference !

> Yes! As mentioned in the other trac ticket I agree with you. Though I still think the current tests are way way to small (testing just a few documentation examples). 

Yep. It's mostly to check different input, and to "remember" that some things have been fixed if we ever reimplement it.

> We need a better framework for extensive tests. Something that you can run over the night, as is I don't feel relieved when the tests pass with success. 

That's definitely worth a long email to sage-devel. And another GSOC project perhaps `:-D`

Nathann


---

Comment by azi created at 2013-05-04 10:55:31

Replying to [comment:6 ncohen]:
> Helloooooooooo !!
> 
> > Yes! Also considering the fact that your hardware setup may change drastically over the years...
> 
> But if you just want to avoid severe regressions, it is enough to check that Sage X+1 is not much slower that Sage X ?... Though it would be nice to know how our performances evolve...
> 
> > BTW do you use the make flag that makes use of parallelization when building sage?
> 
> From time to time. Actually, I run all tests on my lab's computer, not on my laptop. This parallel tests do make a difference !
> 
> > Yes! As mentioned in the other trac ticket I agree with you. Though I still think the current tests are way way to small (testing just a few documentation examples)

Tests? I meant the export "MAKE -j ncores" thing!
> 
> Yep. It's mostly to check different input, and to "remember" that some things have been fixed if we ever reimplement it.

Ahh....

> 
> > We need a better framework for extensive tests. Something that you can run over the night, as is I don't feel relieved when the tests pass with success. 
> 
> That's definitely worth a long email to sage-devel. And another GSOC project perhaps `:-D`
Yes, maybe a good proposal for next year.

Anyways, I still think some of the tests here could still be integrated and I can remove the ones you find too slow.

> 
> Nathann


---

Comment by ncohen created at 2013-05-04 11:13:10

> Tests? I meant the export "MAKE -j ncores" thing!

Oh. I thought that you had "make ptestlong" in mind. I also do this export MAKE="make -j2" then.

> Anyways, I still think some of the tests here could still be integrated and I can remove the ones you find too slow.

Most of them should, indeed, But testing a graph on 1000 vertices is probably too much, and enumerating all trees up to 15 vertices too `^^;`

Not to mention that most of them are very path-shaped... A random tree is not that interesting :-P


```
sage: graphs.RandomTree(100).show(layout="spring",iterations =5000)
```


Nathann


---

Comment by azi created at 2013-05-08 08:10:52

Hello!

I have now corrected this patch. The original patch should be deleted, this second patch is the one that should be considered.


Jernej


---

Comment by ncohen created at 2013-05-08 08:47:03

Helloooooooooooooo !!!

Hmmmm.. The second patch cannot be applied by itself.

Nathann


---

Comment by azi created at 2013-05-08 08:52:10

Hello!

Maybe TRAC did something smart to it and you can perhaps apply first and then second?


---

Comment by ncohen created at 2013-05-08 08:53:48

Didn't you say before that only `trac_14528_newtests.2.patch` had to be considered, and not `trac_14528_newtests.patch` ?

Nathann


---

Comment by azi created at 2013-05-10 17:52:20

There was some mess introduced by TRAC since I uploaded a fresh patch with exactly the same name. The newly attached patch should be good!

Sorry for the confusion!

Jernej


---

Comment by ncohen created at 2013-05-11 10:54:58

Hmmmmmm... This is still very long `:-/`


```
sage: g = graphs.RandomBipartite(7,7,0.7) 
sage: %time g.line_graph().is_perfect() 
CPU times: user 104.32 s, sys: 0.07 s, total: 104.39 s
Wall time: 104.86 s
True
```


Could you make the graph smaller, or at the very list add a "# long time" flag to those two lines ?

By the way, perhaps it could make sense now to add some code in `is_perfect` to check if the graph is the line graph of a bipartite graph... As we can now compute the root graph `:-P` I wonder what the performances would be `:-)`

Nathann


---

Comment by azi created at 2013-05-11 11:01:20

Thanks for the comment I'll fix that.

As for the is_perfect method. The line graph of a bipartite graph is in fact the Cartesian product of complete graphs. Hence an even faster way to recognize them is use the Cartesian factorisation algorithm and check that each component is a clique.

In the near future I'd really love to have the poly time algorithm for testing perfect graphs.


---

Comment by ncohen created at 2013-05-11 11:21:44

> As for the is_perfect method. The line graph of a bipartite graph is in fact the Cartesian product of complete graphs.

Of a *complete* bipartite graph ?

> Hence an even faster way to recognize them is use the Cartesian factorisation algorithm and check that each component is a clique.

Yepyep, but line graphs of bipartite graphs are a larger class of perfect graphs. May even be included in ISGCI !

> In the near future I'd really love to have the poly time algorithm for testing perfect graphs.

Ahahahah. Yep, now that would be something we could boast about `:-)`

Nathann


---

Comment by azi created at 2013-05-12 16:37:27

Replying to [comment:16 ncohen]:
> > As for the is_perfect method. The line graph of a bipartite graph is in fact the Cartesian product of complete graphs.
> 
> Of a *complete* bipartite graph ?
Yes correct. I am making this random mistakes all the time. Your suggestion for is_perfect makes sense in this case. Though I think it still covers only a small % of input graphs.


> 
> > Hence an even faster way to recognize them is use the Cartesian factorisation algorithm and check that each component is a clique.
> 
> Yepyep, but line graphs of bipartite graphs are a larger class of perfect graphs. May even be included in ISGCI !
> 
> > In the near future I'd really love to have the poly time algorithm for testing perfect graphs.
> 
> Ahahahah. Yep, now that would be something we could boast about `:-)`
Yeah! I think it *should* not be that hard to implement but I don't think anyone is really using this test that much...

PS. I have updated the patch, could you please check if its fine with you?
> 
> Nathann


---

Attachment

Hellooooooooooooo !!

> Yes correct. I am making this random mistakes all the time. Your suggestion for is_perfect makes sense in this case. Though I think it still covers only a small % of input graphs.

Agreed. Though I really have no idea what someone who has a use for this method will run it on.

> Yeah! I think it *should* not be that hard to implement but I don't think anyone is really using this test that much...

Agreed too. But at this level, we mostly code algorithms for our own pleasure, even if sometimes, much later, some guys comes up saying that it helped him.

I spent a crazy amount of time writing #14562 and I really have no use for it `:-P`

> PS. I have updated the patch, could you please check if its fine with you?

Immediately !

Nathann


---

Comment by ncohen created at 2013-05-12 17:26:45

Changing status from needs_review to positive_review.


---

Comment by ncohen created at 2013-05-12 17:26:45

Goooooooood to go !

Nathann


---

Comment by azi created at 2013-05-12 17:56:02

Thank you for the review! Should we say to someone which patch to actually apply?


---

Comment by ncohen created at 2013-05-12 17:57:53

OOps, you are right !

Just added the information to the ticket's description.

Nathann


---

Comment by jdemeyer created at 2013-05-13 13:35:39

Changing component from PLEASE CHANGE to graph theory.


---

Comment by jdemeyer created at 2013-05-13 13:35:39

Changing type from PLEASE CHANGE to enhancement.


---

Comment by jdemeyer created at 2013-05-15 08:24:25

Resolution: fixed
