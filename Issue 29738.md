# Issue 29738: Make numerical and probability doctests ready for random seeds

Issue created by migration from https://trac.sagemath.org/ticket/29975

Original creator: @kliem

Original creation time: 2020-06-24 21:26:38

This ticket makes

```
sage -t --long --random-seed=n src/sage/numerical/
sage -t --long --random-seed=n src/sage/probabilty/
```

pass for different values n than just 0.



---

Comment by @kliem created at 2020-06-24 21:27:12


```
sage -t --long --random-seed=151058820726654196682836430928254760259 src/sage/numerical/optimize.py  # 2 doctests failed
sage -t --long --random-seed=151058820726654196682836430928254760259 src/sage/probability/probability_distribution.pyx  # 18 doctests failed
```



---

Comment by @kliem created at 2020-09-18 17:58:26

Changing status from new to needs_review.


---

Comment by @kliem created at 2020-09-18 17:58:26

New commits:


---

Comment by @mwageringel created at 2020-09-19 08:16:49

Changing status from needs_review to needs_work.


---

Comment by @mwageringel created at 2020-09-19 08:16:49

Although this is unlikely to fail, the test should agree with the documentation, so please apply this change for the uniform distribution:


```diff
     Uniform distribution on the interval ``[a, b]``::
 
         sage: a = 0
         sage: b = 2
         sage: T = RealDistribution('uniform', [a, b])
-        sage: a <= T.get_random_element() < b
+        sage: a <= T.get_random_element() <= b
         True
```


For the Pareto distribution, you could also add a test that `s >= b`. Similarly, the Rayleigh, Lognormal, F, Chisquared and Weibull distributions are ≥ 0, and the Beta distribution lives on [0,1].

Finally, I think this test should document the expected outcome, for clarity:


```diff
         sage: [1.0*x/nr_samples for x in counts]  # abs tol 1e-1
-        [0.304200000000000, 0.397300000000000, 0.298500000000000]
+        [0.3, 0.4, 0.3]
```


I hope it is sufficiently unlikely that this test fails, but it is not impossible.


---

Comment by git created at 2020-09-21 04:23:15

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by @kliem created at 2020-09-21 04:29:33

Thanks for improving the doctests.

Replying to [comment:4 gh-mwageringel]:
> Finally, I think this test should document the expected outcome, for clarity:
> 
> {{{#!diff
>          sage: [1.0*x/nr_samples for x in counts]  # abs tol 1e-1
> -        [0.304200000000000, 0.397300000000000, 0.298500000000000]
> +        [0.3, 0.4, 0.3]
> }}}
> 
> I hope it is sufficiently unlikely that this test fails, but it is not impossible.

I even modified it down to `3e-2`. I tested it and the maximal difference is `0.0192` in 10 000 runs. So I guess it is much less likely than 1 in 10 000 that this test will fail.


---

Comment by @kliem created at 2020-09-21 04:30:29

Changing status from needs_work to needs_review.


---

Comment by git created at 2020-09-21 17:35:50

Branch pushed to git repo; I updated commit sha1. This was a forced push. New commits:


---

Comment by @mwageringel created at 2020-09-21 17:39:59

Thanks for the updates. The change to multigraphics seems unintentional – I have removed it from your commit. I have also fixed another doctest:

```
sage -t --long --warn-long 55.4 --random-seed=2001 src/sage/numerical/optimize.py
**********************************************************************
File "src/sage/numerical/optimize.py", line 264, in sage.numerical.optimize.find_local_minimum
Failed example:
    plot(f, (x,-2.5, 2)).ymin()
Expected:
    -2.1827...
Got:
    -2.182677572710766
```

You can set this to positive if you agree with my changes.


---

Comment by @kliem created at 2020-09-21 17:52:47

Changing status from needs_review to positive_review.


---

Comment by @kliem created at 2020-09-21 17:52:47

Thank you. Yes, agreed.


---

Comment by vbraun created at 2020-09-23 21:27:50

Resolution: fixed
