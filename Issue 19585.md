# Issue 19585: Fast polynomial evaluation fmpz_poly/ZZX with mpfr/mpfi input

Issue created by migration from https://trac.sagemath.org/ticket/19822

Original creator: vdelecroix

Original creation time: 2016-01-02 15:09:21

We implement functions that allow fast evaluations of integer polynomials with real input:
- `fmpz_poly_eval_mpfr(mpfr_t res, const fmpz_poly_t poly, const mpfr_t a, mpfr_rnd_t rnd)`
- `fmpz_poly_eval_mpfi(mpfi_t res, const fmpz_poly_t poly, const mpfi_t a)`
- `ZZX_eval_mpfr(mpfr_t res, ZZX_c poly, const mpfr_t a, const mpfr_rnd_t rnd)`
- `ZZX_eval_mpfi(mpfi_t res, ZZX_c poly, const mpfi_t a)`

These functions are integrated in the polynomial code and number field element comparisons (when real embedding is defined, see #17830). For the latter we win a great `x10` speed up. The new code is also is `x50` faster than comparisons in `QQbar`. For the benchmarks, we used the following comparison function

```
def test(a,n):
    cf = continued_fraction(a)
    cv1 = a.parent()(cf.convergent(2*n+1))
    cv2 = a.parent()(cf.convergent(2*n+2))
    for _ in range(200):
        assert cv1 > a > cv2
```

Before

```
sage: x = polygen(ZZ)
sage: K.<a> = NumberField(x^3 - 2, embedding=1.26)
sage: sage: %timeit test(a,10)
10 loops, best of 3: 51.1 ms per loop
sage: sage: %timeit test(a,20)
10 loops, best of 3: 67 ms per loop
sage: sage: %timeit test(a,100)
10 loops, best of 3: 108 ms per loop
sage: sage: %timeit test(a,200)
1 loops, best of 3: 154 ms per loop
```

after

```
sage: x = polygen(ZZ)
sage: K.<a> = NumberField(x^3 - 2, embedding=1.26)
sage: sage: sage: %timeit test(a,10)
100 loops, best of 3: 5.84 ms per loop
sage: sage: sage: %timeit test(a,20)
100 loops, best of 3: 10.2 ms per loop
sage: sage: sage: %timeit test(a,100)
10 loops, best of 3: 33.5 ms per loop
sage: sage: sage: %timeit test(a,200)
10 loops, best of 3: 64.8 ms per loop
```

To be compared with

```
sage: a = AA(2)**(1/3)
sage: a.exactify()
sage: sage: %timeit test(a,10)
10 loops, best of 3: 97.7 ms per loop
sage: sage: %timeit test(a,20)
10 loops, best of 3: 133 ms per loop
sage: sage: %timeit test(a,100)
1 loops, best of 3: 224 ms per loop
sage: sage: %timeit test(a,200)
1 loops, best of 3: 305 ms per loop
```



---

Comment by vdelecroix created at 2016-01-02 15:10:40

New commits:


---

Comment by vdelecroix created at 2016-01-02 15:10:40

Changing status from new to needs_review.


---

Comment by jdemeyer created at 2016-01-02 16:15:49

Some quick comments:

1. `only do` -> `only does`

2. What's the point of the `mpfr_rnd_t rnd` parameter, given that you don't make any guarantees about exact rounding or rounding direction? Given the code, the only sensible rounding mode is `MPFR_RNDN`.

3. Did you investigate special-casing small degrees (say, degree <= 1)?

4. Both `fmpz_poly_degree(poly)` and `ZZX_deg` return `long`, so the loop variable must be `long` too.


---

Comment by jdemeyer created at 2016-01-02 16:15:49

Changing status from needs_review to needs_work.


---

Comment by jdemeyer created at 2016-01-02 16:16:45

5. Please move the changes to `src/sage/rings/number_field/number_field_element.pyx` to a new ticket such that we can focus on the actual issue from the ticket here.


---

Comment by git created at 2016-01-02 17:18:49

Branch pushed to git repo; I updated commit sha1. This was a forced push. New commits:


---

Comment by vdelecroix created at 2016-01-02 17:23:08

For 2. I just forward the rounding mode to the mpfr functions. Having exact rounding for polynomials might actually be tricky... and also useful. The main reason for having this option is to handle simply polynomial evaluations with different RealField input.

For 3. I did not consider it on purpose. Having special case for degree 0,1 will slow down the code of higher degree cases which are indeed the interesting ones.


---

Comment by vdelecroix created at 2016-01-02 17:23:08

Changing status from needs_work to needs_review.


---

Comment by vdelecroix created at 2016-01-02 17:35:58

To be more complient with flint calling convention I will modify the names of the function `eval -> evaluation`.


---

Comment by git created at 2016-01-02 17:42:45

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by jdemeyer created at 2016-01-03 12:57:18

Replying to [comment:6 vdelecroix]:
> For 2. I just forward the rounding mode to the mpfr functions.

I know that but it doesn't make sense to do that!

What would be the point of doing every single operation with `MPFR_RNDU`? That doesn't guarantee anything about the rounding of the result (if I take a number obtained with `MPFR_RNDU` and multiply it with -1, it effectively becomes rounded with `MPFR_RNDD`). Since polynomials use a mixture of additions and multiplications, it becomes difficult to avoid this problem.


---

Comment by jdemeyer created at 2016-01-03 12:58:51

Tiny detail: please keep the alphabetic order in `src/module_list.py`.


---

Comment by jdemeyer created at 2016-01-03 12:58:51

Changing status from needs_review to needs_work.


---

Comment by jdemeyer created at 2016-01-03 12:59:15

Typo: `Hornder` -> `Horner`.


---

Comment by jdemeyer created at 2016-01-03 13:01:21

Avoid `sage/libs/ntl/decl.pxi`: just `cimport` what you need from the `.pxd` files in NTL.


---

Comment by vdelecroix created at 2016-01-03 13:02:03

Replying to [comment:10 jdemeyer]:
> Replying to [comment:6 vdelecroix]:
> > For 2. I just forward the rounding mode to the mpfr functions.
> 
> I know that but it doesn't make sense to do that!
 
I see and you are definitely right. Then what should with `p(x)` when `p` is an integer polynomial and `x` belongs to `RealField(prec, rnd=MPFR_RNDU)`?


---

Comment by jdemeyer created at 2016-01-03 13:03:51

Just use `MPFR_RNDN` for polynomial evaluation in all cases, it's the only sensible thing if you cannot guarantee anything about the rounding.


---

Comment by git created at 2016-01-03 14:08:19

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by vdelecroix created at 2016-01-03 14:09:08

Changing status from needs_work to needs_review.


---

Comment by vdelecroix created at 2016-01-03 14:14:21

remark: in flint they have two polynomial evaluation algorithms: `Horner` and `divide_and_conquer` and they hardcoded the threshold to 50.


---

Comment by git created at 2016-01-06 18:53:49

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2016-01-06 19:00:31

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by vdelecroix created at 2016-01-06 19:02:50

ready for review again.


---

Comment by vdelecroix created at 2016-01-13 20:05:23

ping?


---

Comment by jdemeyer created at 2016-01-13 21:35:21

The code looks good but I need to benchmark it.


---

Comment by vdelecroix created at 2016-01-13 21:49:48

You can also command it if you have precise requests ;-)

BTW, I added special cases for degree 0 and 1 and I have seen no difference.


---

Comment by jdemeyer created at 2016-01-15 18:01:09

Benchmarks indicate that the bound degree < 10 makes no sense at all. The ratio in speed between the old and the new code does not depend on the degree at all.

Something which is strange: it looks like the precision of the real number/interval matters: for small precisions, the new code is faster but for large precisions (> 50000 bits) the old code is faster. This makes no sense to me! I would guess that both implementations should scale the same way if the precision is increased. Any clues?


---

Comment by vdelecroix created at 2016-01-15 18:12:04

Replying to [comment:27 jdemeyer]:
> Benchmarks indicate that the bound degree < 10 makes no sense at all. The ratio in speed between the old and the new code does not depend on the degree at all.
> 
> Something which is strange: it looks like the precision of the real number/interval matters: for small precisions, the new code is faster but for large precisions (> 50000 bits) the old code is faster. This makes no sense to me! I would guess that both implementations should scale the same way if the precision is increased. Any clues?

What kind of polynomials did you use? The old code tries to minimize the number of operation in evaluation. For example `(x+1)^3` is infinitely smarter than `1 + x(3 + x(3 + x))`.


---

Comment by jdemeyer created at 2016-01-15 18:18:22

Replying to [comment:28 vdelecroix]:
> What kind of polynomials did you use?


```
R.<x> = ZZ[]
pol = R.random_element(deg)
```


> The old code tries to minimize the number of operation in evaluation.

I see. I guess that those "random" polynomials are somewhat sparse, so less operations are needed. I will try again with very dense polynomials.


---

Comment by jdemeyer created at 2016-01-15 18:36:07

With dense polynomials and large precision, the timings of the old and new code are essentially the same. That's expected since the MPFR/MPFI operations dominate the runtime.

Can you remove the "degree < 10" check?


---

Comment by jdemeyer created at 2016-01-15 18:36:07

Changing status from needs_review to needs_work.


---

Comment by jdemeyer created at 2016-01-15 18:39:43

On second thought, what if the polynomial is `x^1000`? Then we will lose a lot with your code.


---

Comment by vdelecroix created at 2016-01-15 18:52:56

Replying to [comment:31 jdemeyer]:
> On second thought, what if the polynomial is `x^1000`? Then we will lose a lot with your code.

Indeed. It is possible to implement a less stupid Horner with grouping. In other words `x^6 + 3x^2 + 1` would be `1 + x^2(3 + x^4)`. There would be a small overhead for dense polynomials.


---

Comment by jdemeyer created at 2016-01-15 19:08:21

Or just skip the addition if the term is 0. It would be nice to benchmark that.


---

Comment by vdelecroix created at 2016-01-15 19:12:47

And there is no `mpfi_pow` nor `mpfi_pow_ui`!!


---

Comment by vdelecroix created at 2016-01-15 22:32:11

`mpfr_pow` is *more* reliable than trial multiplication! Hence we should use it

```
sage: a = RR(1.1)
sage: a*a*a*a == a**4    # understandable
False
sage: b = RealField(256)(1.1)
sage: ans=b*b*b*b
sage: (ans-a**4)
-4.44089209850063e-16
sage: (ans-a*a*a*a)
-6.66133814775094e-16
```


(EDIT: I was completely wrong in my first version)


---

Comment by vdelecroix created at 2016-01-16 15:11:56

Horner evaluations degree=20 precision=64


---

Attachment

Horner evaluations degree=20 precision=128


---

Attachment

Horner evaluations degree=10 precision=64


---

Attachment

Horner evaluations degree=10 precision=128


---

Comment by vdelecroix created at 2016-01-16 15:17:14

Horner evaluations degree=20 nb_terms=1


---

Attachment

Horner evaluations degree=20 nb_terms=2


---

Comment by vdelecroix created at 2016-01-16 15:17:43

Horner evaluations degree=20 nb_terms=5


---

Attachment

Horner evaluations degree=20 nb_terms=13


---

Attachment

Horner evaluations degree=20 nb_terms=21


---

Attachment

Horner evaluations degree=10 precision=256


---

Attachment

I attached files which compare the various possibilities for Horner scheme:

 - `eval1`: the current version which is straightforward Horner expansion (red)
 - `eval2`: the same but skip addition if the term is 0 (green)
 - `eval3`: use `mpfr_pow` (blue)

There are files `degree_{deg}_{prec}.png` for fixed degrees where the number of terms vary and `poly_{deg}_{nb_terms}.png` where the percision vary.

[This is the Trac macro *Image* that was inherited from the migration called with arguments (degree_20_64.png,45%))](https://trac.sagemath.org/wiki/WikiMacros#Image-macro) [This is the Trac macro *Image* that was inherited from the migration called with arguments (degree_20_256.png,45%))](https://trac.sagemath.org/wiki/WikiMacros#Image-macro)

[This is the Trac macro *Image* that was inherited from the migration called with arguments (poly_20_2.png,45%))](https://trac.sagemath.org/wiki/WikiMacros#Image-macro) [This is the Trac macro *Image* that was inherited from the migration called with arguments (poly_20_13.png,45%))](https://trac.sagemath.org/wiki/WikiMacros#Image-macro)

`eval2` seems superior over `eval1`. But `eval3` seems only interesting for very sparse polynomials or very large precision. Indeed, for half dense polynomials (degree=20, nb_terms=13), `eval3` gets better than the other two around prec=2<sup>8</sup>


---

Comment by jdemeyer created at 2016-01-17 22:41:13

Do you have code for `eval2`? I think that might be the best in the end, it is sort of a compromise.


---

Comment by git created at 2016-01-18 12:04:36

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2016-01-18 12:08:18

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by vdelecroix created at 2016-01-18 12:08:47

Changing status from needs_work to needs_review.


---

Comment by jdemeyer created at 2016-01-18 13:35:30

Replying to [comment:40 git]:
> ||[6970134](http://git.sagemath.org/sage.git/commit/?id=6970134df31c259484fd3d5fda0a2e6516a7db70)||`Trac 19822: ignore zero coefficients + copyright`||

Could you at least use the [standard copyright template](http://doc.sagemath.org/html/en/developer/coding_basics.html#headings-of-sage-library-code-files) instead?


---

Comment by jdemeyer created at 2016-01-18 13:40:48

In doctests, use the `x^n` notation instead of `x**n`.


---

Comment by jdemeyer created at 2016-01-18 13:40:58

Changing status from needs_review to needs_work.


---

Comment by jdemeyer created at 2016-01-18 13:41:43

Remove the mention of "complex" values:

```
This file provides fast evaluation of integer polynomials with a real
or complex value
```



---

Comment by jdemeyer created at 2016-01-18 14:54:43

The doctests with the various rounding modes are obsolete, since the rounding mode isn't used. I suggest to remove those tests.


---

Comment by git created at 2016-01-18 17:56:39

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by vdelecroix created at 2016-01-18 17:56:56

Changing status from needs_work to needs_review.


---

Comment by jdemeyer created at 2016-01-19 08:52:19

Changing status from needs_review to positive_review.


---

Comment by vbraun created at 2016-01-20 10:19:57

Resolution: fixed
