# Issue 502: pexpect -- optimize; maybe update to newest version?

archive/issues_000502.json:
```json
{
    "assignees": [],
    "body": "pexpect is at version 2.1, but SAGE uses 2.0.  Investigate why 2.1 is so much slower.\nAlso, speed everything up more.  Says dropdrive on irc:\n\n```\n\n13:53 < dropdrive> was_: I looked into the pipes being slow thing, and Pexpect is just horrible with large amounts of data\n                   (O(n^2)).  I made a fix (O(n)) that reads 6MB/s.  But pexpect will always be slow if you have to call\n                   .expect many times (twice per line as it stands), because pexpect slices its buffer every time.\n13:55 < dropdrive> was_: So if you read a 4096-byte block from a pipe, and .expect gets called every 80 characters,\n                   pexpect will build buffer[80*n:] for n from 1 to 50\n\n\n```\n\nAssignee: **@williamstein**\n\nReviewer: **Jeroen Demeyer**\n\n_Issue created by migration from https://trac.sagemath.org/ticket/502_\n\n",
    "closed_at": "2015-12-04T22:12:33Z",
    "created_at": "2007-08-28T21:07:42Z",
    "labels": [
        "https://github.com/sagemath/sage/labels/component%3A%20interfaces",
        "https://github.com/sagemath/sage/labels/duplicate",
        "https://github.com/sagemath/sage/labels/enhancement"
    ],
    "reactions": [],
    "repository": "https://github.com/sagemath/sage",
    "title": "pexpect -- optimize; maybe update to newest version?",
    "type": "issue",
    "updated_at": "2015-12-04T22:12:33Z",
    "url": "https://github.com/sagemath/sage/issues/502",
    "user": "https://github.com/williamstein"
}
```
pexpect is at version 2.1, but SAGE uses 2.0.  Investigate why 2.1 is so much slower.
Also, speed everything up more.  Says dropdrive on irc:

```

13:53 < dropdrive> was_: I looked into the pipes being slow thing, and Pexpect is just horrible with large amounts of data
                   (O(n^2)).  I made a fix (O(n)) that reads 6MB/s.  But pexpect will always be slow if you have to call
                   .expect many times (twice per line as it stands), because pexpect slices its buffer every time.
13:55 < dropdrive> was_: So if you read a 4096-byte block from a pipe, and .expect gets called every 80 characters,
                   pexpect will build buffer[80*n:] for n from 1 to 50


```

Assignee: **@williamstein**

Reviewer: **Jeroen Demeyer**

_Issue created by migration from https://trac.sagemath.org/ticket/502_





---

archive/issue_events_003928.json:
```json
{
    "actor": "https://github.com/williamstein",
    "created_at": "2007-08-28T21:07:42Z",
    "event": "labeled",
    "issue": "https://github.com/sagemath/sage/issues/502",
    "label": "https://github.com/sagemath/sage/labels/component%3A%20interfaces",
    "label_color": "0000ff",
    "label_name": "component: interfaces",
    "label_text_color": "ffffff",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sage/issues/502#event-3928"
}
```



---

archive/issue_events_003929.json:
```json
{
    "actor": "https://github.com/williamstein",
    "created_at": "2007-08-28T21:07:42Z",
    "event": "labeled",
    "issue": "https://github.com/sagemath/sage/issues/502",
    "label": "https://github.com/sagemath/sage/labels/enhancement",
    "label_color": "696969",
    "label_name": "enhancement",
    "label_text_color": "ffffff",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sage/issues/502#event-3929"
}
```



---

archive/issue_events_003930.json:
```json
{
    "actor": "https://github.com/williamstein",
    "created_at": "2007-08-28T21:07:42Z",
    "event": "labeled",
    "issue": "https://github.com/sagemath/sage/issues/502",
    "label": "https://github.com/sagemath/sage/labels/invalid",
    "label_color": "a6a6a6",
    "label_name": "invalid",
    "label_text_color": "ffffff",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sage/issues/502#event-3930"
}
```



---

archive/issue_comments_001847.json:
```json
{
    "body": "<a id='comment:1'>Comment 1:</a>\nFrom dropdrive:\n\n```\nBenchmarks with improved Pexpect\n================================\n\nsage: n, s = 8, '$sage1'\nsage: P = partitions_set(range(n), 3)\nsage: timeit p = gap.get(s, use_file=True).replace(r'\\n', '')\n10 loops, best of 3: 240 ms per loop\nsage: timeit q = gap.get(s, use_file=False).replace(r'\\n', '')\n10 loops, best of 3: 444 ms per loop\nsage: timeit r = gap.get(s, use_file='dropdrive')\n10 loops, best of 3: 22 ms per loop\nsage:\n\nsage: n, s = 10, '$sage1'\nsage: P = partitions_set(range(n), 3)\nsage: timeit p = gap.get(s, use_file=True).replace(r'\\n', '')\n10 loops, best of 3: 582 ms per loop\nsage: timeit r = gap.get(s, use_file='dropdrive')\n10 loops, best of 3: 206 ms per loop\nsage:\n\nsage: n, s = 12, '$sage1'\nsage: P = partitions_set(range(n), 3)\nsage: timeit p = gap.get(s, use_file=True).replace(r'\\n', '')\n10 loops, best of 3: 1.76 s per loop\nsage: timeit r = gap.get(s, use_file='dropdrive')\n10 loops, best of 3: 2.08 s per loop\nsage:\n\n\nIntro\n=====\n\nWe improve Pexpect performance when expecting large amounts of\ndata.  Many interfaces have a maxread of 100000 or higher.\nHowever, os.read (almost?) always returns strings that are 8 KB or\nless, though this may be platform-dependent.  So don't think that\nincreasing maxread will increase performance!\n\nRegardless of version, Pexpect performance is poor when we expect\nlarge amounts of data.  The problem is that the running time of\npexpect.spawn.expect_list is O(N^2) where N is the number of bytes\nreceived, because of os.read (see above).  This is actually\ntheoretically optimal if we want to \"expect\" arbitrary regexps.\nHowever, SAGE mostly \"expect\"s very simple regexps, i.e., prompts\n(Expect._prompt).\n\nI have written a variant of pexpect.spawn.expect called\npexpect.spawn.bounded_expect, which takes \"bounded patterns\": a tuple\n(E, B) such that\n\n(1) E is a basestring or regexp and B is an integer, and \n\n(2) E is never expected to match a string longer than B.\n\n(See docstring for more.)\n\nThis is certainly reasonable if we are expecting prompts.  The running\ntime of pexpect.spawn.bounded_expect is O(N).\n\nWithout the call to time.sleep, pexpect.spawn.bounded_expect can\nprocess 30,468,021 bytes (one \"expect\" call) in 4.63 seconds (wall\ntime), under Linux on a Xeon 3.0ghz.\n\n\ntime.sleep\n==========\n\nPexpect version 2.1 includes calls to time.sleep between successive\nos.read calls.  I think this to get more data per os.read call.\n\n\nEnhancements\n============\n\nBoth pexpect.spawn.expect and pexpect.spawn.bounded_expect can be made\nfaster by implementing a \"greedy\" version of\npexpect.spawn.read_nonblocking if either of the following hold:\n\n(1) We can bound the size of the \"before\" string (i.e., not the\n\"expect\" string) on a per-call basis, or\n\n(2) The size of the \"after\" string is small.\n\nA method greedy_read_nonblocking is included in the patch below.\nOff-the-cuff tests show that the speed gain is minimal.  If we really\ncare about speed then a pure Python expect module isn't the way to go\nanyway.\n\n\nImplementation in SAGE\n======================\n\nThis patch adds only pexpect.spawn.bounded_expect and three helper\nmethods to pexpect.spawn in pexpect.py.  The Pexpect module is\notherwise unaffected.  To use in SAGE, I suggest that the calls to\npexpect.spawn.expect that wait for prompts (mostly in\ninterfaces/expect.py) to be replaced by calls to\npexpect.spawn.bounded_expect.  Interfaces can have a maxpromptlen\nattribute, a length such as 100 can be hard-coded in\nExpect._eval_line, or some clever way of calculating the prompt length\nbased on the prompt's regexp.\n\nUgly demonstration of implementation in SAGE's GAP interface (see\nbenchmarks for sample use):\n\nIn interfaces.gap.Gap:\n\ndef get(self, var, use_file=False):\n    \"\"\"\n    Get the string representation of the variable var.\n    \"\"\"\n    if use_file == 'dropdrive':\n        E = self._expect\n        E.sendline('Print(%s);' % var)\n        E.bounded_expect(('@ngap> @i', 9))\n        return ''.join(E.before.split('@J@n')[1:])\n    if use_file:\n        if os.path.exists(tmp):\n            os.unlink(tmp)\n        self.eval('PrintTo(\"%s\", %s);'%(tmp,var), strip=False)\n        r = open(tmp).read()\n        r = r.strip().replace(\"\\\\\\n\",\"\")\n        os.unlink(tmp)\n        return r\n    else:\n        return self.eval('%s;'%var, newlines=False)\n\n\nPatch\n=====\n\nThe below patch is against pexpect.py in Pexpect version 2.1.\n\n\n--- /tmp/pexpect-2.1/pexpect.py\t2006-05-31 23:07:48.000000000 -0400\n+++ pexpect.py\t2007-08-30 22:01:19.000000000 -0400\n -620,6 +620,36 @@\n         # and blocked on some platforms. TCSADRAIN is probably ideal if it worked.\n         termios.tcsetattr(self.child_fd, termios.TCSANOW, new)\n     \n+    def greedy_read_nonblocking(self, timeout=-1, patience=0.001, recover=0.001):\n+\n+        \"\"\"Repeatedly yield data read from spawn.read_nonblocking\n+        until either (a) the amount of time elapsed is at least\n+        <timeout> or (b) a spawn.read_nonblocking call takes longer\n+        than than <patience> or time left until timeout.  Set\n+        <timeout> to None to make it effectively infinite.  Sleep for\n+        <recover> seconds between reads in hopes of getting more data\n+        per os.read.\n+\n+        Performance may depend on finding good values for <patience>\n+        and <recover>.\n+\n+        \"\"\"\n+        if timeout == -1:\n+            timeout = self.timeout\n+        if timeout is None:\n+            timeout = 99999999 # 3.2 years, or, never time out\n+        end_time = time.time() + timeout\n+        while True:\n+            try:\n+                yield self.read_nonblocking(self.maxread, min(timeout, patience))\n+            except TIMEOUT:\n+                break\n+            timeout = end_time - time.time()\n+            if not timeout > 0:\n+                break\n+            if recover > 0:\n+                time.sleep(recover)\n+\n     def read_nonblocking (self, size = 1, timeout = -1):\n         \"\"\"This reads at most size characters from the child application.\n         It includes a timeout. If the read does not complete within the\n -1148,6 +1178,184 @@\n             self.match_index = None\n             raise\n \n+    def bounded_expect(self, pattern, timeout=-1):\n+\n+        \"\"\"Same as spawn.expect, but expect exceptions (TIMEOUT and\n+        EOF) and *bounded* patterns.  A bounded pattern is a\n+        (basestring, integer) or (regexp, integer) tuple where the\n+        pattern is not expected to match a string longer than the\n+        integer (e.g. prompts).\n+\n+        Use this for performance gain if self.before is expected to be\n+        large.  This method only searches through newly-received data\n+        and not the entire existing buffer, as spawn.expect does.\n+        This method also does not suffer from the Python deadly sin of\n+        building increasingly longer strings by adding, e.g. s = a + b\n+        + c + d + e + f.  (See the line \"incoming = incoming + c\" in\n+        spawn.expect.)\n+\n+        Sample usage:\n+\n+        E.bounded_expect([('@ngap> @i', 9), ('>>> ', 4), EOF])\n+\n+        In the interests of performace, regular patterns are not\n+        allowed.\n+\n+        Unlike spawn.expect, there is no <searchwindowsize> parameter\n+        because bounded patterns are, well, bounded.\n+\n+        \"\"\"\n+        compiled_bounded_pattern_list = list(self._compile_bounded_patterns(pattern))\n+        return self._bounded_expect_list(compiled_bounded_pattern_list, timeout)\n+\n+    def _compile_bounded_patterns(self, patterns):\n+\n+        \"\"\"Basically copied from spawn.compile_pattern_list, but\n+        written as an iterator.  The end-user shouldn't use this!\n+\n+        \"\"\"\n+        try:\n+            len(patterns)\n+        except TypeError:\n+            patterns = [patterns]\n+        else:\n+            if len(patterns) == 2 \\\n+                    and isinstance(patterns[0], (basestring, type(re.compile('')))) \\\n+                    and isinstance(patterns[1], int):\n+                patterns = [patterns]\n+\n+        compile_flags = re.DOTALL\n+        if self.ignorecase:\n+            compile_flags = compile_flags | re.IGNORECASE\n+\n+        num_bounded = 0\n+        for p in patterns:\n+            if p in (EOF, TIMEOUT):\n+                yield p\n+            else:\n+                try:\n+                    if len(p) == 2:\n+                        num_bounded += 1\n+                        yield (re.compile(p[0], compile_flags), int(p[1]))\n+                    else:\n+                        raise TypeError\n+                except TypeError, ValueError:\n+                    raise TypeError, \"%r is not a bounded pattern\" % p\n+\n+        if not num_bounded:\n+            raise ValueError, \"Must have at least one bounded pattern!\"\n+\n+    def _bounded_expect_list(self, pattern_list, timeout = -1):\n+\n+        \"\"\"Copied from spawn.expect_list, but optimized for use with\n+        bounded patterns; see spawn.bounded_expect for details.  The\n+        end-user shouldn't use this!\n+\n+        \"\"\"\n+        self.patterns = pattern_list\n+\n+        if timeout == -1:\n+            timeout = self.timeout\n+        if timeout is not None:\n+            end_time = time.time() + timeout \n+\n+        max_bound = max(pattern[1] for pattern in pattern_list if isinstance(pattern, tuple))\n+\n+        incoming = [self.buffer]\n+        try:\n+            while True: # Keep reading until exception or return.\n+                if len(incoming) == 1: # no reads yet\n+                    search_chunks = [self.buffer]\n+                    search_string = ''\n+                else: # last element of incoming hasn't been searched\n+                    gnimocni = reversed(incoming)\n+                    needed = max_bound - 1\n+                    chunks = [gnimocni.next()[:needed]]\n+                    for chunk in gnimocni:\n+                        if needed > 0:\n+                            if len(chunk) < needed:\n+                                chunks.append(chunk)\n+                                needed -= len(chunk)\n+                            else:\n+                                chunks.append(chunk[-needed:])\n+                                break\n+                    search_chunks = list(reversed(chunks))\n+                    search_string = incoming[-1]\n+\n+                for idx, pattern in enumerate(pattern_list):\n+                    if pattern in (EOF, TIMEOUT):\n+                        continue # PexpectExceptions are handled differently.\n+                    cre, bound = pattern\n+\n+                    match = cre.search(''.join(search_chunks), max_bound - bound)\n+                    if match is not None:\n+                        before_chunks = incoming[:-len(search_chunks)]\n+                        before_chunks.append(incoming[-len(search_chunks)][:-len(search_chunks[-1])])\n+                        before_chunks.append(match.string[:match.start()])\n+                        self.before = ''.join(before_chunks)\n+                        self.after = match.group()\n+                        # I'd like to use buffers here, but can't if\n+                        # we want to behave as in spawn.expect_list\n+                        self.buffer = match.string[match.end():]\n+                        self.match = match\n+                        self.match_index = idx\n+                        # assert (self.before + self.after + self.buffer) == ''.join(incoming)\n+                        return self.match_index\n+\n+                    # no \"overlapped\" match; search the new thing\n+                    match = cre.search(search_string)\n+                    if match is not None:\n+                        incoming[-1] = incoming[-1][:match.start()]\n+                        self.before = ''.join(incoming)\n+                        self.after = match.group()\n+                        self.buffer = match.string[match.end():]\n+                        self.match = match\n+                        self.match_index = idx\n+                        # assert (self.before + self.after + self.buffer) == ''.join(incoming)\n+                        return self.match_index\n+\n+                # No match at this point\n+                if timeout < 0 and timeout is not None:\n+                    raise TIMEOUT ('Timeout exceeded in expect_list().')\n+                # Still have time left, so read more data\n+                if 1: # read and process, recommended\n+                    time.sleep (0.0001)\n+                    c = self.read_nonblocking (self.maxread, timeout)\n+                    incoming.append(c)\n+                else: # read greedily and process (not much faster)\n+                    incoming.append(''.join(self.greedy_read_nonblocking(timeout)))\n+                if timeout is not None:\n+                    timeout = end_time - time.time()\n+        except EOF, e:\n+            self.buffer = ''\n+            self.before = ''.join(incoming)\n+            self.after = EOF\n+            if EOF in pattern_list:\n+                self.match = EOF\n+                self.match_index = pattern_list.index(EOF)\n+                return self.match_index\n+            else:\n+                self.match = None\n+                self.match_index = None\n+                raise EOF (str(e) + '\\n' + str(self))\n+        except TIMEOUT, e:\n+            self.before = ''.join(incoming)\n+            self.after = TIMEOUT\n+            if TIMEOUT in pattern_list:\n+                self.match = TIMEOUT\n+                self.match_index = pattern_list.index(TIMEOUT)\n+                return self.match_index\n+            else:\n+                self.match = None\n+                self.match_index = None\n+                raise TIMEOUT (str(e) + '\\n' + str(self))\n+        except Exception:\n+            self.before = ''.join(incoming)\n+            self.after = None\n+            self.match = None\n+            self.match_index = None\n+            raise\n+\n     def getwinsize(self):\n         \"\"\"This returns the terminal window size of the child tty.\n         The return value is a tuple of (rows, cols).\n```",
    "created_at": "2007-08-31T23:49:05Z",
    "formatter": "markdown",
    "issue": "https://github.com/sagemath/sage/issues/502",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/502#issuecomment-1847",
    "user": "https://github.com/sagetrac-mabshoff"
}
```

<a id='comment:1'>Comment 1:</a>
From dropdrive:

```
Benchmarks with improved Pexpect
================================

sage: n, s = 8, '$sage1'
sage: P = partitions_set(range(n), 3)
sage: timeit p = gap.get(s, use_file=True).replace(r'\n', '')
10 loops, best of 3: 240 ms per loop
sage: timeit q = gap.get(s, use_file=False).replace(r'\n', '')
10 loops, best of 3: 444 ms per loop
sage: timeit r = gap.get(s, use_file='dropdrive')
10 loops, best of 3: 22 ms per loop
sage:

sage: n, s = 10, '$sage1'
sage: P = partitions_set(range(n), 3)
sage: timeit p = gap.get(s, use_file=True).replace(r'\n', '')
10 loops, best of 3: 582 ms per loop
sage: timeit r = gap.get(s, use_file='dropdrive')
10 loops, best of 3: 206 ms per loop
sage:

sage: n, s = 12, '$sage1'
sage: P = partitions_set(range(n), 3)
sage: timeit p = gap.get(s, use_file=True).replace(r'\n', '')
10 loops, best of 3: 1.76 s per loop
sage: timeit r = gap.get(s, use_file='dropdrive')
10 loops, best of 3: 2.08 s per loop
sage:


Intro
=====

We improve Pexpect performance when expecting large amounts of
data.  Many interfaces have a maxread of 100000 or higher.
However, os.read (almost?) always returns strings that are 8 KB or
less, though this may be platform-dependent.  So don't think that
increasing maxread will increase performance!

Regardless of version, Pexpect performance is poor when we expect
large amounts of data.  The problem is that the running time of
pexpect.spawn.expect_list is O(N^2) where N is the number of bytes
received, because of os.read (see above).  This is actually
theoretically optimal if we want to "expect" arbitrary regexps.
However, SAGE mostly "expect"s very simple regexps, i.e., prompts
(Expect._prompt).

I have written a variant of pexpect.spawn.expect called
pexpect.spawn.bounded_expect, which takes "bounded patterns": a tuple
(E, B) such that

(1) E is a basestring or regexp and B is an integer, and 

(2) E is never expected to match a string longer than B.

(See docstring for more.)

This is certainly reasonable if we are expecting prompts.  The running
time of pexpect.spawn.bounded_expect is O(N).

Without the call to time.sleep, pexpect.spawn.bounded_expect can
process 30,468,021 bytes (one "expect" call) in 4.63 seconds (wall
time), under Linux on a Xeon 3.0ghz.


time.sleep
==========

Pexpect version 2.1 includes calls to time.sleep between successive
os.read calls.  I think this to get more data per os.read call.


Enhancements
============

Both pexpect.spawn.expect and pexpect.spawn.bounded_expect can be made
faster by implementing a "greedy" version of
pexpect.spawn.read_nonblocking if either of the following hold:

(1) We can bound the size of the "before" string (i.e., not the
"expect" string) on a per-call basis, or

(2) The size of the "after" string is small.

A method greedy_read_nonblocking is included in the patch below.
Off-the-cuff tests show that the speed gain is minimal.  If we really
care about speed then a pure Python expect module isn't the way to go
anyway.


Implementation in SAGE
======================

This patch adds only pexpect.spawn.bounded_expect and three helper
methods to pexpect.spawn in pexpect.py.  The Pexpect module is
otherwise unaffected.  To use in SAGE, I suggest that the calls to
pexpect.spawn.expect that wait for prompts (mostly in
interfaces/expect.py) to be replaced by calls to
pexpect.spawn.bounded_expect.  Interfaces can have a maxpromptlen
attribute, a length such as 100 can be hard-coded in
Expect._eval_line, or some clever way of calculating the prompt length
based on the prompt's regexp.

Ugly demonstration of implementation in SAGE's GAP interface (see
benchmarks for sample use):

In interfaces.gap.Gap:

def get(self, var, use_file=False):
    """
    Get the string representation of the variable var.
    """
    if use_file == 'dropdrive':
        E = self._expect
        E.sendline('Print(%s);' % var)
        E.bounded_expect(('@ngap> @i', 9))
        return ''.join(E.before.split('@J@n')[1:])
    if use_file:
        if os.path.exists(tmp):
            os.unlink(tmp)
        self.eval('PrintTo("%s", %s);'%(tmp,var), strip=False)
        r = open(tmp).read()
        r = r.strip().replace("\\\n","")
        os.unlink(tmp)
        return r
    else:
        return self.eval('%s;'%var, newlines=False)


Patch
=====

The below patch is against pexpect.py in Pexpect version 2.1.


--- /tmp/pexpect-2.1/pexpect.py	2006-05-31 23:07:48.000000000 -0400
+++ pexpect.py	2007-08-30 22:01:19.000000000 -0400
 -620,6 +620,36 @@
         # and blocked on some platforms. TCSADRAIN is probably ideal if it worked.
         termios.tcsetattr(self.child_fd, termios.TCSANOW, new)
     
+    def greedy_read_nonblocking(self, timeout=-1, patience=0.001, recover=0.001):
+
+        """Repeatedly yield data read from spawn.read_nonblocking
+        until either (a) the amount of time elapsed is at least
+        <timeout> or (b) a spawn.read_nonblocking call takes longer
+        than than <patience> or time left until timeout.  Set
+        <timeout> to None to make it effectively infinite.  Sleep for
+        <recover> seconds between reads in hopes of getting more data
+        per os.read.
+
+        Performance may depend on finding good values for <patience>
+        and <recover>.
+
+        """
+        if timeout == -1:
+            timeout = self.timeout
+        if timeout is None:
+            timeout = 99999999 # 3.2 years, or, never time out
+        end_time = time.time() + timeout
+        while True:
+            try:
+                yield self.read_nonblocking(self.maxread, min(timeout, patience))
+            except TIMEOUT:
+                break
+            timeout = end_time - time.time()
+            if not timeout > 0:
+                break
+            if recover > 0:
+                time.sleep(recover)
+
     def read_nonblocking (self, size = 1, timeout = -1):
         """This reads at most size characters from the child application.
         It includes a timeout. If the read does not complete within the
 -1148,6 +1178,184 @@
             self.match_index = None
             raise
 
+    def bounded_expect(self, pattern, timeout=-1):
+
+        """Same as spawn.expect, but expect exceptions (TIMEOUT and
+        EOF) and *bounded* patterns.  A bounded pattern is a
+        (basestring, integer) or (regexp, integer) tuple where the
+        pattern is not expected to match a string longer than the
+        integer (e.g. prompts).
+
+        Use this for performance gain if self.before is expected to be
+        large.  This method only searches through newly-received data
+        and not the entire existing buffer, as spawn.expect does.
+        This method also does not suffer from the Python deadly sin of
+        building increasingly longer strings by adding, e.g. s = a + b
+        + c + d + e + f.  (See the line "incoming = incoming + c" in
+        spawn.expect.)
+
+        Sample usage:
+
+        E.bounded_expect([('@ngap> @i', 9), ('>>> ', 4), EOF])
+
+        In the interests of performace, regular patterns are not
+        allowed.
+
+        Unlike spawn.expect, there is no <searchwindowsize> parameter
+        because bounded patterns are, well, bounded.
+
+        """
+        compiled_bounded_pattern_list = list(self._compile_bounded_patterns(pattern))
+        return self._bounded_expect_list(compiled_bounded_pattern_list, timeout)
+
+    def _compile_bounded_patterns(self, patterns):
+
+        """Basically copied from spawn.compile_pattern_list, but
+        written as an iterator.  The end-user shouldn't use this!
+
+        """
+        try:
+            len(patterns)
+        except TypeError:
+            patterns = [patterns]
+        else:
+            if len(patterns) == 2 \
+                    and isinstance(patterns[0], (basestring, type(re.compile('')))) \
+                    and isinstance(patterns[1], int):
+                patterns = [patterns]
+
+        compile_flags = re.DOTALL
+        if self.ignorecase:
+            compile_flags = compile_flags | re.IGNORECASE
+
+        num_bounded = 0
+        for p in patterns:
+            if p in (EOF, TIMEOUT):
+                yield p
+            else:
+                try:
+                    if len(p) == 2:
+                        num_bounded += 1
+                        yield (re.compile(p[0], compile_flags), int(p[1]))
+                    else:
+                        raise TypeError
+                except TypeError, ValueError:
+                    raise TypeError, "%r is not a bounded pattern" % p
+
+        if not num_bounded:
+            raise ValueError, "Must have at least one bounded pattern!"
+
+    def _bounded_expect_list(self, pattern_list, timeout = -1):
+
+        """Copied from spawn.expect_list, but optimized for use with
+        bounded patterns; see spawn.bounded_expect for details.  The
+        end-user shouldn't use this!
+
+        """
+        self.patterns = pattern_list
+
+        if timeout == -1:
+            timeout = self.timeout
+        if timeout is not None:
+            end_time = time.time() + timeout 
+
+        max_bound = max(pattern[1] for pattern in pattern_list if isinstance(pattern, tuple))
+
+        incoming = [self.buffer]
+        try:
+            while True: # Keep reading until exception or return.
+                if len(incoming) == 1: # no reads yet
+                    search_chunks = [self.buffer]
+                    search_string = ''
+                else: # last element of incoming hasn't been searched
+                    gnimocni = reversed(incoming)
+                    needed = max_bound - 1
+                    chunks = [gnimocni.next()[:needed]]
+                    for chunk in gnimocni:
+                        if needed > 0:
+                            if len(chunk) < needed:
+                                chunks.append(chunk)
+                                needed -= len(chunk)
+                            else:
+                                chunks.append(chunk[-needed:])
+                                break
+                    search_chunks = list(reversed(chunks))
+                    search_string = incoming[-1]
+
+                for idx, pattern in enumerate(pattern_list):
+                    if pattern in (EOF, TIMEOUT):
+                        continue # PexpectExceptions are handled differently.
+                    cre, bound = pattern
+
+                    match = cre.search(''.join(search_chunks), max_bound - bound)
+                    if match is not None:
+                        before_chunks = incoming[:-len(search_chunks)]
+                        before_chunks.append(incoming[-len(search_chunks)][:-len(search_chunks[-1])])
+                        before_chunks.append(match.string[:match.start()])
+                        self.before = ''.join(before_chunks)
+                        self.after = match.group()
+                        # I'd like to use buffers here, but can't if
+                        # we want to behave as in spawn.expect_list
+                        self.buffer = match.string[match.end():]
+                        self.match = match
+                        self.match_index = idx
+                        # assert (self.before + self.after + self.buffer) == ''.join(incoming)
+                        return self.match_index
+
+                    # no "overlapped" match; search the new thing
+                    match = cre.search(search_string)
+                    if match is not None:
+                        incoming[-1] = incoming[-1][:match.start()]
+                        self.before = ''.join(incoming)
+                        self.after = match.group()
+                        self.buffer = match.string[match.end():]
+                        self.match = match
+                        self.match_index = idx
+                        # assert (self.before + self.after + self.buffer) == ''.join(incoming)
+                        return self.match_index
+
+                # No match at this point
+                if timeout < 0 and timeout is not None:
+                    raise TIMEOUT ('Timeout exceeded in expect_list().')
+                # Still have time left, so read more data
+                if 1: # read and process, recommended
+                    time.sleep (0.0001)
+                    c = self.read_nonblocking (self.maxread, timeout)
+                    incoming.append(c)
+                else: # read greedily and process (not much faster)
+                    incoming.append(''.join(self.greedy_read_nonblocking(timeout)))
+                if timeout is not None:
+                    timeout = end_time - time.time()
+        except EOF, e:
+            self.buffer = ''
+            self.before = ''.join(incoming)
+            self.after = EOF
+            if EOF in pattern_list:
+                self.match = EOF
+                self.match_index = pattern_list.index(EOF)
+                return self.match_index
+            else:
+                self.match = None
+                self.match_index = None
+                raise EOF (str(e) + '\n' + str(self))
+        except TIMEOUT, e:
+            self.before = ''.join(incoming)
+            self.after = TIMEOUT
+            if TIMEOUT in pattern_list:
+                self.match = TIMEOUT
+                self.match_index = pattern_list.index(TIMEOUT)
+                return self.match_index
+            else:
+                self.match = None
+                self.match_index = None
+                raise TIMEOUT (str(e) + '\n' + str(self))
+        except Exception:
+            self.before = ''.join(incoming)
+            self.after = None
+            self.match = None
+            self.match_index = None
+            raise
+
     def getwinsize(self):
         """This returns the terminal window size of the child tty.
         The return value is a tuple of (rows, cols).
```



---

archive/issue_events_003931.json:
```json
{
    "actor": "https://github.com/sagetrac-mabshoff",
    "created_at": "2007-09-10T03:03:50Z",
    "event": "milestoned",
    "issue": "https://github.com/sagemath/sage/issues/502",
    "milestone_number": null,
    "milestone_title": "sage-3.0",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sage/issues/502#event-3931"
}
```



---

archive/issue_comments_001848.json:
```json
{
    "body": "<a id='comment:3'>Comment 3:</a>\npexpect is now in version 2.3.  We appear to still have version 2.0 (? it's hard to tell, no obvious pexpect version command).  Anyway, might upgrading render this obsolete?",
    "created_at": "2009-12-30T04:47:37Z",
    "formatter": "markdown",
    "issue": "https://github.com/sagemath/sage/issues/502",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/502#issuecomment-1848",
    "user": "https://github.com/kcrisman"
}
```

<a id='comment:3'>Comment 3:</a>
pexpect is now in version 2.3.  We appear to still have version 2.0 (? it's hard to tell, no obvious pexpect version command).  Anyway, might upgrading render this obsolete?



---

archive/issue_comments_001849.json:
```json
{
    "body": "<a id='comment:4'>Comment 4:</a>\nRecent version of pexpect is 3.3 (http://pexpect.readthedocs.org/en/latest/index.html) which could be installed using pip. But installing this version will result in failing doctests.",
    "created_at": "2014-08-18T19:38:58Z",
    "formatter": "markdown",
    "issue": "https://github.com/sagemath/sage/issues/502",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/502#issuecomment-1849",
    "user": "https://github.com/a-andre"
}
```

<a id='comment:4'>Comment 4:</a>
Recent version of pexpect is 3.3 (http://pexpect.readthedocs.org/en/latest/index.html) which could be installed using pip. But installing this version will result in failing doctests.



---

archive/issue_comments_001850.json:
```json
{
    "body": "Reviewer: **Jeroen Demeyer**",
    "created_at": "2015-12-04T13:59:47Z",
    "formatter": "markdown",
    "issue": "https://github.com/sagemath/sage/issues/502",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/502#issuecomment-1850",
    "user": "https://github.com/jdemeyer"
}
```

Reviewer: **Jeroen Demeyer**



---

archive/issue_comments_001851.json:
```json
{
    "body": "<a id='comment:5'>Comment 5:</a>\nFixed by #10295.",
    "created_at": "2015-12-04T13:59:47Z",
    "formatter": "markdown",
    "issue": "https://github.com/sagemath/sage/issues/502",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/502#issuecomment-1851",
    "user": "https://github.com/jdemeyer"
}
```

<a id='comment:5'>Comment 5:</a>
Fixed by #10295.



---

archive/issue_events_003932.json:
```json
{
    "actor": "https://github.com/jdemeyer",
    "created_at": "2015-12-04T13:59:47Z",
    "event": "labeled",
    "issue": "https://github.com/sagemath/sage/issues/502",
    "label": "https://github.com/sagemath/sage/labels/needs%20review",
    "label_color": "7fff00",
    "label_name": "needs review",
    "label_text_color": "ffffff",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sage/issues/502#event-3932"
}
```



---

archive/issue_events_003933.json:
```json
{
    "actor": "https://github.com/jdemeyer",
    "created_at": "2015-12-04T14:00:01Z",
    "event": "unlabeled",
    "issue": "https://github.com/sagemath/sage/issues/502",
    "label": "https://github.com/sagemath/sage/labels/needs%20review",
    "label_color": "7fff00",
    "label_name": "needs review",
    "label_text_color": "ffffff",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sage/issues/502#event-3933"
}
```



---

archive/issue_events_003934.json:
```json
{
    "actor": "https://github.com/jdemeyer",
    "created_at": "2015-12-04T14:00:01Z",
    "event": "labeled",
    "issue": "https://github.com/sagemath/sage/issues/502",
    "label": "https://github.com/sagemath/sage/labels/positive%20review",
    "label_color": "dfffc0",
    "label_name": "positive review",
    "label_text_color": "ffffff",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sage/issues/502#event-3934"
}
```



---

archive/issue_comments_001852.json:
```json
{
    "body": "<a id='comment:7'>Comment 7:</a>\nReplying to [@kcrisman](#comment%3A3):\n> pexpect is now in version 2.3.  We appear to still have version 2.0 (? it's hard to tell, no obvious pexpect version command).  Anyway, might upgrading render this obsolete?\n\nJust for information: `pexpect` seems to become *slower* with every upgrade...",
    "created_at": "2015-12-04T14:00:41Z",
    "formatter": "markdown",
    "issue": "https://github.com/sagemath/sage/issues/502",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sage/issues/502#issuecomment-1852",
    "user": "https://github.com/jdemeyer"
}
```

<a id='comment:7'>Comment 7:</a>
Replying to [@kcrisman](#comment%3A3):
> pexpect is now in version 2.3.  We appear to still have version 2.0 (? it's hard to tell, no obvious pexpect version command).  Anyway, might upgrading render this obsolete?

Just for information: `pexpect` seems to become *slower* with every upgrade...



---

archive/issue_events_003935.json:
```json
{
    "actor": "https://github.com/vbraun",
    "created_at": "2015-12-04T22:12:33Z",
    "event": "labeled",
    "issue": "https://github.com/sagemath/sage/issues/502",
    "label": "https://github.com/sagemath/sage/labels/duplicate",
    "label_color": "a6a6a6",
    "label_name": "duplicate",
    "label_text_color": "ffffff",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sage/issues/502#event-3935"
}
```



---

archive/issue_events_003936.json:
```json
{
    "actor": "https://github.com/vbraun",
    "created_at": "2015-12-04T22:12:33Z",
    "event": "unlabeled",
    "issue": "https://github.com/sagemath/sage/issues/502",
    "label": "https://github.com/sagemath/sage/labels/positive%20review",
    "label_color": "dfffc0",
    "label_name": "positive review",
    "label_text_color": "ffffff",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sage/issues/502#event-3936"
}
```



---

archive/issue_events_003937.json:
```json
{
    "actor": "https://github.com/vbraun",
    "created_at": "2015-12-04T22:12:33Z",
    "event": "closed",
    "issue": "https://github.com/sagemath/sage/issues/502",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sage/issues/502#event-3937"
}
```
