# Issue 28557: memleak in poincare_birkhoff_witt

archive/issues_028557.json:
```json
{
    "body": "CC:  @tscrim\n\nThe method `product_on_basis` of `PoincareBirkhoffWittBasis` has `cached_method` decorator. When multiplying many large PBW elements, this causes serious memory usage.\n\nIn fact, clearing the cache or removing parent objects does not clear this memory, and there seems to be a memory leak. Removing the decorator fixes this problem.\n\nIssue created by migration from https://trac.sagemath.org/ticket/28794\n\n",
    "created_at": "2019-11-24T11:03:37Z",
    "labels": [
        "component: algebra"
    ],
    "milestone": "https://github.com/sagemath/sagetest/milestones/sage-duplicate/invalid/wontfix",
    "title": "memleak in poincare_birkhoff_witt",
    "type": "issue",
    "url": "https://github.com/sagemath/sagetest/issues/28557",
    "user": "https://github.com/RikVoorhaar"
}
```
CC:  @tscrim

The method `product_on_basis` of `PoincareBirkhoffWittBasis` has `cached_method` decorator. When multiplying many large PBW elements, this causes serious memory usage.

In fact, clearing the cache or removing parent objects does not clear this memory, and there seems to be a memory leak. Removing the decorator fixes this problem.

Issue created by migration from https://trac.sagemath.org/ticket/28794





---

archive/issue_comments_402785.json:
```json
{
    "body": "A reason you want the caching is for speed: It is a highly recursive procedure, so the caching speeds up multiplication (quite significantly IIRC). So I strongly do not want to remove the ``@`cached_method`. (As you probably know, there is often a trade-off made in code between memory and CPU cycles, and memory is usually relatively cheap compared to time.) Thus I am a very strong -1 on removing the decorator.\n\nWith that being said, if there is a memory leak, then there is a definite problem that needs to be solved. Clearing the cache should be something that frees the memory. I cannot think of any reference cycles, and this is a pattern that is used in many places in Sage. What will be helpful is to see what exactly you are trying to do and how you are measuring/seeing the memory leak.\n\nPS - I saw your paper on the arXiv and [code on github](https://github.com/RikVoorhaar/bgg-cohomology). It looks quite interesting. Hopefully we can get either some version of it merged into Sage or added as an external Sage package.",
    "created_at": "2019-11-27T00:31:50Z",
    "issue": "https://github.com/sagemath/sagetest/issues/28557",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/28557#issuecomment-402785",
    "user": "https://github.com/tscrim"
}
```

A reason you want the caching is for speed: It is a highly recursive procedure, so the caching speeds up multiplication (quite significantly IIRC). So I strongly do not want to remove the ``@`cached_method`. (As you probably know, there is often a trade-off made in code between memory and CPU cycles, and memory is usually relatively cheap compared to time.) Thus I am a very strong -1 on removing the decorator.

With that being said, if there is a memory leak, then there is a definite problem that needs to be solved. Clearing the cache should be something that frees the memory. I cannot think of any reference cycles, and this is a pattern that is used in many places in Sage. What will be helpful is to see what exactly you are trying to do and how you are measuring/seeing the memory leak.

PS - I saw your paper on the arXiv and [code on github](https://github.com/RikVoorhaar/bgg-cohomology). It looks quite interesting. Hopefully we can get either some version of it merged into Sage or added as an external Sage package.



---

archive/issue_comments_402786.json:
```json
{
    "body": "I saw only minor speedup with caching, it probably depends on the use case. \n\nI now tried to reproduce the memory leak, but I was unable. I suspect the following happened: During long computations the memory kept increasing, and to figure out why I actually interrupted the kernel (because I was too impatient for the computation to finish first). I noticed there were was a very large count of dictionary objects in memory. Using the following code I saw most of them were referenced by a `IndexedFreeAbelianMonoid_with_category.element_class`, or `PoincareBirkhoffWittBasis_with_category.element_class` and nothing else (a very short backreference chain. It seems when interrupting the kernel the cached things lose their reference to the cache, but otherwise stay alive. But one shouldn't interrupt the kernel during normal usage, so this isn't so bad.\n {{{#!python\nimport random\nimport objgraph\n\nobjgraph.show_backrefs(random.choice(objgraph.by_type('dict')))\n}}}\n\nWithout ``@`cached_method` I do see higher memory usage, even after calling `.clear_cache()` periodically. I'm not sure why, but this requires further investigation on my part. \n\nAlso it seems that the cache is particularly useful for monomials of low degree which are often looked up. High degree monomials need more memory to store and are only rarely looked up. Is it possible to selectively clear the cache only of monomials of high degree? I suppose one could access the cache directly, but I don't immediately see how. Something should have a `_cache__product_on_basis` property, but it's not the function `product_on_basis` itself. \n\nI would love to contribute some of my code to sage. I have some ideas of things I now know how to do that would be nice to add to sage. I would probably need some guidance on style and some of the inner workings of sage to do this properly.",
    "created_at": "2019-11-27T10:22:46Z",
    "issue": "https://github.com/sagemath/sagetest/issues/28557",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/28557#issuecomment-402786",
    "user": "https://github.com/RikVoorhaar"
}
```

I saw only minor speedup with caching, it probably depends on the use case. 

I now tried to reproduce the memory leak, but I was unable. I suspect the following happened: During long computations the memory kept increasing, and to figure out why I actually interrupted the kernel (because I was too impatient for the computation to finish first). I noticed there were was a very large count of dictionary objects in memory. Using the following code I saw most of them were referenced by a `IndexedFreeAbelianMonoid_with_category.element_class`, or `PoincareBirkhoffWittBasis_with_category.element_class` and nothing else (a very short backreference chain. It seems when interrupting the kernel the cached things lose their reference to the cache, but otherwise stay alive. But one shouldn't interrupt the kernel during normal usage, so this isn't so bad.
 {{{#!python
import random
import objgraph

objgraph.show_backrefs(random.choice(objgraph.by_type('dict')))
}}}

Without ``@`cached_method` I do see higher memory usage, even after calling `.clear_cache()` periodically. I'm not sure why, but this requires further investigation on my part. 

Also it seems that the cache is particularly useful for monomials of low degree which are often looked up. High degree monomials need more memory to store and are only rarely looked up. Is it possible to selectively clear the cache only of monomials of high degree? I suppose one could access the cache directly, but I don't immediately see how. Something should have a `_cache__product_on_basis` property, but it's not the function `product_on_basis` itself. 

I would love to contribute some of my code to sage. I have some ideas of things I now know how to do that would be nice to add to sage. I would probably need some guidance on style and some of the inner workings of sage to do this properly.



---

archive/issue_comments_402787.json:
```json
{
    "body": "Replying to [comment:2 gh-RikVoorhaar]:\n> I saw only minor speedup with caching, it probably depends on the use case. \n\nAs you indicated, doing things with larger monomials is likely to not benefit as much from the caching since you are creating and seeing more monomials than previous times.\n\n> I now tried to reproduce the memory leak, but I was unable. I suspect the following happened: During long computations the memory kept increasing, and to figure out why I actually interrupted the kernel (because I was too impatient for the computation to finish first).\n\nYea, I am not sure how much protections there are in ``@`cached_method` for interruptions. It may also be a difficult-to-impossible problem to solve in general too.\n\n> Without ``@`cached_method` I do see higher memory usage, even after calling `.clear_cache()` periodically. I'm not sure why, but this requires further investigation on my part. \n\nDepends on precisely how you are calling it. If you are calling it in a loop and still doing other computations, the Python gc might not have time to get around to the objects (or get to them quickly). I have found it useful to explicitly run `gc.collect()` (after an `import gc`) once done with a large object in memory. It is a bit slower, but clearing the memory is more important and can lead to better memory mapping later on (which ends up speeding things up too).\n\n> Also it seems that the cache is particularly useful for monomials of low degree which are often looked up. High degree monomials need more memory to store and are only rarely looked up. Is it possible to selectively clear the cache only of monomials of high degree? I suppose one could access the cache directly, but I don't immediately see how. Something should have a `_cache__product_on_basis` property, but it's not the function `product_on_basis` itself. \n\nYou would almost certainly need to implement a custom cache or get into the inner workings of the ``@`cache_function` decorator. However, the cutoff might be different for different people, and if you are talking about that, I would say you generally are experienced enough of a programmer to go in and quickly implement your own cache.\n\n> I would love to contribute some of my code to sage. I have some ideas of things I now know how to do that would be nice to add to sage. I would probably need some guidance on style and some of the inner workings of sage to do this properly. \n\nI am happy to help. Although from a quick glance it looks like you are rewriting a few things to heavily optimize them, so it might end up being best having your code as a separate (optional) package. However, there might be some parts that we can add in without causing them to slow down (too much) and fit the generality the framework in Sage might require.",
    "created_at": "2019-11-27T16:16:27Z",
    "issue": "https://github.com/sagemath/sagetest/issues/28557",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/28557#issuecomment-402787",
    "user": "https://github.com/tscrim"
}
```

Replying to [comment:2 gh-RikVoorhaar]:
> I saw only minor speedup with caching, it probably depends on the use case. 

As you indicated, doing things with larger monomials is likely to not benefit as much from the caching since you are creating and seeing more monomials than previous times.

> I now tried to reproduce the memory leak, but I was unable. I suspect the following happened: During long computations the memory kept increasing, and to figure out why I actually interrupted the kernel (because I was too impatient for the computation to finish first).

Yea, I am not sure how much protections there are in ``@`cached_method` for interruptions. It may also be a difficult-to-impossible problem to solve in general too.

> Without ``@`cached_method` I do see higher memory usage, even after calling `.clear_cache()` periodically. I'm not sure why, but this requires further investigation on my part. 

Depends on precisely how you are calling it. If you are calling it in a loop and still doing other computations, the Python gc might not have time to get around to the objects (or get to them quickly). I have found it useful to explicitly run `gc.collect()` (after an `import gc`) once done with a large object in memory. It is a bit slower, but clearing the memory is more important and can lead to better memory mapping later on (which ends up speeding things up too).

> Also it seems that the cache is particularly useful for monomials of low degree which are often looked up. High degree monomials need more memory to store and are only rarely looked up. Is it possible to selectively clear the cache only of monomials of high degree? I suppose one could access the cache directly, but I don't immediately see how. Something should have a `_cache__product_on_basis` property, but it's not the function `product_on_basis` itself. 

You would almost certainly need to implement a custom cache or get into the inner workings of the ``@`cache_function` decorator. However, the cutoff might be different for different people, and if you are talking about that, I would say you generally are experienced enough of a programmer to go in and quickly implement your own cache.

> I would love to contribute some of my code to sage. I have some ideas of things I now know how to do that would be nice to add to sage. I would probably need some guidance on style and some of the inner workings of sage to do this properly. 

I am happy to help. Although from a quick glance it looks like you are rewriting a few things to heavily optimize them, so it might end up being best having your code as a separate (optional) package. However, there might be some parts that we can add in without causing them to slow down (too much) and fit the generality the framework in Sage might require.



---

archive/issue_comments_402788.json:
```json
{
    "body": "Just a pointer for tracking memory leaks: see the code at #17360. Generally, run your code that leaks but shouldn't (e.g., include the cache clearing inside the test loop) and then look at the objects that have accumulated on the heap by type. That usually quickly gives a pointer to what the object is. A very likely culprit is that there's a `CachedRepresentation` object involved that is directly or indirectly referencing one of its construction parameters. That nullifies a weak referencing system that would normally allow such objects to be GC-ed. Hence, a pile-up of a certain type that happens to be `CachedRepresentation` would give a pretty strong indication to what's going wrong. Looking at the backrefs and forward refs of such objects usually gets you the culprit pretty quickly.",
    "created_at": "2019-11-27T19:12:05Z",
    "issue": "https://github.com/sagemath/sagetest/issues/28557",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/28557#issuecomment-402788",
    "user": "https://github.com/nbruin"
}
```

Just a pointer for tracking memory leaks: see the code at #17360. Generally, run your code that leaks but shouldn't (e.g., include the cache clearing inside the test loop) and then look at the objects that have accumulated on the heap by type. That usually quickly gives a pointer to what the object is. A very likely culprit is that there's a `CachedRepresentation` object involved that is directly or indirectly referencing one of its construction parameters. That nullifies a weak referencing system that would normally allow such objects to be GC-ed. Hence, a pile-up of a certain type that happens to be `CachedRepresentation` would give a pretty strong indication to what's going wrong. Looking at the backrefs and forward refs of such objects usually gets you the culprit pretty quickly.



---

archive/issue_comments_402789.json:
```json
{
    "body": "Replying to [comment:3 tscrim]:\n\n> \n> Depends on precisely how you are calling it. If you are calling it in a loop and still doing other computations, the Python gc might not have time to get around to the objects (or get to them quickly). I have found it useful to explicitly run `gc.collect()` (after an `import gc`) once done with a large object in memory. It is a bit slower, but clearing the memory is more important and can lead to better memory mapping later on (which ends up speeding things up too).\n\nThanks, I'll try that. \n\n> You would almost certainly need to implement a custom cache or get into the inner workings of the ``@`cache_function` decorator. However, the cutoff might be different for different people, and if you are talking about that, I would say you generally are experienced enough of a programmer to go in and quickly implement your own cache.\n\nYes implementing my own cache is easy, and I already did it in a number of places before I even figured out the ``@`cached_method` decorator exists. I was merely wondering if it would be possible to selectively clear the cache, since this would not require modifying the code of `poincare_birkhoff_witt`. Ultimately, including a slightly modified version of `poincare_birkhoff_witt` with my package seems the best option. \n\n\n> I am happy to help. Although from a quick glance it looks like you are rewriting a few things to heavily optimize them, so it might end up being best having your code as a separate (optional) package. However, there might be some parts that we can add in without causing them to slow down (too much) and fit the generality the framework in Sage might require.\n\n\nIndeed I tried making some things faster by implementening them myself. However the speedup of this only turned out to be minor, and I still have a bunch of code that should fit better in the general framework of sage. \n\nIn particular noticed there is very little code for Lie algebra representations in sagemath. I was thinking of contributing in this regard. Can I send you an email at some point with some of my ideas? Or is there particular place where I should put these kind of proposals?\n\nSince this ticket has gone very far off topic, and my issue turned out to be stupid, I guess this ticket should be closed, but I don't see how to do this.",
    "created_at": "2019-11-28T14:08:42Z",
    "issue": "https://github.com/sagemath/sagetest/issues/28557",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/28557#issuecomment-402789",
    "user": "https://github.com/RikVoorhaar"
}
```

Replying to [comment:3 tscrim]:

> 
> Depends on precisely how you are calling it. If you are calling it in a loop and still doing other computations, the Python gc might not have time to get around to the objects (or get to them quickly). I have found it useful to explicitly run `gc.collect()` (after an `import gc`) once done with a large object in memory. It is a bit slower, but clearing the memory is more important and can lead to better memory mapping later on (which ends up speeding things up too).

Thanks, I'll try that. 

> You would almost certainly need to implement a custom cache or get into the inner workings of the ``@`cache_function` decorator. However, the cutoff might be different for different people, and if you are talking about that, I would say you generally are experienced enough of a programmer to go in and quickly implement your own cache.

Yes implementing my own cache is easy, and I already did it in a number of places before I even figured out the ``@`cached_method` decorator exists. I was merely wondering if it would be possible to selectively clear the cache, since this would not require modifying the code of `poincare_birkhoff_witt`. Ultimately, including a slightly modified version of `poincare_birkhoff_witt` with my package seems the best option. 


> I am happy to help. Although from a quick glance it looks like you are rewriting a few things to heavily optimize them, so it might end up being best having your code as a separate (optional) package. However, there might be some parts that we can add in without causing them to slow down (too much) and fit the generality the framework in Sage might require.


Indeed I tried making some things faster by implementening them myself. However the speedup of this only turned out to be minor, and I still have a bunch of code that should fit better in the general framework of sage. 

In particular noticed there is very little code for Lie algebra representations in sagemath. I was thinking of contributing in this regard. Can I send you an email at some point with some of my ideas? Or is there particular place where I should put these kind of proposals?

Since this ticket has gone very far off topic, and my issue turned out to be stupid, I guess this ticket should be closed, but I don't see how to do this.



---

archive/issue_comments_402790.json:
```json
{
    "body": "Changing status from new to needs_review.",
    "created_at": "2019-11-29T00:02:38Z",
    "issue": "https://github.com/sagemath/sagetest/issues/28557",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/28557#issuecomment-402790",
    "user": "https://github.com/tscrim"
}
```

Changing status from new to needs_review.



---

archive/issue_comments_402791.json:
```json
{
    "body": "Replying to [comment:5 gh-RikVoorhaar]:\n> Replying to [comment:3 tscrim]:\n> > You would almost certainly need to implement a custom cache or get into the inner workings of the ``@`cache_function` decorator. However, the cutoff might be different for different people, and if you are talking about that, I would say you generally are experienced enough of a programmer to go in and quickly implement your own cache.\n> \n> Yes implementing my own cache is easy, and I already did it in a number of places before I even figured out the ``@`cached_method` decorator exists. I was merely wondering if it would be possible to selectively clear the cache, since this would not require modifying the code of `poincare_birkhoff_witt`. Ultimately, including a slightly modified version of `poincare_birkhoff_witt` with my package seems the best option. \n\nI looked into this. So you can just delete from the `Foo.bar.cache` dict object to clear objects from the cache I believe.\n\nThere are probably ways you can improve the multiplication to involve less indirection and temporary objects, both of which will get you some more speed.\n\n> > I am happy to help. Although from a quick glance it looks like you are rewriting a few things to heavily optimize them, so it might end up being best having your code as a separate (optional) package. However, there might be some parts that we can add in without causing them to slow down (too much) and fit the generality the framework in Sage might require.\n> \n> \n> Indeed I tried making some things faster by implementening them myself. However the speedup of this only turned out to be minor, and I still have a bunch of code that should fit better in the general framework of sage. \n\nAh, great. Then something I would suggest is thinking about how to break your current code into smaller parts to include piecemeal into Sage. This makes is easier to review and include in.\n\n> In particular noticed there is very little code for Lie algebra representations in sagemath. I was thinking of contributing in this regard. Can I send you an email at some point with some of my ideas? Or is there particular place where I should put these kind of proposals?\n\nThere is in general very little representation theory in Sage (something I am trying to improve bit by bit). So big +1 for getting more representations in. Feel free to email me at anytime (tcscrims|gmail), but you can always just make tickets with proposals/wishlists/etc. too and cc me.\n\n> Since this ticket has gone very far off topic, and my issue turned out to be stupid, I guess this ticket should be closed, but I don't see how to do this. \n\nSo this is what you would normally do to say the ticket can be closed. Then someone sets it to a positive review because they agree, and that is all you do.",
    "created_at": "2019-11-29T00:02:38Z",
    "issue": "https://github.com/sagemath/sagetest/issues/28557",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/28557#issuecomment-402791",
    "user": "https://github.com/tscrim"
}
```

Replying to [comment:5 gh-RikVoorhaar]:
> Replying to [comment:3 tscrim]:
> > You would almost certainly need to implement a custom cache or get into the inner workings of the ``@`cache_function` decorator. However, the cutoff might be different for different people, and if you are talking about that, I would say you generally are experienced enough of a programmer to go in and quickly implement your own cache.
> 
> Yes implementing my own cache is easy, and I already did it in a number of places before I even figured out the ``@`cached_method` decorator exists. I was merely wondering if it would be possible to selectively clear the cache, since this would not require modifying the code of `poincare_birkhoff_witt`. Ultimately, including a slightly modified version of `poincare_birkhoff_witt` with my package seems the best option. 

I looked into this. So you can just delete from the `Foo.bar.cache` dict object to clear objects from the cache I believe.

There are probably ways you can improve the multiplication to involve less indirection and temporary objects, both of which will get you some more speed.

> > I am happy to help. Although from a quick glance it looks like you are rewriting a few things to heavily optimize them, so it might end up being best having your code as a separate (optional) package. However, there might be some parts that we can add in without causing them to slow down (too much) and fit the generality the framework in Sage might require.
> 
> 
> Indeed I tried making some things faster by implementening them myself. However the speedup of this only turned out to be minor, and I still have a bunch of code that should fit better in the general framework of sage. 

Ah, great. Then something I would suggest is thinking about how to break your current code into smaller parts to include piecemeal into Sage. This makes is easier to review and include in.

> In particular noticed there is very little code for Lie algebra representations in sagemath. I was thinking of contributing in this regard. Can I send you an email at some point with some of my ideas? Or is there particular place where I should put these kind of proposals?

There is in general very little representation theory in Sage (something I am trying to improve bit by bit). So big +1 for getting more representations in. Feel free to email me at anytime (tcscrims|gmail), but you can always just make tickets with proposals/wishlists/etc. too and cc me.

> Since this ticket has gone very far off topic, and my issue turned out to be stupid, I guess this ticket should be closed, but I don't see how to do this. 

So this is what you would normally do to say the ticket can be closed. Then someone sets it to a positive review because they agree, and that is all you do.



---

archive/issue_comments_402792.json:
```json
{
    "body": "Changing status from needs_review to positive_review.",
    "created_at": "2019-12-09T02:32:18Z",
    "issue": "https://github.com/sagemath/sagetest/issues/28557",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/28557#issuecomment-402792",
    "user": "https://github.com/tscrim"
}
```

Changing status from needs_review to positive_review.



---

archive/issue_events_026422.json:
```json
{
    "actor": "@fchapoton",
    "created_at": "2019-12-09T07:55:59Z",
    "event": "closed",
    "issue": "https://github.com/sagemath/sagetest/issues/28557",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sagetest/issues/28557#event-26422"
}
```



---

archive/issue_comments_402793.json:
```json
{
    "body": "Resolution: invalid",
    "created_at": "2019-12-09T07:55:59Z",
    "issue": "https://github.com/sagemath/sagetest/issues/28557",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/28557#issuecomment-402793",
    "user": "https://github.com/fchapoton"
}
```

Resolution: invalid
