# Issue 13746: Sage-patchbot improvements

archive/issues_013746.json:
```json
{
    "body": "Assignee: mvngu\n\nCC:  @vbraun\n\nSpkg up at http://sage.math.washington.edu/home/robertwb/patches/patchbot-1.2.spkg Most notably, this adds:\n\n* Startup-time plugin.\n* Non-ascii plugin.\n* Spkg inspection.\n* Better redundancy avoidance.\n\nIssue created by migration from https://trac.sagemath.org/ticket/13950\n\n",
    "created_at": "2013-01-13T10:15:11Z",
    "labels": [
        "component: doctest"
    ],
    "milestone": "https://github.com/sagemath/sagetest/milestones/sage-5.7",
    "title": "Sage-patchbot improvements",
    "type": "issue",
    "url": "https://github.com/sagemath/sagetest/issues/13746",
    "user": "https://github.com/robertwb"
}
```
Assignee: mvngu

CC:  @vbraun

Spkg up at http://sage.math.washington.edu/home/robertwb/patches/patchbot-1.2.spkg Most notably, this adds:

* Startup-time plugin.
* Non-ascii plugin.
* Spkg inspection.
* Better redundancy avoidance.

Issue created by migration from https://trac.sagemath.org/ticket/13950





---

archive/issue_comments_170331.json:
```json
{
    "body": "Looks good to me!\n\nThe non-ascii plugin causes lots of false positives. It is fine to use non-ascii in thedocumentation if the correct coding was specified in the file. While non-ascii in the actual code would be wrong, of course. Though that can't be checked by looking at the patch only, but requires some actual understanding of the code...",
    "created_at": "2013-01-13T11:41:14Z",
    "issue": "https://github.com/sagemath/sagetest/issues/13746",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/13746#issuecomment-170331",
    "user": "https://github.com/vbraun"
}
```

Looks good to me!

The non-ascii plugin causes lots of false positives. It is fine to use non-ascii in thedocumentation if the correct coding was specified in the file. While non-ascii in the actual code would be wrong, of course. Though that can't be checked by looking at the patch only, but requires some actual understanding of the code...



---

archive/issue_comments_170332.json:
```json
{
    "body": "Is this ticket ready for review?",
    "created_at": "2013-01-13T11:59:57Z",
    "issue": "https://github.com/sagemath/sagetest/issues/13746",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/13746#issuecomment-170332",
    "user": "https://github.com/vbraun"
}
```

Is this ticket ready for review?



---

archive/issue_comments_170333.json:
```json
{
    "body": "OK, a couple more tweaks on spkg detection. Yeah, the non-ascii probably has some false-positives, but as we've seen it's better than false-negatives going in, and in any case the blue means \"check this out/are you sure you want to do this\" rather than \"this is a blocker.\" Thanks for looking at this (and running a patchbot!)",
    "created_at": "2013-01-15T06:45:04Z",
    "issue": "https://github.com/sagemath/sagetest/issues/13746",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/13746#issuecomment-170333",
    "user": "https://github.com/robertwb"
}
```

OK, a couple more tweaks on spkg detection. Yeah, the non-ascii probably has some false-positives, but as we've seen it's better than false-negatives going in, and in any case the blue means "check this out/are you sure you want to do this" rather than "this is a blocker." Thanks for looking at this (and running a patchbot!)



---

archive/issue_comments_170334.json:
```json
{
    "body": "Changing status from new to needs_review.",
    "created_at": "2013-01-15T06:45:04Z",
    "issue": "https://github.com/sagemath/sagetest/issues/13746",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/13746#issuecomment-170334",
    "user": "https://github.com/robertwb"
}
```

Changing status from new to needs_review.



---

archive/issue_comments_170335.json:
```json
{
    "body": "Looks good to me. Can you commit the change to the SPKG.txt?",
    "created_at": "2013-01-15T15:38:00Z",
    "issue": "https://github.com/sagemath/sagetest/issues/13746",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/13746#issuecomment-170335",
    "user": "https://github.com/vbraun"
}
```

Looks good to me. Can you commit the change to the SPKG.txt?



---

archive/issue_comments_170336.json:
```json
{
    "body": "I get this mysterious error:\n\n```\n[...]\n----------------------------------------------------------------------\nAll tests passed!\nTotal time for all tests: 814.2 seconds\nTests -- 814 seconds\n\nApply -- 19 seconds\nBuild -- 1 seconds\nplugins.commit_messages -- 0 seconds\nplugins.coverage -- 2 seconds\nplugins.non_ascii -- 0 seconds\nplugins.startup_time -- 52 seconds\nplugins.startup_modules -- 1 seconds\nTests -- 814 seconds\n2013-01-15 15:53:13 +0000\n890 seconds\nReporting 0 PluginFailed\n0 PluginFailed\nok\nDone reporting 0\n\n\n\nFailing tests in your install: PluginFailed. Continue anyways? [y/N] \n```\n",
    "created_at": "2013-01-15T18:12:09Z",
    "issue": "https://github.com/sagemath/sagetest/issues/13746",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/13746#issuecomment-170336",
    "user": "https://github.com/vbraun"
}
```

I get this mysterious error:

```
[...]
----------------------------------------------------------------------
All tests passed!
Total time for all tests: 814.2 seconds
Tests -- 814 seconds

Apply -- 19 seconds
Build -- 1 seconds
plugins.commit_messages -- 0 seconds
plugins.coverage -- 2 seconds
plugins.non_ascii -- 0 seconds
plugins.startup_time -- 52 seconds
plugins.startup_modules -- 1 seconds
Tests -- 814 seconds
2013-01-15 15:53:13 +0000
890 seconds
Reporting 0 PluginFailed
0 PluginFailed
ok
Done reporting 0



Failing tests in your install: PluginFailed. Continue anyways? [y/N] 
```




---

archive/issue_comments_170337.json:
```json
{
    "body": "OK, new spkg. \n\nIt looks like something happened on your system around `[..., 0.718256950378418, 0.7461650371551514, 0.8157329559326172, ...]`. I've changed it to be more aggressive about keeping only the lower timings and switch between ticket/pristine one more time.",
    "created_at": "2013-01-15T18:59:10Z",
    "issue": "https://github.com/sagemath/sagetest/issues/13746",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/13746#issuecomment-170337",
    "user": "https://github.com/robertwb"
}
```

OK, new spkg. 

It looks like something happened on your system around `[..., 0.718256950378418, 0.7461650371551514, 0.8157329559326172, ...]`. I've changed it to be more aggressive about keeping only the lower timings and switch between ticket/pristine one more time.



---

archive/issue_comments_170338.json:
```json
{
    "body": "I still got \"Reporting 0 PluginFailed\"....",
    "created_at": "2013-01-15T22:42:27Z",
    "issue": "https://github.com/sagemath/sagetest/issues/13746",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/13746#issuecomment-170338",
    "user": "https://github.com/vbraun"
}
```

I still got "Reporting 0 PluginFailed"....



---

archive/issue_comments_170339.json:
```json
{
    "body": "I am mystified. Here's the log\n\nhttp://patchbot.sagemath.org/log/0/Fedora/18/x86_64/3.7.2-201.fc18.x86_64/volker-desktop.stp.dias.ie/2013-01-15%2023:18:53%20+0000?plugin=plugins.startup_time\n\nThe timings are right there (and I even ignore the top 15, but that doesn't impact the results much here as there's little warm-up needed).\n\nWhat the patchbot did is\n\n\n```\nfor k in range(10):\n    os.system(\"sage -b 0\")\n    for n in range(8):\n        os.system(\"sage -c ''\")\n```\n\n\nand, with a high statistical significance, it took longer when k was even then when k was odd. Unless I'm completely off on the math here...\n\nAny ideas?",
    "created_at": "2013-01-16T00:05:09Z",
    "issue": "https://github.com/sagemath/sagetest/issues/13746",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/13746#issuecomment-170339",
    "user": "https://github.com/robertwb"
}
```

I am mystified. Here's the log

http://patchbot.sagemath.org/log/0/Fedora/18/x86_64/3.7.2-201.fc18.x86_64/volker-desktop.stp.dias.ie/2013-01-15%2023:18:53%20+0000?plugin=plugins.startup_time

The timings are right there (and I even ignore the top 15, but that doesn't impact the results much here as there's little warm-up needed).

What the patchbot did is


```
for k in range(10):
    os.system("sage -b 0")
    for n in range(8):
        os.system("sage -c ''")
```


and, with a high statistical significance, it took longer when k was even then when k was odd. Unless I'm completely off on the math here...

Any ideas?



---

archive/issue_comments_170340.json:
```json
{
    "body": "The even/odd values of k are main vs ticket?\n\n```\nMain:   0.65512 sec (25 samples, std_dev=0.00494)\nTicket: 0.65906 sec (25 samples, std_dev=0.00382)\n```\n\nJust eyeballing things, they are within one standard deviation. So Student-t is about 3. Which makes it pretty unlikely. \n\nI think its dangerous to remove the top 15 values here, though. It makes the distribution artificially narrower, which inflates the t-value. \n\nAlso, I was using the computer at the time and its possible that I did something that was periodic with the frequency of the tests. E.g. click on web links in a ~5 second rhythm. In other words, I'm not sure that it is valid to treat the samples as statistically independent. Its probably better to randomize which test counts as main and ticket for the startup.\n\n\n\n```\nWith 70% confidence, startup time increased by at least 0.5%\nWith 75% confidence, startup time increased by at least 0.47%\nWith 90% confidence, startup time increased by at least 0.36%\nWith 95% confidence, startup time increased by at least 0.29%\nWith 99% confidence, startup time increased by at least 0.17%\nWith 99.7% confidence, startup time increased by at least 0.1%\nWith 99.9% confidence, startup time increased by at least 0.035%\n```\n\nI'm a bit confused here. You can't be 100% sure that the startup time increased at all. Which statistical test is going on? (Yes I could read the source ;-)",
    "created_at": "2013-01-16T00:57:38Z",
    "issue": "https://github.com/sagemath/sagetest/issues/13746",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/13746#issuecomment-170340",
    "user": "https://github.com/vbraun"
}
```

The even/odd values of k are main vs ticket?

```
Main:   0.65512 sec (25 samples, std_dev=0.00494)
Ticket: 0.65906 sec (25 samples, std_dev=0.00382)
```

Just eyeballing things, they are within one standard deviation. So Student-t is about 3. Which makes it pretty unlikely. 

I think its dangerous to remove the top 15 values here, though. It makes the distribution artificially narrower, which inflates the t-value. 

Also, I was using the computer at the time and its possible that I did something that was periodic with the frequency of the tests. E.g. click on web links in a ~5 second rhythm. In other words, I'm not sure that it is valid to treat the samples as statistically independent. Its probably better to randomize which test counts as main and ticket for the startup.



```
With 70% confidence, startup time increased by at least 0.5%
With 75% confidence, startup time increased by at least 0.47%
With 90% confidence, startup time increased by at least 0.36%
With 95% confidence, startup time increased by at least 0.29%
With 99% confidence, startup time increased by at least 0.17%
With 99.7% confidence, startup time increased by at least 0.1%
With 99.9% confidence, startup time increased by at least 0.035%
```

I'm a bit confused here. You can't be 100% sure that the startup time increased at all. Which statistical test is going on? (Yes I could read the source ;-)



---

archive/issue_comments_170341.json:
```json
{
    "body": "Replying to [comment:10 vbraun]:\n> The even/odd values of k are main vs ticket?\n> {{{\n> Main:   0.65512 sec (25 samples, std_dev=0.00494)\n> Ticket: 0.65906 sec (25 samples, std_dev=0.00382)\n> }}}\n> Just eyeballing things, they are within one standard deviation. So Student-t is about 3. Which makes it pretty unlikely. \n>\n> I think its dangerous to remove the top 15 values here, though. It makes the distribution artificially narrower, which inflates the t-value. \n\nReally, what we're trying to do is estimate the minimum startup time, and cut out the possibility of some short-term activity messing up the timings. I'm open for other suggestions. \n\n> Also, I was using the computer at the time and its possible that I did something that was periodic with the frequency of the tests. E.g. click on web links in a ~5 second rhythm. In other words, I'm not sure that it is valid to treat the samples as statistically independent. Its probably better to randomize which test counts as main and ticket for the startup.\n\nI'd think it'd already be randomized based on when the test starts. I alternate back and forth to try to eliminate any bias, but I suppose this won't catch something periodic. \n\n> {{{\n> With 70% confidence, startup time increased by at least 0.5%\n> With 75% confidence, startup time increased by at least 0.47%\n> With 90% confidence, startup time increased by at least 0.36%\n> With 95% confidence, startup time increased by at least 0.29%\n> With 99% confidence, startup time increased by at least 0.17%\n> With 99.7% confidence, startup time increased by at least 0.1%\n> With 99.9% confidence, startup time increased by at least 0.035%\n> }}}\n> I'm a bit confused here. You can't be 100% sure that the startup time increased at all. Which statistical test is going on? (Yes I could read the source ;-)\n\nArgh, found the error: https://github.com/robertwb/sage-patchbot/blob/master/src/plugins.py#L244 I should be using variance, not standard deviation.  I'm using Welch's t-test (well, actually computing various confidence intervals around the observed mean.)\n\nThanks for taking a deeper look at this. Wonder why it never tripped up on my computer. Now I just hope we're doing enough samples to ever detect anything...",
    "created_at": "2013-01-16T02:07:56Z",
    "issue": "https://github.com/sagemath/sagetest/issues/13746",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/13746#issuecomment-170341",
    "user": "https://github.com/robertwb"
}
```

Replying to [comment:10 vbraun]:
> The even/odd values of k are main vs ticket?
> {{{
> Main:   0.65512 sec (25 samples, std_dev=0.00494)
> Ticket: 0.65906 sec (25 samples, std_dev=0.00382)
> }}}
> Just eyeballing things, they are within one standard deviation. So Student-t is about 3. Which makes it pretty unlikely. 
>
> I think its dangerous to remove the top 15 values here, though. It makes the distribution artificially narrower, which inflates the t-value. 

Really, what we're trying to do is estimate the minimum startup time, and cut out the possibility of some short-term activity messing up the timings. I'm open for other suggestions. 

> Also, I was using the computer at the time and its possible that I did something that was periodic with the frequency of the tests. E.g. click on web links in a ~5 second rhythm. In other words, I'm not sure that it is valid to treat the samples as statistically independent. Its probably better to randomize which test counts as main and ticket for the startup.

I'd think it'd already be randomized based on when the test starts. I alternate back and forth to try to eliminate any bias, but I suppose this won't catch something periodic. 

> {{{
> With 70% confidence, startup time increased by at least 0.5%
> With 75% confidence, startup time increased by at least 0.47%
> With 90% confidence, startup time increased by at least 0.36%
> With 95% confidence, startup time increased by at least 0.29%
> With 99% confidence, startup time increased by at least 0.17%
> With 99.7% confidence, startup time increased by at least 0.1%
> With 99.9% confidence, startup time increased by at least 0.035%
> }}}
> I'm a bit confused here. You can't be 100% sure that the startup time increased at all. Which statistical test is going on? (Yes I could read the source ;-)

Argh, found the error: https://github.com/robertwb/sage-patchbot/blob/master/src/plugins.py#L244 I should be using variance, not standard deviation.  I'm using Welch's t-test (well, actually computing various confidence intervals around the observed mean.)

Thanks for taking a deeper look at this. Wonder why it never tripped up on my computer. Now I just hope we're doing enough samples to ever detect anything...



---

archive/issue_comments_170342.json:
```json
{
    "body": "Welch t-test is appropriate, but I don't think this is right:\n\n```\nerr = math.sqrt(s1**2 * (n1-1) / n1 + s2**2 * (n2-1) / n2)\n```\n\nThe t-value should asymptotically be proportional to sqrt(n), so that more samples = more certain that the observed difference is actual effect (if sample means and stddevs remain unchanged).",
    "created_at": "2013-01-16T11:08:27Z",
    "issue": "https://github.com/sagemath/sagetest/issues/13746",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/13746#issuecomment-170342",
    "user": "https://github.com/vbraun"
}
```

Welch t-test is appropriate, but I don't think this is right:

```
err = math.sqrt(s1**2 * (n1-1) / n1 + s2**2 * (n2-1) / n2)
```

The t-value should asymptotically be proportional to sqrt(n), so that more samples = more certain that the observed difference is actual effect (if sample means and stddevs remain unchanged).



---

archive/issue_comments_170343.json:
```json
{
    "body": "Originally I had \n\n\n```\nerr = math.sqrt(s1**2 / n1 + s2**2 / n2)\n```\n\n\nwhich, after more thought (and actually looking it up) was correct, so I've changed it back. I've also changed it so that the number of runs on each branch varies, so as to avoid periodic issues. You're right about taking the max influencing the distribution, but it seems the simplest way to avoid one or two random actions on the system completely throwing things off.",
    "created_at": "2013-01-19T00:31:37Z",
    "issue": "https://github.com/sagemath/sagetest/issues/13746",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/13746#issuecomment-170343",
    "user": "https://github.com/robertwb"
}
```

Originally I had 


```
err = math.sqrt(s1**2 / n1 + s2**2 / n2)
```


which, after more thought (and actually looking it up) was correct, so I've changed it back. I've also changed it so that the number of runs on each branch varies, so as to avoid periodic issues. You're right about taking the max influencing the distribution, but it seems the simplest way to avoid one or two random actions on the system completely throwing things off.



---

archive/issue_comments_170344.json:
```json
{
    "body": "Aren't the large outliers (in one direction only!) a sign that the distribution is not normal? The standard technique to deal with that would be a non-parametric (=does not depend on actual values but only on comparison of samples) test, and in particular Wilcox rank-sum: http://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U You wouldn't have to change much, its just a different test statistic that you plug into the cumulative distribution function.",
    "created_at": "2013-01-19T12:35:42Z",
    "issue": "https://github.com/sagemath/sagetest/issues/13746",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/13746#issuecomment-170344",
    "user": "https://github.com/vbraun"
}
```

Aren't the large outliers (in one direction only!) a sign that the distribution is not normal? The standard technique to deal with that would be a non-parametric (=does not depend on actual values but only on comparison of samples) test, and in particular Wilcox rank-sum: http://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U You wouldn't have to change much, its just a different test statistic that you plug into the cumulative distribution function.



---

archive/issue_comments_170345.json:
```json
{
    "body": "Yes, that looks better suited, though for your data it still gives z=2.76 (!). Is there any way to get at the probability of the magnitude of the change (e.g. could I reject/accept the null hypothosis [x-0.001 for x in ticket_timings], or is this statistically unsound (I haven't taken stats since undergrad)).",
    "created_at": "2013-01-19T19:33:14Z",
    "issue": "https://github.com/sagemath/sagetest/issues/13746",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/13746#issuecomment-170345",
    "user": "https://github.com/robertwb"
}
```

Yes, that looks better suited, though for your data it still gives z=2.76 (!). Is there any way to get at the probability of the magnitude of the change (e.g. could I reject/accept the null hypothosis [x-0.001 for x in ticket_timings], or is this statistically unsound (I haven't taken stats since undergrad)).



---

archive/issue_comments_170346.json:
```json
{
    "body": "I think its perfectly fine to re-run the test with a shift in the timings to estimate the probability of a certain magnitude increase. \n\nOne of the hidden assumptions of the test is that the distribution, even though it is not normal, is at least the same for the two populations that you are comparing. Thats at least not changed by the constant shift.",
    "created_at": "2013-01-19T21:32:13Z",
    "issue": "https://github.com/sagemath/sagetest/issues/13746",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/13746#issuecomment-170346",
    "user": "https://github.com/vbraun"
}
```

I think its perfectly fine to re-run the test with a shift in the timings to estimate the probability of a certain magnitude increase. 

One of the hidden assumptions of the test is that the distribution, even though it is not normal, is at least the same for the two populations that you are comparing. Thats at least not changed by the constant shift.



---

archive/issue_comments_170347.json:
```json
{
    "body": "OK, I've implemented the Mann-Whitney U-test which seems to be a much better fit. PTAL.",
    "created_at": "2013-01-20T06:43:40Z",
    "issue": "https://github.com/sagemath/sagetest/issues/13746",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/13746#issuecomment-170347",
    "user": "https://github.com/robertwb"
}
```

OK, I've implemented the Mann-Whitney U-test which seems to be a much better fit. PTAL.



---

archive/issue_comments_170348.json:
```json
{
    "body": "Changing status from needs_review to positive_review.",
    "created_at": "2013-01-28T19:27:37Z",
    "issue": "https://github.com/sagemath/sagetest/issues/13746",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/13746#issuecomment-170348",
    "user": "https://github.com/vbraun"
}
```

Changing status from needs_review to positive_review.



---

archive/issue_comments_170349.json:
```json
{
    "body": "Sounds good to me!",
    "created_at": "2013-01-28T19:27:37Z",
    "issue": "https://github.com/sagemath/sagetest/issues/13746",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/13746#issuecomment-170349",
    "user": "https://github.com/vbraun"
}
```

Sounds good to me!



---

archive/issue_comments_170350.json:
```json
{
    "body": "Changing component from doctest to optional packages.",
    "created_at": "2013-01-29T07:45:34Z",
    "issue": "https://github.com/sagemath/sagetest/issues/13746",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/13746#issuecomment-170350",
    "user": "https://github.com/jdemeyer"
}
```

Changing component from doctest to optional packages.



---

archive/issue_comments_170351.json:
```json
{
    "body": "spkg on the servers is updated!",
    "created_at": "2013-01-30T16:30:45Z",
    "issue": "https://github.com/sagemath/sagetest/issues/13746",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/13746#issuecomment-170351",
    "user": "https://github.com/haraldschilly"
}
```

spkg on the servers is updated!



---

archive/issue_events_013588.json:
```json
{
    "actor": "https://github.com/jdemeyer",
    "created_at": "2013-01-30T16:35:22Z",
    "event": "closed",
    "issue": "https://github.com/sagemath/sagetest/issues/13746",
    "type": "issue_event",
    "url": "https://github.com/sagemath/sagetest/issues/13746#event-13588"
}
```



---

archive/issue_comments_170352.json:
```json
{
    "body": "Resolution: fixed",
    "created_at": "2013-01-30T16:35:22Z",
    "issue": "https://github.com/sagemath/sagetest/issues/13746",
    "type": "issue_comment",
    "url": "https://github.com/sagemath/sagetest/issues/13746#issuecomment-170352",
    "user": "https://github.com/jdemeyer"
}
```

Resolution: fixed
