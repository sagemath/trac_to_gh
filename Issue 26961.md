# Issue 26961: Fix overflow problems for extremely large meataxe matrices

Issue created by migration from https://trac.sagemath.org/ticket/27198

Original creator: SimonKing

Original creation time: 2019-02-01 13:09:23

As observed at #27152, extremely large MeatAxe matrices seem to be problematic in several regards.

```
sage: %time M = matrix(GF(243), 2^16, 2^16)
CPU times: user 7min 23s, sys: 1.06 s, total: 7min 24s
Wall time: 7min 25s
sage: M[0,0]
0
sage: M[2^16-1,0]
0
sage: M[2^16-1,2^16-1]
0
sage: M[2^16-1,2^16-1] = 123
sage: M[2^16-1,2^16-1]  # wrong
0
sage: pickle = dumps(M)
<segfault>
```



---

Comment by jdemeyer created at 2019-02-01 20:05:28

Note that the problems could be either in the Sage wrapper or it could also be upstream in (shared)meataxe.


---

Comment by SimonKing created at 2019-02-01 20:14:19

Replying to [comment:1 jdemeyer]:
> Note that the problems could be either in the Sage wrapper or it could also be upstream in (shared)meataxe.

Right. I've never actually worked with matrices that big, and it could very well be that there is some kind of overflow in SharedMeatAxe. But first, I'd like to see what is the smallest example exposing the wrong item access resp. the segfault, so that it doesn't take so long time (7 minutes) for each test run.


---

Comment by SimonKing created at 2019-02-01 20:22:37

Ouch, I am so stupid. I worked with a field of size `243=3^5` and was assigning the value `123`, which is divisible by 3 and thus zero. So, the item assignment probably is a non-issue.


---

Comment by SimonKing created at 2019-02-01 20:39:53

PS: I find it unlikely that the problem is upstrem. Both `__reduce__` and `mtx_unpickle` hardly call a meataxe library function. It's basically memcopy and pointer advancement. With one exception, though: The global variables `FfCurrentRowSize` and `FfCurrentRowSizeIo` are set by calling a library function. So, that could potentially go wrong upstream.

We'll see.


---

Comment by SimonKing created at 2019-02-01 20:51:36

Interestingly, allocating an empty matrix of only 1/4 of the size takes about the same time. Could that indicate a problem? Pickling of that smaller matrix fails, because Sage cannot allocate enough memory. But it doesn't crash:

```
sage: %time M = matrix(GF(243), 2^16-1, 2^16-1)
CPU times: user 7min 33s, sys: 809 ms, total: 7min 34s
Wall time: 7min 34s
sage: d = dumps(M)
---------------------------------------------------------------------------
MemoryError                               Traceback (most recent call last)
<ipython-input-2-aaf8f192cb1c> in <module>()
----> 1 d = dumps(M)

/home/king/Sage/git/py3/local/lib/python3.6/site-packages/sage/misc/persist.pyx in sage.misc.persist.dumps (build/cythonized/sage/misc/persist.c:4160)()
    281         picklejar(obj)
    282     try:
--> 283         return obj.dumps(compress)
    284     except (AttributeError, RuntimeError, TypeError):
    285         return _base_dumps(obj, compress=compress)

/home/king/Sage/git/py3/local/lib/python3.6/site-packages/sage/structure/sage_object.pyx in sage.structure.sage_object.SageObject.dumps (build/cythonized/sage/structure/sage_object.c:3638)()
    462         """
    463 
--> 464         return _base_dumps(self, compress=compress)
    465 
    466     #############################################################################

/home/king/Sage/git/py3/local/lib/python3.6/site-packages/sage/misc/persist.pyx in sage.misc.persist._base_dumps (build/cythonized/sage/misc/persist.c:3894)()
    254     """
    255 
--> 256     gherkin = SagePickler.dumps(obj)
    257 
    258     if compress:

/home/king/Sage/git/py3/local/lib/python3.6/site-packages/sage/misc/persist.pyx in sage.misc.persist.SagePickler.dumps (build/cythonized/sage/misc/persist.c:6609)()
    833         buf = io.BytesIO()
    834         pickler = cls(buf, **kwargs)
--> 835         pickler.dump(obj)
    836         return buf.getvalue()
    837 

/home/king/Sage/git/py3/local/lib/python3.6/site-packages/sage/matrix/matrix_gfpn_dense.pyx in sage.matrix.matrix_gfpn_dense.Matrix_gfpn_dense.__reduce__ (build/cythonized/sage/matrix/matrix_gfpn_dense.c:6122)()
    531             FfSetNoc(self.Data.Noc)
    532             pickle_size = FfCurrentRowSizeIo*self.Data.Nor
--> 533             d = <char*>check_malloc(pickle_size)
    534             p = self.Data.Data
    535             x = d

memory.pxd in cysignals.memory.check_malloc (build/cythonized/sage/matrix/matrix_gfpn_dense.c:17384)()

MemoryError: failed to allocate 18446744073709420545 bytes
```

I find the number of bytes-to-be-allocated interesting. It should allocate `pickle_size` bytes, and `pickle_size=FfCurrentRowSizeIo*self.Data.Nor`. We have `self.Data.Nor = 2^16-1`, and `FfCurrentRowSizeIo` should be the number of bytes needed to store one row. Since the field is relatively large, one item will be stored in a single byte, and thus I'd expect `FfCurrentRowSizeIo=2^16-1`.

Hence, the number of bytes to be allocated should be `4294836225 = (2<sup>16-1)</sup>2`, and that's far less than what the `__reduce__` method is trying to allocate.


---

Comment by jdemeyer created at 2019-02-01 20:57:24

Replying to [comment:6 SimonKing]:
> {{{
> MemoryError: failed to allocate 18446744073709420545 bytes
> }}}
> I find the number of bytes-to-be-allocated interesting.

Yes. As I mentioned already in #27152, there is an overflow in the line 

```
pickle_size = FfCurrentRowSizeIo*self.Data.Nor
```



---

Comment by SimonKing created at 2019-02-01 21:35:40

Replying to [comment:7 jdemeyer]:
> Yes. As I mentioned already in #27152, there is an overflow in the line 
> {{{
> pickle_size = FfCurrentRowSizeIo*self.Data.Nor
> }}}

Right, I thought I had fixed it by using `Py_ssize_t`, but just realise that that was in a different place.


---

Comment by SimonKing created at 2019-02-01 21:51:05

I don't understand what type I should use for pickle_size.

When using `Py_ssize_t`, I still get `failed to allocate 18446744073709420545 bytes`.


---

Comment by jdemeyer created at 2019-02-01 21:57:06

Replying to [comment:9 SimonKing]:
> When using `Py_ssize_t`, I still get `failed to allocate 18446744073709420545 bytes`.

The problem is not the assignment, the problem is the multiplication. You need to do something like

```
pickle_size = <Py_ssize_t>FfCurrentRowSizeIo * <Py_ssize_t>self.Data.Nor
```

(one of the two casts should be sufficient)


---

Comment by SimonKing created at 2019-02-01 21:59:40

Replying to [comment:10 jdemeyer]:
> Replying to [comment:9 SimonKing]:
> > When using `Py_ssize_t`, I still get `failed to allocate 18446744073709420545 bytes`.
> 
> The problem is not the assignment, the problem is the multiplication. You need to do something like
> {{{
> pickle_size = <Py_ssize_t>FfCurrentRowSizeIo * <Py_ssize_t>self.Data.Nor
> }}}
> (one of the two casts should be sufficient)

I see. Actually I figured something like that. Would it be ok to first assign `cdef Py_ssize_t pickle_size = FfCurrentRowSizeIo` and then later do `pickle_size *= self.Data.Nor`? That's what I am testing right now, but when you find that problematic, I could change it before posting a commit.


---

Comment by SimonKing created at 2019-02-01 22:51:37

Replying to [comment:11 SimonKing]:
> I see. Actually I figured something like that. Would it be ok to first assign `cdef Py_ssize_t pickle_size = FfCurrentRowSizeIo` and then later do `pickle_size *= self.Data.Nor`?

It works, but the size of data is so that my computer basically freezes.

Another question: The pickling does

```
            d = <char*>check_malloc(pickle_size)
            p = self.Data.Data
            x = d
            for i in range(self.Data.Nor):
                memcpy(x, p, FfCurrentRowSizeIo)
                sig_check()
                x += FfCurrentRowSizeIo
                FfStepPtr(&p)
```

which is basically copied from an upstream function that directly writes to a file (that's why pickling doesn't use that upstream function).

Then, it does

```
            pickle_str = PyBytes_FromStringAndSize(d, pickle_size)
            sig_free(d)
```


If I understand correctly, `PyBytes_FromStringAndSize` _copies_ `d`.

Wouldn't it be better to use the above loop to directly write into a Python `bytes` using cpython functions, rather than creating a `char*` temporarily? But how?


---

Comment by git created at 2019-02-02 20:31:17

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by SimonKing created at 2019-02-02 21:10:50

The segfault / overflow seems to be gone.


---

Comment by SimonKing created at 2019-02-02 21:10:50

Changing status from new to needs_review.


---

Comment by jdemeyer created at 2019-02-04 09:10:07

Replying to [comment:12 SimonKing]:
> Another question: The pickling does
> {{{
>             d = <char*>check_malloc(pickle_size)
>             p = self.Data.Data
>             x = d
>             for i in range(self.Data.Nor):
>                 memcpy(x, p, FfCurrentRowSizeIo)
>                 sig_check()
>                 x += FfCurrentRowSizeIo
>                 FfStepPtr(&p)
> }}}
> which is basically copied from an upstream function that directly writes to a file (that's why pickling doesn't use that upstream function).
> 
> Then, it does
> {{{
>             pickle_str = PyBytes_FromStringAndSize(d, pickle_size)
>             sig_free(d)
> }}}
> 
> If I understand correctly, `PyBytes_FromStringAndSize` _copies_ `d`.
> 
> Wouldn't it be better to use the above loop to directly write into a Python `bytes` using cpython functions, rather than creating a `char*` temporarily? But how?


```
cdef bytes pickle_bytes = PyBytes_FromStringAndSize(NULL, pickle_size)
cdef char* x = PyBytes_AS_STRING(pickle_bytes)
```

and then write into `x` as before and return `pickle_bytes` (which is a better name than `pickle_str`)


---

Comment by jdemeyer created at 2019-02-04 09:14:06

Replying to [comment:11 SimonKing]:
> Would it be ok to first assign `cdef Py_ssize_t pickle_size = FfCurrentRowSizeIo` and then later do `pickle_size *= self.Data.Nor`?

Technically, yes that would work. But I think it's worse in terms of understanding what the code does: what is the meaning (to a human) of `cdef Py_ssize_t pickle_size = FfCurrentRowSizeIo`?

It's fine for me if you use a different variable name:

```
cdef Py_ssize_t row_size = FfCurrentRowSizeIo
cdef Py_ssize_t pickle_size = row_size * self.Data.Nor
```



---

Comment by jdemeyer created at 2019-02-04 09:14:33

You have

```
pickle_str = PyBytes_FromStringAndSize(NULL, pickle_size)
```

twice. Why that?


---

Comment by SimonKing created at 2019-02-04 09:17:35

Replying to [comment:18 jdemeyer]:
> You have
> {{{
> pickle_str = PyBytes_FromStringAndSize(NULL, pickle_size)
> }}}
> twice. Why that?

Oops. Thanks for catching it.


---

Comment by jdemeyer created at 2019-02-04 09:19:57

Isn't this an unused variable?

```
nor = self.Data.Nor
```


For `pickled_rowsize`, I would also use `Py_ssize_t`.


---

Comment by git created at 2019-02-04 11:47:04

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by SimonKing created at 2019-02-04 11:48:23

The last commit addresses your comments. Also I deal with another potential overflow, namely

```diff
-            if <size_t>pickled_rowsize == FfCurrentRowSize:
-                memcpy(OUT.Data.Data, x, OUT.Data.RowSize*OUT.Data.Nor)
+            if pickled_rowsize == <Py_ssize_t>FfCurrentRowSize:
+                memcpy(OUT.Data.Data, x, <Py_ssize_t>OUT.Data.RowSize*<Py_ssize_t>OUT.Data.Nor)
```



---

Comment by embray created at 2019-03-25 10:56:15

Ticket retargeted after milestone closed (if you don't believe this ticket is appropriate for the Sage 8.8 release please retarget manually)


---

Comment by embray created at 2019-07-03 11:37:56

Moving tickets from the Sage 8.8 milestone that have been actively worked on in the last six months to the next release milestone (optimistically).


---

Comment by embray created at 2019-12-30 14:48:17

Ticket retargeted after milestone closed


---

Comment by chapoton created at 2020-01-02 19:52:11

red branch


---

Comment by chapoton created at 2020-01-02 19:52:11

Changing status from needs_review to needs_work.


---

Comment by SimonKing created at 2020-01-02 21:27:40

Sigh. I totally forgot about that ticket. Really unfortunate that the review wasn't finished.


---

Comment by git created at 2020-01-10 20:51:19

Branch pushed to git repo; I updated commit sha1. This was a forced push. New commits:


---

Comment by SimonKing created at 2020-01-10 20:52:39

Changing status from needs_work to needs_review.


---

Comment by SimonKing created at 2020-01-10 20:52:39

I hope I succeeded in rebasing the branch. Hopefully this time it doesn't start to bit rot.


---

Comment by tscrim created at 2020-01-14 16:45:32

The `_richcmp_` -> `_cmp_` change is backwards, so I think that needs to be reverted.

Also, why all the changes `size_t` -> `int`?


---

Comment by SimonKing created at 2020-01-14 16:49:57

Replying to [comment:30 tscrim]:
> The `_richcmp_` -> `_cmp_` change is backwards, so I think that needs to be reverted.

OK. I don't recall why this change was made (actually I don't recall THAT such change was made).

> Also, why all the changes `size_t` -> `int`?

I think it was an attempt to fix some compiler warnings concerning comparison of signed and unsigned types. Or it was because the original MeatAxe had int where it ought to be size_t, and I didn't change the types in my fork (yet), and I wanted to be consistent in the Sage wrapper. I don't recall which of the two reasons it was.


---

Comment by tscrim created at 2020-01-14 17:14:55

Replying to [comment:31 SimonKing]:
> Replying to [comment:30 tscrim]:
> > The `_richcmp_` -> `_cmp_` change is backwards, so I think that needs to be reverted.
> 
> OK. I don't recall why this change was made (actually I don't recall THAT such change was made).

My guess from the looks of it comes from a mistake during a merge.

> > Also, why all the changes `size_t` -> `int`?
> 
> I think it was an attempt to fix some compiler warnings concerning comparison of signed and unsigned types. Or it was because the original MeatAxe had int where it ought to be size_t, and I didn't change the types in my fork (yet), and I wanted to be consistent in the Sage wrapper. I don't recall which of the two reasons it was.

Okay. I just couldn't see anything in the comments about this, so I was curious. This change is good with me.


---

Comment by mkoeppe created at 2020-05-01 04:28:42

Moving tickets to milestone sage-9.2 based on a review of last modification date, branch status, and severity.


---

Comment by chapoton created at 2020-05-30 06:55:08

Changing status from needs_review to needs_work.


---

Comment by chapoton created at 2020-05-30 06:55:08

the wrong change from richcmp to cmp is still there


---

Comment by mkoeppe created at 2021-02-13 20:51:01

Setting new milestone based on a cursory review of ticket status, priority, and last modification date.


---

Comment by mkoeppe created at 2021-07-19 00:44:56

Setting a new milestone for this ticket based on a cursory review.
