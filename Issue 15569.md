# Issue 15569: Integrable representations of (affine) Kac-Moody Lie Algebras

Issue created by migration from https://trac.sagemath.org/ticket/15806

Original creator: bump

Original creation time: 2014-02-10 19:31:18

CC:  bump sage-combinat

Keywords: Kac-Moody

Integrable representations of Kac-Moody Lie algebras are parametrized by dominant weights. They satisfy a character formula which is a straightforward generalization of the Weyl character formula. See Kac, Infinite-dimensional Lie algebras, Chapter 10. The affine case is an important special case that was developed in connection with string theory. Since (in this affine case) generating functions for the weight dimensions may be modular forms there are all sorts of connections and it would be good to have this in Sage. It should be straighforward to write such code, and that is the purpose of this ticket.
I am unsure at this point whether to implement only the affine case or the general Kac-Moody case.


---

Comment by bump created at 2014-02-10 20:22:24

New commits:


---

Comment by bump created at 2014-02-10 20:24:32

Set assignee to bump.


---

Comment by tscrim created at 2014-02-10 23:51:47

Hey Dan,

I don't know how much of #14901 you might be able to use, but if you want to use parts of it here, let me know and I can split off the necessary portions.

Also I'd like to see the general Kac-Moody case if it's not too much more work.

Best,

Travis


---

Comment by tscrim created at 2014-02-10 23:52:08

Changing type from PLEASE CHANGE to enhancement.


---

Comment by bump created at 2014-02-11 01:09:41

Mainly what I need is the weight lattice and its invariant inner product. In the affine case, what is in `weight_lattice_realizations.py` is not what is needed because this describes the weight lattice for the derived Lie algebra. In other words, for type `['X',r,1]` the weight space that is currently available in Sage is r+1 dimensional, while the realization in Kac's book is r+2 dimensional, and this is what we need. It is not too hard to construct in the affine case. But is this in #14901?

I agree that it is very desirable to have the general KM case. Can your code compute the multiplicities of the imaginary roots?


---

Comment by tscrim created at 2014-02-11 15:56:55

There's currently the extended weight space:

```
sage: P = RootSystem(['A', 3, 1]).weight_space(extended=True)
sage: P.basis()
Finite family {0: Lambda[0], 1: Lambda[1], 2: Lambda[2], 3: Lambda[3], 'delta': delta}
sage: P.simple_root(2).scalar(P.simple_coroot(1))
-1
sage: P.simple_root(2).scalar(P.simple_coroot(2))
2
sage: P.simple_root(2).scalar(P.null_coroot())
0
sage: P.basis()['delta'].scalar(P.simple_coroot(0))
0
sage: P.basis()['delta'].scalar(P.simple_coroot(3))
0
sage: P.basis()['delta'].scalar(P.null_coroot())
0
```

and that doesn't that work?

In principle, my code can compute multiplicities of imaginary root space of the KM algebra (once I fix the finitely-presented Lie algebras).


---

Comment by bump created at 2014-02-11 18:47:05

The extended weight space should work. Thanks ...


---

Comment by git created at 2014-10-02 17:57:12

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by bump created at 2015-04-03 23:04:33

New commits:


---

Comment by git created at 2015-04-10 20:53:52

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2015-04-12 03:07:41

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by tscrim created at 2015-04-12 03:32:18

Okay, I've made some major optimization progress and now it takes half the time as previously. This was mainly achieved by being smart about the computation in `_freudenthal_accum` as to avoid doing multiple vector additions. The downside is this is also more obscure as code. I also did a bunch of other speedups on a smaller scale using little tricks I know and some timings.

I've also some cleanup of the code. In particular, I changed the interface so that `depth` is something passed to the `string` argument rather than as part of the representation's construction data.

The biggest thing I would want to be changed is that `dominant_maximal` should not need `string` to be called (with some reasonable depth) in order to be computed. Thus if this could be done as a stand-alone, we could cache this, and at the very least, it would mean one less call to `string` in `strings`.

I'm going to hack away at it a bit more tonight to see what other optimizations I might be able to get out of this.


---

Comment by git created at 2015-04-12 05:21:12

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by tscrim created at 2015-04-12 05:27:28

So I managed to get another 30% out of it by making sure the tuples all contain integers (it surprised me how much those little casts from `QQ` to `ZZ` added up) and a more cleaver implementation of `to_dominant` and removed the recurrence calls. Both parts resulted in equal gain.

I got a little bit more by taking advantage of the fact that roots are sometimes dense and directly storing and calling the inverse Cartan matrix. I also made the `inner_*q` methods private since they make some relatively strong assumptions.

I'm done for now. Could you test it to make sure everything still works and perhaps also see if you can get further than before?


---

Comment by git created at 2015-04-13 23:33:56

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by bump created at 2015-04-13 23:41:04

I pushed some mainly minor changes. I do an idea how things could be speeded up, which would be to use (Lambda+rho|Lambda+rho) - (mu+rho|mu+rho) as a hash function. This might be cheaper to compute than to_dominant(mu) and would almost determine m(mu).

I have something else I want to implement, which is the modular characteristic. At the moment I'm trying to implement something that could be called _inner_pp which might be relevant to #18034.


---

Comment by git created at 2015-04-14 20:12:10

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by bump created at 2015-04-14 20:19:22

With the last commit inner products are implemented for (x|y) in three cases: when x and y are both elements of the root lattice, when one is in the root lattice and the other in the weight lattice, and when both are in the weight lattice. This code could be moved to `root_lattice_realizations.py` and `weight_lattice_realizations.py` addressing the problem in #18034.


---

Comment by git created at 2015-04-15 02:09:58

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2015-04-16 00:56:17

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by bump created at 2015-04-16 01:01:05

Most of the objectives I had have been accomplished. There is just one problem, which is that the dominant_maximal method needs work. As implemented, the dominant maximal roots weights by just searching out of a suitably large set of roots. The algorithm is not guaranteed to be either correct or efficient. Instead, we should implement Proposition 12.6 of Kac (Infinite-dimensional Lie algebras) which says that the dominant integral weights are in bijection with the elements of the classical root lattice in a suitable dilation and translate of the fundamental alcove.


---

Comment by bump created at 2015-04-16 08:38:49

Continuing from previous comment:

Proposition 12.6 describes the dominant maximal weights as follows. They depend only on two things: the level `k` (currently implemented as `self.level()` and a coset of the weight lattice in the root lattice (called the class in KMPS). So different representations with the same level and class will have the same number of dominant maximal weights, and the same number of strings.

The weight lattice P has the classical weight lattice P0 of codimension two. It is obtained from P0 by adjoining Lambda[0] and the nullroot delta. The projection of the dominant maximal weights onto P0 has a simple description. Let F be the fundamental alcove, and let `k F` be the dilation of F by the level. So it is bounded by the innequalities `alphacheck[i] >= 0` for i nonzero, and `alphacheck[0] <= k`, where `alphacheck[0]` is the negative of the highest classical root.

Then the projections of the dominant maximal roots into P0 are just the elements of `k F` that are in the right coset of the root lattice. If these are known, then I don't think it will be difficult to recover the dominant maximal roots. I believe that only the method `dominant_maximal` needs to be reimplemented.


---

Comment by bump created at 2015-04-16 08:41:59

Changing keywords from "Kac-Moody" to "Kac-Moody, Integrable Representation, Affine Lie Algebra".


---

Comment by tscrim created at 2015-04-16 14:56:22

Here's some code which to get all weights in the `lvl`-dilated dominant chamber:

```
sage: P = RootSystem(['A',4,1]).weight_lattice(extended=True)
sage: La = P.fundamental_weights()
sage: lvl = 3
sage: def next_level(wt):
    return [wt + la for la in La if (wt+la).level() < lvl]
....: 
sage: R = RecursivelyEnumeratedSet([P.zero()], next_level)
sage: list(R)
[0,
 Lambda[2],
 Lambda[4],
 Lambda[1],
 Lambda[3],
 Lambda[0],
 Lambda[3] + Lambda[4],
 2*Lambda[0],
 Lambda[2] + Lambda[4],
 2*Lambda[1],
 Lambda[2] + Lambda[3],
 Lambda[1] + Lambda[2],
 Lambda[1] + Lambda[3],
 Lambda[1] + Lambda[4],
 2*Lambda[2],
 Lambda[0] + Lambda[4],
 Lambda[0] + Lambda[1],
 Lambda[0] + Lambda[3],
 Lambda[0] + Lambda[2],
 2*Lambda[4],
 2*Lambda[3]]
```

if you just want the classical fundamental weights, then do:

```
sage: La = [P.fundamental_weight(i) for i in P.index_set() if i != 0]
sage: R = RecursivelyEnumeratedSet([P.zero()], next_level)
sage: list(R)
[0,
 Lambda[2],
 Lambda[4],
 Lambda[1],
 Lambda[3],
 Lambda[3] + Lambda[4],
 Lambda[2] + Lambda[4],
 2*Lambda[1],
 Lambda[2] + Lambda[3],
 Lambda[1] + Lambda[2],
 Lambda[1] + Lambda[3],
 Lambda[1] + Lambda[4],
 2*Lambda[2],
 2*Lambda[4],
 2*Lambda[3]]
```

I'm not sure how to check if it's in the right coset off-hand.


---

Comment by bump created at 2015-04-17 11:44:03

> I'm not sure how to check if it's in the right coset off-hand.

This is how I think it goes. Add a multiple of Lambda[0] to give it the right level.
Then apply `from_weight`. If it does not give integers, discard. Then subtract the
smallest multiple of delta that makes `(Lambda+rho|Lambda+rho)-(mu+rho|mu+rho)`
positive.

I will try to implement this using `RecursivelyEnumeratedSet` as you suggest.


---

Comment by git created at 2015-04-17 17:42:39

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by bump created at 2015-04-17 17:47:50

I pushed some code creating a new method `dommax` which is intended to substitute for `dominant_maximal`. I think it is correct and if it tests out OK I'll rename it `dominant_maximal` and retire the old function. At this point I think the status of the patch will be `needs_review`. Thanks Travis for suggesting `RecursivelyEnumeratedSet`.


---

Comment by git created at 2015-04-18 15:11:19

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2015-04-18 15:24:58

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by bump created at 2015-04-18 15:26:46

I have replaced the `dominant_maximal` method as outlined above (after fixing a bug). I am not changing the status of the patch to `needs_review` yet because I still need to write doctests for a few methods, most importantly the modular characteristic.


---

Comment by git created at 2015-04-19 21:24:32

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2015-04-20 19:35:32

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by bump created at 2015-04-20 19:36:45

Changing status from new to needs_review.


---

Comment by git created at 2015-04-21 00:19:31

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2015-04-21 02:44:16

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by bump created at 2015-04-21 02:55:05

I added the branching rule from `["X", r, 1]` to ["X", r].

There is one branching rule for every node in the extended Dynkin diagram. The rule corresponding to the affine node was not too hard to add, so I added it.


---

Comment by git created at 2015-04-22 13:29:30

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2015-04-22 16:19:24

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2015-04-22 20:05:54

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by bump created at 2015-04-22 20:27:31

I think everything I wanted to implement is now implemented.
Here is a link to the reference manual documentation for this patch.

http://sporadic.stanford.edu/reference/combinat/sage/combinat/root_system/integrable_representations.html


---

Comment by git created at 2015-04-22 20:50:45

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2015-04-22 22:18:43

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2015-04-24 01:28:04

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by tscrim created at 2015-04-24 01:36:47

I added doctests to get full coverage, along with some other tweaks and fixes that I wanted to do. I changed the string representation to remove the "the" to follow Sage's conventions:

```
sage: ZZ
Integer Ring
sage: QQ
Rational Field
```

I also changed the output of `strings` to be a `dict` and implemented `print_strings` to have the formatted printing of the strings you previously had. I also removed the `rho` and `null_root` methods since you can get those from the weight lattice (where they are cached).

However, what notation do you want for the representation, as I believe are using V<sub>\Lambda</sub> and B(\Lambda)?


---

Comment by bump created at 2015-04-24 04:11:06

>However, what notation do you want for the representation, as I believe are using V\Lambda and B(\Lambda)?

Not sure I understand the question.

The following takes a long time but is sort of cool:


```
sage: Lambda = RootSystem("E8~").weight_lattice(extended=true).fundamental_weights()
sage: gdim = [x.degree() for x in IntegrableRepresentation(Lambda[0]).branch(depth=4)]
sage: gdim
[1, 248, 4124, 34752, 213126]
sage: oeis(gdim)
0: A007245: McKay-Thompson series of class 3C for the Monster group.
```



---

Comment by bump created at 2015-04-24 04:56:15

> However, what notation do you want for the representation, as I believe are using V\Lambda and B(\Lambda)?

The letter v is used in the doc but perhaps this should be changed.


---

Comment by bump created at 2015-04-24 13:39:29

In the example from comment:57 the coefficients are actually those from the cube root of j.


```
sage: R.<q>=PowerSeriesRing(QQ)
sage: j = j_invariant_qexp(5); j
q^-1 + 744 + 196884*q + 21493760*q^2 + 864299970*q^3 + 20245856256*q^4 + O(q^5)
sage: j.parent()
Laurent Series Ring in q over Rational Field
sage: q=j.parent().gen()
sage: exp(R(q*j).log()/3)
1 + 248*q + 4124*q^2 + 34752*q^3 + 213126*q^4 + 1057504*q^5 + O(q^6)
```


Playing around with oeis gives occasional interpretations of characters and string functions.


```
sage: Lambda = RootSystem("A1~").weight_lattice(extended=true).fundamental_weights()
sage: V = IntegrableRepresentation(Lambda[0])
sage: [x.degree() for x in V.branch(depth=10)]
[1, 3, 4, 7, 13, 19, 29, 43, 62, 90, 126]
sage: oeis(_)
0: A029552: Expansion of phi(x) / f(-x) in powers of x where phi(), f() are Ramanujan 
theta functions.
sage: V.string(Lambda[0])
[1, 1, 2, 3, 5, 7, 11, 15, 22, 30, 42, 56]
sage: oeis(_)
0: A000041: a(n) = number of partitions of n (the partition numbers).
```

Kac and Peterson showed in general that the string functions and characters have modular interpretation


---

Comment by git created at 2015-04-24 17:24:52

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2015-04-24 18:20:32

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2015-04-24 19:21:38

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2015-04-24 19:26:52

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2015-04-24 23:05:57

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2015-04-25 14:03:27

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2015-04-26 13:43:39

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by tscrim created at 2015-04-28 18:07:11

From our discussion on Friday, my testing, and the patchbot, I'm ready to set this to positive review as we can make the possible cache speedup on a follow-up ticket. Are there any more changes you want to make before then?


---

Comment by bump created at 2015-04-28 20:08:17

I tried the hash trick, and it seemed slower.

So I have no more changes I want to make at this time.


---

Comment by tscrim created at 2015-04-28 20:38:20

Then let's get this into Sage.


---

Comment by tscrim created at 2015-04-28 20:38:20

Changing status from needs_review to positive_review.


---

Comment by vbraun created at 2015-04-29 03:13:47

Resolution: fixed


---

Comment by jdemeyer created at 2016-09-01 08:42:30

In #20686, I will mark `TestSuite(V).run()` as `# known bug` because `IntegrableRepresentation` does not properly implement everything needed for its category. For example, it does not implement `zero()`.

These problems were not seen before simply because the category tests were not run. #20686 ensures that the correct tests are run, but then they fail for `IntegrableRepresentation`.


---

Comment by jdemeyer created at 2016-09-01 08:51:57

See #21387.
