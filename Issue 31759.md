# Issue 31759: Efficient Integration on Riemann Surfaces

Issue created by migration from https://trac.sagemath.org/ticket/31996

Original creator: @DisneyHogg

Original creation time: 2021-06-17 16:36:55

CC:  nbruin




---

Comment by @DisneyHogg created at 2021-06-17 16:47:56

Changing type from PLEASE CHANGE to enhancement.


---

Comment by @DisneyHogg created at 2021-06-17 16:47:56

Changing component from PLEASE CHANGE to algebraic geometry.


---

Comment by @DisneyHogg created at 2021-06-17 16:47:56

Set assignee to @DisneyHogg.


---

Comment by git created at 2021-06-24 08:35:38

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2021-06-25 18:12:12

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by @DisneyHogg created at 2021-06-25 18:12:53

Changing status from new to needs_review.


---

Comment by git created at 2021-06-27 16:00:01

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by nbruin created at 2021-06-30 23:47:00

As an example of a curve "from the wild" (well, it's still constructed, but it was encountered somewhere else, and apart from rational bitangents it probably doesn't have particular properties that are relevant for its periods):

```
P2.<X,Y,Z>=ProjectiveSpace(QQ,2)
f=X^4 - 2*X^3*Y + 5*X^2*Y^2 + 4*X*Y^3 + Y^4 + 2*X^3*Z - 5*X^2*Y*Z - 9*X*Y^2*Z - 6*Y^3*Z - 3*X^2*Z^2 - X*Y*Z^2 + 7*Y^2*Z^2 + 6*Y*Z^3 + Z^4
C=Curve(f)
S1=C.riemann_surface(prec=500,integration_method="heuristic")
S2=C.riemann_surface(prec=500,integration_method="rigorous")
```

The first one completes about 76 seconds, doing (according to prun) 41627 function evaluations. Interestingly enough, there are 49 line_integral calls and 67 calls to integrate_vector_N, indicating that the interval splitting is very modest in this case, but as you can see, has great effect.

The second one completes in 554 seconds, doing (according to prun) 121052 function evaluations. A large part of that difference is probably computing integration nodes (based on the evaluations, we'd expect about three times the run time).

So, I think this code is a big improvement, and I'm expecting that we can turn to "rigorous" as our default strategy.

**EDIT**: as pointed out in #9, the numbers are swapped. `S1` takes longer, with more evaluations and `S2` takes less time, with less evaluations.


---

Comment by @DisneyHogg created at 2021-07-01 09:29:14

Replying to [comment:9 nbruin]:

> The first one completes about 76 seconds, doing (according to prun) 41627 function evaluations. Interestingly enough, there are 49 line_integral calls and 67 calls to integrate_vector_N, indicating that the interval splitting is very modest in this case, but as you can see, has great effect.
> 
> The second one completes in 554 seconds, doing (according to prun) 121052 function evaluations. A large part of that difference is probably computing integration nodes (based on the evaluations, we'd expect about three times the run time).
> 
I think you have the two cases reversed, on my machine I get that `S1.period_matrix()` takes about 387s with 121052 function calls, while `S2.period_matrix()` takes 53s with 41627 function calls.


---

Comment by git created at 2021-07-02 12:24:33

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by nbruin created at 2021-07-08 04:02:52

Branch needs rebasing (note that #30698 is merged now).


---

Comment by nbruin created at 2021-07-08 04:02:52

Changing status from needs_review to needs_work.


---

Comment by mkoeppe created at 2021-07-19 00:44:56

Setting a new milestone for this ticket based on a cursory review.


---

Comment by git created at 2021-07-30 11:13:16

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by @DisneyHogg created at 2021-07-30 11:14:40

Branch rebased


---

Comment by @DisneyHogg created at 2021-07-30 11:14:40

Changing status from needs_work to needs_review.


---

Comment by nbruin created at 2021-08-12 22:46:20

Changing status from needs_review to needs_work.


---

Comment by nbruin created at 2021-08-12 22:46:20

In my tests it seems the "heuristic" method is still faster for low precisions and "easy" integration paths. As one increases the precision, it seems that "rigorous" starts to win out.

I think in the introduction documentation of the module, you'll have to add a section explaining what the different integration methods do and briefly explain what the benefits and draw-backs of the methods are.

Otherwise, the present code looks pretty good!

----------------------
line 1519, _bounding_data:

Perhaps describe the input and output a little more unambgiously. Introducing notation may help:

for input:
 - differentials are specified as by `cohomology_basis`.

Output is a tuple (Rzw, [(g, dgdz, F, a0_info), ...]) where:
 - Rzw is a polynomial in z and w over the base ring of the defining equation
 - the list has a tuple for each differential, in order
 - g is a rational function in the quotient field of the parent of the defining polynomial of the curve such that
   g dz represents the differential
 - dgdz is the derivative of g with respect to z, but now represented in Rzw
 - F is the minimal polynomial of g over z (represented as a bivariate polynomial in z and g
 - a0_info is a tuple (a0L, [r,...]) where describing the leading coefficient of F in g (which is itself a polynomial in z):
   a0L is its leading coefficient (as a complex number) and the r is a list of the roots, listed with multiplicity.

Note the awkward description of g. Perhaps put it in Rzw instead.

To illustrate the names used (and the fact that we're forcing the names z,w,g for the variables here), perhaps use x,y in the example instead, so that the difference is visible.
Also, perhaps display S.cohomology_basis() so that it's clearer what the relation is with the data given here. You should probably explain that the "1" given there stands for 1/(df/dw), as the output shows.

line 1577 rigorous_line_integral:

The reference "Developed by Gao" needs adjustment. Perhaps describe: bounding an algebraic integrand on a circular domain using Cauchy's form of the remainder in Taylor approximation combined with Fujiwara's bound on algebraic functions. (see [Bruin-DisneyHogg-Gau, in preparation] ) or something like that.

Certainly "Gao" is an entirely unhelpful reference :-)

line 1619: allow for tolerance on the numerical output here. Also note that the labelling of the upstairs edge is entirely arbitrary, so this doctest is liable to break in the future.
(there are other tests in this file like that and it's probably hard to fix this).

line 1629: I think you can comment more positively here: the reason to make `differentials` available separately is so that a fast-callable version can be supplied, which
speeds up the evaluation of the integrands significantly. This is also why the differentials are all represented relative to the same denominator (df/dw).

line 1646: "it's" -> "its"

line 1659: float literals can be tricky: in library code they will be actual python "float" objects. "0.5" is explicitly representable, so it's fine here. The 0.912 is probably approximate anyway, so it doesn't matter.
 
line 1672: can you put a comment in that explains what this loop does? i.e., cover the line segment along which we'll be integrating with ellipses inscribed in circles that avoid branch points? and that the loop continues to bisect the line segments until each fits in such an ellipse?


---

Comment by nbruin created at 2021-08-12 23:18:36

Wow. I tried some random examples. For hyperelliptic curves it seems heuristic (for low precisions) is often faster than than rigorous. Exchanging the roles of x, y for those generally leads to very high degree covers, which I guess is not so good for Fujiwara, so that didn't seem to be such a great thing to do for rigorous either.

However, when we more to general plane curves (a quartic here):

```
f = -3*y^4 + 3*y^3*x + 2*y^2*x^2 + 4*y*x^3 - 4*x^4 - y^3 - 4*y^2*x + 2*y*x^2 + x^3 - 3*y^2 - 2*y*x + x^2 - 4*x + 4
```

the results become quite striking!

```
%time B=Sh.riemann_matrix()  # heuristic
CPU times: user 1min 11s, sys: 1.06 ms, total: 1min 11s
Wall time: 1min 11s

%time B = Sr.riemann_matrix()  # rigorous
CPU times: user 5.67 s, sys: 4.99 ms, total: 5.68 s
Wall time: 5.71 s
```

This timing is with a warmed-up cache for integration nodes: the first run took more than 2 minutes.

For hyperelliptic curves one shouldn't be using this code anyway, so I think "rigorous" might actually be a better default setting.


---

Comment by git created at 2021-08-13 15:25:45

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2021-08-13 15:35:30

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by @DisneyHogg created at 2021-08-13 15:36:15

Changing status from needs_work to needs_review.


---

Comment by @DisneyHogg created at 2021-08-13 15:36:15

Documentation issues raised by nbruin in comment 16 dealt with.


---

Comment by nbruin created at 2021-08-14 00:00:00

We're getting there! Some knock-on corrections:

Line 400: "approximately half" -- that's only the case if the two methods eventually use about the same number of nodes to compute the answer they return. It's not what I observed for lower precisions. I didn't particularly see the overhead of computing the bounds for N show up in the profiles either.

Line 1696: "howver" -> "however"

Line 1751: "Neu2018": reference markup

Line 1760: "more reliable faster" -> "more reliable and faster"


---

Comment by git created at 2021-08-14 00:19:13

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by nbruin created at 2021-08-15 19:49:46

... and "practuce" -> "practice" (just introduced)


---

Comment by git created at 2021-08-15 20:56:15

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by nbruin created at 2021-08-15 23:04:31

Great!


---

Comment by nbruin created at 2021-08-15 23:04:31

Changing status from needs_review to positive_review.


---

Comment by slelievre created at 2021-08-16 00:05:46

A space after `#` for all code comments and
commented-out code lines would be nice.


---

Comment by git created at 2021-08-16 08:34:23

Changing status from positive_review to needs_review.


---

Comment by git created at 2021-08-16 08:34:23

Branch pushed to git repo; I updated commit sha1 and set ticket back to needs_review. New commits:


---

Comment by slelievre created at 2021-08-17 09:49:46

Some more polishing, if you don't mind.

Please use two spaces before `#` for inline comments.

Both in example blocks for `# random` and `# abs tol`, etc.,
and for regular code such as:

```diff
-        KP = PolynomialRing(k, 'W') # W->fraction field
+        KP = PolynomialRing(k, 'W')  # W -> fraction field
```


In the `_bounding_data` docstring's OUTPUT block,
add a blank line before the itemized list.

Consider using comprehension syntax here:

```diff
-        integral_dict = dict()
-        for upstairs_edge in occurring_edges:
-            integral_dict[upstairs_edge] = line_int(upstairs_edge)
+        integral_dict = {edge: line_int(edge)
+                         for edge in occurring_edges}
```


Comparison operators `==`, `!=`, `<`, `<=`, `>`, `>=`
want a space on each side. Here:

```diff
-        if integration_method=="heuristic":
+        if integration_method == "heuristic":
             line_int = lambda edge: self.simple_vector_line_integral(edge,fcd)
-        elif integration_method=="rigorous":
+        elif integration_method == "rigorous":
```



---

Comment by git created at 2021-08-17 10:55:24

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by git created at 2021-08-17 10:57:50

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by nbruin created at 2021-08-17 17:41:29

Or just run the code through [black](https://github.com/psf/black) and be done with it.


---

Comment by slelievre created at 2021-08-17 22:45:11

Running this command based on the current branch:

```
$ ./sage --tox -- src/sage/schemes/riemann_surfaces/riemann_surface.py
```

gives one failing doctest:

```
Using --optional=4ti2,build,dochtml,fricas,homebrew,latte_int,lidia,pip,sage,sage_spkg
Doctesting 1 file using 4 threads.
sage -t --random-seed=0 sage/schemes/riemann_surfaces/riemann_surface.py
**********************************************************************
File "sage/schemes/riemann_surfaces/riemann_surface.py", line 1939, in sage.schemes.riemann_surfaces.riemann_surface.RiemannSurface.period_matrix
Failed example:
    (RM_S - rm).norm() < (RM_T - rm).norm()
Expected:
    True
Got:
    False
**********************************************************************
1 item had failures:
   1 of  18 in sage.schemes.riemann_surfaces.riemann_surface.RiemannSurface.period_matrix
    [360 tests, 1 failure, 30.62 s]
----------------------------------------------------------------------
sage -t --random-seed=0 sage/schemes/riemann_surfaces/riemann_surface.py  # 1 doctest failed
----------------------------------------------------------------------
Total time for all tests: 30.8 seconds
    cpu time: 24.9 seconds
    cumulative wall time: 30.6 seconds
```

and reports three typos:

```
sage/schemes/riemann_surfaces/riemann_surface.py:352: specifing ==> specifying
sage/schemes/riemann_surfaces/riemann_surface.py:1709: requierd ==> required
sage/schemes/riemann_surfaces/riemann_surface.py:1720: funcions ==> functions
```



---

Comment by slelievre created at 2021-08-17 22:49:19

This line can now be removed.


```diff
-        integral_dict = dict()
         integral_dict = {edge: line_int(edge) for edge in occurring_edges}
```


PEP 8 recommends putting operators
(such as `+` or `or`) after a line break:

- https://www.python.org/dev/peps/pep-0008/#should-a-line-break-before-or-after-a-binary-operator

in case you want to change this block and similar ones:


```diff
-                        if ((a_in_arg < b_in_arg < a_out_arg) or
-                                (b_in_arg < a_out_arg < a_in_arg) or
-                                (a_out_arg < a_in_arg < b_in_arg)):
+                        if ((a_in_arg < b_in_arg < a_out_arg)
+                            or (b_in_arg < a_out_arg < a_in_arg)
+                            or (a_out_arg < a_in_arg < b_in_arg)):
```


Sorry for holding the ticket with minor things,
feel free to set back to positive review at any point.


---

Comment by nbruin created at 2021-08-18 02:18:10

Replying to [comment:32 slelievre]:
> Running this command based on the current branch:
> {{{
> $ ./sage --tox -- src/sage/schemes/riemann_surfaces/riemann_surface.py
> }}}
Oh boy, thanks for checking this. When I checked https://patchbot.sagemath.org/ticket/31996/ I noticed the yellow question mark and saw the red "x" for non-ascii output (which is no issue) and thought *that* was why the yellow question mark was yellow. But there are actually tests failing! Yes, the file should pass its doctests! I don't know what the 'tox' option does, but with a plain `sage -t src/sage/schemes/riemann_surfaces/riemann_surface.py` you should be getting a passing result. Failing doctests definitely needs work.

(it may still be that some bot gives failing results, but in that case one just needs to double-check that the bot is malconfigured)


---

Comment by nbruin created at 2021-08-18 02:18:10

Changing status from needs_review to needs_work.


---

Comment by git created at 2021-08-18 09:51:28

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by slelievre created at 2021-08-18 09:53:26

Running tests with `--long` seems adequate
as some tests are marked long. I tried

```
$ sage -t --long src/sage/schemes/riemann_surfaces/riemann_surface.py
```

which trips on `%time` (apparently that is
a syntax error in doctests) and fails on

```
File "src/sage/schemes/riemann_surfaces/riemann_surface.py", line 1939, in
sage.schemes.riemann_surfaces.riemann_surface.RiemannSurface.period_matrix
Failed example:
    (RM_S - rm).norm() < (RM_T - rm).norm()
Expected:
    True
Got:
    False
```



---

Comment by @DisneyHogg created at 2021-08-18 10:15:11

Replying to [comment:36 slelievre]: I cannot run `./sage --tox -- src/sage/schemes/riemann_surface/riemann_surface.py` on my machine, it raises an IsADirectoryError which I don't understand:

```
Traceback (most recent call last):
  File "/usr/bin/tox", line 11, in <module>
    load_entry_point('tox==2.5.0', 'console_scripts', 'tox')()
  File "/usr/lib/python3/dist-packages/tox/session.py", line 38, in main
    config = prepare(args)
  File "/usr/lib/python3/dist-packages/tox/session.py", line 26, in prepare
    config = parseconfig(args)
  File "/usr/lib/python3/dist-packages/tox/config.py", line 239, in parseconfig
    parseini(config, inipath)
  File "/usr/lib/python3/dist-packages/tox/config.py", line 657, in __init__
    self._cfg = py.iniconfig.IniConfig(config.toxinipath)
  File "/usr/lib/python3/dist-packages/py/_vendored_packages/iniconfig.py", line 52, in __init__
    f = open(self.path)
IsADirectoryError: [Errno 21] Is a directory: '/home/s1504632/sage/src'
```


What I can do is cd into src, and run `tox -- sage/schemes/riemann_surfaces/riemann_surface.py`, which runs with all tests passed (though it did pick up the typos before I fixed those). Indeed, running the test leading to `(RM_S - rm).norm() < (RM_T - rm).norm()` manually in the command line interface or in a notebok succeeds for me. Running `-t --long` does raise error for the `%time` syntax too, which I will edit, but still doesn't fail on the period matrix test. 

What are your system details? Perhaps that will be illuminating, as I don't know enough about the lint badges to know how to use them to diagnose a problem.


---

Comment by git created at 2021-08-18 10:27:38

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by slelievre created at 2021-08-18 12:58:31

Replying to [comment:37 gh-DisneyHogg]:
> 
> What are your system details?

So far I tested on macOS 10.14.6 with
lots of packages installed via Homebrew.

If I find time I can also test on Cygwin,
Debian and Ubuntu (and more via tox).


---

Comment by @DisneyHogg created at 2021-08-18 14:19:32

Replying to [comment:39 slelievre]:
> So far I tested on macOS 10.14.6 with
> lots of packages installed via Homebrew.
Ok, I am using Ubuntu 18.04.04, so it's possible that this is a system issue, I think I should be able to test on a macOS so will try and check that. 

Replying to [comment:34 nbruin]: 
What system are you using, and were/are you able to try running the test with tox?


---

Comment by nbruin created at 2021-08-18 14:20:25

Replying to [comment:36 slelievre]:
> Running tests with `--long` seems adequate
> as some tests are marked long. I tried
> {{{
> $ sage -t --long src/sage/schemes/riemann_surfaces/riemann_surface.py
> }}}
> which trips on `%time` (apparently that is
> a syntax error in doctests)
Indeed it is, because it's line magic in IPython, which isn't active during doctesting (indeed, the doctest environment, while it pretends to test sage input, isn't identical to the actual interactive environment, so you may need to adjust code for doctests a bit so that it executes correctly).

In this case, `time` is hard to access, because it's entirely wrapped up in `IPython`s environment. Closest thing is `timeit`, which is available as a function in sage. So then to display times one can do:

```
        sage: A2.<x,y>=QQ[]
        sage: C=Curve(y^2-x^4-1)
        sage: S=C.riemann_surface()
        sage: timeit("S.period_matrix()", number=1, repeat=1)
```

The statement gets executed in a local scope, so normal assignments wouldn't capture the return value. In this case, the period_matrix is available for cheap afterwards thanks to caching. In general, something like

```
sage: L=[None]
sage: timeit("L[0]=expensive_result()", number=1, repeat=1)
sage: L[0]
```

might be required if capturing the returned object is desired.


---

Comment by nbruin created at 2021-08-18 14:25:38

Replying to [comment:40 gh-DisneyHogg]:
> What system are you using, and were/are you able to try running the test with tox? 
Fedora. I don't know what tox is. Testing with sage's doctesting tools should be sufficient. Irregularities between architectures are always a pain. I think you need to see the MacOS output to check what MacOS is doing differently (choosing different integration paths?). Results from MPFR shouldn't depend on hardware: it's directly based on integer arithmetic, so it's completely shielded from hardware float peculiarities.


---

Comment by @DisneyHogg created at 2021-08-19 22:32:13

Replying to [comment:39 slelievre]:
> So far I tested on macOS 10.14.6 with
> lots of packages installed via Homebrew.
As an update, I have just tested on macOS 11.5.2, running from a conda environment to do most of the package installs. This test also fails there, so I will investigate what is going on.


---

Comment by @DisneyHogg created at 2021-08-20 11:17:54

Running the test and printing output gets 

```
sage: (RM_S-rm).norm()
1.1102230246251565e-16
sage: (RM_T-rm).norm()
2.482534153247273e-16
```

on my Linux machine, whereas on my Mac it gets 

```
sage: (RM_S-rm).norm()
1.1102230246251565e-16
sage: (RM_T-rm).norm()
1.1102230246251565e-16
```

We thus know the problem is not something within the `rigorous` method, but something a little more fundamental with floats. Comparing over a range of precisions shows that in general the two machines give answers that differ by a value in the range of `RealField(prec)(2)**(-prec)` (it may be helpful to note that when `prec=53`, this expression is `1.110223024625156e-16`). As such I'd suggest removing the test to show that the rigorous method is more accurate for this value of `prec`, as in general even on the Linux machine this test would fail if the precision was increased, for example. 

```
sage: f = y^2-x^3+1
sage: p = 200
sage: Sh = RiemannSurface(f, prec=p, integration_method='heuristic')
sage: Sr = RiemannSurface(f, prec=p, integration_method='rigorous')
sage: Rh = Sh.riemann_matrix()
sage: Rr = Sr.riemann_matrix()
sage: (Rh-Rr).norm()
4.186105399376987e-60
sage: rm = (-1+I*sqrt(3))/2
sage: (Rr-rm).norm()
1.1102230246251565e-16
sage: (Rh-rm).norm()
1.1102230246251565e-16
sage: (Rr-rm).norm()<(Rh-rm).norm()
False
```

The fact that, at this higher precision, both methods of calculating the Riemann matrix still have an error of about `RealField(53)(2)**(-53)` suggests to me that there is another source of error in the module, and that this should be its own ticket.


---

Comment by git created at 2021-08-20 11:20:28

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by nbruin created at 2021-08-21 08:29:41

Replying to [comment:44 gh-DisneyHogg]:
> The fact that, at this higher precision, both methods of calculating the Riemann matrix still have an error of about `RealField(53)(2)**(-53)` suggests to me that there is another source of error in the module, and that this should be its own ticket. 

No, the problem is in how the doctest is formulated:

```
sage: rm=(-1+I*sqrt(3))/2
sage: M=matrix(1,1,[rm.n(200)])
sage: (M-rm).norm()
1.1102230246251565e-16
```

The problem is that `rm` lives in the symbolic ring. `M` is a float matrix with high precision, because the precision is explicitly requested. When you construct `M-rm` you get a matrix over the symbolic ring. Apparently `norm` then asks for a numerical result, to standard precision [no precision is requested] and apparently, `rm` computed to 53 bits does not agree with `rm` computered to 200 bits and then rounded to 53 bits. In fact:

```
sage: (M-rm).norm().parent()
Real Double Field
```

so we did end up with system floats ... which are a little more susceptible to architecture-dependent peculiarities. They shouldn't be if they are properly IEEE ...


---

Comment by slelievre created at 2021-08-21 09:34:27

About tox: it is a powerful tool for testing.

It can help build and test Sage in various
operating systems via Docker:

- [Sage 9.1 release tour > Portability > For developers](https://wiki.sagemath.org/ReleaseTours/sage-9.1#For_developers)

The `sage --tox` option runs the tests and a few extra
tools to check code style and spelling.

- [Sage 9.2 release tour > Testing and linting with tox](https://wiki.sagemath.org/ReleaseTours/sage-9.2#Testing_and_linting_with_tox)
- [Sage 9.3 release tour > Cleaning of the Sage codebase to conform to best practices](https://wiki.sagemath.org/ReleaseTours/sage-9.3#Cleaning_of_the_Sage_codebase_to_conform_to_best_practices)


---

Comment by slelievre created at 2021-08-21 09:34:34

Comparing accuracy can be a different ticket,
if you want to set back to needs_review.


---

Comment by @DisneyHogg created at 2021-08-21 11:14:09

Replying to [comment:46 nbruin]:
> No, the problem is in how the doctest is formulated:
> {{{
> sage: rm=(-1+I*sqrt(3))/2
> sage: M=matrix(1,1,[rm.n(200)])
> sage: (M-rm).norm()
> 1.1102230246251565e-16
> }}}
> The problem is that `rm` lives in the symbolic ring. `M` is a float matrix with high precision, because the precision is explicitly requested. When you construct `M-rm` you get a matrix over the symbolic ring. Apparently `norm` then asks for a numerical result, to standard precision [no precision is requested] and apparently, `rm` computed to 53 bits does not agree with `rm` computered to 200 bits and then rounded to 53 bits. 
Ah brilliant spot, thanks! Instead defining `rm = ComplexField(p)((-1+I*sqrt(3))/2)` fixes this results for the Riemann matrices.


---

Comment by @DisneyHogg created at 2021-08-21 11:14:17

Changing status from needs_work to needs_review.


---

Comment by nbruin created at 2021-08-21 16:12:10

Replying to [comment:49 gh-DisneyHogg]:
> Ah brilliant spot, thanks! Instead defining `rm = ComplexField(p)((-1+I*sqrt(3))/2)` fixes this results for the Riemann matrices. 

The problem is actually a little more fundamental: `norm` is implemented in an unsuitable way, at least for the 2-norm, which is the default: It converts to CDF or RDF, so it ignores precision completely! So it's not just matrices over the symbolic ring that suffer from this problem (although, as you noticed above, if your matrix has all itsentries tiny, then `RDF` may perform a little better because ... these numbers are floats.

Perhaps a measure like `max(abs(c) for c in M.list())` is a better way of measuring how far a matrix is from being a zero matrix [making sure that M has the accuracy and precision desired of course]

It looks like you're now just removing the doctest. It may sound a bit paranoid, but if you do that, you have to very clearly state what's wrong with the removed test. A failing test can point at a mistaken assumption somewhere, and testing on different OS-es and architectures can uncover these problems. So just removing the test is often not the right response: it's often an opportunity to uncover previously undiagnosed bad edge cases or assumptions.

Once you've identified what is going wrong on OSX, can you amend the test to hold by testing what you want to test in a more robust way? It looks useful to compare the methods with a known result somewhere and detecting changes in precision with which the example is computed seems like something useful.

Note that you want to protect your code against at some point becoming completely dysfunctional due to changes in behaviour elsewhere in the system. If you don't test your routines for some sanity somewhere, your code will most likely (almost certainly) break in the future and not be noticed doing so. The test looks like a good canary in a coalmine to me. Just make sure the canary isn't already dead :-).


---

Comment by @DisneyHogg created at 2021-08-22 10:56:45

Replying to [comment:51 nbruin]:
> It looks like you're now just removing the doctest. It may sound a bit paranoid, but if you do that, you have to very clearly state what's wrong with the removed test. A failing test can point at a mistaken assumption somewhere, and testing on different OS-es and architectures can uncover these problems. So just removing the test is often not the right response: it's often an opportunity to uncover previously undiagnosed bad edge cases or assumptions.

In this case, the test actually has no mathematical reason to be true, as even though both method are aiming for the same error bound, due to rounding in the number of nodes used in each method, neither of them will be expect to achieve this bound exactly, and so by how much this is overshot will depend on the rounding. Indeed running the test with curve given by `f=y<sup>2-x</sup>4-1` and precision 300 instead, the output is false on my Linux machine. I had initially written the test purely to demonstrate that the speed of the rigorous routine does not necessarily come at the expense of slightly less accuracy. As such I think we can safely say that this test isn't the right one. 

> Once you've identified what is going wrong on OSX, can you amend the test to hold by testing what you want to test in a more robust way? It looks useful to compare the methods with a known result somewhere and detecting changes in precision with which the example is computed seems like something useful.

As mentioned in comments 44 and 48, I think this should perhaps be a separate ticket, as the differences between OSX and other systems is present even in the original Riemann surfaces. I will be unable to work on OSX for a week, but I have created such a ticket as #32409.


---

Comment by nbruin created at 2021-08-24 03:06:00

Changing status from needs_review to positive_review.


---

Comment by nbruin created at 2021-08-24 03:06:00

Back to positive then!


---

Comment by vbraun created at 2021-08-30 21:22:17

Changing status from positive_review to needs_work.


---

Comment by vbraun created at 2021-08-30 21:22:17

The abs tol must be on the first line:

```
**********************************************************************
File "src/sage/schemes/riemann_surfaces/riemann_surface.py", line 1687, in sage.schemes.riemann_surfaces.riemann_surface.RiemannSurface.rigorous_line_integral
Failed example:
    S.rigorous_line_integral([(0,0), (1,0)], differentials, 
                             bounding_data)  # abs tol 1e-10
Expected:
    (1.80277751848459e-16 - 0.352971844594760*I)
Got:
    (1.94516164135444e-16 - 0.352971844594760*I)
**********************************************************************
1 item had failures:
   1 of   9 in sage.schemes.riemann_surfaces.riemann_surface.RiemannSurface.rigorous_line_integral
    [373 tests, 1 failure, 47.34 s]
----------------------------------------------------------------------
sage -t --long --random-seed=0 src/sage/schemes/riemann_surfaces/riemann_surface.py  # 1 doctest failed
----------------------------------------------------------------------
```



---

Comment by git created at 2021-08-31 10:09:36

Branch pushed to git repo; I updated commit sha1. New commits:


---

Comment by nbruin created at 2021-09-01 03:51:59

Yes, exceeding line length because the doctest system requires things to be on one line is a very valid thing! Let's try again with positive review (it's almost a good idea to change a few "non-significant" digits in doctest output with tolerance, so that you test if the tolerance is actually taken into account)


---

Comment by nbruin created at 2021-09-01 03:51:59

Changing status from needs_work to positive_review.


---

Comment by @DisneyHogg created at 2021-09-03 15:06:10

There might be an error on line 1796, that the code should be 

```diff
-    N_required = ((64*M/(15*(1-1/expr)*E_global)).log()/(2*expr.log())).ceil()
+    N_required = ((64*M/(15*(1-expr**(-2))*E_global)).log()/(2*expr.log())).ceil()
```

This is from the different between the exp(-r) and exp(-2r) in equations 3.11 and 3.25 of http://oops.uni-oldenburg.de/3607/1/neueff18.pdf ([Neu2018]). This would only have the effect of making `N_required` smaller, meaning the code isn't currently inaccurate, but perhaps slightly less optimised. I can't currently decipher where the change occurs in the text, perhaps someone can see this?


---

Comment by nbruin created at 2021-09-03 17:24:55

In [Trefethen, 2008] equation (4.14) is
`|I-I_n|\leq \frac{64 M}{15(1-\rho<sup>{-2})\rho</sup>{2n+2}`
which is attributed to [P. Rabinowitz, Rough and ready error estimates in Gaussian integration of analytic functions, Comm. ACM, 12 (1969), pp. 268–270.: Equation 18] and [H. Brass, Quadraturverfahren, 1977: Theorem 90]. The Rabinowitz reference is readily available.

I don't think there is a contradiction between (3.11) and (3.25): it looks like (3.25) receives some more advanced arguments. It's certainly not claimed to be derived from (3.11) directly. It may be worth checking if the extra +2 in Trefethen's version gives a further improvement (and if it's correct!)


---

Comment by vbraun created at 2021-09-05 21:38:56

Resolution: fixed


---

Comment by @DisneyHogg created at 2021-09-08 14:03:45

Replying to [comment:58 nbruin]:
> In [Trefethen, 2008] equation (4.14) is
> `|I-I_n|\leq \frac{64 M}{15(1-\rho<sup>{-2})\rho</sup>{2n+2}`
> which is attributed to [P. Rabinowitz, Rough and ready error estimates in Gaussian integration of analytic functions, Comm. ACM, 12 (1969), pp. 268–270.: Equation 18] and [H. Brass, Quadraturverfahren, 1977: Theorem 90]. The Rabinowitz reference is readily available.
> 
> I don't think there is a contradiction between (3.11) and (3.25): it looks like (3.25) receives some more advanced arguments. It's certainly not claimed to be derived from (3.11) directly. It may be worth checking if the extra +2 in Trefethen's version gives a further improvement (and if it's correct!)

Trefethen is using a modification of equation (19) from Rabinowitz, which I have checked and get the same answer, so there is the room for this modification (which, now that this ticket is closed, I will add on to #32297). You are right the equations don't follow directly, hence the reason the factors are not identical.
